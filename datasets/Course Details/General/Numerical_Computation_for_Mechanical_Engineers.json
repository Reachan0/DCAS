{
  "course_name": "Numerical Computation for Mechanical Engineers",
  "course_description": "This class introduces elementary programming concepts including variable types, data structures, and flow control. After an introduction to linear algebra and probability, it covers numerical methods relevant to mechanical engineering, including approximation (interpolation, least squares and statistical regression), integration, solution of linear and nonlinear equations, ordinary differential equations, and deterministic and probabilistic approaches. Examples are drawn from mechanical engineering disciplines, in particular from robotics, dynamics, and structural analysis. Assignments require MATLAB® programming.",
  "topics": [
    "Engineering",
    "Mechanical Engineering",
    "Systems Engineering",
    "Numerical Simulation",
    "Mathematics",
    "Differential Equations",
    "Linear Algebra",
    "Probability and Statistics",
    "Engineering",
    "Mechanical Engineering",
    "Systems Engineering",
    "Numerical Simulation",
    "Mathematics",
    "Differential Equations",
    "Linear Algebra",
    "Probability and Statistics"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nRecitation / labs: 1 session / week, 3 hours / session\n\nRelated Courses\n\nPrerequisites:\n2.001 Mechanics and Materials I\n,\n2.003J Dynamics and Control I\n\nCo-requisite:\n2.005 Thermal-Fluids Engineering I\n\nThis course is geared toward undergraduate students. A more advanced graduate-level treatment can be found in\n16.920J/2.097J/6.339J Numerical Methods for Partial Differential Equations\n.\n\nSoftware\n\nThis course is based on MATLAB(r). MIT students can run MATLAB on their own laptops, or use the shared Athena machines in the class recitation/lab room.\n\nCourse Objectives\n\nKnowledge\n\nAn understanding (in some cases review) of the mathematical ingredients on which numerical methods are based: calculus; probability; linear algebra; and differential equations.\n\nAn understanding of the basic \"canon\" of numerical approaches and numerical methods relevant to MechE: To what problems does an approach or method apply? How does the method work? What are the limitations and pros/cons? What can go wrong? What are the sources of error and uncertainty?\n\nAn understanding of elementary programming concepts and of the basic MATLAB architecture/environment, data types, syntax, and mathematical/numerical routines.\n\nSkills\n\nThe ability to formulate an engineering problem in a mathematical form appropriate for subsequent computational treatment and to choose an appropriate numerical approach.\n\nThe ability to select, test, and use (or reject) third-party numerical programs with confidence.\n\nThe ability to solve mechanical engineering problems by computational approaches through a combination of\nad hoc\nMATLAB scripts (typically rather short) and validated and informed calls to MATLAB or third-party numerical routines.\n\nAttitudes and Professional Values\n\nA commitment to always provide with any numerical prediction or recommendation some indication of error and uncertainty--and associated engineering implications--due to numerical treatment (and modeling error, however the latter is the emphasis of other MechE subjects).\n\nCourse Delivery\n\nThe course delivery includes lectures, recitations, reading assignments from the textbook\nMath, Numerics, and Programming (for Mechanical Engineers)\n, problem sets, quizzes, and MATLAB exercises. These elements are summarized in the class\ncalendar\n.\n\nLectures will comprise motivation/engineering demonstrations, blackboard review of key concepts, animations of numerical techniques, and examples of MATLAB implementations. The lectures will emphasize the math and numerics, but also the connection to MATLAB programming.\n\nRecitations will comprise mini-lectures on MATLAB topics, programming of the assigned MATLAB exercises, and discussion of the problem sets. The recitations will emphasize MATLAB programming, but with connection to the math and numerics.\n\nReading assignments will be provided at the beginning of each Unit.\n\nThe problem sets will include \"theory,\" formulation, implementation (MATLAB), and interpretation and assessment. The write-up of each problem set should be succinct but should clearly answer all questions and, as necessary, show all supporting work and evidence. MATLAB programs associated with the problem set should not be submitted\nunless specifically requested in a question\nbut should be kept on file until the end of the semester (after final subject grades are assigned).\n\nThe quizzes will cover the math, numerics, and programming concepts explicitly covered in lectures, recitations, assigned MATLAB exercises, and problems sets; a detailed study guide will be provided prior to each quiz. Quizzes will take place during the usual lecture period but will typically be less than the full 1.5 hours (the remainder of the period to be devoted to lecture/new material).\n\nThe MATLAB exercises for each recitation will be distributed prior to recitation. Students should review these exercises and even sketch the necessary MATLAB programs prior to recitation in order to make good progress during recitation. On the due date (Monday of the following week with exceptions for holidays) by 5 PM students should upload to the course website a folder containing the completed scripts and functions for the assignment. All of the scripts should be in a single file, with each script preceded by a comment line which indicates the exercise number; each function .m file should contain a comment line which indicates the exercise number.\n\nAssessment\n\nAssessment is based on three components: five problem sets, four (in-class) quizzes, and the cumulative MATLAB exercises for the entire semester.\n\nCOURSEWORK\n\nGRADING WEIGHTS\n\nProblem sets 1-3 and 5\n\n(200/19)% each\n\nProblem Set 4\n\n(400/19)%\n\nFour quizzes\n\n(125/19)% each\n\nCumulative MATLAB exercises\n\n(200/19)%\n\nNote the preponderance of MATLAB exercises will be during the first month of the semester.\n\nPolicy on Collaboration\n\nStudents may discuss all class material and assignments at length with one another, including derivations and code. But there can be no written transcript, no code transfer, and no electronic record whatsoever of a session: upon terminating a discussion, the blackboard must be erased, the paper recycled, the screen cleared, and all files deleted; any take-away must be exclusively in each student's own head. Students choosing to collaborate must list their collaborators in the header of their submitted assignments.",
  "files": [
    {
      "category": "Resource",
      "title": "MATLAB® Exercises 1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-086-numerical-computation-for-mechanical-engineers-fall-2012/3c7854eaaa89dcdcbd38fa7639049a94_MIT2_086F12_matlab_ex1.pdf",
      "content": "Matlab Exercises Recitation 1+\n2.086 Spring 2012\nRecitation 1: Wednesday, 8 February / Friday, 10 February\nMatlab Exercises Recitation 1 due: Monday, 13 February 2012 at 5 PM by upload to Stellar\nFormat for upload: Students should upload to the course Stellar website a folder\nYOURNAME MatlabExercises Rec1\nwhich contains the completed scripts and functions for the assigned Matlab Exercises Recitation 1:\nall the scripts should be in a single file, with each script preceded by a comment line which indi\ncates the exercise number; each function .m file should contain a comment line which indicates the\nexercise number.\n1. (Driscoll 1.1) Evaluate the following mathematical expressions in Matlab. Display your\nevaluations by omitting semicolons at the end of your lines.\n(a) 28\n(b)\n- π\n(c)\n4 92 + 192 - π\nπ\n(d) π - e\n(e) log10(2)\n(f ) tanh(e)\nNote it is crucial to write arithmetic operations in a transparent and de-buggable form. Good\npractices include breaking a single formula into several pieces each of which is evaluated in\na separate Matlab statement, breaking a single Matlab statement into multiple lines with\nthe ellipsis continuation syntax, and including parentheses and spaces. (Order of precedence\nis not an excuse for impossibly dense lines of Matlab code.)\n2. Evaluate the following expressions, omitting semicolons at the ends of your lines. You should\nhave the format short (the default) in effect for all but the last two items.\n(a) 1/0\n(b) 0/0\n(c) 1 - 10-8\n(d) 1 - 10-20\n(e) 1 - 10-8 with format long in effect\n(f ) 1 - 10-20 with format long in effect\n+Some of the questions were derived from Learning Matlab by Tobin Driscoll, Numerical Computing With Mat-\nlab by Cleve Moler, Getting Started With Matlab by Rudra Pratap, The Art of Matlab by Loren Shure, and\nthe MIT 2010 IAP course 6.094; these are attributed where applicable. These exercises were initially assembled by\nDr. Justin Kao.\n\nNote that this exercise highlights two different points: there is an internal representation of\nfloating point numbers with only a finite number of bits of precision; there are a number of\ndifferent formats possible for presentation of floating point numbers.\n·\nBackground: The Fibonacci sequence is defined by,\nFn =\n⎧\n⎪\n⎨\n⎪\n⎩\n1,\nn = 1;\n1,\nn = 2;\nFn-1 + Fn-2,\nn ≥ 3.\nWe will take advantage of this sequence in the following exercises (and an exercise for next\nweek).\nCartoon by Sidney Harris\n·\n3. Write a script which calculates F20. Use a for loop. Note that at any given time you need\nonly store the three active members of the sequence, say F_curr, F_old, and F_older, which\nyou will \"shuffle\" appropriately.\nNote you can also use some \"quick and dirty\" plotting to help debug and confirm correct\nbehavior: add a hold on and plot(n,F_curr,'o') in your loop. Note that \"quick and\ndirty\" plotting for debugging is different from \"presentation\" plotting for consumption by\nothers; the latter must contain labels and titles and legends to be useful (we review this in\nRecitation 2).\n4. Write a script which finds N ∗ such that FN ∗ < 1000 and FN∗+1 ≥ 1000. Use a while loop.\nNote the \"interior\" block of your while loop will be quite similar to the block of your for\nloop of Exercise 3 but now you must include a (say) Nstar_tmp variable which is initialized\noutside the loop and incremented each time through the loop.\n5. Write a script which finds the sum of the first 40 Fibonacci numbers Fn, 1 ≤ n ≤ 40, for\n\nwhich Fn is divisible by either 2 or 5,\n\nt\nFn if Fn is divisible by 2 or 5\n0 otherwise .\nn=1\n(For example, the first Fibonacci number to be included in the sum will be F3 = 2, and the\nsecond Fibonacci number to be included in the sum will be F5 = 5.) Use a for statement\nsimilar to Exercise 3 but now add the necessary relational and logical operations, an if,\nand also a fibsum summation variable which is initialized outside the loop and appropriately\nincremented inside the loop. You should find the Matlab built-in function mod helpful.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n2.086 Numerical Computation for Mechanical Engineers\nFall 2012\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-086-numerical-computation-for-mechanical-engineers-fall-2012/97b8460d504d0baab7b62cf2acc7c29b_MIT2_086F12_pset1.pdf",
      "content": "Problem Set 1\n2.086 Spring 2012\nReleased: Tuesday, 14 February 2012, at 4 PM.\nDue:\nTuesday, 28 February 2012, at 2:30 PM by hardcopy at the beginning of class.\nA Robot in a Room\nIt is critical for a robot to be able to determine the layout of its environment and also its own\nposition within the environment for purposes of navigation and also task completion. In this\nproblem set we consider a simple scenario: a robot first scans the environment to determine the\nshape (boundaries) of a room and its position within this room; the robot then calculates the area\nof the room in order to plan for tasks. (These tasks could take a variety of forms such as cleaning\nthe surface or perhaps inspecting the surface for the presence of flaws or contaminants.)\nIn Figure 1 we depict the actual robot equipped with an Infrared (IR) Range-Finder which will\nserve to determine distance (to obstacles) and hence room shape. (In fact, the robot is equipped\nwith several Range-Finders, but we will consider here data obtained from a single sensor.) We\nshall describe the IR Range-Finder in more detail below. Note the IR Range-Finder is mounted on\na turret which rotates relative to the robot and hence the robot can scan the surroundings while\nremaining stationary.\nFigure 1: Robot equipped with an Infrared (IR) Range-Finder.\nIn Figure 2 we show a schematic of the robot in the room. We are concerned only with the two-\ndimensional plane, and hence we may describe the room boundary as (X(θ), Y (θ)) for 0 ≤ θ < 2π.\nNote the coordinate system is centered on the robot IR Range-Finder and furthermore we assume\nthat θ = 0 is aligned with the positive x direction. (The front of the robot is referenced to θ = 90*.)\n\nRobot\nIR Range-Finder\nθ\nx\ny\n(X(θ), Y (θ))\nRoom\nFigure 2: Schematic of the robot in the room.\n0.5\n1.5\n2.5\n(a) The Sharp IR distance sensor\n(c) Sharp Electronics. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see http://ocw.mit.edu/fairuse.\nD\ndistance\n(cm)\nvoltage (volts)\n(b) Calibration curve\nFigure 3: (a) Sharp GP2Y0A02YK0F infrared distance sensor and (b) associated calibration curve.\nInfrared Range-Finder\nInfrared rangefinders are relatively inexpensive distance sensors which nevertheless achieve rea\nsonable performance -- speed and accuracy -- relative to much more expensive approaches.\nOur robot is equipped with the Sharp BP2Y0A02YK0F IR distance sensor shown in Figure 3(a).\nThe Sharp sensor uses triangulation to calculate distance from measurements of the angle of inci\ndence of IR beams reflected from the distant surface of interest back to a receiving position sensitive\ndevice (PSD) mounted on the transducer. We show in Figure 3(b) the calibration data: the in\ndependently determined distance D (measured in cm) to a surface versus the voltage recorded by\nthe transducer. Note this calibration data is discrete -- we perforce consider only a finite number\nof positions for our calibration wall -- and hence we will need to use interpolation in order to ob\ntain accurate voltagetodistance conversion for the actual room data. (Note we expect D to vary\ninversely with voltage, however we ask you to feign ignorance of this dependence for the purposes\nof this particular problem set.)\n\nInstructions\nYou should download from the website the file PSet1.mat.\nThis file, which you should load into your workspace, contains single-index row arrays RefDistance\nand RefVoltage which contain the calibration data of Figure 3(b).\nThis file also contains single-index row arrays RoomVoltage and RoomTheta_Deg for the ac\ntual room data: RoomVoltage(i) is the voltage measured at angle RoomTheta_Deg(i), for i =\n1, . . ., K ≡ length(RoomTheta_Deg); note the angles are distinct and positive and ordered in\nstrictly increasing (counter-clockwise) fashion. Note that RoomDistance and RoomTheta_Deg do\nnot wraparound -- we do include θ = 0 but do not include θ = 360* (the last angle is less than\nand distinct from 360*).\nThe RoomTheta_Deg data is in degrees rather than radians, so you should convert to radians --\na new vector RoomTheta -- promptly to avoid any subsequent errors.\nRoom Shape\n1. (10 pts) Plot RefDistance versus RefVoltage. Make sure that in all figures in all problem\nsets you label your axes, add a plot title, indicate all units as appropriate, and include a\nlegend (whenever there is more than a single curve in a figure).\nThe deliverable here is the plot.\n2. (15 pts) Write a script which converts a single-index row array of test voltages TestVoltage\nto a single-index row array of distances TestDistance based on piecewise linear interpolation\nwith respect to the distance-voltage calibration data of RefDistance, RefVoltage. (The first\nlines of your script should load the calibration data and define the single-index row array\nTestVoltage.) You should find Exercise 4. of Matlab Exercises_Recitation 2 quite useful\nin this regard.\nThe deliverables here are\n(i) the Matlab script (copied and pasted into your problem set document), and\n(ii) a table which compares the output of your script for TestDistance with \"by-hand\"\ncalculation of the same quantity for the particular case of TestVoltage = [1,1.5,2].\nThe purpose of the latter is of course to confirm that your code is performing correctly.\n3. (10 pts) Now run your script with TestVoltage = RoomVoltage to determine RoomDistance.\nThen process the array RoomDistance -- transforming from polar coordinates to Carte-\nX\nX\nsian coordinates -- to obtain X(θi), Y (θi), 1 ≤ i ≤ K; X(θi), Y (θi), 1 ≤ i ≤ K, is our\nexperimental/data-based approximation to the actual room boundary X(θi), Y (θi), 1 ≤ i ≤\nK. You should store X(θi) and YX(θi) as two separate single-index Matlab row arrays Xvec\nand Yvec, respectively, each of length K.\nThe deliverable here is a plot of the room shape: the room boundary, as described by\nX\nX(θi), Y (θi), 1 ≤ i ≤ K. You should find the standard plot routine up to the job; please\nremember to label the axes and provide a title.\n\n4. (10 pts) There are many sources of error in the distance measurement (and hence in ( XX(θ), YX(θ))\nrelative to (X(θ), Y (θ)): spurious scattering/reflections in particular near corners or rapid\nvariations in the room shape (which should be apparent in your plot); the resolution of the\nPSD transducer; the error in the linear interpolation of the calibration data.\nHere we analyze briefly the error due to the PSD transducer. We know from independent\nsources that the measurement error in the voltage is ±EV = ±0.02 volts. We wish to estimate\nthe induced error in the distance, ±ED cm, for distances D ≈ 30 cm and also D ≈ 130 cm.\nThe deliverables here are, for each of the two distances requested (approximately 30 cm and\napproximately 130 cm),\n(i) an estimate for the error in the distance, ±ED cm, induced by the measurement error\nin the voltage, ±EV = ±0.02 volts;\n(ii) the derivation and justification of your error estimate.\nRoom Area\nWe know that the area of the room, Aroom, can be evaluated as the line integral around the boundary\nof the room,\n\nAroom = -\nY (θ) dX(θ) .\n(1)\nRoom Boundary\nIn performing the line integral we proceed in counter-clockwise fashion such that (thanks to the\nminus sign out front) positive dx and negative dx conspire to give a positive area. The formula\nEq. (1), and related formulas, can be deduced from standard integral theorems of vector calculus.\n5. (10 pts) We now wish to approximate Eq. (1): we invoke experimental measurements of\ndistance to deduce the room shape and then apply the trapezoidal rule to obtain\nK\nK\nAXroom\nX\n= -\nci Y (θi) .\n(2)\nh\ni=1\nNote that the \"hat\" indicates the approximation of the boundary from measurements/inter\npolation and then the subscript h refers to the trapezoidal rule approximation of the integral.\nThe deliverable here is expressions for ci, 1 ≤ i ≤ K. Hints: For 2 ≤ i ≤ K - 1, the ci will\ndepend at most on XX(θi-1), XX(θi), and XX(θi+1); c1 will depend at most on XX(θK ), XX(θ1), and\nX\nX\nX\nX\nX(θ2), and cK will depend at most on X(θK-1), X(θK ), and X(θ1). Recall that i increasing\ncorresponds to counter-clockwise rotation, as desired.\n6. (15 pts) Develop a Matlab script which implements your trapezoidal rule approximation.\nThe deliverable here is the Matlab script (copied and pasted into your problem set docu\nment).\n\n7. (10 pts) To test your integration code, replace (temporarily) in your script the actual room\ndata with \"synthetic room data\": replace Xvec with [1,1,-1,-1,1], Yvec with [0,1,1,-1,-1]\nand K with 5.\nThe deliverables here are\n(i) the answer your code should provide and your simple derivation of this result (you should\nnot need to actually execute your integration script by hand), and\n(ii) the answer your code actually does provide.\nThe purpose here is of course to test that your code performs correctly. Do not just say \"it\nworks\": provide the numbers requested.\n8. (10 pts) Now apply your integration code to the actual room data.\nThe deliverables here are\nAXroom\n(i) the value for\nh\npredicted by your script, and\n(ii) your \"guess\" for the room area based on your plot of Question 3, eyeball estimates for\ndimensions, and a simple area derivation. (Always perform a \"sanity check\" as a good\nway to avoid blunders.)\nPlease make sure to always present numerical answers within a full sentence which clearly\nindicates what the number actually represents in terms of well-defined variables; also provide\nunits as appropriate.\nX\nX\n9. (10 pts) Inspection of your room geometry plot of Question 3 suggests that X(θi), Y (θi),\n1≤ i ≤ K, is certainly a bit noisy in particular near the corners. Do you think this noise will\nAXroom\nhave a large, medium, or small effect on the accuracy of\nh\nand why? You may assume\nthat the noise oscillates relatively regularly between positive (an overestimation of the true\ndistance) and negative (an underestimation of the true distance), even though this is not\nquite true for our experimental data.\nThe deliverable here is an essay of no more than three sentences.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n2.086 Numerical Computation for Mechanical Engineers\nFall 2012\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "MATLAB® Exercises 2",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-086-numerical-computation-for-mechanical-engineers-fall-2012/6ef6b74ead842d8fe442fbcbb7477293_MIT2_086F12_matlab_ex2.pdf",
      "content": "Matlab Exercises Recitation 2+\n2.086 Spring 2012\nRecitation 2: Wednesday, 15 February / Friday, 17 February\nMatlab Exercises Recitation 2 due: Tuesday, 21 February 2012 at 5 PM by upload to Stellar\nFormat for upload: Students should upload to the course Stellar website a folder\nYOURNAME MatlabExercises Rec2\nwhich contains the completed scripts and functions for the assigned Matlab Exercises Recitation 2:\nall the scripts should be in a single file, with each script preceded by a comment line which indi\ncates the exercise number; each function .m file should contain a comment line which indicates the\nexercise number.\n1. (6.094 1.2) Write a script to make the following single-index arrays. Leave off the semicolons\nso that your results are displayed.\n(a) p = [3.14, 15, 9, 26]\n(b) r = [100, 99, 98, . . . , 2, 1]\n(c) s = [0,\n. . . ,\n1]\n99 , 99 ,\n99 ,\nNote you should find the colon operator helpful in constructing these single-index arrays.\n2. (This is an extension to Exercise 4. of Recitation 1.) Write a script which finds N∗ such that\nFN∗ < 1000 and FN∗+1 ≥ 1000 and also constructs the single-index array Ffib of the associ\nated Fibonacci numbers [F1, F2, . . . , FN∗ ]. This should be a relatively simple modification to\nyour while loop of Exercise 4. of Recitation 1: initialize (say) Ffib outside the loop, and then\nuse horizontal concatenation to \"grow\" the Ffib array each time through the loop; note you\ncan eliminate your Nstar_tmp variable from earlier and instead evaluate the length of the\nfinal Ffib array. Note a \"quick and dirty\" debug plot can be performed after (and outside)\nthe loop with plot(Ffib,'o').\nComment: When we get to double-index arrays we will emphasize the importance of ini\ntializing arrays (with zeros and later spalloc). Initialization ensures that you control the\nsize/shape of the array and also is the most efficient way to allocate memory. On the other\nhand, concatenation can be very useful in dynamic contexts (in which array size may not\nbe known a priori) or in situations in which a large array is most easily expressed in terms\nof several smaller arrays. But use concatenation sparingly in particular in computationally\nintensive codes.\n3. Write a script to calculate the sum of a geometric series with N + 1 terms,\nN\nN\nN\nS =\nr i = 1 + r + r + r + . . . + r\n,\ni=0\n+Some of the questions were derived from Learning Matlab by Tobin Driscoll, Numerical Computing With Mat-\nlab by Cleve Moler, Getting Started With Matlab by Rudra Pratap, The Art of Matlab by Loren Shure, and\nthe MIT 2010 IAP course 6.094; these are attributed where applicable. These exercises were initially assembled by\nDr. Justin Kao.\n\nfor the particular case of N = 10 and r = 1/2. Use ones(1,N+1) to set up a single-index (row)\narray of all r's, the colon operator to set up a single-index array of exponents, array \"dotted\"\noperators to perform the exponentiation, and the Matlab built-in function sum to perform\nthe summation -- no for or while loops allowed! (In fact, a single line of Matlab code\nshould suffice, though you may wish to break this into a few lines for improved readability.)\n4. Write a script which given a vector of distinct points xvec = [x1, x2, . . . , xN ] and a point x\nfinds the index i∗ such that xi∗ ≤ x and xi∗+1 > x. You may assume that the points are\nordered and distinct, xi < xi+1, 1 ≤ i ≤ N - 1, but you should not assume that the points\nare equidistantly spaced. You may also assume that x1 ≤ x ≤ xN .\nTo write your code, you should use array relational operators, the Matlab built-in find,\nand then (say) the Matlab built-in max (or length) -- no for loops allowed.\nRun your script for two cases: x = 1./sqrt(2) and xvec = 0.01*[0:100]; x = 0.5 and\nxvec = sort(rand(1,100)). (In each case, include these assignment statements as the first\ntwo lines of your script.)\n5. (Driscoll 5.1) Write a script to do the following: On a single figure, plot the functions sinh x,\nx\ncosh x, tanh x, and e\nfor -1 ≤ x ≤ 1, with point spacing Δx = 1/10. Make sinh a red line,\ncosh a black dotted line, tanh a blue line with circles at each point, and ex just green ×'s with\nno line. Make a legend. Label your axes and give the figure a title. Use linspace to create\na vector of x values and call each Matlab mathematical function with vector arguments\nto create the corresponding vector of \"y\" values. (See Section 5.4 of the text for a plotting\n\"template.\")\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n2.086 Numerical Computation for Mechanical Engineers\nFall 2012\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 2",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-086-numerical-computation-for-mechanical-engineers-fall-2012/2adb19a2bdbf02b4fa3f576bf3ead22d_MIT2_086F12_pset2.pdf",
      "content": "Problem Set 2\n2.086 Spring 2012\nReleased: Tuesday, 28 February 2012, at 4 PM.\nDue:\nFriday, 9 March 2012, at 5:00 PM by hardcopy.\nPlease also upload to Stellar any Matlab function/script files you were required to supply by hard\ncopy in your problem set document.\nx (in meters)\ny (in meters)\nFigure 1: A surveillance robot scanning a room. Obstructions (in black) divide the space into a\nvisible region (the white region) and a non-visible region (the gray and black regions).\nIntroduction\nA museum has enlisted a camera-equipped mobile robot for surveillance purposes. The robot will\nnavigate the museum's premises, pausing to take one or more 360 degree scans in each room.\nFigure 1 shows a typical room filled with various stationary obstructions (in black). We wish to\ndetermine the vantage point in each room from which the robot will have the most unobstructed\nview for its scan by estimating the area of the visible region (in white) for each candidate vantage\npoint. (Note the obstructions are considered part of the non-visible region.) Considering that\nthe robot might want to calculate a rough estimate of this result very quickly for real-time path\nmodification purposes, we decide to use a Monte Carlo integration approach which deals easily with\nthe complex \"implicit\" definition of the visible region and also will allow us to stop calculating as\nsoon as the relative error of our estimate has reached an acceptable level.\nWe first define, for any vantage point xV and any surveillance point (to be watched) in the\nroom xW , the line segment S(xV , xW ) that connects xV and xW . We can then express the area\n\nZ\nvisible from a vantage point xV as the integral\nA(xV ) =\ndxW ,\n(1)\nxW in R such that S(xV ,xW )∩O=∅\nwhere R is the (rectangular) room and O is the collection of obstructions. The visible area is thus\ndefined as the integral over all points in the room such that the line segment S(xV , xW ) between\nxV and xW does not intersect an obstruction (or, equivalently, such that the intersection of sets S\nand O is the null set).\n?\nThere are many ways to do the visibility test S(xV , xW ) ∩ O = ∅, but perhaps the method\nmost amenable to mobile robotics is to use an \"occupancy grid,\" a discretization of the map in\nwhich each cell's value corresponds to the likelihood that the cell is empty or occupied. See the\nappendix for a description of how to use the occupancy-grid-based \"visibility test\" code we provide\nfor your programming convenience.\nInstructions\nDownload the two files assignment2.mat and isvisible.m from Stellar. Loading assignment2.mat\nin Matlab will load all the data for this assignment.\nQuestions\n1. (20 pts) We first consider the simple test case shown in Figure 2, where exactly one quarter of\na 10 meters by 10 meters room R has been completely walled off by obstruction O. Calculate\nby hand the area visible from vantage point xV = (x, y) = [2; 2]. (Recall that points within\nthe obstruction also count as non-visible.) Describe a very simple visibility test\n?\nS(xV , xW ) ∩ O = ∅\nfor this particular test room (Figure 2) and vantage point xV = [2; 2], and then implement\nthis test as a Matlab function test_isvisible.m which takes as its single argument a\nsurveillance point xW and returns a logical 1 if the point is visible from vantage point xV =\n[2; 2] and a logical 0 otherwise.\nThe deliverables here are\n(i) A(xV ) (a numerical value) for the data given; and\n(ii) your very simple visibility test for this particular test room (Figure 2) and vantage point\nxV = [2; 2]: a mathematical/logical expression (not yet Matlab code) in terms of xW\n(and constants) which is true if and only if xW is within the visible region; and\n(iii) your Matlab function test_isvisible.m (which you should copy and paste into your\nproblem set document and also upload to Stellar) which implements your test of (ii)\nabove.\n2. (40 pts) Construct a Monte Carlo code -- based on Sections 10.2.2, 10.3, and 11.1.4 of the\ntext -- to estimate A(xV ) to within a relative error of 4%1 for a 95% (normal-approximation\n1Note by a relative error of 4% here (and elsewhere in the problem set) we mean RelErr = 0.04 (and not\nRelErr = 0.0004).\n\n(0,0)\n(5,5)\n(10,10)\n(2,2)\nx (in meters)\ny\ny (in meters)\nO\nFigure 2: Test room.\nbinomial) confidence level. Note you are asked for the visible area, not the fraction of the\nroom which is visible.\nTest your Monte Carlo code for the test case of Question 1 using first, your own room-specific\ntest_isvisible.m function of Question 1 and second, the provided general, occupancy-grid\nbased isvisible.m function and occupancy grid testmap described in the appendix. Note\nyou should run your Monte-Carlo code twice: once with your code test_isvisible.m, and\nonce with \"our\" code isvisible.m.\nThe deliverables here are first,\n(i) A Monte Carlo convergence plot for the case in which you use test_isvisible.m to\ndetermine visibility; and\n(ii) A Monte Carlo convergence plot for the case in which you use isvisible.m to determine\nvisibility.\nNote in each case the plot should include title, axis labels (the abscissa label should be n\n(of Section 11.1.4) and the ordinate label should be \"Visible Area (in meters squared)\"),\nand legend. The plot should contain the information of Figure 11.2(a) but of course up\ndated to reflect your particular calculation: you should include the visible area estimate,\nthe visible area confidence interval, and the expected (exact) result for the visible area\n-- all clearly labeled in the legend. Note you should not plot the confidence interval if\nnθˆn ≤ 5 or n(1 - θˆn) ≤ 5.\nAlso please provide\n(iii) A table which indicates, for both cases (in which you use test_isvisible.m and\nisvisible.m, respectively), (a) the value of n (for nθˆn > 5 and n(1 - θˆn) > 5) at\nwhich the relative error first falls below 4%, and for that value of n the associated values\nof (b) the Monte Carlo visible area estimate, and (c) the visible area confidence interval\n(as lower and upper visible area bounds). Note the data in your table should be for the\nparticular \"runs\" reported in your plots (i) and (ii) above.\n\n3. (10 pts) For the provided occupancy grid museummap (corresponding to the map of Figure 3\nand also Figure 4(a)) and using the provided isvisible.m function, use your Monte Carlo\ncode to estimate (again, within a relative error of 4% for a 95% confidence level) the visible\nlarge\narea from the vantage point xV\n= [27.5; 21.5]. Note: the required number of samples should\nbe less than 5,000.\nThe deliverables here are\n(i) A Monte Carlo convergence plot (with all the same attributes as in Question 2. except\nthat you can no longer provide the exact result); and\n(ii) (a) the value of n at which the relative error first falls below 4%, and for that value of\nn the associated values of (b) the Monte Carlo visible area estimate, and (c) the visible\narea confidence interval (as lower and upper visible area bounds).\nsmall\n4. (15 pts) Repeat the analysis of Question 3, this time for the vantage point xV\n= [7; 36.5].\nlarge\nsmall\nExplain why xV\nand xV\nrequire such a different number of samples to provide the same\n4% relative accuracy. Note: the required number of samples should be less than 500,000.\nThe deliverables here are\n(i) A Monte Carlo convergence plot with all the same attributes as in Question 3. (to avoid\nslowing down your code, make sure you do not plot inside the loop); and\n(ii) (a) the value of n at which the relative error first falls below 4%, and for that value of\nn the associated values of (b) the Monte Carlo visible area estimate, and (c) the visible\narea confidence interval (as lower and upper visible area bounds); and\n(iii) a short but quantitative explanation, in terms of relative error, for the larger Monte\nCarlo sample size required by the vantage point of Question 4. relative to the Monte\nCarlo sample size required by the vantage point of Question 3.\nWe provide a comment which requires no action on your part: in this question, it would be\nmuch better to first eliminate a large part of the museum room which by inspection is clearly\nnot visible and then perform Monte Carlo over the remaining part of the museum room (of\ncourse being careful to now interpret the \"fraction of darts in\" as the ratio of the visible\narea to the area of the remaining part of the museum room). This is known as \"importance\nsampling\" within the Monte Carlo literature.\n5. (15 pts) Now try to find a candidate \"best\" vantage point for the robot in the museum room.\nUsing Figure 4(a), choose 4 potentially good points for xV and determine which one yields the\nlargest visible area (again, within a relative error of 4% for a 95% confidence level). Provide\nthe visible area estimate and confidence interval for each of your candidate vantage points,\nmaking sure to specify the one you found to be best.\n\nxV\nsmall\nxV\nlarge\n(0,0)\n(55,43)\nx (in meters)\ny (in meters)\nFigure 3: Museum room.\nThe deliverables here are\n(i) a table which reports for each of your 4 vantage points the corresponding visible area estimate\nand confidence interval (as lower and upper visible area bounds); and\n(ii) the vantage point which provides the best result (largest visible area); and\n(iii) a short discussion of what the confidence intervals in your table say about your ability to\ndistinguish the best vantage point (amongst your 4 candidates) based on your Monte Carlo\ncalculations.\nAppendix\nWe begin by converting our map of the room to an \"occupancy grid,\" a discretization of the map\nin which each cell's value corresponds to the likelihood that the cell is empty or occupied. In our\ncase, because we know ahead of time the layout of the room, a given cell contains either a zero\nif the cell is empty, or a one if the cell is occupied. Figure 4(a) shows a visualization of a fairly\nlow-resolution occupancy grid for our map, where occupied cells are shown in black. Figure 4(b)\nshows the discretization convention we have adopted for our grid, in which the cell in row i and\ncolumn j is defined by grid points xj , xj+1 and yi, yi+1, where 1 ≤ i ≤ 43, 1 ≤ j ≤ 55; note the\nmesh spacing is 1 meter in each direction.\nWe can use the occupancy grid to determine the visibility of a point xW in the room from a given\nvantage point xV . To do this, we draw a line between the two points, determine through which\ncells the line passes, and then check the occupancy condition of each of the intervening cells. If all\nof the cells are empty, the point is visible. If any of the cells are occupied, the point is not visible.\nThe provided function isvisible.m takes as arguments xV , xW (both 2 × 1 column vectors) and\nan occupancy grid of the room and performs this visibility check for you, returning a logical 1 if the\nspecified point is visible from the specified vantage point and a logical 0 otherwise. For example, for\n\nx (in meters)\ny (in meters)\n(0,0)\n(55,43)\n(a) Occupancy grid for museummap.\ny\ncell\n(i, j)\nx\nyi\nxj\nxj+1\nyi+1\n(b) Discretization scheme.\nFigure 4: Occupancy grid and its discretization scheme. Note in Figure 4(a) each tick mark is one\nmeter.\n\nx (in meters)\ny (in meters)\nFigure 5: Visibility checking of two points from a single vantage point for the room mapname. Cell\ncorresponding to visible point marked in blue; cell corresponding to non-visible point marked in\nred.\nthe two points in Figure 5, a call to isvisible() would return a logical 1 for the surveillance point at\n[30.5; 40.5] (i.e., isvisible([25.5; 24.5], [30.5; 40.5], mapname) returns 1) and a logical 0\nfor the surveillance point at [45.5; 37.5] (i.e., isvisible([25.5; 24.5], [45.5; 37.5], mapname)\nreturns 0). Note the units of length are specific to each map; for the maps in this problem set length\nis measured in meters.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n2.086 Numerical Computation for Mechanical Engineers\nFall 2012\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "MATLAB® Exercises 3",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-086-numerical-computation-for-mechanical-engineers-fall-2012/2ab48928ba8604f71276ec19f5320d00_MIT2_086F12_matlab_ex3.pdf",
      "content": "Matlab Exercises Recitation 3\n2.086 Spring 2012\nRecitation 3: Wednesday, 22 February / Friday, 24 February\nMatlab Exercises Recitation 3 due: Monday, 27 February 2012 at 5 PM by upload to Stellar\nFormat for upload: Students should upload to the course Stellar website a folder\nYOURNAME MatlabExercises Rec3\nwhich contains the completed scripts and functions for the assigned Matlab Exercises Recitation 3:\nall the scripts should be in a single file, with each script preceded by a comment line which indi\ncates the exercise number; each function .m file should contain a comment line which indicates the\nexercise number.\n1. (a) Write a function with \"signature\"\nfunction [bern_rvs] = Bernoulli(n,theta)\nwhich returns a row vector bern_rvs of n independent random variables (more precisely,\nrealizations of independent random variables) drawn from the Bernoulli probability mass\nfunction fX (x; θ) for given θ ≡ theta. Note the inputs n and theta are scalars. Your\nfunction should take advantage of the Matlab built-in rand -- called as rand(1,n) to\ncreate a row vector.\n(b) Then write a script which calls your function Bernoulli for n = 1000 and theta = 0.25\nand furthermore calculates and displays\nn\n\nfrac_one =\nbern_rvs(i) ,\n(1)\nn i=1\nwhich is simply the fraction of \"one\" entries in your random vector (realization). Of\ncourse frac_one should be roughly theta. Make sure to run your script for several\ndifferent sets of inputs (n, theta) to Bernoulli in order to confirm that both the script\nand Bernoulli are working correctly.\n2. (a) Write a function with \"signature\"\nfunction [x1pts,x2pts] = unif_over_rect(a1,b1,a2,b2,n)\nwhich provides the coordinates (x1pts(i),x2pts(i)), 1 ≤ i ≤ n, of n random darts\n(more precisely, realizations of random darts) thrown at the rectangle a1 ≤ x1 ≤ b1,\na2 ≤ x2 ≤ b2. (The lower left corner of the rectangle is a1,a2; the upper right corner\nof the rectangle is b1,b2.) You may assume that the darts are drawn from the bivariate\nuniform distribution over the rectangle and hence correspond to independent random\nvariables x1pts(i) and x2pts(i).\nNote that x1pts and x2pts should each be single-index row arrays of length n -- two\nseparate outputs. (In the next recitation we will consider double-index arrays.) The\ninputs a1, b1, a2, b2, and n are all scalars.\n\n(b) Then write a script which calls unif_over_rect for a1 = -1, b1 = 1, a2 = -1, b2 = 1,\nn = 2000 and calculates and displays frac_in_circ, the fraction of darts that fall inside\nthe unit circle (radius unity) centered at the origin. Of course frac_in_circ should be\nclose to π/4.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n2.086 Numerical Computation for Mechanical Engineers\nFall 2012\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 3",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-086-numerical-computation-for-mechanical-engineers-fall-2012/01a78b34e5b6be5e50e8d9d12b7375d4_MIT2_086F12_pset3.pdf",
      "content": "Problem Set 3\n2.086 Spring 2012\nReleased: Tuesday, 13 March 2012\nDue: Tuesday, 3 April, at 2:30 PM by hardcopy at the beginning of class.\nNote that no Matlab scripts need be uploaded to Stellar for this problem set.\nIntroduction\nIn this problem set, we will determine the friction coefficient between a robot's wheels and the\nground. The friction coefficient directly affects the robot's resistance to slippage, and hence also\nthe tasks the robot may perform. In particular, the friction coefficient can limit the load which the\nrobot can pull or push.\nFnormal, front\nFnormal, rear\nw\nFf\nv\nFdrag\nW\nFigure 1: A mobile robot in motion.\nWhen a mobile robot such as shown in Figure 1 is commanded to move forward, a number\nof forces come into play. Internally, the drive motors exert a torque (not shown in the figure) on\nthe wheels, which is resisted by the friction force Ff between the wheels and the ground. If the\nmagnitude of Ff dictated by the sum of the drag force Fdrag (a combination of all forces resisting\nthe robot's motion) and the product of the robot's mass and acceleration is less than the maximum\nstatic friction force F max\nf, static between the wheels and the ground, the wheels will roll without slipping\n\nand the robot will move forward with velocity v = ωrwheel (here ω is the angular velocity of the\nwheel). If, however, the magnitude of Ff reaches Ff max\n, static, the wheels will begin to slip and F\n\nf\nwill drop to a lower level Ff, kinetic, the kinetic friction force. The wheels will continue to slip\n(v < ωrwheel) until zero relative motion between the wheels and the ground is restored (when\nv = ωrwheel).\nThe critical value defining the boundary between rolling and slipping, therefore, is the maximum\nstatic friction force. Amontons' \"law\" states that\nF max\nf, static = μs Fnormal, rear,\n(1)\nwhere μs is the static coefficient of friction and Fnormal, rear is the normal force from the ground on\nthe rear, driving, wheels. In order to minimize the risk of slippage, robot wheels should be designed\nfor a high value of μs between the wheels and the ground. This value, although difficult to predict\naccurately by modeling, can be determined by experiment.\n\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n\ntime (seconds)\ntime (seconds)\nFfriction\nfriction vs.\nvs. Tim\nTime for\nfor 500\n500 Gr\nGram\nam Load\nLoad\nFf, ki\nkine\nnetic\nic = μk Fnor\nnorma\nmal + exp\nexperi\nerimen\nental\ntal error\nerror\nFfriction\nfriction (Newtons)\n(Newtons)\nFf, stat\nstatic\nic = Fta\ntangen\nngentia\nial, appl\napplied\nied ≤μs Fnor\nnorma\nmal\nmeas\neas\n\n= μs Fnor\nnorma\nmal + exp\nexperirimen\nental\ntal error\nerror\nFf, stat\nstatic\nic\nmax,\nax, meas\nmeas\nFigure 2: Experimental setup for friction\nmeasurement: Force transducer (A) is con-\nnected to contact area (B) by a thin wire.\nNormal force is exerted on the contact area\nby load stack (C). Tangential force is ap\nplied using turntable (D) via the friction be\ntween the turntable surface and the contact\narea. Apparatus and photograph courtesy of\nJames Penn.\n\nWe first conduct experiments to determine the friction force\n\nF max\nf,\n(in Newtons) as a function\nstatic\n\nof normal load Fnormal, applied (in Newtons) and (nominal) surface area of contact Asurface (in cm2)\nwith the 2.086 friction turntable apparatus depicted in Figure 2. Weights permit us to vary the\nnormal load and \"washer\" inserts permit us to vary the nominal surface area of contact. We next\napply a force Ftangential, applied to the turntable which is balanced by the friction force Ffriction; the\nlatter is then measured by a transducer which relates voltage to deflection to force. A typical\nmeasurement point (at a particular prescribed value of Fnormal, applied and Asurface) yields the time\n\nmax, meas\ntrace of Figure 3: we increase Ftangential, applied until slippage occurs; F\n(our measurement\nf, static\n\nof F max\nf,\n)\nstatic is deduced as the maximum force achieved.\nThe experimental data comprises 50 measurements: 2 (distinct) measurements at each of 25\npoints on a 5 × 5 \"grid\" in (Fnormal, applied, Asurface) space. The data is provided to you in the .mat\nfile friction_data_PSet3 as 50 × 1 arrays F_fstaticmaxmeas, F_normalload, and A_surface.\nEntry i of F_fstaticmaxmeas, F_normalload, and A_surface provides respectively the measured\nfriction force\nmax, meas\nF\n(in Newtons), the prescribed normal load F\n(in Newtons), and\nf , static\n\nnormal, applied\n\nthe prescribed surface\nfor\n\narea Asurface (in cm2),\nthe ith measurement. For example, in the first\nmeasurement, i = 1, the measured friction force is 0.1080 Newtons, the imposed normal load is\n0.9810\n\nNewtons, and the nominal surface area is 1.2903 cm2.\nWe next postulate a dependence (or \"model\")\nmax\nFf, static(Fnormal, applied, Asurface; β) = β0 + β1 Fnormal, applied + β2 Asurface ,\n(2)\nwhere\n\nβ = (β0, β1, β2)T. We expect -- but do not a priori assume -- from Messieurs Amontons\nData courtesy of James Penn.\nFigure 3:\nSample data for one friction\nmeasurement, yielding one data point for\nF max, meas.\nf , static\n\nand Coulomb that β0 = 0 and β2 = 0. We shall refer to (2) as the \"full model.\" We assume that\nthe experimental measurements follow the response model\nF max, meas = F max\ntrue\nf, static\nf, static(Fnormal, applied, Asurface; β\n) + E\n(3)\nwhere βtrue is the true value of β in the absence of noise, and E is the noise. We implicitly assume\nby the existence of βtrue that our model is bias-free. We further assume that the noise is normal,\nhomoscedastic, and uncorrelated (at different Fnormal, applied and Asurface) per our assumptions (N1),\n(N2), and (N3) of the text. We would like you to perform a regression analysis to determine\nestimates and confidence\n\nintervals for the coefficients βtrue, βtrue\ntrue\n, and β2\n.\nNote for each question we identify each deliverable as a subquestion which you should clearly de\nlineate ((a), (b), . . . ) in your report. All quantities not explicitly defined in the problem statement\nare taken directly from the text.\nQuestions\n1. (15 pts) Indicate the correspondence between (mapping from) the general formulation and\nvariables of Section 17.2.1 of the text to our particular case here described by equations (2)\nand (3).\nmax, meas\nWe provide the first correspondence: F\ncorresponds to\nf\nY . Please fill in the\n, static\n\nrest:\n(a) p = ?;\n(b) x (a p-vector) corresponds to ?;\n(c) Ymodel(x; β) corresponds to ? ;\n(d) n = ? ;\n(e) hj (x), 1 ≤ j ≤ n - 1 corresponds to ? ;\n(f ) m = ? .\nNote in each case the ? should be replaced by variables or numbers provided in this Problem\nSet 3 statement (not the generic variables of Section 17.2.1).1\n2. (10 pts)\n(a) Complete the (single-line) Matlab assignment statement X = ? which forms the X\nmatrix for your regression analysis.\nNote your statement should be a syntactically correct line of code cut from Matlab\nand pasted to your problem set document. The statement should use only standard\nMatlab built-in's (if you like) and the arrays F_fstaticmaxmeas, F_normalload, and\nA_surface.\n(b) What is the size of X?\n1Hint: Recall that n is the number of regression coefficients which is also equal to the number of basis functions\n(one basis function per regression coefficient) if we recall that the basis function h0(x) = 1 (multiplied by β0) is\nincluded in this count.\n\n3. (5 pts)\n(a) Complete the (single-line) Matlab assignment statement Y = ? which forms the Y\nvector for your regression analysis. (Same rules apply as for Question 2. above.)\n(b) What is the size of Y?\n4. (10 pts)\n(a) Provide mathematical expressions (no Matlab syntax required) for 95% (confidence\n\njoint\njoint\njoint\n\nlevel) joint confidence intervals I\nfor βtrue, βtrue\n, I1\n, and I2\n, and βtrue,\n\nrespec\n\ntively.\nYour expressions should contain only the variables ˆ\nˆ\nˆ\nβ0, β1, and β2, the Σ matrix, and\nsγ=0.95,k,q. Please provide values for k and q, but you need not yet evaluate\nb\nsγ=0.95,k,q.\nYour confidence intervals should be of the form [lower limit, upper limit].\n(b) Provide a numerical value for \"sγ=0.95,k,q \" for your chosen k, q. Indicate, briefly, how\nyou obtained this result. Note you may use interpolation in Table 17.1(b) of the text to\nobtain an appropriate (approximate) \"sγ=0.95,k,q\" value.\n5. (15 pts) Perform your regression analysis and provide numerical values for\nˆ\n(a) β0,\nˆ\n(b) β1 ,\nˆ\n(c) β2 ,\n(d) σˆ, and\n(e) Σb (all entries of this matrix). (Note to find Σ for this small problem you may just use\nthe Matlab matrix inverse routine inv.)\nb\n6. (12 pts)\n(a) Provide numerical values for the\n\nt\nconfidence\njoint\njoint\njoin\nintervals I0\n, I\n\n,\n\nand I2\n.\n\nYour confi\ndence intervals should be of the form [lower limit, upper limit], where now \"lower limit\"\nand \"upper limit\" are numbers evaluated from your formulas of Question 4(a).\n\n(b)\njoin\nIs the value\nt\n0 included in I0\n?\n\njoint\n(c) Is the value 0 included in I2\n?\n\n(d) What do you conclude about the correctness of equation (1) from your answers to 6.(b)\nand 6.(c)?\n7. (4 pts)\n(a) What is the average of the measured friction force data (over the 50 measurements)?\n(b) What is the average of the predicted friction\nˆ\nˆ\nforce (average of (Xβ)i ≡ Ybi ≡ Ymodel(xi; β),\n1 ≤ i ≤ m)?\n(Your two means (measured, predicted) should be the same. If not, you have a bug.)\n\n8. (9 pts)\n(a) Provide a histogram of Y - Yb . You may use the Matlab built-in function hist with\nthe default number of bins.\n(b) Create and provide several -- at least three -- histograms for samples of size 50 from the\nnormal density N (0, σˆ2). (You should use the randn built-in and then the appropriate\nscaling, as described in the Appendix to Unit II on Estimation: the Normal Density.)\n(c) Ask a friend to pick the \"odd character\" from the histograms of (a) and (b). Is the\nhistogram of the experimental data chosen?\n9. (14 pts) Repeat Questions 1-7 (now 2 pts each) but now rather than the full model given by\nequation (2) consider an abridged model corresponding to equation (2) without the β2 Asurface\nterm. Note please mark your answers Q9/1(a), Q9/1(b), ..., Q9/7(a), Q9/7(b) so that we\ncan clearly identify each part.\n10. (6 pts)\n\n(a) Which model, full or abridged, realizes a lower value of IY - Y I2 -- and why must this\nbe the case?\n(b) Which model, full or abridged, do you think is better -- giv\nb\nes a better prediction for\nβtrue\n-- and why? (Tricky question, with no right or wrong answer. But your reasoning\nshould be sound in any event.)\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n2.086 Numerical Computation for Mechanical Engineers\nFall 2012\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Exam",
      "title": "Quiz 1 sample problems with solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-086-numerical-computation-for-mechanical-engineers-fall-2012/0153abf4d67bbfd7788b8d608403e130_MIT2_086F12_quiz1_samples.pdf",
      "content": "Unit I Quiz Question Sampler\n2.086/2.090 Fall 2012\nYou may refer to your text and other class materials as well as your own notes and scripts. You\nmay not use computers, tablets, calculators, or smartphones. If you wish to simulate real quiz\nconditions you should allocate roughly 15 minutes for each question.\nNAME\nAll questions are multiple choice; unless otherwise explicitly indicated, circle one and only one\nanswer. We provide a blank page at the end of these questions (and for each quiz) and we encourage\nyou to work through each question carefully; but note that, under real quiz conditions, we only\ngrade your multiple choice selections.\nYou may assume that all arithmetic operations are performed exactly (with no floating point\ntruncation or round-off errors).\nAnswer Key: The answer key is provided at the end of this collection of questions. You should not\nexpect a similar courtesy on the actual quiz.\n\nQuestion 1. Consider the integral of a linear function,\nZ 1\nI =\n(α + βx) dx\n(1)\nin which α and β are any non-zero constants (e.g., α = 2, β = 4.5). We approximate this integral\nby first breaking up the full interval into N - 1 segments of equal length h and then applying an\nintegration rule. Which of the following integration rules will yield the exact result for the integral\nof equation (1) for any value of h?\n(a) rectangle, left\n(b) rectangle, right\n(c) trapezoid\n(d) rectangle, midpoint\nPlease circle all answers that apply. You will get full credit for circling all the correct answers\nand no incorrect answers, proportional partial credit for circling some of the correct answer(s) and\nno incorrect answers, and zero credit if you circle any incorrect answers. (Hint: Draw a simple\npicture.)\n\nQuestion 2. The function f(x) is defined over the interval 0 ≤ x ≤ 1 by\n⎧\n⎨ x\nfor 0 ≤ x ≤ 1/2\nf(x) =\n.\n⎩ 1 - x for 1/2 < x ≤ 1\nWe also introduce a set of points xi = i-1 , 1 ≤ i ≤ 6, which define segments Si = [xi, xi+1],\n1 ≤ i ≤ 5 (for example, the first segment, S1, is given by 0 ≤ x ≤ 0.20). The function f(x), points\nxi, 1 ≤ i ≤ 6, and segments Si, 1 ≤ i ≤ 5, are depicted in Figure 1.\nIn the below we consider two different interpolation procedures, \"piecewise-constant, left endpoint\"\nand \"piecewise-linear,\" based on the segments Si, 1 ≤ i ≤ 5. In each case we evaluate the interpolant\nof f(x) for any given value of x by first finding the segment which contains x and then within that\nsegment applying the particular interpolation procedure indicated. Note your interpolants should\nnot involve evaluations of the function f(x) at points other than the xi, 1 ≤ i ≤ 6, defined above.\n(i) Let (I0f)(x) be the \"piecewise-constant, left endpoint\" interpolant of f based on the segments\nSi, 1 ≤ i ≤ 5. The error in this \"piecewise-constant, left, endpoint\" interpolant at x = 0.3,\ndefined as |f(x = 0.3) - (I0f)(x = 0.3)|, is\n(a) 0\n(b) 0.05\n(c) 0.02\n(d) 0.1\n(e) 0.2\n(ii) Let (I1f)(x) be the \"piecewise-linear\" interpolant of f based on the segments Si, 1 ≤ i ≤ 5.\nThe error in this \"piecewise-linear\" interpolant at x = 0.3, defined as |f(x = 0.3) - (I1f)(x =\n0.3)|, is\n(a) 0\n(b) 0.05\n(c) 0.02\n(d) 0.10\n(e) 0.2\n\n0.5\nS1\nx1 = 0\nS2\nS3\nS4\nS5\nx6 = 1\nx\n1 -x\n0.2\n0.2\nx2 = 0.2\n0.2\nx3 = 0.4\n0.4\nx4 = 0.6\n0.6\nx5 = 0.8\n0.8\n0.6\n0.7\n0.8\n0.9\n0.4\n0.3\n0.2\n0.1\nFigure 1: A plot of the function\n⎧\n⎨ x\nfor 0 ≤ x ≤ 1/2\nf(x) = ⎩ 1 - x for 1/2 < x ≤ 1\n,\nas well as the points xi, 1 ≤ i ≤ 6, and associated segments Si, 1 ≤ i ≤ 5. Note the points xi,\n1 ≤ i ≤ 6, are equidistant, and hence the segments Si, 1 ≤ i ≤ 5, are all the same length 0.2.\n\nZ\nQuestion 3. The function f(x) is defined over the interval 0 ≤ x ≤ 1 by\n⎧\n⎨ x\nfor 0 ≤ x ≤ 1/2\nf(x) =\n.\n⎩ 1 - x for 1/2 < x ≤ 1\nWe also introduce a set of points xi = i-1 , 1 ≤ i ≤ 6, which define segments Si = [xi, xi+1],\n1 ≤ i ≤ 5 (for example, the first segment, S1, is given by 0 ≤ x ≤ 0.20). The function f(x), points\nxi, 1 ≤ i ≤ 6, and segments Si, 1 ≤ i ≤ 5, are depicted in Figure 1.\nWe further define the definite integral\nI =\nf(x) dx .\nIn the below we shall consider two different numerical approximations to this integral , \"rectangle\nrule, left\" and \"trapezoidal rule,\" based on the particular segments Si, 1 ≤ i ≤ 5. Note your\nnumerical approximations should not involve evaluations of the function f(x) at points other than\nthe xi, 1 ≤ i ≤ 6, defined above.\n0, left\n(i) Let Ih\nbe the \"rectangle rule, left\" approximation to the integral I. The error in this\n0, left\n\"rectangle rule, left\" approximation, defined as |I - I\n|, is\nh\n(a) 0\n(b) 0.01\n(c) 0.06\n(d) 0.09\n(e) 0.2\n(ii) Let I1 be the \"trapezoidal rule\" approximation to the integral I. The error in this \"trapezoidal\nh\nrule\" approximation, defined as |I - I1|, is\nh\n(a) 0\n(b) 0.01\n(c) 0.06\n(d) 0.09\n(e) 0.2\nZ\n\nQuestion 4. We consider the differentiation of a very smooth function f(x) by finite differences.\n(The function is very smooth, but not constant -- for example, f(x) might be x ex.) You are given\nthe values of f(x) at three points x1, x2, and x3 which are equi-spaced in the sense that x2 -x 1 = h\nand x3 - x 2 = h; you wish to approximate the first derivative of f at the particular point x = x 2,\nf'( x2).\nThe following finite difference formulas are proposed to approximate f'( x2):\nf( x2) - f( x1)\n(a)\nh\nf( x3) - f( x1)\n(b)\n2h\nf( x3) - f( x2)\n(c)\n2h\nf( x3) - f( x2)\n(d)\nh/2\n(i) Circle all answers which converge to f'( x2) as h tends to zero.\nYou will get full credit for circling all the correct answers and no incorrect answers, propor\ntional partial credit for circling some of the correct answer(s) and no incorrect answers, and\nzero credit if you circle any incorrect answers. (Hint: If the formula gives the wrong result\nfor a linear function f(x) then certainly the formula can not converge to the correct result in\ngeneral.)\n(ii) Mark \"BEST\" next to the answer above which will give the most accurate approximation to\nf'( x2) (for h sufficiently small).\n\nQuestion 5. Consider the Matlab script\nclear\ny = [5,-3,2,7];\nval = y(1);\nfor i = 2:length(y)\n% either && or & will work in the statement below\nif ( (y(i) <= val) && (y(i) >= 0) )\nval = y(i);\nend\nend\nval_save = val\n(i) The first time through the loop, when i = 2, the expression (y(i) <= val) will evaluate to\n(a) (logical) 0\n(b) (logical) 1\n(c) 5\n(d) -3\nwhere logical here refers to the logical data type or class.\n(ii) Upon running the script above (to completion) val_save will have the value\n(a) 5\n(b) -3\n(c) 2\n(d) 7\n\nQuestion 6. Consider the Matlab script\nclear\nx = [1,0,0,2];\ny = [0,2,4,5];\nz = (x.^2) + y;\nind_vec = find( z > 3 );\nr = z(ind_vec);\n(i) This script will calculate z to be\n(a) [1,2,4,7]\n(b) [1,2,4,9]\n(c) [2,2,4,9]\n(d) [1,0,0]\n(ii) This script will calculate ind_vec to be\n(a) [0,0,1,1]\n(b) [0,1,1,0]\n(c) [2,3]\n(d) [3,4]\n(iii) This script will calculate r to be\n(a) [4,7]\n(b) [4,9]\n(c) [3,4]\n(d) [25]\n\nZ\nQuestion 7. We wish to approximate the integral\nI =\nxe x dx\nby two different approaches (A and B) in the script\n% begin script\nclear\nnumpts = 21;\n% number of points in x\nh = 1/(numpts-1);\n% distance between points in x\nxpts = h*[0:numpts-1];\n% points in x\nfval_at_xpts = xpts.*exp(xpts);\nweight_vecA = [0,h*ones(1,numpts-1)];\nweight_vecB = [0.5*h,h*ones(1,numpts-2),0.5*h];\nIA = sum(weight_vecA.*fval_at_xpts);\nIB = sum(weight_vecB.*fval_at_xpts);\n% end script\nThe first approach (A) yields IA; the second approach (B) yields IB. We can readily derive (by\nintegration by parts) that the exact result is I = 1.\nHint: Run the script \"by hand\" for numpts = 3 and draw a picture representing the areas associated\nwith IA and IB. The graph in Figure 2 may prove helpful.\n0.2\n0.4\n0.6\n0.8\n0.5\n1.5\n2.5\nx\nxe\nxe\nx\nx\nx\nx\nFigure 2: A graph of the integrand xe . Note that the second derivative of xe\nis positive for all\nx, 0 ≤ x ≤ 1.\nWe now run the script (for numpts = 21).\nZ\n\n(i) We will obtain\n(a) IA greater than 1\n(b) IA less than 1\n(c) IA exactly equal to 1\nwhere we recall that the exact result is I = 1.\n(ii) We will obtain\n(a) IB greater than 1\n(b) IB less than 1\n(c) IB exactly equal to 1\n(iii) We will find\n(a) abs(IA - 1) less than abs(IB - 1)\n(b) abs(IA - 1) greater than abs(IB - 1)\n(c) abs(IA - 1) equal to abs(IB - 1)\nNote that abs is the Matlab built-in absolute value function: abs(z) returns the absolute\nvalue of z. Hence in (iii) we are comparing the absolute value of error in the two approaches.\n\nAnswer Key\nQ1 (c), (d)\nQ2 (i) (d)\n(ii) (a)\nQ3 (i) (b)\n(ii) (b)\nQ4 (i) (a), (b)\n(ii) (b) is BEST\nQ5 (i) (b)\n(ii) (c)\nQ6 (i) (b)\n(ii) (d)\n(iii) (b)\nQ7 (i) (a)\n(ii) (a)\n(iii) (b)\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n2.086 Numerical Computation for Mechanical Engineers\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Exam",
      "title": "Quiz 1 study guide",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-086-numerical-computation-for-mechanical-engineers-fall-2012/1df8500a393ca6b9507e3ac2e6d24597_MIT2_086F12_quiz1_study.pdf",
      "content": "Quiz 1 Study Guide\n2.086/2.090 Fall 2012\nQuiz 1 will take place on Wednesday, September 26, at 7:30 PM, in Rooms 1-190 and 3-270.\nStudents with last names beginning \"A\" through \"L\" should report to Room 1-190; students with\nlast names beginning \"M\" through \"Z\" should report to Room 3-270.\nQuiz 1 is \"open book\": you may refer to the text and other class materials as well as your\nown notes and scripts; we would also advise you to prepare a short cheat sheet so that you have\nquick access to key material. In Quiz 1 you may not use any computers, tablets, calculators, or\nsmartphones. The quiz will consist exclusively of multiple-choice questions.\nQuiz 1 is on the material of Unit I. In preparation for Quiz 1 you might find the study guide\nbelow useful. You should also review the textbook reading for Unit I, your notes from lecture,\nthe Matlab Exercises Recitation 1 and Recitation 2, as well as the questions in the Unit I Quiz\nQuestion Sampler.\n·\nMatlab:\nData types (in particular, logical and floating point (double)).\nBasic operations on scalars: assignment, arithmetic, relational and logical, flow control (if,\nfor, while).\nStandard constructs such as (incremented) counter variables, (incremented) summation/ac\ncumulation variables, and shuffled recurrence variables.\nSingle-index arrays: assignment, indexing, indirect indexing (in which the index is itself a\nsingle-index array of integers), concatenation, the colon; dotted arithmetic operators; rela\ntional and logical operators.\nKey Matlab built-in functions: basic mathematical functions such as the trigonometric and\nexponential functions; \"data\" creation and manipulation functions such as length, find, sum,\nmax, min, ones, zeros.\n·\nMath and Numerics:\nInterpolation, univariate: piecewise-constant, left (endpoint); piecewise-constant, right (end\npoint); piecewise-linear.\nUnderstand the \"piecewise\" part in which you find the segment in which the point of interest\nx resides; understand the \"constant left, constant right, and linear\" part which determines (i)\nthe functional form of the interpolant within the segment, and (ii) the interpolation points\nat which the interpolant and the function (to be interpolated) must agree.\nIntegration, univariate: rectangle rule, left; rectangle rule, right; rectangle rule, midpoint;\ntrapezoidal.\n\nUnderstand the decomposition over segments as well as the \"rule\" within each segment;\nappreciate the geometric/area picture which corresponds to each rule. Also understand the\nintegration formulas in terms of a sum of [quadrature weights × function values at quadrature\npoints].\nDifferentiation, univariate: first derivative (forward difference, backward difference, cen\ntered difference); second derivative (centered difference).\nUnderstand the points at which the function is evaluated, the point at which the derivative\nis approximated, and the specific \"finite difference\" formula.\nBasic Concepts and Attributes: accuracy, convergence, convergence rate and order,\nsmoothness, resolution, computational cost, memory. These concepts are applicable to inter\npolation, integration, and differentiation.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n2.086 Numerical Computation for Mechanical Engineers\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Exam",
      "title": "MIT2_086F12_quiz4_samples.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-086-numerical-computation-for-mechanical-engineers-fall-2012/ded4333b1b94703255f4b8811e999db6_MIT2_086F12_quiz4_study.pdf",
      "content": "Quiz 4 Study Guide\n2.086/2.088 Fall 2012\nQuiz 4 will take place on Wednesday, 5 December, starting promptly at 7:30 PM, in Rooms\n1-190 and 3-270. Students with last names beginning \"A\" through \"L\" should report to Room\n1-190; students with last names beginning \"M\" through \"Z\" should report to Room 3-270. You\nwill be given 90 minutes to complete the quiz.\nQuiz 4 will be \"open book\": you may refer to the textbook and other class materials as well\nas your own notes and scripts. You will not need a calculator for Quiz 4; however you can use a\ncalculator, if you like, in order to check simple arithmetic operations. As always, laptops, tablets,\nand smartphones are not permitted. The quiz is entirely multiple-choice questions.\nQuiz 4 is focused on the material of Unit V. In preparation for Quiz 4 you should find the\nstudy guide/summary below useful. You should also review the Unit V textbook reading, your\nlecture notes, and the Matlab Exercises Rec10 11. You are also encouraged to take the Unit V\nQuiz Question Sampler \"practice quiz.\"\nMatlab:\nThe main new material is creation, inspection, and manipulation of sparse matrices: the\nnotion of \"declared sparse\"; Matlab built-in functions such as spalloc, sparse, issparse,\nnnz, spy, and full; Matlab sparse matrix storage; sparse matrix and vector operations;\nsparse backslash (for sparse Gaussian Elimination and Back Subsitution). You should under\nstand the effect on operation counts both of the number of nonzero entries in a matrix and\nof whether the matrix is declared sparse or not. Also, understand the use of tic and toc for\ntiming operations. Finally, recall from Unit III the Matlab built-in function inv for the evil\ninverse.\nMath & Numerics:\nExistence and uniqueness of solutions to linear systems of n equations in n unknowns: row\nview; column view; the three possibilities (the solution exists and is unique; the solution exists\nbut is not unique; the solution does not exist); the various conditions confirmation of which\nassure a unique solution; infinite families of solutions in the non-unique case.\nYou should be prepared to do \"by hand\" calculations, including verification of general\nsolutions in the non-unique case, for n = 2 (two equations in two unknowns) and n = 3 (three\nequations in three unknowns). Note for the case of n = 3 we will restrict attention to matrices\nA with relatively simple columns and hence correspondingly simple calculations.\nSpring-mass problems: Hooke's law; derivation of equilibrium (force balance) equations; ma\ntrix formulation of the equilibrium equations as Ku = f; the origins of sparsity in \"local\ninteractions\" between nearest neighbors.\nSymmetric Positive Definite (SPD) matrices: definition of S (Symmetry) and PD (Positive\nDefiniteness); relation of the quadratic form (1/2)uTKu to the potential (elastic) energy in a\nspring system; implications for Gaussian Elimination (see below).\nGaussian Elimination and Back Substitution for Au = f: pivots and row operations; con\nstruction of U and fˆ from A and f; back substitution to obtain u from U and fˆ; operation\n\ncounts for general matrices. Note you should be comfortable both with the general concepts\nand with \"by hand\" calculation for small systems (i.e., n = 2 or n = 3).\nSparse storage and operation counts for matrix and vector operations, such as the matrix\nvector product.\nGaussian Elimination and Back Substitution for sparse matrices: sparsity and fill-in (in U\nduring the Gaussian Elimination process); storage requirements; operation counts (and hence\ntimings); the special cases of tridiagonal and pentadiagonal matrices; cyclic springs and re\nlated systems.\nYou should understand that row permutations (\"pivoting\" or \"partial pivoting\") are\nsometimes required for numerical stability, and that column permutations (reordering of un\nknowns) can be electively pursued to reduce fill-in and improve computational performance.\nFor SPD systems stability is ensured and no pivoting is required; however, even for SPD sys\ntems, often column permutations are performed to improve efficiency -- and then similar row\npermutations are also affected to preserve symmetry (and positive definiteness) and hence\nstability. Note on the quiz, we will always give you SPD matrices and furthermore we will\nnever consider either row permutations or column permutations -- Gaussian Elimination and\nBack Substitution will always be performed (by you or Matlab) on the matrix \"as given.\"\nThe Evil Inverse (of A): definition of the matrix inverse; physical interpretation of the columns\nof A-1; non-sparsity of A-1; solution of Au = f as u = A-1f; operation counts and timings (in\nparticular, comparisons with sparse Gaussian Elimination and Back Substitution for solution\nof sparse linear systems).\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n2.086 Numerical Computation for Mechanical Engineers\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Exam",
      "title": "Quiz 2 sample problems with solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-086-numerical-computation-for-mechanical-engineers-fall-2012/d054b4777ed6ded1b090a88f72e15aec_MIT2_086F12_quiz2_samples.pdf",
      "content": "Unit II Quiz Question Sampler\n2.086/2.090 Fall 2012\nYou may refer to the text and other class materials as well as your own notes and scripts.\nFor Quiz 2 (on Unit II) you will need a calculator (for arithmetic operations and standard func\ntions); note, however, that laptops, tablets, and smartphones are not permitted.\nTo simulate real quiz conditions you should complete all the questions in this sampler in 90 minutes.\nNAME\nThere are a total of 100 points: five questions, each worth 20 points.\nAll questions are multiple choice; in all cases circle one and only one answer.\nWe include a blank page at the end which you may use for any derivations, but note that we do\nnot refer to your work and in any event your grade is determined solely by your multiple choice\nselections.\nYou may assume throughout this quiz that all arithmetic operations are performed exactly (with no\nfloating point truncation or round-off errors). We may display the numbers in the multiple-choice\noptions to just a few digits, however you should always be able to clearly discriminate the correct\nanswer from the incorrect answers.\n\nQuestion 1 (20 points). In this question we consider a discrete random variable X which can take\non three values, -1 or 0 or 1, according to the probability mass function fX (x) given by\n⎧\n⎨ 1/3 x = -1\nfX (x) =\n1/3 x = 0\n.\n(1)\n⎩ 1/3 x = 1\nWe recall that fX (x) is the probability that the random variable X takes on the value x. We also\nconsider a second random variable Y which is a function of X: Y = X2, or equivalently\n0 if X = 0\nY =\n.\n(2)\n1 if X = -1 or X = 1\nNote that Y can take on only two values, either 0 or 1.\n(i) (6 points) The mean of X is\n(a) -1/6\n(b) 0\n(c) 1/2\n(d) 2/3\n(e) 1\n(ii) (6 points) The standard deviation of X is\n(a) 1\n(b) 0.4714\n(c) 0\n(d) 0.8165\n(e) 0.5000\nNote we are asking for the standard deviation, not the variance.\n\n(iii) (4 points) The mean of Y is\n(a) -1/6\n(b) 0\n(c) 1/2\n(d) 2/3\n(e) 1\n(iv) (4 points) The standard deviation of Y is\n(a) 1\n(b) 0.4714\n(c) 0\n(d) 0.8165\n(e) 0.5000\nNote we are asking for the standard deviation, not the variance.\n\nQuestion 2 (20 points). Victory in a football game can be affected by which team wins the coin\nflip (also known as the coin toss). We consider the case of a particular team, say the New England\nPatriots. We denote by COIN a random \"variable\" which represents the result of the coin flip.\nThe random variable COIN can take on two \"values\" (or outcomes): COIN = WIN FLIP -- the\nPatriots win the coin flip; COIN = LOSE FLIP -- the Patriots lose the coin flip. We denote by\nFINAL a random \"variable\" which represents the result of the game. The random variable FINAL\ncan take on two \"values\" (or outcomes): FINAL = WIN GAME -- the Patriots win the game;\nFINAL = LOSE GAME -- the Patriots lose the game.\nYou are given the following conditional probabilities: P(FINAL = WIN GAME | COIN = WIN FLIP)\n= 0.92; P(FINAL = WIN GAME | COIN = LOSE FLIP) = 0.82. We shall further assume that\nthe coin is \"fair\": we are given the marginal probability P(COIN = WIN FLIP) = 0.50. (Note\nthat the data for this problem is entirely fictitious, and of course our model is very simplistic.)\n(i) (8 points) The marginal probability P(FINAL = WIN GAME) is\n(a) 0.50\n(b) 0.92\n(c) 0.87\n(d) 0.82\n(ii) (6 points) The conditional probability P(COIN = LOSE FLIP | FINAL = WIN GAME) is\n(a) 0.080\n(b) 0.820\n(c) 0.471\n(d) 0.446\n\n(iii) (6 points) Over the course of many seasons and hence may games in what fraction (expressed\nas a percentage) of the total games played do the Patriots lose the coin flip and win the game\n(i.e., both events occur)? (For example, if the Patriots play 100 games, and in 20 of these\ngames the Patriots lose the coin flip and win the game, then the fraction is 20%.)\n(a) 87%\n(b) 47%\n(c) 41%\n(d) 50%\nYou should choose the answer which is most likely (in the limit of many games). Hint:\nConsider the appropriate joint probability and then apply the frequentist interpretation of\nprobabilities.\n\nQuestion 3 (20 points) A company manufactures a widget which contains a hole for a wire bundle.\nThe customer will accept the widgets only if at least 98% of the (many) widgets delivered have\na hole radius r greater than 0.1 cm. The widget company decides to a perform a test prior to\nshipment to the customer.\nA quality control engineer at the widget company draws a random sample of n = 2000 (independent)\nwidgets and proceeds to measure the hole radius of each widget. It is found that, of these 2000\nrandomly chosen widgets, 1990 of the widgets do indeed have a hole radius greater than 0.1 cm;\nthe remaining 10 widgets have a hole radius less than (or equal to) 0.1 cm.\nTo model this situation we introduce a Bernoulli random variable B: a hole radius R less than\nor equal to 0.1 cm is encoded as a 0 and occurs with probability 1 - θ; a hole radius R greater\nthan 0.1 cm is encoded as a 1 and occurs with probability θ. Here R is the random variable which\nrepresents the hole radius which in turn determines the Bernoulli random variable.\n(i) (8 points) Based on the experimental data from the sample of n = 2000 widgets, the sample\nmean estimate for θ is\n(a) 0.950\n(b) 0.995\n(c) 0.980\n(d) 0.005\n(ii) (8 points) Based on the experimental data from the sample of n = 2000 widgets, the (two-\nsided) normal-approximation confidence interval for θ at confidence level γ = 0.95 is given\nby\n(a) [0.8568, 1.1332]\n(b) [0.9934 ,0.9966]\n(c) [0.9919, 0.9981]\n(d) can not be evaluated as the normal-approximation criteria are not satisfied\n(iii) (4 points) From your result of part (ii) can you conclude with confidence level 0.95 that 98% of\nthe (very many) widgets delivered to the customer will have hole radius greater than 0.1 cm?\n(a) Yes\n(b) No\nNote you may assume here that our random model for the widget hole radius R and hence\nBernoulli variable B is valid (as only in this case can you make rigorous statistical inferences).\n\nQuestion 4 (20 points). Consider the following Matlab script\n% begin script\nclear\n% note we \"clear\" the workspace,\n% and hence no variables are shared between the different scripts in this quiz\nn = 10000; % number of random darts\nu1 = rand(1,n);\nu2 = rand(1,n);\nx1 = 1 + u1;\nx2 = 3*u2;\nmultfac = 2.0;\nnuminside = sum( x2 <= f_of_x(x1,multfac) );\narea_estimate = (numinside/n)*3.0;\n% end script\nand function f_of_x\nfunction [value] = f_of_x(x,const)\nvalue = zeros(1,length(x));\nfor i = 1:length(x)\nvalue(i) = const/x(i);\nend\nreturn\nend\nfor approximating an area AD of a domain D by the Monte Carlo method. In the limit that n\ntends to infinity, area_estimate will approach AD.\n\n(i) (10 points) Each of the bivariate uniform random variates (realizations of random variables\nfrom the bivariate uniform density) (x1(i),x2(i)), i = 1, . . . , n, resides in the rectangle\n(a) 0 ≤ x1(i) ≤ 1, 0 ≤ x2(i) ≤ 3\n(b) 0 ≤ x1(i) ≤ 1, 0 ≤ x2(i) ≤ 2\n(c) 1 ≤ x1(i) ≤ 2, 0 ≤ x2(i) ≤ 3\n(d) 1 ≤ x1(i) ≤ 2, 0 ≤ x2(i) ≤ 2\n(ii) (10 points) The area AD is given by\n(a) 2.000\n(b) 0.693\n(c) 1.387\n(d) 3.000\nHint: draw a sketch in which you indicate the rectangle over which x1,x2 is defined (i.e.,\nat which you throw your darts); then include in your sketch the domain D defined by the\nconditional x2 <= f_of_x(x1,multfac); finally, recall the area interpretation of the definite\nintegral (and perform the integral) to determine AD.\n\nQuestion 5 (20 points). Consider the following Matlab script\n% begin script\nclear\n% note we \"clear\" the workspace,\n% and hence no variables are shared between the different scripts in this quiz\nn = 100000; % number of random darts\nu1 = rand(1,n);\nu2 = rand(1,n);\nx = 10*u1;\ny = u2;\nx_exp = [];\nfor i = 1:n\nif( y(i) <= EXPR1 )\n% EXPR1 to be chosen below\nx_exp = EXPR2;\n% EXPR2 to be chosen below\nend\nend\n% end script\nwhich is intended to provide random variates from the exponential density function, fX (x) = e-x ,\n0 ≤ x ≤ 10, based on the acceptance-rejection method. (The \"true\" exponential density can\nactually take on any value x over 0 ≤ x ≤inf. However, e-10 is extremely small, so we can just\nconsider a truncated interval 0 ≤ x ≤ 10.)\n(i) (5 points) The expression EXPR1 should be\n(a) n\n(b) exp(-x(i))\n(c) exp(-y(i))\n(d) x(i)\n\n(ii) (5 points) The expression EXPR2 should be\n(a) [x_exp,x(i)]\n(b) [x_exp,y(i)]\n(c) [x_exp,exp(-y(i))]\n(d) [x_exp,exp(-x(i))]\n(iii) (5 points) We would expect length(x_exp) to be roughly\n(a) 10000 (i.e., ten thousand)\n(b) 1000 (i.e., one thousand)\n(c) 10000/e (i.e., ten thousand divided by e)\n(d) 10\n(iv) (5 points) A histogram of the data x_exp (Figure 1, next page) would produce the plot given\nby\n(a) Figure 1(a)\n(b) Figure 1(b)\n(c) Figure 1(c)\n(d) Figure 1(d)\n(Of course the histogram will depend on the particular realization. However, you can deduce\nwhich three histograms are either impossible or extremely unlikely, and hence identify the\ncorrect answer.)\n\nfrequency\nfrequency\n(a)\n(b)\n-30\n-20\n-10\nfrequency\nfrequency\n(c)\n(d)\nFigure 1: Candidate histograms. Note \"frequency\" here refers to the number of variates that take\non a value in a given bin (there are 50 bins, and hence for example in Figure 1(b) the first bin is\ndefined as 0 ≤ x < 10/50(= .2)).\n\nAnswer Key\nQ1 (i) (b) 0\n(ii) (d) 0.8165\n(iii) (d) 2/3\n(iv) (b) 0.4714\nQ2 (i) (c) 0.87\n(ii) (c) 0.471\n(iii) (c) 41%\nQ3 (i) (b) 0.995\n(ii) (c) [0.9919, 0.9981]\n(iii) (a) Yes\nQ4 (i) (c) 1 ≤ x1(i) ≤ 2, 0 ≤ x2(i) ≤ 3\n(ii) (c) 1.387\nQ5 (i) (b) exp(-x(i))\n(ii) (a) [x_exp,x(i)]\n(iii) (a) 10000\n(iv) (d) Figure 1(d)\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n2.086 Numerical Computation for Mechanical Engineers\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Exam",
      "title": "Quiz 2 study guide",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-086-numerical-computation-for-mechanical-engineers-fall-2012/af7466045e74fea9c9a40b13b49e97be_MIT2_086F12_quiz2_study.pdf",
      "content": "Quiz 2 Study Guide\n2.086/2.090 Fall 2012\nNOTE: Quiz 2 requires a CALCULATOR; please bring a calculator with you to the quiz.\nQuiz 2 will take place on Wednesday, October 10, at 7:30 PM, in Rooms 1-190 and 3-270.\nStudents with last names beginning \"A\" through \"L\" should report to Room 1-190; students with\nlast names beginning \"M\" through \"Z\" should report to Room 3-270. You will be given 90 minutes\nto complete the quiz.\nQuiz 2 will be \"open book\": you may refer to the text and other class materials as well as your\nown notes and scripts. You will need a calculator (for arithmetic operations and simple functions)\nfor Quiz 2; note, however, that laptops, tablets, and smartphones are not permitted. The quiz will\nconsist exclusively of multiple-choice questions.\nQuiz 2 is on the material of Unit II. In preparation for Quiz 2 you might find the study guide\nbelow useful. You should also review the textbook reading for Unit II, your notes from lecture,\nthe Matlab Exercises Recitation 3 and Recitation 4, as well as the questions in the Unit II Quiz\nQuestion Sampler. On Quiz 2 you are not responsible for the material of Chapter 11 of the text\n(on statistical estimation for the parameters of the normal density), however you are responsible\nfor the material in Chapter 9 and Chapter 10 related to the normal density.\nMatlab: (Note that your Matlab knowledge should be cumulative; we list below only the\nnew aspects introduced in Unit II.)\nDouble-index arrays (assignment, indexing, dotted arithmetic operators). User-defined func\ntions (syntax, inputs, outputs). The Matlab built-in's zeros, eye, and ones and in partic\nular rand and randn.\nMath and Numerics:\nFrequentist view of probabilities and probability distributions. Collectively exhaustive events,\nmutually exclusive events, and corresponding probability \"rules.\"\nRandom variables (discrete and continuous); probability mass functions and probability den\nsity functions.\nMean, variance, and standard deviation.\nRandom vectors: conditional probabilities, marginal probabilities, and joint probabilities.\nIndependence.\nBayes Theorem (with particular emphasis on the case of two random variables each of which\ncan take on two outcomes).\nFunctions (and transformations) of random variables and random vectors.\nThe Bernoulli discrete random variable (r.v.): 0 and 1 outcomes; probability mass function;\nsignificance of the parameter θ; interpretation as coin flips; mean and variance and standard\ndeviation as a function of θ.\n\nThe binomial r.v.: definition as a sum of n independent Bernoulli coin flips; outcome tables\nand probabilities; shape of the probability mass function.\nThe univariate and bivariate uniform (continuous) r.v.: probability density; interpretation of\nprobability as relative area; generation over any interval or (by independence) rectangle using\nthe rand function and affine transformation (scale and shift).\nThe univariate normal density (continuous) r.v.: shape and properties; mean μ and standard\ndeviation σ; generation of normal r.v. realizations for any μ and σ using the randn function\nand affine transformation (scale and shift).\nGeneration of random variates (realizations of random variables) by the acceptance-rejection\napproach: correct choice of a bounding rectangle; random darts; criterion for accepting or\nrejecting a dart according to the y position of the dart relative to the probability density\nfunction fX (x); efficiency of the approach in terms of fraction of random darts accepted.\nBernoulli estimation: sample mean estimate θˆn for the parameter θ; (two-sided) normal-\napproximation confidence intervals [lower limit, upper limit] for θ; criteria for validity of\nnormal-approximation confidence intervals; relationship between confidence level γ and zγ ,\nand the particular value of zγ for the confidence level γ = 0.95; confidence interval Half\nLength and RelErr; dependence on sample size n.\nMonte Carlo area estimation (of a region D): random darts from the uniform distribution over\na bounding rectangular region R; relationship between random darts and a Bernoulli \"inside\nD\" random variable B; relationship between the area of the region D (and the known area\nof the rectangle R) and the Bernoulli parameter θ; estimation of the area of D by estimation\nof the Bernoulli parameter θ.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n2.086 Numerical Computation for Mechanical Engineers\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Exam",
      "title": "Quiz 3 sample problems with solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-086-numerical-computation-for-mechanical-engineers-fall-2012/6b7c4883b61358d63198615055ffb456_MIT2_086F12_quiz3_samples.pdf",
      "content": "Unit III Quiz Question Sampler\n2.086/2.090 Fall 2012\nYou may refer to the text and other class materials as well as your own notes and scripts.\nFor Quiz 3 (on Unit III) you will need a calculator (for arithmetic operations and standard func\ntions); note, however, that laptops, tablets, and smartphones are not permitted.\nTo simulate real quiz conditions you should complete all the questions in this sampler in 90 minutes.\nNAME\nThere are a total of 100 points: five questions, each worth 20 points.\nAll questions are multiple choice; in all cases circle one and only one answer.\nWe include a blank page at the end which you may use for any derivations, but note that we do\nnot refer to your work and in any event on the quiz your grade will be determined solely by your\nmultiple choice selections.\nYou may assume that all arithmetic operations are performed exactly (with no floating point\ntruncation or round-off errors). We may display the numbers in the multiple-choice options to just\na few digits, however you should always be able to clearly discriminate the correct answer from the\nincorrect answers.\n\nQuestion 1 (20 points)\nYou are given a matrix u of size 4 × 1,\n⎞\n⎛\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎠\nu =\n,\nin Matlab u = [2;1;1;1], and a second matrix v of size 4 × 1,\n⎛ 1\n⎞\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎠\nv =\n,\nin Matlab v = [0.5;1;0;0]. Here the size of a matrix, m × n, refers to the number of rows (m)\nand number of columns (n) in the matrix. (In order to avoid any ambiguity we shall refer solely to\nmatrices in this question, although of course some of the entities are vectors.)\nWe now perform the matrix-matrix product \"u times vT,\"\nw = u(v T) ,\n(1)\nwhere recall that T denotes transpose.\n(i) (3 points) The size of the matrix w is\n(a) 1 × 1\n(b) 1 × 4\n(c) 4 × 4\n(d) 4 × 1\n(ii) (3 points) The operation of equation (1) is implemented in Matlab as\n(a) w = u.*v\n(b) w = v.*u\n(c) w = u'*v\n(d) w = u*v'\n\n(iii) (4 points) The value of w(1,1) is\n(a) 0.5\n(b) 1.0\n(c) 2.5\n(d) 2.0\nWe now perform the matrix-matrix product \"uT times v,\"\nz = (u T)v ,\n(2)\nwhere again T denotes transpose.\n(iv) (3 points) The size of the matrix z is\n(a) 1 × 1\n(b) 1 × 4\n(c) 4 × 4\n(d) 4 × 1\n(v) (3 points) The operation of equation (2) is implemented in Matlab as\n(a) z = u.*v\n(b) z = v.*u\n(c) z = u'*v\n(d) z = u*v'\n(vi) (4 points) The value of z(1,1) is\n(a) 0.5\n(b) 1.0\n(c) 2.5\n(d) 2.0\n\nQuestion 2 (20 points)\nWe run the script\n% begin script\nclear\nn = 1000;\nA = zeros(1000,1000);\nA(400,404) = 1.0;\nA(678,2) = 8.0;\nA(678,999) = 4.0;\nA(705,678) = 2.0;\nA(705,999) = 10.0;\nw = ones(1000,1);\nv = A*w;\n% end script\nNote that A is a 1,000 × 1,000 matrix with only five non-zero entries, and that w is a 1,000 × 1\nvector of all ones.\n(i) (5 points) The value of v(678) is\n(a) 0\n(b) 8\n(c) 12\n(d) 14\nHint: Consider the \"row interpretation\" of the matrix-vector product.\n(ii) (5 points) The value of v(999) is\n(a) 0\n(b) 8\n(c) 12\n(d) 14\nHint: Consider the \"row interpretation\" of the matrix-vector product.\n\nWe (now clear all variables and) define a 1,000 5 matrix B (in Matlab, B) and a 5 1 vector\n×\n×\nw (in Matlab, w) as\n⎞\n⎛\nB =\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎝\n1 2 3 4 5\n1 2 3 4 5\n1 2 3 4 5\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎠\n,\nw =\n⎞\n⎛\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎠\n,\n-1\n(the jth column of B consists of \"all j's\"). We then evaluate\nv = Bw\nand find the maximum of the vector v as\nM =\nmax vi .\n(3)\n1≤i≤1000\nIf you wish to see the corresponding Matlab script, refer to Appendix A at the end of the sampler.\n(iii) (10 points) The value of M from equation (3) is\n(a) -2\n(b) 0\n(c) 2\n(d) 4\n(e) 5\nHint: Consider the \"column interpretation\" of the matrix-vector product.\n\nQuestion 3 (20 points)\nWe consider linear regression for a particular simple case: a single independent variable (p = 1),\nwhich we denote x; as always, a single dependent variable, y; a model with only n = 2 terms,\nYmodel(x; β) = β0 + β1x ,\n(4)\n(hence h0(x) = 1, h1(x) = x); and m = 3 noisy measurements given by (x1 = 0, Y1 = 0),\n(x2 = 1, Y2 = 0), (x3 = 2, Y3 = 2). We denote by Y the 3 × 1 column vector (0 0 2)T, and by β\nthe 2 × 1 column vector (β0 β1)T .\n(i) (3 points) The \"regression matrix\" X is given by\n\n(a)\n⎛\n⎞\n⎝\n⎠\n(b)\n⎛\n⎞\n⎝\n⎠\n(c)\n\n(d)\nRecall that (Xβ)i (the ith component of the vector Xβ) is equal to Ymodel(xi; β) for the measurement\npoints xi, i = 1, 2, 3.\n(ii) (3 points) The equation\nXβ = Y\n(5)\nhas, for our particular (noisy) measurements and hence Y vector (0 0 2)T indicated above,\n(a) no solution for β\n(b) a unique solution for β\n(c) many solutions for β\nHint: Consider the relationship of equation (5) to the problem of putting a straight line\nthrough three points; plot the experimental data (xi, Yi), i = 1, 2, 3.\n\n(iii) (5 points) The matrix XTX is given by\n⎛\n⎞\n(a) ⎝ 1\n3 ⎠\n(b)\n⎛\n⎞\n⎝\n⎠\n(c)\n(d)\n(iv) (4 points) The matrix XTY is given by\n(a)\n(b)\n(c)\n⎛\n⎞\n⎝\n⎠\n(d)\n(v) (5 points) The least squares solution βˆ to our problem is\n(a) βˆ0 = -0.3333 , βˆ1 = 1.0\n(b) βˆ0 = -0.1667 , βˆ1 = 1.5\n(c) βˆ0 = 0 , βˆ1 = 1.0\n(d) βˆ0 = -0.5 , βˆ1 = 1.2\n(Recall that the least-squares solution βˆ is the particular β which minimizes the norm of the\nresidual squared (i.e., IY - XβI2).)\nHint: Recall the simple formula for the inverse of a 2 × 2 matrix.\n\nQuestion 4 (20 points)\nA naturalist studying a pair of geese devises a camouflaged scale to provide weight data for each\nof the geese (henceforth denoted Goose 1 and Goose 2). Sometimes a single goose will walk onto\nthe scale but on other occasions both geese walk onto the scale at the same time. On a given day\nthe naturalist records in the logbook\nObservation 1: Goose 1 on scale; scale transducer indicates 12.3 kilos.\nObservation 2: Goose 1 and Goose 2 on scale; scale transducer indicates 26.3 kilos.\nObservation 3: Goose 2 on scale; scale transducer indicates 13.1 kilos.\nWe wish to infer from this data a good estimate for the weights of each of the geese.\nIn what follows we shall denote by W1 the weight of Goose 1 (in kilos) and by W2 the weight of\nGoose 2 (in kilos); we further denote by W the 2 × 1 vector\nW1\nW ≡\n.\n(6)\nW2\nWe further define the 3 × 1 vector of scale readings\n⎛\n⎞\n12.3\n⎝\n⎠\nS ≡\n26.3\n(7)\n13.1\n(where again the units are kilos). The naturalist's three observations above can be summarized as\nBW = S + E,\n(8)\nwhere B is a matrix and E is a 3 × 1 noise vector. We shall assume that the noise vector E (in\nkilos) relates to transducer error and does not depend on the weight on the scale.\n(i) (8 points) The matrix B is given by\n⎛\n⎞\n12.3\n⎝\n⎠\n(a)\n26.3 26.3\n13.1\n⎛\n⎞\n⎝\n⎠\n(b)\n⎛\n⎞\n12.3\n-1\n(c) ⎝ 26.3 26.3 -2 ⎠\n13.1 -1\n⎛\n⎞\n(d) ⎝ 1 -1 ⎠\n(ii) (4 points) The matrix equation (system of linear equations) BW = S has\n\n(a) a unique solution for W\n(b) no solution for W\n(c) many solutions for W\nˆ\n(iii) (8 points) The weight vector W which\nminimizes the norm of the residual squared, IS - BW I2, over all vectors W\nsatisfies the linear system of equations\n2 1\n12.3\n(a)\n1 2\nW =\n26.3\n2 1\n38.6\n(b)\n1 2\nW =\n39.4\n1 0\n12.3\n(c)\n1 1\nW =\n26.3\n1 0\n38.6\n(d)\n1 1\nW =\n39.4\n\nQuestion 5 (20 points)\nThe average skin friction coefficient (nondimensional and positive), Cf , for a turbulent boundary\nlayer depends on the Reynolds number (nondimensional and positive), Re, as\nCf = α(Reρ) ,\n(9)\nwhere α and ρ are unknown constants (i.e., which do not depend on Re). Note that α is a positive\nmultiplicative factor and ρ is the exponent of Re. The above form would lead to a nonlinear\nregression problem. We thus define y = log(Cf ) and x = log(Re) such that now y may be expressed\nas y = Ymodel(x; β) with\nYmodel(x; β) = β0 + β1x\n(10)\nfor β0 and β1 independent of x. Here log refers to the natural logarithm (with corresponding\nMatlab built-in function log). This form, you will agree, is amenable to linear regression analysis.\nWe shall assume that the model of equation (10) is bias-free: there exists a unique βtrue ≡\n(βtrue βtrue)T such that equation (10) exactly predicts log(Cf ).\nWe further provide m×1 arrays xpts (values of log(Re)) and Y (values of log(Cf )) corresponding to\n(noisy) measurements (xpts(i), Y(i)), 1 ≤ i ≤ m, for m = 52. We assume that the measurements\nare given by\nY(i) = Ymodel(xpts(i); βtrue) + E(i),\n1 ≤ i ≤ m ,\nwhere the noise E(i) satisfies our assumptions N1, N2, and N3 (normal zero-mean, homoscedastic\nwith standard deviation σ, uncorrelated in x).\nWe now run the script∗\n% begin script\nm = 52;\nX = [ones(m,1), xpts];\nbetahat = X \\ Y;\n% end script\n(i) (5 points) Based on the regression analysis above, our estimate for α is\n(a) betahat(1)\n(b) exp(betahat(1))\n(c) log(betahat(1))\n(d) -betahat(1)\nwhere exp is the Matlab built-in exponential function.\nHint: Consider the log transformation of equation (9) to equation (10).\n∗ Note that prior to running the script the Matlab workspace contains only xpts and Y.\n\n(ii) (5 points) Based on the regression analysis above, our estimate for ρ is\n(a) betahat(2)\n(b) exp(betahat(2))\n(c) log(betahat(2))\n(d) -betahat(2)\nHint: Consider the log transformation of equation (9) to equation (10).\n(iii) (5 points) We now calculate, based on the data provided, joint 0.95-confidence-level confidence\nand βtrue\njoint\njoint\njoint\nintervals for βtrue\n, I\nand I\n, respectively. We obtain for I\n(the confidence\ninterval for βtrue) the interval [-0.1560, -0.1262]. With confidence level 0.95 we may then\nconclude that (over the range of Re covered by the experimental data)\n(a) Cf increases with increasing Re\n(b) Cf decreases with increasing Re\n(c) Cf is independent of Re\n(d) Cf is always negative\n(iv) (5 points) The length of the confidence interval of Question 5(iii) is deemed too large and\nhence the accuracy of our βtrue estimate potentially too low. To remedy the situation you\nshould\nnew\n(a) increase the number of measurements from m = 52 to m\n(> m), and then re-perform\nthe regression analysis\n(b) retain the m = 52 measurements but replace the model of equation (10) (which has\nn = 2 terms) by a new model (which has n = 52 terms)\nY new\nj\n51) ,\nβj x\n(= β0 + β1x + · ·\nmodel(x; β) =\n· + β51x\nj=0\nand then re-perform the regression analysis\n\nAppendix A\nMatlab Script for Question 2(iii)\n% begin script\nclear\nm = 1000;\nB = zeros(1000,5);\nfor i = 1:m\nfor j = 1:5\nB(i,j) = j;\nend\nend\nw = zeros(5,1);\nw(3) = 1.0;\nw(5) = -1.0;\nv = B*w;\nM = max(v);\n% end script\nwhere max is the Matlab built-in function which returns the maximum of a vector.\n\nAnswer Key\nQ1 (i) (c) 4 × 4\n(ii) (d) w = u*v'\n(iii) (b) 1.0\n(iv) (a) 1 × 1\n(v) (c) z = u'*v\n(vi) (d) 2.0\nQ2 (i) (c) 12\n(ii) (a) 0\n(iii) (a) -2\n⎛\n⎞\nQ3 (i) (b) ⎝ 1\n1 ⎠\n(ii) (a) no solution for β\n(iii) (b)\n(iv) (c)\n(v) (a) βˆ0 = -0.3333, βˆ1 = 1.0\n⎛\n⎞\n⎝\n⎠\nQ4 (i) (b)\n(ii) (b) no solution for W\n38.6\n(iii) (b)\nW =\n,\n39.4\nQ5 (i) (b) exp(betahat(1))\n(ii) (a) betahat(2)\n(iii) (b) Cf decreases with increasing Re\n(iv) (a) increase the number of measurements\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n2.086 Numerical Computation for Mechanical Engineers\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Exam",
      "title": "Quiz 3 study guide",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-086-numerical-computation-for-mechanical-engineers-fall-2012/03772ce90bc882104f07559ffd0eb253_MIT2_086F12_quiz3_study.pdf",
      "content": "Quiz 3 Study Guide\n2.086/2.090 Fall 2012\nNOTE: Quiz 3 requires a CALCULATOR; please bring a calculator with you to the quiz.\nQuiz 3 will take place on Wednesday, 24 October, starting promptly at 7:30 PM, in Rooms\n1-190 and 3-270. Students with last names beginning \"A\" through \"L\" should report to Room\n1-190; students with last names beginning \"M\" through \"Z\" should report to Room 3-270. You\nwill be given 90 minutes to complete the quiz.\nQuiz 3 will be \"open book\": you may refer to the text and other class materials as well as your\nown notes and scripts. You will need a calculator (for simple arithmetic operations and simple\nfunctions) for Quiz 3. However, laptops, tablets, and smartphones are not permitted. The quiz is\nentirely multiple-choice questions.\nQuiz 3 is on the material of Unit III. In preparation for Quiz 3 you should find the study\nguide/summary below useful. You should also review the textbook reading for Unit III, your notes\nfrom lecture, the Matlab Exercises Recitation 5 and Recitation 6, as well as the questions in the\nUnit III Quiz Question Sampler.\nNote we will not ask you on the quiz to calculate any confidence intervals (this aspect of Unit\nIII will be covered in Problem Set 3). However, we may well ask you on the quiz to interpret\nconfidence intervals, relate confidence intervals to conclusions about the regression coefficients β,\nand appreciate that the confidence intervals shrink as we increase the number of measurements.\nMatlab: (Note that your Matlab knowledge should be cumulative; we list below the new\naspects introduced in Unit III).\nMatrix and vector operations: inner product, norm (and corresponding Matlab built-in\nnorm), transpose (the Matlab ' operator), inv (Matlab built-in to find inverse matrix),\neye (Matlab built-in for identity matrix), matrix vector product, matrix matrix product.\nThe distinction between dotted operators and un-dotted operators.\nFormation of regression matrix X in terms of columns.\nThe Matlab backslash: application to solution of a system of linear equations; application\nto solution of least squares problems.\nLinear Algebra Operations:\nVectors and matrices: definition; rows and columns of a matrix; a matrix as n m×1 (column)\nvectors or m 1 × n (row) vectors; the transpose operation.\nVector operations (and associated rules): scaling; addition; the inner product.\nMatrix operations (and associated rules): scaling; addition; and multiplication.\nRequirements for matrix multiplication: agreement on inner dimension.\nRules for matrix multiplication: ABC = A(BC) = (AB)C, A(B + C) = AB + AC, (AB)T =\nBTAT, but in general AB does NOT equal BA (even if both products can be formed).\n\nMatrix vector products in terms of both the row interpretation (see page 222 of text) and the\ncolumn interpretation (page 223 of text).\nFormulation of a system of m equations in n unknowns in terms of a matrix equation (e.g.,\nBz = g, for B an m × n matrix, z a n × 1 vector (the \"unknown\"), and g an m × 1 vector).\nDefinition of the identity matrix I. Definition of the inverse matrix for a non-singular matrix\nA: A-1A = AA-1 = I; formula for the inverse of a 2 × 2 non-singular matrix.\nSuggestion: Practice vector and matrix operations \"by hand\" for small systems (e.g., for\nmatrix dimensions up to 2 × 3 and 3 × 2).\nLeast Squares and Regression:\nThe general model of Section 19.2.1: x, p, y, βj , hj , n, m; m×1 vector of measurements Y , and\nm × n regression matrix X; fundamental relationship (Xβ)i = Ymodel(xi; β), for i = 1, ..., m.\nNotion of \"bias-free\" and βtrue . (We will only consider bias-free models in the quiz.) Con\nditions for which Xβ = Y has a solution (i.e., when Y is noise free); conditions for which\nXβ = Y in general has no solution (i.e., when m > n and Y is noisy). Simple example of an\noverdetermined system: a straight line through m > 2 points.\nThe residual vector r(β) = Y - Xβ as \"misfit\" or \"misprediction\"; the least squares formu\nlation -- βˆ minimizes Ir(β)I2 over all possible β; the normal equations for βˆ -- (XTX)βˆ =\nXTY .\nAssumptions on noise: normal and zero mean (N1); homoscedastic (N2) with standard devi\nation σ (a scalar); uncorrelated (N3).\nRegression estimates: estimate βˆ for βtrue; estimate ˆσ (in terms of IY - XβˆI) for σ; \"reason\"\nfor m - n rather than just m in the ˆσ expression; interpretation of βˆ as \"best explanation\nof data\" and of ˆσ as \"what is left over\"; joint confidence intervals for the βtrue in terms of\nthe n × n matrix ˆΣ; frequentist interpretation of joint confidence intervals; \"hypothesis test\"\ninterpretation of joint confidence intervals (in particular, conclusions about coefficients βtrue);\nshrinking of the confidence intervals as the number of measurements, m, increases.\nOverfitting: why it is evil, why m should be large compared to n, and how overfitting is\nreflected in confidence intervals.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n2.086 Numerical Computation for Mechanical Engineers\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Exam",
      "title": "Quiz 4 study guide",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-086-numerical-computation-for-mechanical-engineers-fall-2012/019820beff95c5e66ad28ed15977e764_MIT2_086F12_quiz4_samples.pdf",
      "content": "Unit V Quiz Question Sampler\n2.086/2.090 Fall 2012\nYou may refer to the text and other class materials as well as your own notes and scripts.\nFor Quiz 4 (on Unit V) you will not need a calculator; however, if you like, you may use a calculator\nto confirm arithmetic results. In any event, laptops, tablets, and smartphones are not permitted.\nTo simulate real quiz conditions you should complete all the questions in this sampler in 90 minutes.\nNAME\nThere are a total of 100 points: four questions, each worth 25 points.\nAll questions are multiple choice; in all cases circle one and only one answer.\nWe include a blank page at the end which you may use for any derivations, but note that we do\nnot refer to your work and in any event on the quiz your grade will be determined solely by your\nmultiple choice selections.\nYou may assume that all arithmetic operations are performed exactly (with no floating point\ntruncation or round-off errors). We may display the numbers in the multiple-choice options to just\na few digits, however you should always be able to clearly discriminate the correct answer from the\nincorrect answers.\n\nQuestion 1 (25 points).\nWe consider in this problem the system of linear equations\nAu = f\n(1)\nwhere A is a given 2 × 2 matrix, f is a given 2 × 1 vector, and u is the 2 × 1 vector we wish to find.\nWe introduce two matrices\n\n1 -2\nAI =\n,\n(2)\n3 -6\nand\n\n1 -2\nAII =\n,\n(3)\n3 -4\nwhich will be relevant in Parts (i),(ii) and Parts (iii),(iv) respectively.\nIn Parts (i),(ii), A of equation (1) is given by AI of equation (2). (In other words, we consider the\nsystem AIu = f.)\n(i) (6.25 points) For f = (1/2\n3/2)T (recall T denotes transpose),\n(a) AIu = f has a unique solution\n(b) AIu = f has no solution\n(c) AIu = f has an infinity of solutions of the form\n\n1/2\nu =\n+ α\nfor any (real number) α\n(d) AIu = f has an infinity of solutions of the form\n\n1/2\nu =\n+ α\nfor any (real number) α.\n\n(ii) (6.25 points) For f = (1/2 1)T ,\n(a) AIu = f has a unique solution\n(b) AIu = f has no solution\n(c) AIu = f has an infinity of solutions of the form\n1/2\nu =\n+ α\nfor any (real number) α\n(d) AIu = f has an infinity of solutions of the form\n1/2\nu =\n+ α\nfor any (real number) α.\nNow, in Parts (iii), (iv), A of equation (1) is given by AII of equation (3). (In other words, we\nconsider the system AIIu = f.)\n(iii) (6.25 points) For f = (1/2\n3/2)T (recall T denotes transpose),\n(a) AIIu = f has a unique solution\n(b) AIIu = f has no solution\n(c) AIIu = f has an infinity of solutions of the form\n1/2\nu =\n+ α\nfor any (real number) α\n(d) AIIu = f has an infinity of solutions of the form\n1/2\nu =\n+ α\nfor any (real number) α.\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n(iv) (6.25 points) For f = (1/2 1)T ,\n(a) AIIu = f has a unique solution\n(b) AIIu = f has no solution\n(c) AIIu = f has an infinity of solutions of the form\n1/2\nu =\n+ α\nfor any (real number) α\n(d) AIIu = f has an infinity of solutions of the form\n1/2\nu =\n+ α\nfor any (real number) α.\n\n!\n\n!\n\n!\n\n!\n\nQuestion 2 (25 points).\nWe consider the system of three springs and masses shown in Figure 1.\nwall\nk2 = 1\nk3 = 3\nk1 = 1\nf3 = 1\nu3\nm\nf1 = 0\nu1\nm1\nf2 = 1\nu2\nm2\nFigure 1: The spring-mass system for Question 2.\nThe equilibrium displacements satisfy the linear system of three equations in three unknowns,\nAu = f, given by\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n2 -1\nu1\n⎜\n⎜\n⎜\n⎝ -1\n4 -3\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎠\nu2\n⎟\n⎟\n⎟\n⎠ =\n⎜\n⎜\n⎜\n⎝ 1\n⎟\n⎟\n⎟\n⎠ .\n(4)\n0 -3\nu3\nA\nu\nf\nThe matrix A is SPD (Symmetric Positive Definite). Note you should only consider the particular\nright-hand side f (forces) indicated.\nWe now reduce the system by Gaussian Elimination to form Uu = fˆ, where U is an upper triangular\nmatrix. We may then find u by Back Substitution. Note that we do not perform any partial pivoting\n-- reordering of the rows of A -- for stability (since the matrix is SPD), and furthermore we do\nnot perform any reordering of the columns of the matrix A for optimization: we work directly on\nthe matrix A as given by equation (4).\n(i) (5 points) The element U2 2 (i.e., the entry in the i = second row, j = second column) of U\nis given by\n(a) 4\n(b) 5/2\n(c) 9/2\n(d) 7/2\nNote: If at any point you are confused about which entry (row, column) we are referring to\nin a question, please ask.\n\n(ii) (5 points) The element U3 3 (i.e., the entry in the i = third row, j = third column) of U is\ngiven by\n(a) 2/5\n(b) 3/7\n(c) 4/9\n(d) 3\n(iii) (5 points) The element fˆ2 (i.e., the second entry in the fˆ vector) is given by\n(a) 1\n(b) 3/2\n(c) 1/2\n(d) 0\n(iv) (5 points) The element fˆ3 (i.e., the third entry in the fˆ vector) is given by\n(a) 1\n(b) 5/3\n(c) 13/7\n(d) 9/5\n(v) (5 points) The displacement of the third mass, u3, is given by\n(a) 13/3\n(b) 9/2\n(c) 1/3\n(d) 1\n\nQuestion 3 (25 points).\nwall\nf3\nu3\nm\nf4\nu4\nm\nf5\nu5\nm\nf6\nu6\nm\nf1\nu1\nf2\nu2\nm2\nk = 1\nk = 1\nk = 1\nk = 1\nk = 1\nk = 1\nm1\nksp\nspecia\necial = 2\nFigure 2: The spring-mass system for Question 3. Note that all the spring constants are unity,\nk = 1, except for the \"special\" spring which links mass 1 and mass 6, kspecial = 2. Note that all\nthe springs are described by the linear Hooke relation.\nWe consider the system of springs and masses shown in Figure 2. Equilibrium -- force balance\non each mass and Hooke's law for the spring constitutive relation -- leads to the system of six\nequations in six unknowns, Au = f,\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛ a -1\nc\nu1\nf1\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎝\n-1\n2 -1\n0 -1\n2 -1\n0 -1\n2 -1\n0 -1\n2 -1\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎠\nu2\nu3\nu4\nu5\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎠\n=\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎝\nf2\nf3\nf4\nf5\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎠\n.\n(5)\nc\n0 -1\nb\nu6\nf6\nA\nu\nf\nwhere we will ask you to specify a, b, and c in the questions below.∗ Note for the correct choices of\na, b, and c the matrix A is SPD.\nWe now reduce the system Au = f by Gaussian Elimination to form Uu = fˆ, where U is an upper\ntriangular matrix. Note that we do not perform any partial pivoting -- reordering of the rows of A\n-- for stability (since the matrix is SPD), and furthermore we do not perform any reordering of the\ncolumns of the matrix A for optimization: we work directly on the matrix A as given by equation\n(5).\n(i) (5 points) The value of a is\n(a) 2\n(b) -1\n(c) -2\n∗ We presume that all quantities are provided in consistent units.\n\n(d) 3\n(e) 4\n(ii) (5 points) The value of b is\n(a) 2\n(b) -1\n(c) -2\n(d) 3\n(e) 4\n(iii) (5 points) The value of c is\n(a) 0\n(b) -1\n(c) -2\n(d) 3\n(e) 4\n(iv) (5 points) The number of nonzero elements in the (upper triangular) matrix U is\n(a) 24\n(b) 15\n(c) 12\n(d) 11\n(e) 36\nHint: Consider the initial stage of Gaussian Elimination (and the fill-in process) to deduce\nthe only possibly correct option from the available choices.\n(v) (5 points) The number of nonzero elements in A-1 (the inverse of A) is\n(a) 24\n\n(b) 15\n(c) 12\n(d) 11\n(e) 36\nHint: Make an educated guess based on the physical interpretation of the columns of A-1 .\n\nQuestion 4 (25 points)\nWe consider the spring-mass system shown in Figure 3: there are n masses, each of which (except\nthose near the two ends) is connected to its four nearest neighbors.\nk = 1\nwall\nu3\nm\nu4\nm\nun\nmn\nu2\nm2\nk = 1\nk = 1\nk = 1\nk = 1\nk = 1\nk = 1\nu1\nm1\nf1 = 1\nf2 = 1\nf3 = 1\nf4 = 1\nfn = 1\nk = 1\nk = 1\nk = 1\nk = 1\nk = 1\nFigure 3: The spring-mass system for Question 4.\nThe displacements of the masses, u, satisfies a linear system of n equations in n unknowns, Au = f.\nThe Matlab script\nclear\nn = 1000; % number of masses, assumed greater than 4\nA = spalloc(n,n,5*n);\nA(1,1) = 4.;\nA(1,2) = -1.;\nA(1,3) = -1.;\nA(2,2) = 4.;\nA(2,1) = -1.;\nA(2,3) = -1.;\nA(2,4) = -1.;\nfor i = 3:n-2\nA(i,i) = 4.;\nA(i,i-1) = -1.;\nA(i,i-2) = -1.;\nA(i,i+1) = -1.;\nA(i,i+2) = -1.;\nend\nA(n-1,n-1) = 3.;\nA(n-1,n-2) = -1.;\nA(n-1,n-3) = -1.;\nA(n-1,n) = -1.;\nA(n,n) = 2.;\nA(n,n-1) = -1.;\nA(n,n-2) = -1.;\n\nf = ones(n,1);\nnumnonzero_of_A = nnz(A);\nnumtimes_compute = 20;\ntic;\nfor itimes = 1:numtimes_compute\nu = A \\ f;\nend\navg_time_to_find_u = toc/numtimes_compute;\n% repeat calculation numtimes_compute times to get reliable timing\nPE = 0.5*u'*A*u;\nforms the stiffness matrix A ( = A in Matlab) and force vector f ( = f in Matlab) and then\nsolves for the displacements u ( = u in Matlab). Note that the matrix A is SPD.\nYou may assume that the Matlab backslash operator need not perform any partial pivoting --\nreordering of the rows of A -- for stability (since the matrix is SPD), and furthermore will not\nperform any reordering of the columns of the matrix A for optimization (the ordering is already\nthe best possible): Matlab works directly on the matrix A as given -- Gaussian Elimination to\nobtain U ( = U in Matlab) and fˆ followed by Back Substitution to obtain u.\nWe run the script for n = 1000 as indicated above.\n(i) (5 points) The script will set the value of A(3,2) to\n(a) 4.\n(b) -1.\n(c) 3.\n(d) 2.\n(e) 0.\n(ii) (5 points) The script will set the value of numnonzero_of_A to\n(a) 2998\n(b) 3996\n(c) 4994\n(d) 6001\nHint: How many diagonals of A are populated?\n\n(iii) (5 points) The number of nonzero elements of U will be\n(a) 1999\n(b) 2997\n(c) 3000\n(d) 500500\n(Note you do not see U explicitly in the script of page 10 but it is formed internally as part\nof the backslash operation u = A \\ f.)\nHint: Recall Gaussian Elimination for banded matrices.\n(iv) (5 points) The script will set the value of PE to\n(a) 0\n(b) -3.3231e+06\n(c) [1,1]\n(d) 3.3411e+07\nHint: You need not calculate the exact answer to identify the correct answer amongst the\navailable choices.\n(v) (5 points) For n = 1000 we find avg_time_to_find_u to be 4.6e-04 seconds. We now rerun\nthe script but we change the line n = 1000 to n = 10000 such that n is 10 times as large.\n(We make no other changes.)\nNow, running the script for n = 10000, we obtain for avg_time_to_find_u\n(a) 4.2e-04\n(b) 6.0e-02\n(c) 4.1e-03\n(d) 5.1e-01\nYou should choose the most plausible answer assuming that computational time is roughly\nproportional to the number of flops.\n\nAnswer Key\nQ1 (i) (c) AIu = f has an infinity of solutions of the form\n1/2\nu =\n+ α\nfor any (real number) α\n(ii) (b) AIu = f has no solution\n(iii) (a) AIIu = f has a unique solution\n(iv) (a) AIIu = f has a unique solution\nQ2 (i) (d) 7/2\n(ii) (b) 3/7\n(iii) (a) 1\n(iv) (c) 13/7\n(v) (a) 13/3\nQ3 (i) (e) 4\n(ii) (d) 3\n(iii) (c) -2\n(iv) (b) 15\n(v) (e) 36\nQ4 (i) (b) -1.\n(ii) (c) 4994\n(iii) (b) 2997\n(iv) (d) 3.3411e+07\n(v) (c) 4.1e-03\n\n!\n\n!\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n2.086 Numerical Computation for Mechanical Engineers\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Slides on Bernoulli/Area Estimation",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-086-numerical-computation-for-mechanical-engineers-fall-2012/a7c117d905e682f5553efc8ab84f27fa_MIT2_086F12_unit2_bern.pdf",
      "content": "Bernoulli/Area Estimation Summary\nAT Patera\n2.086: Unit II\nFebruary 29, 2012\nupdated 1 October 2012\n\nEstimation of θ (A Coin)\nAT Patera / 2.086 Unit II\nEstimation of θ\n\nq\nq\n\nA realization:\nunknown θ, given a coin\ndraw b1, b2, . . . , bn\n(flip coin n times),\ncalculate estimate (sample mean)\nn\nθˆn = 1 P bj\n(fraction heads);\nn j=1\ncalculate confidence interval for θ,\nθˆn(1-θˆn)\nθˆn(1-θˆn)\n[ci]θ;n = θˆn - zγ\n, θˆn + zγ\n.\nn\nn\nAT Patera / 2.086 Unit II\nEstimation of θ\n\nSome details:\nγ (confidence level) → zγ\nγ\n0.8\n0.95\nzγ\n1.28\n;\n1.96\ninf\ncheck n θˆn > 5, n(1 - θˆn) > 5 (normal approximation).\nAT Patera / 2.086 Unit II\nEstimation of θ\n\n|\n{z\n}\n|\n{z\n}\nFrequentist interpretation:\ndemo\nIf perform nexp (→inf) realizations\nn flips → θˆn performed nexp times ,\none realization\nnexp realizations\nthen in a fraction γ of these nexp realizations\nθ is inside the interval [ci]θ;n .\nAT Patera / 2.086 Unit II\nEstimation of θ\n\ns\ns\nError measures:\nwith confidence γ\nθˆn(1 - θˆn)\n|θ - θˆn| ≤ zγ\n≡ Half Lengthθ;n ,\n|\n{zn\n}\nestimate for\nstandard deviation of Θb n\nNOTE: √ (binomial); zγ .\nn\n|θ - θˆn|\n(1 - θˆn)\n≤ zγ\n≡ RelErrθ;n ,\nˆ\nˆ\nθn\nn θn\nNOTE: p\n.\nˆθn\nAT Patera / 2.086 Unit II\nEstimation of θ\n\nCumulative sample means (Section 10.3):\n→\nRelErrθ;1\n→\nRelErrθ;2\n→\nRelErrθ;3\n→ RelErrθ;nmax\nb1\n→ θˆ1 → [ci]θ;1\nkeep, b2 → θˆ2 → [ci]θ;2\nkeep, b3 → θˆ3 → [ci]θ;3\n. . .\n\"n required\"\n.\n. .\nkeep, bnmax →θˆnmax →[ci]θ;nmax\nAT Patera / 2.086 Unit II\n.\n≤\n≤\n≤\ntol ? if no\ntol ? if no\ntol ? if no\n≤ tol ? yes STOP\nEstimation of θ\n\nEstimation of Area (AD)\nAT Patera / 2.086 Unit II\nEstimation of θ\n\n(\nA realization:\nor cumulative\nthrow darts (x1, x2)1, . . . , (x1, x2)n uniform over R ;\nevaluate Bernoulli bj\nθ = AD/AR\n0 (x1, x2)j not in D\nbj =\n;\n1 (x1, x2)j in D\ncalculate estimate for θ, AD\nn\nθˆn = 1 P bj\n⇒\n(AˆD)n = AR θˆn ;\nn j=1\nAT Patera / 2.086 Unit II\nEstimation of θ\n\nA realization (cont'd):\nconfidence level γ\ncalculate [ci]AD;n for AD\n\nq\n\nq\n\nθˆn(1-θˆn)\nθˆn(1-θˆn)\nˆ\nˆ\nAR · θn - zγ\n, AR · θn + zγ\n.\nn\nn\n|\n{z\n} |\n{z\n}\nlower bound\nupper bound\nNote: only require \" in D vs. not in D\" decision.\nAT Patera / 2.086 Unit II\nEstimation of θ\n\ns\ns\nr\ns\nError measures:\nθˆn(1 - θˆn)\n|AD - (AˆD)n| ≤ AR · zγ\nn\n≡ Half LengthAD;n ;\n|AD - (AˆD)n|\n(1 - θˆn)\n≤ zγ\n(AˆD)n\nn θˆn\n≡ RelErrAD;n .\nAR\nNote: p\n≈\n=\n.\nˆ\nθ\nAD\nθn\nAT Patera / 2.086 Unit II\nEstimation of θ\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n2.086 Numerical Computation for Mechanical Engineers\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Unit 1: . (Numerical) Calculus; Elementary Programming Concepts from Math, Numerics, and Programming (for Mechanical Engineers). V1.2, September 2012.",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-086-numerical-computation-for-mechanical-engineers-fall-2012/60dcae084890daa22bad45fa1d8b8da6_MIT2_086F12_notes_unit1.pdf",
      "content": "DRAFT V1.2\nFrom\nMath, Numerics, & Programming\n(for Mechanical Engineers)\nMasayuki Yano\nJames Douglass Penn\nGeorge Konidaris\nAnthony T Patera\nSeptember 2012\n(c) The Authors. License: Creative Commons Attribution-Noncommercial-Share Alike 3.0\n(CC BY-NC-SA 3.0), which permits unrestricted use, distribution, and reproduction\nin any medium, provided the original authors and MIT OpenCourseWare source\nare credited; the use is non-commercial; and the CC BY-NC-SA license is\nretained. See also http://ocw.mit.edu/terms/.\n\nContents\nI\n(Numerical) Calculus. Elementary Programming Concepts.\n1 Motivation\n1.1 A Mobile Robot . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2 Global Position Estimation: Infra-red Range-Finding . . . . . . . . . . . . . . . . . .\n1.3 Local Position Tracking: Odometry . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.4 The Numerical Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n2 Interpolation\n2.1 Interpolation of Univariate Functions\n. . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.1.1\nBest Fit vs. Interpolation: Polynomials of Degree n . . . . . . . . . . . . . . 25\n2.2 Interpolation of Bivariate Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n3 Differentiation\n3.1 Differentiation of Univariate Functions . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n3.1.1\nSecond Derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n3.2 Differentiation of Bivariate Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n4 Elements of a Program and Matlab Basics\n4.1 Computer Architecture and Computer Programming . . . . . . . . . . . . . . . . . . 45\n4.1.1\nVirtual Processor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n4.1.2\nThe Matlab Environment . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\n4.2 Data Types (and Classes) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\n4.3 Variables and Assignment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n4.4 The Workspace and Saving/Loading Data . . . . . . . . . . . . . . . . . . . . . . . . 50\n4.5 Arithmetic Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n4.6 Floating Point Numbers (FPNs): Representation and Operations . . . . . . . . . . . 53\n4.6.1\nFPN Truncation and Representation . . . . . . . . . . . . . . . . . . . . . . . 53\n4.6.2\nArithmetic Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\n4.7 Relational and Logical Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n4.7.1\nRelational Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n4.7.2\nLogical Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n4.8 Flow Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\n4.8.1\nThe if Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\n4.8.2\nThe while Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n4.8.3\nThe for Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\n\n5 Matlab Arrays\n5.1 Single-Index Floating Point Arrays . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n5.1.1\nThe Concept . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n5.1.2\nAssignment and Access . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n5.1.3\n(Dotted) Arithmetic Operations . . . . . . . . . . . . . . . . . . . . . . . . . 66\n5.1.4\nRelational and Logical (Array) Operations . . . . . . . . . . . . . . . . . . . . 70\n5.1.5\n\"Data\" Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71\n5.2 Characters and Character Single-Index Arrays (Strings) . . . . . . . . . . . . . . . . 73\n5.3 Double-Index Arrays . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\n5.3.1\nConcept . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\n5.3.2\nAssignment and Access . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\n5.3.3\nOperations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\n5.4 Line Plotting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85\n6 Functions in Matlab\n6.1 The Advantage: Encapsulation and Re-Use . . . . . . . . . . . . . . . . . . . . . . . 89\n6.2 Always Test a Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\n6.3 What Happens in a Function Stays in a Function . . . . . . . . . . . . . . . . . . . . 90\n6.4 Syntax: Inputs (Parameters) and Outputs . . . . . . . . . . . . . . . . . . . . . . . . 91\n6.5 Functions of Functions: Handles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\n6.6 Anonymous (or In-Line) Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94\n6.7 String Inputs and the eval Function . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\n7 Integration\n7.1 Integration of Univariate Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97\n7.2 Integration of Bivariate Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107\n7.3 Gauss Quadrature . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109\n\nUnit I\n(Numerical) Calculus. Elementary\nProgramming Concepts.\n\nChapter 1\nMotivation\n1.1\nA Mobile Robot\nRobot self-localization, or the ability of a robot to figure out where it is within its environment, is\narguably the most fundamental skill for a mobile robot, such as the one shown in Figure 1.1. We\ncan divide the robot self-localization problem into two parts: global position estimation and local\nposition tracking. Global position estimation is the robot's ability to determine its initial position\nand orientation (collectively, pose) within a known map of its environment. Local position tracking\nis then the ability of the robot to track changes in its pose over time. In this assignment, we will\nconsider two basic approaches to global position estimation and local position tracking.\n1.2\nGlobal Position Estimation: Infra-red Range-Finding\nMany systems exist today for robot global position estimation. Perhaps the most familiar example\nis the Global Positioning System (GPS), a network of 24 satellites that can give an absolute po\nsition estimate accurate to within several meters. For smaller scale position estimation, high-end\nsolutions such as robotic vision and laser range-finding can provide millimeter accuracy distance\nmeasurements, which can then be matched with map data to convert local distance measurements\nto global position. As an alternative to these more expensive systems, ultrasonic and infrared dis\ntance sensors can offer similar performance with modest compromises in speed and accuracy. Of\nthese two, infrared distance sensors often have slightly narrower beam width and faster response.\nFigure 1.2(a) shows the Sharp GP2Y0A21YK0F, a popular medium range (10-80 cm), infrared\n(IR) distance sensor. The Sharp sensor uses triangulation to calculate distance by measuring the\nangle of incidence of a transmitted IR beam reflected from a distant surface onto a receiving posi\ntion sensitive device (PSD). Because the angle is a nonlinear function of the distance to the surface,\nthe Sharp sensor has the nonlinear calibration curve shown in Figure 1.2(b). Given discrete cali\nbration data, we can linearly interpolate voltage readings taken from the sensor to derive distance\nmeasurements.\n1.3\nLocal Position Tracking: Odometry\nDead reckoning, which tracks location by integrating a moving system's speed and heading over\ntime, forms the backbone of many mobile robot navigation systems. The simplest form of dead\nDRAFT V1.2 (c) The Authors. License: Creative Commons BY-NC-SA 3.0.\n\nX\nY\nx\ny\nq\nFigure 1.1: A mobile robot with pose (x, y, θ).\n0.5\n1.5\n2.5\n3.5\nvoltage (V)\ndistance (cm)\nSharp GP2Y0A21YK0F calibration curve\n(a) The Sharp IR distance sensor\n(b) Calibration curve\nFigure 1.2: Sharp GP2Y0A21YK0F infrared distance sensor and its calibration curve.\nreckoning for land-based vehicles is odometry, which derives speed and heading information from\nsensed wheel rotations.\nOptical encoders like the one shown in Figure 1.3 are often used to derive linear displacements\nof the left and right wheels (Δsleft and Δsright) from incremental wheel rotations. In the optical\nencoder design shown, the encoder senses changes in the reflectance of a striped pattern on the\nwheels, generating a pulse or \"tick\" for each passing stripe. Two sensors A and B placed in\nquadrature -- 90 degrees out of phase with each other (when one is centered on a stripe, the other\nis centered on an edge) -- permit differentiation between forward and reverse rotation. For wheels\nof diameter dwheel with N ticks per rotation, the distance traveled by each wheel in Δn ticks can\nbe derived as\nΔnleft\nΔsleft = πdwheel\n,\n(1.1)\nN\nΔnright\nΔsright = πdwheel\n.\n(1.2)\nN\n(c) Sharp Electronics. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/fairuse.\n\nA\nB\nForward\nReverse\nA\nB\nForward rotation: B lags A by 90\no\nA\nB\nReverse rotation: A lags B by 90\no\nFigure 1.3: A quadrature rotary encoder and its output for clockwise and counterclockwise rotation.\ndwheel\n2.71\ninches\nLbaseline\n5.25\ninches\nN\nticks\nTable 1.1: Mobile robot parameters.\nBy \"summing up\" the increments, we can compute the total cumulative distances sleft and sright\ntraveled by the left and right wheels, respectively.\nThe variables time, LeftTicks, and RightTicks from assignment1.mat contain sample times\ntk (in seconds) and cumulative left and right encoder counts nleft and nright, respectively, recorded\nduring a single test run of a mobile robot. Note that the quadrature decoding for forward and\nreverse rotation has already been incorporated in the data, such that cumulative counts increase\nfor forward rotation and decrease for reverse rotation. The values of the odometry constants for\nthe mobile robot are given in Table 1.\nFor a mobile robot with two-wheel differential drive, in which the two (left and right) driven\nwheels can be controlled independently, the linear velocities vleft and vright at the two wheels\nmust (assuming no slippage of the wheels) be both directed in (or opposite to) the direction θ of\nthe robot's current heading. The motion of the robot can thus be completely described by the\nvelocity vcenter of a point lying midway between the two wheels and the angular velocity ω about\nan instantaneous center of curvature (ICC) lying somewhere in line with the two wheels, as shown\nin Figure 1.4.\nWe can derive vcenter and ω from vleft and vright as\nvcenter = vleft + vright\n,\n(1.3)\nω = vright - vleft\nLbaseline\n,\n(1.4)\nwhere\nvleft = dsleft\ndt ,\n(1.5)\nvright = dsright\ndt\n,\n(1.6)\n\nq\nLbaseline\nICC\nvright\nvcenter\nvleft\nw\nFigure 1.4: Robot trajectory.\nand Lbaseline is the distance between the points of contact of the two wheels. We can then integrate\nthese velocities to track the pose [x(t), y(t), θ(t)] of the robot over time as\nt\nx(t) =\nvcenter(t) cos[θ(t)] dt ,\n(1.7)\nt\ny(t) =\nvcenter(t) sin[θ(t)] dt ,\n(1.8)\nt\nθ(t) =\nω(t) dt .\n(1.9)\nIn terms of the sample times tk, we can write these equations as\ntk\nx k = x k-1 +\nvcenter(t) cos[θ(t)] dt ,\n(1.10)\ntk-1\ntk\ny k = y k-1 +\nvcenter(t) sin[θ(t)] dt ,\n(1.11)\ntk-1\ntk\nθk = θk-1 +\nω(t) dt .\n(1.12)\ntk-1\n1.4\nThe Numerical Tasks\nTo calculate distance from our transducer we must be able to interpolate; and to calculate our\nposition from dead reckoning we must be able to differentiate and integrate. In this unit we\nintroduce the necessary numerical approaches and also understand the possible sources of error.\n\nChapter 2\nInterpolation\n2.1\nInterpolation of Univariate Functions\nThe objective of interpolation is to approximate the behavior of a true underlying function using\nfunction values at a limited number of points. Interpolation serves two important, distinct purposes\nthroughout this book. First, it is a mathematical tool that facilitates development and analysis\nof numerical techniques for, for example, integrating functions and solving differential equations.\nSecond, interpolation can be used to estimate or infer the function behavior based on the function\nvalues recorded as a table, for example collected in an experiment (i.e., table lookup).\nLet us define the interpolation problem for an univariate function, i.e., a function of single\nvariable. We discretize the domain [x1, xN ] into N - 1 non-overlapping segments, {S1, . . . , SN-1},\nusing N points, {x1, . . . , xN }, as shown in Figure 2.1. Each segment is defined by\nSi = [xi, xi+1],\ni = 1, . . . , N - 1 ,\nand we denote the length of the segment by h, i.e.\nh ≡ xi+1 - xi .\nFor simplicity, we assume h is constant throughout the domain. Discretization is a concept that\nis used throughout numerical analysis to approximate a continuous system (infinite-dimensional\nproblem) as a discrete system (finite-dimensional problem) so that the solution can be estimated\nusing a computer. For interpolation, discretization is characterized by the segment size h; smaller\nh is generally more accurate but more costly.\nSuppose, on segment Si, we are given M interpolation points\nm\nx ,\nm = 1, . . . , M ,\nx1\nx2\nx3\nx4\nS1\nS2\nS3\nh\nxN-1\nxN\nSN-1\nFigure 2.1: Discretization of a 1-D domain into N - 1 segments.\nDRAFT V1.2 (c) The Authors. License: Creative Commons BY-NC-SA 3.0.\n\nx1\nx2\nx3\nx4\nx5\nS2\ndiscretization\nx1\nx2\nx3\nlocal segment S2\nx1\nx2\nx3\nx4\nx5\nx6\nx7\nx8\nx9\nfunction evaluation points\nei\nSi\n( x1 ,f( x1))\n( x2 ,f( x2))\n( x3 ,f( x3))\nxi\nxi+1\n\ninterpolant\ninterpolation points\nfunction\n(a) discretization\n(b) local interpolation\nFigure 2.2: Example of a 1-D domain discretized into four segments, a local segment with M = 3\nfunction evaluation points (i.e., interpolation points), and global function evaluation points (left).\nConstruction of an interpolant on a segment (right).\nand the associated function values\nf( x m),\nm = 1, . . . , M .\nWe wish to approximate f(x) for any given x in Si. Specifically, we wish to construct an interpolant\nIf that approximates f in the sense that\n(If)(x) ≈ f(x),\n∀ x ∈ Si ,\nand satisfies\n(If)( x m) = f( x m),\nm = 1, . . . , M .\nNote that, by definition, the interpolant matches the function value at the interpolation points,\n{x m}.\nThe relationship between the discretization, a local segment, and interpolation points is illus\ntrated in Figure 2.2(a). The domain [x1, x5] is discretized into four segments, delineated by the\npoints xi, i = 1, . . . , 5. For instance, the segment S2 is defined by x2 and x3 and has a characteristic\nlength h = x3 - x2. Figure 2.2(b) illustrates construction of an interpolant on the segment S2 using\nM = 3 interpolation points. Note that we only use the knowledge of the function evaluated at the\ninterpolation points to construct the interpolant. In general, the points delineating the segments,\nxi, need not be function evaluation points xi, as we will see shortly.\nWe can also use the interpolation technique in the context of table lookup, where a table consists\nof function values evaluated at a set of points, i.e., ( xi, f( xi)). Given a point of interest x, we first\nfind the segment in which the point resides, by identifying Si = [xi, xi+1] with xi ≤ x ≤ xi+1.\nThen, we identify on the segment Si the evaluation pairs ( xj, f( xj )), j = . . ., ⇒ ( xm, f( xm)),\nm = 1, . . . , M. Finally, we calculate the interpolant at x to obtain an approximation to f(x),\n(If)(x).\n(Note that, while we use fixed, non-overlapping segments to construct our interpolant in this\nchapter, we can be more flexible in the choice of segments in general. For example, to estimate\n\nthe value of a function at some point x, we can choose a set of M data points in the neighborhood\nof x. Using the M points, we construct a local interpolant as in Figure 2.2(b) and infer f(x)\nby evaluating the interpolant at x. Note that the local interpolant constructed in this manner\nimplicitly defines a local segment. The segment \"slides\" with the target x, i.e., it is adaptively\nchosen. In the current chapter on interpolation and in Chapter 7 on integration, we will emphasize\nthe fixed segment perspective; however, in discussing differentiation in Chapter 3, we will adopt\nthe sliding segment perspective.)\nTo assess the quality of the interpolant, we define its error as the maximum difference between\nthe true function and the interpolant in the segment, i.e.\nei ≡ max |f(x) - (If)(x)| .\nx∈Si\nBecause the construction of an interpolant on a given segment is independent of that on another\nsegment1 , we can analyze the local interpolation error one segment at a time. The locality of\ninterpolation construction and error greatly simplifies the error analysis. In addition, we define\nthe maximum interpolation error, emax, as the maximum error over the entire domain, which is\nequivalent to the largest of the segment errors, i.e.\nemax ≡\nmax\nei .\ni=1,...,N-1\nThe interpolation error is a measure we use to assess the quality of different interpolation schemes.\nSpecifically, for each interpolation scheme, we bound the error in terms of the function f and the\ndiscretization parameter h to understand how the error changes as the discretization is refined.\nLet us consider an example of interpolant.\nExample 2.1.1 piecewise-constant, left endpoint\nThe first example we consider uses a piecewise-constant polynomial to approximate the function\nf. Because a constant polynomial is parameterized by a single value, this scheme requires one\ninterpolation point per interval, meaning M = 1. On each segment Si = [xi, xi+1], we choose the\nleft endpoint as our interpolation point, i.e.\nx = xi .\nAs shown in Figure 2.3, we can also easily associate the segmentation points, xi, with the global\nfunction evaluation points, xi, i.e.\nx i = xi,\ni = 1, . . . , N - 1 .\nExtending the left-endpoint value to the rest of the segment, we obtain the interpolant of the form\n(If)(x) = f( x 1) = f( xi) = f(xi),\n∀ x ∈ Si .\nFigure 2.4(a) shows the interpolation scheme applied to f(x) = exp(x) over [0, 1] with N =\n5. Because f' > 0 over each interval, the interpolant If always underestimate the value of f.\nConversely, if f' < 0 over an interval, the interpolant overestimates the values of f in the interval.\nThe interpolant is exact over the interval if f is constant.\nIf f' exists, the error in the interpolant is bounded by\nei ≤ h · max |f'(x)| .\nx∈Si\n1for the interpolants considered in this chapter\n\nx1\nx2\nx3\nx4\nx5\nS2\ndiscretization\nx1\nlocal segment S2\nx1\nx2\nx3\nx4\nfunction evaluation points\nFigure 2.3: The relationship between the discretization, a local segment, and the function evaluation\npoints for a piecewise-constant, left-endpoint interpolant.\n0.2\n0.4\n0.6\n0.8\n0.5\n1.5\n2.5\n\ninterpolant\ninterpolation points\nfunction\n-2\n-1\n-1.00\n1/h\nmax(ei)\n(a) interpolant\n(b) error\nFigure 2.4: Piecewise-constant, left-endpoint interpolant.\n\nSince ei = O(h) and the error scales as the first power of h, the scheme is said to be first-order\naccurate. The convergence behavior of the interpolant applied to the exponential function is shown\nin Figure 2.4(b), where the maximum value of the interpolation error, emax = maxi ei, is plotted as\na function of the number of intervals, 1/h.\nIf f(x) is linear, then the error bound can be shown using a direct argument. Let f(x) = mx+b.\nThe difference between the function and the interpolant over Si is\nf(x) - (If)(x) = [mx - b] - [mx 1 - b] = m · (x - x 1) .\nRecalling the local error is the maximum difference in the function and interpolant and noting that\nSi = [xi, xi+1] = [ x1 , x 1 + h], we obtain\nei = max |f(x) - (If)(x)| = max |m · (x - x 1)| = |m| ·\nmax\n|x - x 1| = |m| · h .\nx∈Si\nx∈Si\nx∈[ x ,x 1+h]\nFinally, recalling that m = f ' (x) for the linear function, we have ei = |f ' (x)| · h. Now, let us prove\nthe error bound for a general f.\nProof. The proof follows from the definition of the interpolant and the fundamental theorem of\ncalculus, i.e.\nf(x) - (If)(x) = f(x) - f( x 1)\n(by definition of (If))\nx\n=\nf ' (ξ)dξ\n(fundamental theorem of calculus)\nx\nx\n≤\n|f ' (ξ)|dξ\nx\n≤ max |f ' (x)|\nx∈[ x1,x]\nx\nx\ndξ\n\n(H older's inequality)\n≤ max |f ' (x)| · h,\n∀ x ∈ Si = [ x , x + h] .\nx∈Si\nSubstitution of the expression into the definition of the error yields\nei ≡ max |f(x) - (If)(x)| ≤ max |f ' (x)| · h .\nx∈Si\nx∈Si\nIt is important to note that the proof relies on the smoothness of f. In fact, if f is discontinuous\n'\nand f does not exist, then ei can be O(1). In other words, the interpolant does not converge to\nthe function (in the sense of maximum error), even if the h is refined. To demonstrate this, let us\nconsider a function\nf(x) =\n⎧\n⎪\n⎨\n⎪\n⎩\nsin(πx),\nx ≤ 3\n,\n2 sin(πx), x > 3\nwhich is discontinuous at x = 1/3. The result of applying the piecewise constant, left-endpoint\nrule to the function is shown in Figure 2.5(a). We note that the solution on the third segment is\nZ\nZ\nZ\n\n0.2\n0.4\n0.6\n0.8\n0.2\n0.4\n0.6\n0.8\n\ninterpolant\ninterpolation points\nfunction\n-2\n-1\n1/h\nmax(ei)\n(a) interpolant\n(b) error\nFigure 2.5: Piecewise-constant, left-endpoint interpolant for a non-smooth function.\nnot approximated well due to the presence of the discontinuity. More importantly, the convergence\nplot, Figure 2.5(b), confirms that the maximum interpolation error does not converge even if h\nis refined. This reduction in the convergence rate for non-smooth functions is not unique to this\nparticular interpolation rule; all interpolation rules suffer from this problem. Thus, we must be\ncareful when we interpolate a non-smooth function.\nLet us more formally define some of the key concepts visited in the first example. While we\nintroduce the following concepts in the context of analyzing the interpolation schemes, the concepts\napply more generally to analyzing various numerical schemes.\n- Accuracy relates how well the numerical scheme (finite-dimensional) approximates the con\ntinuous system (infinite-dimensional). In the context of interpolation, the accuracy tells how\nwell the interpolant If approximates f and is measured by the interpolation error, emax.\n- Convergence is the property that the error vanishes as the discretization is refined, i.e.\n→ 0 as h → 0 .\nemax\nA convergent scheme can achieve any desired accuracy (error) in infinite prediction arith\nmetics by choosing h sufficiently small. The piecewise-constant, left-endpoint interpolant is\na convergent scheme, because emax = O(h), and emax → 0 as h → 0.\n- Convergence rate is the power p such that\nemax ≤ Chp\nas h → 0 ,\nwhere C is a constant independent of h. The scheme is first-order accurate for p = 1, second-\norder accurate for p = 2, and so on. The piecewise-constant, left-endpoint interpolant is\nfirst-order accurate because emax = Ch1 .\n- Resolution is the characteristic length hcrit for any particular problem (described by f) for\nwhich we see the asymptotic convergence rate for h ≤ hcrit. Convergence plot in Figure 2.4(b)\nshows that the piecewise-constant, left-endpoint interpolant achieves the asymptotic conver\ngence rate of 1 with respect to h for h ≤ 1/2; note that the slope from h = 1 to h = 1/2\n\nis lower than unity. Thus, hcrit for the interpolation scheme applied to f(x) = exp(x) is\napproximately 1/2.\n- Computational cost or operation count is the number of floating point operations (FLOPs2) to\ncompute Ih. As h → 0, the number of FLOPs approaches inf. The scaling of the computation\ncost with the size of the problem is referred to as computational complexity. The actual run\ntime of computation is a function of the computational cost and the hardware. The cost of\nconstructing the piecewise-constant, left end point interpolant is proportional to the number\nof segments. Thus, the cost scales linearly with N, and the scheme is said to have linear\ncomplexity.\n- Memory or storage is the number of floating point numbers that must be stored at any point\nduring execution.\nWe note that the above properties characterize a scheme in infinite precision representation and\narithmetic. Precision is related to machine precision, floating point number truncation, rounding\nand arithmetic errors, etc, all of which are absent in infinite-precision arithmetics.\nWe also note that there are two conflicting demands; the accuracy of the scheme increases\nwith decreasing h (assuming the scheme is convergent), but the computational cost increases with\ndecreasing h. Intuitively, this always happen because the dimension of the discrete approximation\nmust be increased to better approximate the continuous system. However, some schemes produce\nlower error for the same computational cost than other schemes. The performance of a numerical\nscheme is assessed in terms of the accuracy it delivers for a given computational cost.\nWe will now visit several other interpolation schemes and characterize the schemes using the\nabove properties.\nExample 2.1.2 piecewise-constant, right end point\nThis interpolant also uses a piecewise-constant polynomial to approximate the function f, and thus\nrequires one interpolation point per interval, i.e., M = 1. This time, the interpolation point is at\nthe right endpoint, instead of the left endpoint, resulting in\nx = xi+1,\n(If)(x) = f( x 1) = f(xi+1),\n∀ x ∈ Si = [xi, xi+1] .\nThe global function evaluation points, xi, are related to segmentation points, xi, by\nx i = xi+1,\ni = 1, . . . , N - 1 .\nFigure 2.6 shows the interpolation applied to the exponential function.\n'\nIf f exists, the error in the interpolant is bounded by\nei ≤ h · max |f ' (x)| ,\nx∈Si\nand thus the scheme is first-order accurate. The proof is similar to that of the piecewise-constant,\nright-endpoint interpolant.\nExample 2.1.3 piecewise-constant, midpoint\nThis interpolant uses a piecewise-constant polynomial to approximate the function f, but uses the\nmidpoint of the segment, Si = [xi, xi+1], as the interpolation point, i.e.\nx 1 =\n(xi + xi+1) .\n2Not to be confused with the FLOPS (floating point operations per second), which is often used to measure the\nperformance of a computational hardware.\n\n0.2\n0.4\n0.6\n0.8\n0.5\n1.5\n2.5\n\ninterpolant\ninterpolation points\nfunction\nFigure 2.6: Piecewise-constant, right-endpoint interpolant.\nx1\nx2\nx3\nx4\nx5\nS2\ndiscretization\nx1\nlocal segment S2\nx1\nx2\nx3\nx4\nfunction evaluation points\nFigure 2.7: The relationship between the discretization, a local segment, and the function evaluation\npoints for a piecewise-constant, midpoint interpolant.\nDenoting the (global) function evaluation point associated with segment Si as xi, we have\nx i =\n(xi + xi+1),\ni = 1, . . . , N - 1 ,\nas illustrated in Figure 2.7. Note that the segmentation points xi do not correspond to the function\n1) = f(\nevaluation points x i unlike in the previous two interpolants. This choice of interpolation point\nresults in the interpolant\n\n(If)(x) = f( x\nxi) = f\n(xi + xi+1)\n,\nx ∈ Si .\nFigure 2.8(a) shows the interpolant for the exponential function. In the context of table lookup,\nthis interpolant naturally arises if a value is approximated from a table of data choosing the nearest\ndata point.\nThe error of the interpolant is bounded by\nh\nei ≤\n· max |f ' (x)| ,\nx∈Si\n\n0.2\n0.4\n0.6\n0.8\n0.5\n1.5\n2.5\n\ninterpolant\ninterpolation points\nfunction\n-2\n-1\n-1.00\n1/h\nmax(ei)\n\nconstant, left\nconstant, right\nconstant, middle\n(a) interpolant\n(b) error\nFigure 2.8: Piecewise-constant, mid point interpolant.\nwhere the factor of half comes from the fact that any function evaluation point is less than h/2\ndistance away from one of the interpolation points. Figure 2.8(a) shows that the midpoint inter\npolant achieves lower error than the left- or right-endpoint interpolant. However, the error still\nscales linearly with h, and thus the midpoint interpolant is first-order accurate.\nFor a linear function f(x) = mx + b, the sharp error bound can be obtained from a direct\nargument. The difference between the function and its midpoint interpolant is\nm\no\nf(x) - (If)(x) = [mx + b] - mx + b = m · (x - x 1) .\nThe difference vanishes at the midpoint, and increases linearly with the distance from the midpoint.\nThus, the difference is maximized at either of the endpoints. Noting that the segment can be\nm\no\nexpressed as Si = [xi, xi+1] = x 1 - h\n2 , x 1 + h , the maximum error is given by\nei ≡ max(f(x) - (If)(x)) =\nmax\n|m · (x - x 1)|\nh\nx∈Si\nx∈[x 1- h ,x 1+ ]\nh\n= |m · (x - x 1)|\n= |m| ·\n.\nx= x1±h/2\nRecalling m = f ' (x) for the linear function, we have ei = |f ' (x)|h/2. A sharp proof for a general f\nfollows essentially that for the piecewise-constant, left-endpoint rule.\nProof. The proof follows from the fundamental theorem of calculus,\n\nx\nx\nx\nf(x) - (If)(x) = f(x) - f\nx\n=\nf ' (ξ)dξ ≤\n|f ' (ξ)|dξ ≤ max |f ' (x)|\ndξ\nx\nx\nx∈[x ,x]\nx\n\nh\nh\nh\n1 -\n≤\nmax\n|f ' (x)| · ,\n∀ x ∈ Si =\nx\n, x +\n.\nx∈[x 1- h ,x 1+ h ]\nZ\nZ\nZ\n\nx1\nx2\nx3\nx4\nx5\nS2\ndiscretization\nx1\nx2\nlocal segment S2\nx1\nx2\nx3\nx4\nx5\nfunction evaluation points\nFigure 2.9: The relationship between the discretization, a local segment, and the function evaluation\npoints for a linear interpolant.\nThus, we have\nh\nei = max |f(x) - (If)(x)| ≤ max |f ' (x)| ·\n.\nx∈Si\nx∈Si\nExample 2.1.4 piecewise-linear\nThe three examples we have considered so far used piecewise-constant functions to interpolate the\nfunction of interest, resulting in the interpolants that are first-order accurate. In order to improve\nthe quality of interpolation, we consider a second-order accurate interpolant in this example. To\nachieve this, we choose a piecewise-linear function (i.e., first-degree polynomials) to approximate the\nfunction behavior. Because a linear function has two coefficients, we must choose two interpolation\npoints per segment to uniquely define the interpolant, i.e., M = 2. In particular, for segment\nSi = [xi, xi+1], we choose its endpoints, xi and xi+1, as the interpolation points, i.e.\nx 1 = xi\nand x 2 = xi+1 .\nThe (global) function evaluation points and the segmentation points are trivially related by\nx i = xi,\ni = 1, . . . , N ,\nas illustrated in Figure 2.9.\nThe resulting interpolant, defined using the local coordinate, is of the form\n\nf( x2) - f( x1)\n(If)(x) = f( x 1) +\n(x - x 1),\n∀ x ∈ Si ,\n(2.1)\nh\nor, in the global coordinate, is expressed as\nf(xi+1) - f(xi)\n(If)(x) = f(xi) +\n(x - xi),\n∀ x ∈ Si .\nhi\n\n0.2\n0.4\n0.6\n0.8\n0.5\n1.5\n2.5\n\ninterpolant\ninterpolation points\nfunction\n-4\n-3\n-2\n-1\n-1.00\n-2.00\n1/h\nmax(ei)\n\nconstant, left\nlinear\n(a) interpolant\n(b) error\nFigure 2.10: Piecewise-linear interpolant.\nFigure 2.10(a) shows the linear interpolant applied to f(x) = exp(x) over [0, 1] with N = 5. Note\nthat this interpolant is continuous across the segment endpoints, because each piecewise-linear\nfunction matches the true function values at its endpoints. This is in contrast to the piecewise\nconstant interpolants considered in the previous three examples, which were discontinuous across\nthe segment endpoints in general.\n''\nIf f exists, the error of the linear interpolant is bounded by\nh2\nei ≤\n· max |f '' (x)| .\nx∈Si\nThe error of the linear interpolant converges quadratically with the interval length, h. Because the\nerror scales with h2, the method is said to be second-order accurate. Figure 2.10(b) shows that\nthe linear interpolant is significantly more accurate than the piecewise-linear interpolant for the\nexponential function. This trend is generally true for sufficient smooth functions. More importantly,\nthe higher-order convergence means that the linear interpolant approaches the true function at a\nfaster rate than the piecewise-constant interpolant as the segment length decreases.\nLet us provide a sketch of the proof. First, noting that f(x)-(If)(x) vanishes at the endpoints,\nwe express our error as\nx\nf(x) - (If)(x) =\n(f -If) ' (t) dt .\nx\n∈ Si\n∗\n= [ x 1 , x 2] such that f ' (x ∗) - (If) ' (x ∗)\nNext, by Rolle's theorem, we have a point x\n= 0.\nApplying the fundamental theorem of calculus again, the error can be expressed as\nx\nx\nt\nx\nt\nf(x) - (If)(x) =\n(f -If) ' (t) dt =\n(f -If) '' (s) ds dt =\nf '' (s) ds dt\nx\nx\nx ∗\nx\nx ∗\nx\nt\nh2\nx ∗ ds dt ≤\n· max |f\nx∈Si\n'' (x)|\n'' (x)| .\n≤ max |f\nx∈Si\nx1\nThis simple sketch shows that the interpolation error is dependent on the second derivative of f\nand quadratically varies with the segment length h; however, the constant is not sharp. A sharp\nproof is provided below.\nZ\nZ\nZ\nZ\nZ\nx\nZ\nZ\nZ\n\nProof. Our objective is to obtain a bound for |f(ˆx) -If(ˆx)| for an arbitrary ˆx ∈ Si. If ˆx is the\none of the endpoints, the interpolation error vanishes trivially; thus, we assume that ˆx is not one of\nthe endpoints. The proof follows from a construction of a particular quadratic interpolant and the\napplication of the Rolle's theorem. First let us form the quadratic interpolant, q(x), of the form\nq(x) ≡ (If)(x) + λw(x) with w(x) = (x - x 1)(x - x 2) .\nSince (If) matches f at x1 and x2 and q( x1) = q( x2) = 0, q(x) matches f at x1 and x . We select\nλ such that q matches f at ˆx, i.e.\nf(ˆx) - (If)(ˆx)\nq(ˆx) = (If)(ˆx) + λw(ˆx) = f(ˆx)\n⇒\nλ =\n.\nw(ˆx)\nThe interpolation error of the quadratic interpolant is given by\nφ(x) = f(x) - q(x) .\nBecause q is the quadratic interpolant of f defined by the interpolation points x1, x2, and ˆx, φ has\nthree zeros in Si. By Rolle's theorem, φ ' has two zeros in Si. Again, by Rolle's theorem, φ '' has\none zero in Si. Let this zero be denoted by ξ, i.e., φ '' (ξ) = 0. Evaluation of φ '' (ξ) yields\n'' (ξ) - q\n'' (ξ) - 2λ\n'' (ξ) .\n0 = φ '' (ξ) = f\n'' (ξ) = f '' (ξ) - (If) '' (ξ) - λw '' (ξ) = f\n⇒\nλ = 1 f\nEvaluating φ(ˆx), we obtain\n0 = φ(ˆx) = f(ˆx) - (If)(ˆx) - 1 f '' (ξ)w(ˆx)\n(2.2)\nf(ˆx) - (If)(ˆx) = 1 f '' (ξ)(ˆx - x 1)(ˆx - x 2) .\n(2.3)\n∗\nThe function is maximized for ˆx = ( x1 + x2)/2, which yields\n'' (ξ),\nf(ˆx) - (If)(ˆx) ≤ f '' (ξ)( x 2 - x 1)2 = h2f\n∀ xˆ ∈ [ x , x 2]\nSince ξ ∈ Si, it follows that,\nei = max |f(x) - (If)(x)| ≤ h2f '' (ξ) ≤ h2 max |f '' (x)| .\nx∈Si\nx∈Si\nExample 2.1.5 piecewise-quadratic\nMotivated by the higher accuracy provided by the second-order accurate, piecewise-linear inter\npolants, we now consider using a piecewise-quadratic polynomial to construct an interpolant. Be\ncause a quadratic function is characterized by three parameters, we require three interpolation\npoints per segment (M = 3). For segment Si = [xi, xi+1], a natural choice are the two endpoints\nand the midpoint, i.e.\nx = xi,\nx = (xi + xi+1),\nand x = xi+1 .\n\n0.2\n0.4\n0.6\n0.8\n0.5\n1.5\n2.5\n\ninterpolant\ninterpolation points\nfunction\n-8\n-6\n-4\n-2\n-1.00\n-2.00\n-3.00\n1/h\nmax(ei)\n\nconstant, left\nlinear\nquadratic\n(a) interpolant\n(b) error\nFigure 2.11: Piecewise-quadratic interpolant.\nTo construct the interpolant, we first construct Lagrange basis polynomial of the form\n(x - x 2)(x - x 3)\n(x - x 1)(x - x 3)\n(x - x 1)(x - x 2)\nφ1(x) =\n,\nφ2(x) =\n,\nand φ3(x) =\n.\n( x1 - x 2)( x1 - x 3)\n( x2 - x 1)( x2 - x 3)\n( x3 - x 1)( x3 - x 2)\nBy construction, φ1 takes the value of 1 at x\nand vanishes at x\nand x . More generally, the\nLagrange basis has the property\n⎧\n⎨1,\nn = m\nφm( x n) =\n.\n⎩0,\nn =6\nm\nUsing these basis functions, we can construct the quadratic interpolant as\n(If)(x) = f( x 1)φ1(x) + f( x 2)φ2(x) + f( x 3)φ3(x),\n∀ x ∈ Si .\n(2.4)\nWe can easily confirm that the quadratic function goes through the interpolation points, ( xm, f( xm)),\nm = 1, 2, 3, using the property of the Lagrange basis. Figure 2.11(a) shows the interpolant for the\nexponential function.\n'''\nIf f\nexists, the error of the quadratic interpolant is bounded by\nh3\n''' (x) .\nei ≤\n√ max f\n72 3 x∈Si\nThe error converges as the cubic power of h, meaning the scheme is third-order accurate. Fig\nure 2.11(b) confirms the higher-order convergence of the piecewise-quadratic interpolant.\nProof. The proof is an extension of that for the linear interpolant. First, we form a cubic interpolant\nof the form\nq(x) ≡ (If)(x) + λw(x) with w(x) = (x - x 1)(x - x 2)(x - x 3) .\n\nWe select λ such that q matches f at ˆx. The interpolation error function,\nφ(x) = f(x) - q(x) ,\nhas four zeros in Si, specifically x , x , x 3, and ˆx. By repeatedly applying the Rolle's theorem\nthree times, we note that φ ''' (x) has one zero in Si. Let us denote this zero by ξ, i.e., φ ''' (ξ) = 0.\nThis implies that\nφ ''' (ξ) = f ''' (ξ) - (cIf) ''' (ξ) - λw ''' (ξ) = f ''' (ξ) - 6λ = 0\n1 ''' (ξ) .\n⇒\nλ = f\nRearranging the expression for φ(ˆx), we obtain\n1 ''' (ξ)w(ˆ\nf(ˆx) - (If)(ˆx) = f\nx) .\n√\n''' (ξ)\nThe maximum value that w takes over Si is h3/(12 3).\nCombined with the fact f\n≤\nmaxx∈Si f ''' (x), we obtain the error bound\nh3\n''' (x) .\nei = max |f(x) - (If)(x)| ≤\n√ max f\nx∈Si\n72 3 x∈Si\nNote that the extension of this proof to higher-order interpolants is straight forward. In general, a\npiecewise pth-degree polynomial interpolant exhibits p + 1 order convergence.\nThe procedure for constructing the Lagrange polynomials extends to arbitrary degree polyno\nmials. Thus, in principle, we can construct an arbitrarily high-order interpolant by increasing the\nnumber of interpolation points. While the higher-order interpolation yielded a lower interpolation\nerror for the smooth function considered, a few cautions are in order. First, higher-order inter\npolants are more susceptible to modeling errors. If the underlying data is noisy, the \"overfitting\" of\nthe noisy data can lead to inaccurate interpolant. This will be discussed in more details in Unit III\non regression.\nSecond, higher-order interpolants are also susceptible to non-smooth function. To see this, we\nrevisit the simple discontinuous function,\nf(x) =\n⎧\n⎪\n⎪\n⎨\n⎪\n⎩\nsin(πx),\nx ≤ 3\n.\n2 sin(πx), x > 3\nThe result of applying the piecewise-quadratic interpolation rule to the function is shown in Fig\nure 2.12(a). The quadratic interpolant closely matches the underlying function in the smooth region.\nHowever, in the third segment, which contains the discontinuity, the interpolant differs consider\nably from the underlying function. Similar to the piecewise-constant interpolation of the function,\nwe again commit O(1) error measured in the maximum difference. Figure 2.12(b) confirms that\nthe higher-order interpolants do not perform any better than the piecewise-constant interpolant\nin the presence of discontinuity. Formally, we can show that the maximum-error convergence of\nany interpolation scheme can be no better than hr, where r is the highest-order derivative that\nis defined everywhere in the domain. In the presence of a discontinuity, r = 0, and we observe\nO(hr) = O(1) convergence (i.e., no convergence).\n\n0.2\n0.4\n0.6\n0.8\n0.2\n0.4\n0.6\n0.8\n\ninterpolant\ninterpolation points\nfunction\n-2\n-1\n1/h\nmax(ei)\n\nconstant, left\nlinear\nquadratic\n(a) interpolant\n(b) error\nFigure 2.12: Piecewise-quadratic interpolant for a non-smooth function.\nThird, for a very high-order polynomials, the interpolation points must be chosen carefully to\nachieve a good result. In particular, the uniform distribution suffers from the behavior known\nas Runge's phenomenon, where the interpolant exhibits excessive oscillation even if the underlying\nfunction is smooth. The spurious oscillation can be minimized by clustering the interpolation points\nnear the segment endpoints, e.g., Chebyshev nodes.\nAdvanced Material\n2.1.1\nBest Fit vs. Interpolation: Polynomials of Degree n\nWe will study in more details how the choice of interpolation points affect the quality of a polynomial\ninterpolant. For convenience, let us denote the space of nth-degree polynomials on segment S by\nPn(S). For consistency, we will denote nth-degree polynomial interpolant of f, which is defined\nby n + 1 interpolation points {x m}n+1 , by Inf. We will compare the quality of the interpolant\nm=1\nwith the \"best\" n + 1 degree polynomial. We will define \"best\" in the infinity norm, i.e., the best\n∗\npolynomial v ∈Pn(S) satisfies\nmax |f(x) - v ∗ (x)| ≤ max |f(x) - v(x)| ,\n∀ v ∈Pn(x) .\nx∈S\nx∈S\n∗\nIn some sense, the polynomial v fits the function f as closely as possible. Then, the quality of\n∗\na nth-degree interpolant can be assessed by measuring how close it is to v . More precisely, we\nquantify its quality by comparing the maximum error of the interpolant with that of the best\npolynomial, i.e.\nmax |f(x) - (If)(x)| ≤ (1 + Λ({x m}n+1 )) max |f(x) - v ∗ (x)| ,\nm=1\nx∈S\nx∈S\nwhere the constant Λ is called the Lebesgue constant. Clearly, a smaller Lebesgue constant implies\nsmaller error, so higher the quality of the interpolant. At the same time, Λ ≥ 0 because the\nmaximum error in the interpolant cannot be better than that of the \"best\" function, which by\n\ndefinition minimizes the maximum error. In fact, the Lebesgue constant is given by\nn+1\nn\nΛ {x m}n+1\n= max\n|φm(x)| ,\nm=1\nx∈S m=1\nwhere φm, m = 1, . . . , n + 1, are the Lagrange bases functions defined by the nodes {x m}n+1\nm=1.\nProof. We first express the interpolation error in the infinity norm as the sum of two contributions\nmax |f(x) - (If)(x)| ≤ max |f(x) - v ∗ (x) + v ∗ (x) - (If)(x)|\nx∈S\nx∈S\n≤ max |f(x) - v ∗ (x)| + max |v ∗ (x) - (If)(x)|.\nx∈S\nx∈S\nNoting that the functions in the second term are polynomial, we express them in terms of the\nLagrange basis φm, m = 1, . . . , n,\nn+1\nn\nmax |v ∗ (x) - (If)(x)| = max\n(v ∗ ( x m) - (If)( x m))φm(x)\nx∈S\nx∈S m=1\nn+1\nn\n≤ max\nmax\n|v ∗ ( x m) - (If)( x m)| ·\n|φm(x)|\nx∈S\nm=1,...,n+1\nm=1\nn+1\nn\n=\nmax\n|v ∗ ( x m) - (If)( x m)| · max\n|φm(x)| .\nm=1,...,n+1\nx∈S m=1\nBecause If is an interpolant, we have f( xm) = (If)( xm), m = 1, . . . , n+1. Moreover, we recognize\nthat the second term is the expression for Lebesgue constant. Thus, we have\nmax |v ∗ (x) - (If)(x)| ≤\nmax\n|v ∗ ( x m) - f( x m)| · Λ\nx∈S\nm=1,...,n+1\n≤ max |v ∗ (x) - f(x)| Λ .\nx∈S\nwhere the last inequality follows from recognizing xm ∈ S, m = 1, . . . , n+1. Thus, the interpolation\nerror in the maximum norm is bounded by\nmax |f(x) - (If)(x)| ≤ max |v ∗ (x) - f(x)| + max |v ∗ (x) - f(x)| Λ\nx∈S\nx∈S\nx∈S\n≤ (1 + Λ) max |v ∗ (x) - f(x)| ,\nx∈S\nwhich is the desired result.\nIn the previous section, we noted that equally spaced points can produce unstable interpolants\nfor a large n. In fact, the Lebesgue constant for the equally spaced node distribution varies as\n2n\nΛ ∼\n,\nen log(n)\n\nn\nΛ\n\nequally spaced\nChebyshev\nFigure 2.13: The approximate Lebesgue constants for equally-spaced and Chebyshev node distri\nbutions.\ni.e., the Lebesgue constant increases exponentially with n. Thus, increasing n does not necessary\nresults in a smaller interpolation error.\nA more stable interpolant can be formed using the Chebyshev node distribution. The node\ndistribution is given (on [-1, 1]) by\n2m - 1\nm\nx\n= cos\nπ\n,\nm = 1, . . . , n + 1 .\n2(n + 1)\nNote that the nodes are clustered toward the endpoints. The Lebesgue constant for Chebyshev\nnode distribution is\nΛ = 1 +\nlog(n + 1) ,\nπ\ni.e., the constant grows much more slowly. The variation in the Lebesgue constant for the equally-\nspaced and Chebyshev node distributions are shown in Figure 2.13.\nExample 2.1.6 Runge's phenomenon\nTo demonstrate the instability of interpolants based on equally-spaced nodes, let us consider inter\npolation of\nf(x) =\n2 .\n1 + 25x\nThe resulting interpolants for p = 5, 7, and 11 are shown in Figure 2.14. Note that equally-spaced\nnodes produce spurious oscillation near the end of the intervals. On the other hand, the clustering\nof the nodes toward the endpoints allow the Chebyshev node distribution to control the error in\nthe region.\nEnd Advanced Material\n2.2\nInterpolation of Bivariate Functions\nThis section considers interpolation of bivariate functions, i.e., functions of two variables. Following\nthe approach taken in constructing interpolants for univariate functions, we first discretize the\n\n-1\n-0.5\n0.5\n-0.2\n0.2\n0.4\n0.6\n0.8\n\nn=5\nn=7\nn=11\nf\n-1\n-0.5\n0.5\n-0.2\n0.2\n0.4\n0.6\n0.8\n\nn=5\nn=7\nn=11\nf\n(a) equally spaced\n(b) Chebyshev distribution\nFigure 2.14: High-order interpolants for f = 1/(x + 25x2) over [-1, 1].\ndomain into smaller regions, namely triangles. The process of decomposing a domain, D ⊂ R2 ,\ninto a set of non-overlapping triangles {Ri}N\nis called triangulation. An example of triangulation\ni=1\nis shown in Figure 2.15. By construction, the triangles fill the domain in the sense that\nN\n\nD =\nRi ,\ni=1\n\nwhere ∪ denotes the union of the triangles. The triangulation is characterized by the size h, which\nis the maximum diameter of the circumscribed circles for the triangles.\nWe will construct interpolant over triangle R. Let us assume that we are given M interpolation\npoints,\nx\nm\nm = ( x , y m) ∈ R,\nm = 1, . . . , M ,\n\nand the function values evaluated at the interpolation points,\nx\nf( m),\nm = 1, . . . , M .\n\nOur objective is to construct the interpolant If that approximates f at any point x ∈ R,\nIf(x) ≈ f(x),\n∀ x ∈ R ,\nwhile matching the function value at the interpolations points,\nx\nx\n(If)( m) = f(\nm),\nm = 1, . . . , M .\nAs before, we assess the quality of the interpolant in terms of the error\ne = max |f(x) - (If)(x)| .\nx∈R\nFor the next two examples, we consider interpolation of bivariate function\nf(x, y) = sin(πx) sin(πy),\n(x, y) ∈ [0, 1]2 .\nThe function is shown in Figure 2.16.\n\nR1\nR2\nR3\nRi\nRi\nx1\nx2\nx3\n(a) mesh\n(b) triangle Ri\nFigure 2.15: Triangulation of a 2-D domain.\nFigure 2.16: Function f(x, y) = sin(πx) sin(πy)\n\n9.4\n18.8\n37.5\n75.0\n150.1\n-2\n-1\n-1.00\n1/h\nmax(ei)\n(a) interpolant\n(b) error\nFigure 2.17: Piecewise-constant interpolation\nExample 2.2.1 Piecewise-constant, centroid\nThe first interpolant approximates function f by a piecewise-constant function. To construct a\nconstant function on R, we need just one interpolation point, i.e., M = 1. Let us choose the\ncentroid of the triangle to be the interpolation point,\nx 1 =\n(x1 + x2 + x3) .\nThe constant interpolant is given by\nIf(x) = f(x 1),\n∀x ∈R .\nAn example of piecewise-constant interpolant is shown in Figure 2.17(a). Note that the interpolant\nis discontinuous across the triangle interfaces in general.\nThe error in the interpolant is bounded by\ne ≤h max IVf(x)I2 ,\nx∈R\nwhere IVf(x)I2 is the two-norm of the gradient, i.e.\n\n∂f\n∂f\nIVfI2 =\n+\n.\n∂x\n∂y\nThe interpolant is first-order accurate and is exact if f is constant. Figure 2.17(b) confirms the h1\nconvergence of the error.\nExample 2.2.2 Piecewise-linear, vertices\nThis interpolant approximates function f by a piecewise-linear function. Note that a linear function\nin two dimension is characterized by three parameters. Thus, to construct a linear function on a\ntriangular patch R, we need to choose three interpolation points, i.e., M = 3. Let us choose the\nvertices of the triangle to be the interpolation point,\nx = x1,\nx = x2,\nand x = x3 .\n\n9.4\n18.8\n37.5\n75.0\n150.1\n-4\n-3\n-2\n-1\n-1.00\n-2.00\n1/h\nmax(ei)\n\nconstant, middle\nlinear\n(a) interpolant\n(b) error\nFigure 2.18: Piecewise-linear interpolation\nThe linear interpolant is of the form\n(If)(x) = a + bx + cy .\nTo find the three parameters, a, b, and c, we impose the constraint that the interpolant matches\nthe function value at the three vertices. The constraint results in a system of three linear equations\n1) = a + bx + cy\n1) ,\n(If)( x\n= f( x\n2) = a + bx + cy\n2) ,\n(If)( x\n= f( x\n3) = a + bx + cy\n3) ,\n(If)( x\n= f( x\nwhich can be also be written concisely in the matrix form\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n1 y 1\n1)\n1 x\n1 x\n1 x\nf( x\na\n⎜\n⎜\n⎜\n⎜\n⎝\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\n⎟\n⎟\n⎟\n⎟\n⎠\n=\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\n2 y 2\n2)\nb\nf( x\nx\n.\n3 y 3\n3)\nf(\nc\nThe resulting interpolant is shown in Figure 2.18(a). Unlike the piecewise-constant interpolant, the\npiecewise-linear interpolant is continuous across the triangle interfaces.\nThe approach for constructing the linear interpolation requires solving a system of three linear\nequations. An alternative more efficient approach is to consider a different form of the interpolant.\nNamely, we consider the form\n(If)(x) = f( x 1) + b ' (x - x 1) + c ' (y - y 1) .\nNote that the interpolant is still linear, but it already satisfies the interpolation condition at\n( x 1, f( x 1)) because\n(If)( x 1) = f( x 1) + b ' ( x 1 - x 1) + c ' ( y 1 - y 1) = f( x 1) .\n\nThus, our task has been simplified to that of finding the two coefficients b ' and c ' , as oppose to the\nthree coefficients a, b, and c. We choose the two coefficients such that the interpolant satisfies the\n2 and\n3, i.e.\ninterpolaion condition at x\nx\nx\nx\nx\n1) + b ' ( x 2 - x 1) + c ' ( y\n2) = f(\n1) = f(\n2) ,\n(If)(\n2 - y\n1) + b ' ( x 3 - x 1) + c ' ( y\n3) = f(\n1) = f(\n3) .\n(If)( x\nx\nx\n3 - y\nOr, more compactly, we can write the equations in matrix form as\n⎛\n⎞⎛\n⎞\n⎛\n⎞\nx\n2 - x\ny 2 - y\nb '\nf( x 2) - f( x 1)\n⎝\n⎠⎝\n⎝\n⎠\n⎠ =\n.\nx\n'\n3 - x\ny 3 - y\nc\nf( x 3) - f( 1\n)\nx\nWith some arithmetics, we can find an explicit form of the coefficients,\nm\no\n1) - (f( x\nb '\n2) - f(\n1))( y 3 - y\n3) - f(\n1))( y 2 - y 1)\n=\n(f( x\nx\nx\n,\nA\nm\no\n'\n3) - f(\n1))( x 2 - x 1) - (f(\n2) - f(\n1))( x 3 - x 1)\nc =\n(f( x\nx\nx\nx\n,\nA\nwith\nA = ( x 2 - x 1)( y 3 - y 1) - ( x 3 - x 1)( y 2 - y 1) .\nNote that A is twice the area of the triangle. It is important to note that this second form of the\nlinear interpolant is identical to the first form; the interpolant is just expressed in a different form.\nThe error in the interpolant is governed by the Hessian of the function, i.e.\ne ≤ Ch2IV2fIF ,\nwhere IV2fIF is the Frobenius norm of the Hessian matrix, i.e.\n∂2f\n∂2f\n∂2f\nIV2fIF =\n+\n+ 2\n.\n∂x2\n∂y2\n∂x∂y\nThus, the piecewise-linear interpolant is second-order accurate and is exact if f is linear. The\nconvergence result shown in Figure 2.18(b) confirms the h2 convergence of the error.\ns\n\nh\n( x1 ,f( x1))\n( x2 ,f( x2))\n( x3 ,f( x3))\nxi\nxi-1\nxi+1\nChapter 3\nDifferentiation\n3.1\nDifferentiation of Univariate Functions\nOur objective is to approximate the value of the first derivative, f ' , for some arbitrary univariate\nfunction f. In particular, we assume the values of the function is provided at a set of uniformly\nspaced points1 as shown in Figure 3.1. The spacing between any two function evaluation points is\ndenoted by h .\nOur approach to estimating the derivative is to approximate function f by its interpolant\nIf constructed from the sampled points and then differentiate the interpolant. Note that the\ninterpolation rules based on piecewise-constant representation do not provide meaningful results,\nas they cannot represent nonzero derivatives. Thus, we will only consider linear and higher order\ninterpolation rules.\nTo construct an interpolant If in the neighborhood of xi, we can first choose M interpolation\npoints, xj , j = s(i), . . . , s(i) + M - 1 in the neighborhood of xi, where s(i) is the global function\nevaluation index of the left most interpolation point. Then, we can construct an interpolant If\nfrom the pairs ( xj, If( xj )), j = s(i), . . . , s(i)+ M - 1, and If is linear on the function values. As a\n1The uniform spacing is not necessary, but it simplifies the analysis\nFigure 3.1: Stencil for one-dimensional numerical differentiation.\nDRAFT V1.2 (c) The Authors. License: Creative Commons BY-NC-SA 3.0.\n\nresult, the derivative of the interpolant is also a linear function of f( xj ), j = s(i), . . . , s(i) + M - 1.\n'\nSpecifically, our numerical approximation to the derivative, fh( xi), is of the form\ns(i)+M -1\nn\n'\nfh( xi) ≈\nωj (i)f( xj ) ,\nj=s(i)\nwhere ωj (i), j = 1, . . . , M, are weights that are dependent on the choice of interpolant.\nThese formulas for approximating the derivative are called finite difference formulas. In the\ncontext of numerical differentiation, the set of function evaluation points used to approximate the\nderivative at x i is called numerical stencil. A scheme requiring M points to approximate the\nderivative has an M-point stencil. The scheme is said to be one-sided, if the derivative estimate\nonly involves the function values for either x ≥ x i or x ≤ x i. The computational cost of numerical\ndifferentiation is related to the size of stencil, M.\nThroughout this chapter, we assess the quality of finite difference formulas in terms of the error\n'\ne ≡|f ' ( xi) - fh( xi)| .\nSpecifically, we are interested in analyzing the behavior of the error as our discretization is refined,\n\n'\ni.e., as h decreases. Note that, because the interpolant, If, from which f ( xi) is constructed\nh\n'\napproaches f as h → 0 for smooth functions, we also expect f ( xi) to approach f ' ( xi) as h → 0.\nh\nThus, our goal is not just to verify that f ' ( xi) approaches f( xi), but also to quantify how fast it\nconverges to the true value.\nLet us provide a few examples of the differentiation rules.\nExample 3.1.1 forward difference\nThe first example is based on the linear interpolation. To estimate the derivative at x i, let us\nfirst construct the linear interpolant over segment [ xi, x i+1]. Substituting the interpolation points\nx 1 = x i and x2 = x i+1 into the expression for linear interpolant, Eq. (2.1), we obtain\n(If)(x) = f( xi) + (f( xi+1) - f( xi))(x - x i) .\nh\nThe derivative of the interpolant evaluated at x = x i (approaching from x > x i) is\n'\nfh( xi) = (If) ' ( xi) = 1(f( xi+1) - f( xi)) .\nh\nThe forward difference scheme has a one-sided, 2-point stencil. The differentiation rule applied to\nf(x) = exp(x) about x = 0 is shown in Figure 3.2(a). Note that the linear interpolant matches the\nfunction at xi and xi + h and approximates derivative at x = 0.\nThe error in the derivative is bounded by\nh\nei = |f ' ( xi) - fh\n' ( xi)| ≤\nmax\n|f '' (x)| .\n2 x∈[ xi,x i+1]\nThe convergence plot in Figure 3.2(b) of the error with respect to h confirms the first-order con\nvergence of the scheme.\n\n-0.2\n0.2\n0.4\n0.6\n0.8\n1.2\n0.5\n1.5\n2.5\n3.5\n\nf'h(x)\nf'(x)\ninterpolation points\nfunction\n-3\n-2\n-1\n-1.00\n1/h\n|f'-f'h|\n(a) differentiation\n(b) error\nFigure 3.2: Forward difference.\nProof. The proof of the error bound follows from Taylor expansion. Recall, assuming f '' (x) is\nbounded in [ xi, x i+1],\n1 '' (ξ)h 2\nf( xi+1) = f( xi + h ) = f( xi) + f ' ( xi)h + f\n,\nfor some ξ ∈ [ xi, x i+1]. The derivative of the interpolant evaluated at x = x i can be expressed as\n1 '' (ξ)\n1 '' (ξ)\n(If) ' ( xi) =\nf( xi) + f ' ( xi)h + f\nh2 - f( xi)\n= f ' ( xi) + f\nh ,\nh\nand the error in the derivative is\n|f ' ( xi) - (If) ' ( xi)| =\nf '' (ξ)h ≤ h\nmax\n|f '' (x)| .\nx∈[ xi,x i+1]\nExample 3.1.2 backward difference\nThe second example is also based on the piecewise linear interpolation; however, instead of con\nstructing the interpolant over segment [ xi, x i+1], we construct the interpolant over segment [ xi-1, x i].\nSubstituting the interpolation points x1 = x i-1 and x2 = x i into the linear interpolant expression,\nEq. (2.1), we obtain\n(If)(x) = f( xi-1) + (f( xi) - f( xi-1))(x - x i-1) .\nh\nThe derivative of the interpolant evaluated at x = x i (approaching from x < x i) is\n'\nfh( xi) = (If) ' ( xi) = 1(f( xi) - f( xi-1)) .\nh\nThe backward difference scheme has a one-sided, 2-point stencil. The differentiation rule applied\n\n-1\n-0.8\n-0.6\n-0.4\n-0.2\n0.2\n-0.2\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n\nf'h(x)\nf'(x)\ninterpolation points\nfunction\n(a) differentiation\n(b) error\nFigure 3.3: Backward difference.\nto f(x) = exp(x) about x = 0 is shown in Figure 3.3(a). The construction is similar to that of the\nforward difference, except that the interpolant matches the function at xi - h and xi.\nThe error in the derivative is bounded by\nh\nei = |f ' ( xi) - fh\n' ( xi)| ≤\nmax\n|f '' (x)| .\n2 x∈[ xi-1,x i]\nThe proof is similar to the proof for the error bound of the forward difference formula. The\nconvergence plot for f(x) = exp(x) is shown in Figure 3.3(b).\nExample 3.1.3 centered difference\nTo develop a more accurate estimate of the derivative at xi, let us construct a quadratic interpolant\nover segment [ xi-1, x i+1] using the function values at xi-1, xi, and xi+1, and then differentiate the\ninterpolant. To form the interpolant, we first construct the quadratic Lagrange basis functions on\n[ xi-1, x i+1] using the interpolation points x = x i-1, x = x i, and x = x i+1, i.e.\n(x - x 2)(x - x 3)\n(x - x i)(x - x i+1)\nφ1(x) =\n=\n=\n(x - x i)(x - x i+1) ,\n( x1 - x 2)( x1 - x 3)\n( xi-1 - x i)( xi-1 - x i+1)\n2h 2\n(x - x 1)(x - x 3)\n(x - x i-1)(x - x i+1)\nφ2(x) =\n=\n= -\n(x - x i)(x - x i+1) ,\n( x2 - x 1)( x2 - x 3)\n( xi - x i-1)( xi - x i+1)\nh 2\n(x - x 1)(x - x 2)\n(x - x i-1)(x - x i)\nφ3(x) =\n=\n=\n(x - x i-1)(x - x i) ,\n( x3 - x 1)( x3 - x 2)\n( xi+1 - x i-1)( xi+1 - x i)\n2h 2\nwhere h = x i+1 - x i = x i - x i-1.\nSubstitution of the basis functions into the expression for a\n2Note that, for the quadratic interpolant, h is half of the h defined in the previous chapter based on the length of\nthe segment.\n\n-1\n-0.5\n0.5\n-0.5\n0.5\n1.5\n2.5\n3.5\n\nf'h(x)\nf'(x)\ninterpolation points\nfunction\n-5\n-4\n-3\n-2\n-1\n-1.00\n-2.00\n1/h\n|f'-f'h|\n\nfoward\nbackward\ncentered\n(a) differentiation\n(b) error\nFigure 3.4: Centered difference.\nquadratic interpolant, Eq. (2.4), yields\n(If)(x) = f( x 1)φ1(x) + f( x 2)φ2(x) + f( x 3)φ3(x)\n=\nf( xi-1)(x - x i)(x - x i+1) -\nf( xi)(x - x i-1)(x - x i+1)\n2h 2\nh 2\n+\nf( xi+1)(x - x i-1)(x - x i) .\n2h 2\nDifferentiation of the interpolant yields\n(If) ' (x) =\nf( xi-1)(2x - x i - x i+1) -\nf( xi)(2x - x i-1 - x i+1) +\nf( xi+1)(2x - x i-1 - x i) .\n2h 2\nh 2\n2h 2\nEvaluating the interpolant at x = x i, we obtain\n'\nfh( xi) = (If) ' ( xi) = 1 f( xi-1)( xi - x i+1) + 1 f( xi+1)( xi - x i-1)\n2h 2\n2h 2\n=\n1 f( xi-1)(-h ) + 1 f( xi+1)(h )\n2 h2\n2h 2\n=\n(f( xi+1) - f( xi-1)) .\n2 h\nNote that even though the quadratic interpolant is constructed from the three interpolation points,\nonly two of the three points are used in estimating the derivative. The approximation procedure is\nillustrated in Figure 3.4(a).\nThe error bound for the centered difference is given by\nh 2\nei = |f( xi) - fh\n' ( xi)| ≤\nmax\n|f ''' (x)| .\n6 x∈[ xi-1,x i+1]\nThe centered difference formula is second-order accurate, as confirmed by the convergence plot in\nFigure 3.4(b).\n\n\"\n#\nProof. The proof of the error bound follows from Taylor expansion. Recall, assuming f ''' (x) is\nbounded in [ xi-1, x i+1],\n1 f ''' (ξ+)\nf( xi+1) = f( xi + h ) = f( xi) + f ' ( xi)h + f '' ( xi)h 2 +\nh3 ,\n1 f '' (\n1 f ''' (ξ-)h 3\nf( xi-1) = f( xi - h ) = f( xi) - f ' ( xi)h +\nxi)h 2 -\n,\nfor some ξ+ ∈ [ xi, x i+1] and ξ- ∈ [ xi-1, x i]. The centered difference formula gives\n(If) ' ( xi) = 1 (f(xi+1) - f( xi-1))\n2h\n1 f '' ( h2\n1 f ''' (ξ+)h 3\n=\nf( xi) + f ' ( xi)h +\nxi) +\n2h\nf '' ( h2 - f ''' (ξ-)h 3\n- f( xi) - f ' ( xi)h + 1\nxi)\n1 h 2 f ''' (ξ+) - f ''' (ξ-)\n= f ' ( xi) +\n.\nThe error in the derivative estimate is\nf ' ( xi) - (If) ' ( xi) = 1 h 2 f ''' (ξ+) - f ''' (ξ-)\n= h 2\nmax\n|f ''' (x)| .\nx∈[ xi-1,x i+1]\nUsing a higher-order interpolation scheme, we can develop higher-order accurate numerical\ndifferentiation rules. However, the numerical stencil extends with the approximation order, because\nthe number of interpolation points increases with the interpolation order.\nWe would also like to make some remarks about how noise affect the quality of numerical\ndifferentiation. Let us consider approximating a derivative of f(x) = exp(x) at x = 0. However,\nassume that we do not have access to f itself, but rather a function f with some small noise added\nto it. In particular, let us consider\ng(x) = f(x) + E sin(kx) ,\nwith E = 0.04 and k = 1/E. We can think of E sin(kx) as noise added, for example, in a measuring\nprocess. Considering f(0) = 1, this is a relatively small noise in terms of amplitude.\nThe result of applying the finite difference formulas to g in an attempt to approximate f ' (0)\nis shown in Figure 3.5. Comparing the approximations obtained for h = 1/2 and 1/16, we see\nthat the approximation in fact gets worse as h is refined. Figure 3.6 confirms that all numerical\ndifferentiation formulas considered in this section fail to converge. In fact, they all asymptotically\ncommit O(1) error as h → 0, even though the error decreases to less than 10-2 for a certain choice\nof h.\n\n-1\n-0.5\n0.5\n0.5\n1.5\n2.5\n\ng'h(x)\nf'(x)\ninterpolation points\nfunction\n-1\n-0.5\n0.5\n0.5\n1.5\n2.5\n\ng'h(x)\nf'(x)\ninterpolation points\nfunction\n(a) h = 1/2\n(b) h = 1/16\nFigure 3.5: The centered difference formula applied to a noisy function.\n-3\n-2\n-1\n1/h\n|f'-g'h|\n\nfoward\nbackward\ncentered\nFigure 3.6: Convergence of the numerical differentiation formula applied to a noisy function.\n\nAs essentially any data taken in real life is inherently noisy, we must be careful when differ\nentiating the data. For example, let us say that our objective is to estimate the acceleration of\nan object by differentiating a velocity measurement. Due to the presence of measurement noise,\nwe in general cannot expect the quality of our acceleration estimate to improve as we improve the\nsampling rate and decreasing the discretization scale, h .\nOne strategy to effectively differentiate a noisy data is to first filter the noisy data. Filtering is a\ntechnique to clean a signal by removing frequency content above a certain frequency3 For example,\nif a user is only interested in estimating the behavior of a signal below a certain frequency, all\ncontent above that threshold can be deemed noise. The cleaned data is essentially smooth with\nrespect to the scale of interest, and thus can be safely differentiated.\n3.1.1\nSecond Derivatives\nFollowing the same interpolation-based template, we can develop a numerical approximation to\nhigher-order derivatives. In general, to estimate the pth-derivative, we must use an interpolation\nrule based on pth- or higher-degree polynomial reconstruction. As an example, we demonstrate how\nto estimate the second derivative from a quadratic interpolation.\nExample 3.1.4 second-order centered difference\nWe can use the quadratic interpolant considered in the previous case to estimate the second deriva\ntive of the function. Again, choosing x = x i-1, x = x i, x = x i+1 as the interpolation points, the\nquadratic reconstruction is given by\n(If)(x) = f( xi-1)φ1(x) + f( xi)φ2(x) + f( xi+1)φ3(x) ,\nwhere the Lagrange basis function are given by\n(x - x i)(x - x i+1)\nφ1(x) =\n,\n( xi-1 - x i)( xi-1 - x i+1)\n(x - x i-1)(x - x i+1)\nφ2(x) =\n,\n( xi - x i-1)( xi - x i+1)\n(x - x i-1)(x - x i)\nφ3(x) =\n.\n( xi+1 - x i-1)( xi+1 - x i)\nComputing the second derivative of the quadratic interpolant can be proceeded as\nxi-1)φ ''\nxi)φ ''\n(If) '' (x) = f(\n1(x) + f(\n2 (x) + f( xi+1)φ3\n'' (x) .\nIn particular, note that once the second derivatives of the Lagrange basis are evaluated, we can\nexpress the second derivative of the interpolant as a sum of the functions evaluated at three points.\nThe derivatives of the Lagrange basis are given by\nφ ''\n1(x) =\n=\n=\n,\n( xi-1 - x i)( xi-1 - x i+1)\n(-h )(-2h )\nh 2\nφ ''\n2(x) =\n=\n= -\n,\n( xi - x i-1)( xi - x i+1)\n( h)(-h )\nh 2\nφ ''\n3(x) =\n=\n=\n.\n( xi+1 - x i-1)( xi+1 - x i)\n(2h )(h )\nh 2\n3Sometimes signals below a certain frequency is filtered to eliminate the bias.\n\n\"\n\n#\n\nSubstitution of the derivatives to the second derivative of the quadratic interpolant yields\n-2\n(If) '' ( xi) = f( xi-1)\n+ f( xi)\n+ f( xi+1)\nh 2\nh 2\nh 2\n=\nf( xi-1) - 2f( xi) + f( xi+1) .\nh2\nThe error in the second-derivative approximation is bounded by\nh 2\nei ≡|f '' ( xi) - (If) '' ( xi)| ≤\nmax\n|f(4)(x)| .\n12 x∈[ xi-1,x i+1]\nThus, the scheme is second-order accurate.\nProof. The proof of the error bound again follows from Taylor expansion. Recall, assuming f(4)(x)\nis bounded in [ xi-1, x i+1],\n1 '' ( h2\n1 ''' ( h3\n1 f(4)(ξ+)h 4\nf( xi+1) = f( xi + h ) = f( xi) + f ' ( xi)h + f\nxi) + f\nxi) +\n,\n1 ''' (\n1 f(4)(ξ-)\nf( xi-1) = f( xi - h ) = f( xi) - f ' ( xi)h + f '' ( xi)h 2 - f\nxi)h 3 +\nh4 .\nThe second derivative estimation gives\n1 ''' (\n1 f(4)(ξ+)\n(If) '' ( xi) =\nf( xi) + f ' ( xi)h + f '' ( xi)h 2 + f\nxi)h 3 +\nh4\nh 2\n- 2f( xi)\n1 '' ( h2 - 1 ''' ( h3\n1 f(4)(ξ-)h 4\n+ f( xi) - f ' ( xi)h + f\nxi)\nf\nxi) +\n= f '' ( xi) + 1 h 2 f(4)(ξ+) + f(4)(ξ-) .\nThe error in the second derivative is\n|f '' ( xi) - (If) '' ( xi)| =\nh 2 f(4)(ξ+) + f(4)(ξ-)\n≤\nh2\nmax\n|f(4)(x)| .\nx∈[ xi-1,x i+1]\nLet us demonstrate that the second-order derivative formula works for constant, linear, and\nquadratic function. First, we consider f(x) = c. Clearly, the second derivative is f '' (x) = 0. Using\nthe approximation formula, we obtain\n(If) '' ( xi) =\nf( xi-1) - 2f( xi) + f( xi+1) =\n(c - 2c + c) = 0 .\nh 2\nh 2\n\n\"\n\n#\n\nThus, the approximation provides the exact second derivative for the constant function. This is\nnot surprising, as the error is bounded by the fourth derivative of f, and the fourth derivative of\nthe constant function is zero.\nSecond, we consider f(x) = bx+c. The second derivative is again f '' (x) = 0. The approximation\nformula gives\n(If) '' ( xi) = 1 f( xi-1) - 2f( xi) + f( xi+1) = 1 [(bx i-1 + c) - 2(bx i + c) + (bx i+1 + c)]\nh 2\nh 2\n=\nh\n2 [(b( xi - h ) + c) - 2(bx i + c) + (b( xi + h ) + c)] = 0 .\nThus, the approximation also works correctly for a linear function.\nFinally, let us consider f(x) = ax + bx + c. The second derivative for this case is f '' (x) = 2a.\nThe approximation formula gives\n(If) '' ( xi) = 1 [(ax i-1 + bx i-1 + c) - 2(ax i + bx i + c) + (ax i+1 + bx i+1 + c)]\nh 2\n= 1 [(a( xi - h )2 + b( xi - h ) + c) - 2(ax i + bx i + c) + (a( xi + h )2 + b( xi + h ) + c)]\nh 2\nm\no\n= 1 a( xi - 2h x i + h 2) - 2ax i + a( xi + 2h x i + h 2)\nh 2\nm\no\nh 2\n=\n2a\n= 2a .\nh 2\nThus, the formula also yields the exact derivative for the quadratic function.\nThe numerical differentiation rules covered in this section form the basis for the finite difference\nmethod -- a framework for numerically approximating the solution to differential equations. In\nthe framework, the infinite-dimensional solution on a domain is approximated by a finite number\nof nodal values on a discretization of the domain. This allows us to approximate the solution to\ncomplex differential equations -- particularly partial differential equations -- that do not have\nclosed form solutions. We will study in details these numerical methods for differential equations\nin Unit IV, and we will revisit the differential rules covered in this section at the time.\n3.2\nDifferentiation of Bivariate Functions\nLet us briefly consider differentiation of bivariate functions. For simplicity, we restrict ourselves to\nestimation of the first derivative, i.e., the gradient.\nExample 3.2.1 first-order gradient\nFollowing the procedure for estimating the first derivative of univariate functions, we first construct\na polynomial interpolant and then evaluate its derivative. In particular, we consider a linear\ninterpolant on a triangle. Recall the second form of linear interpolant,\n1) + b ' (x - x 1) + c ' (y - y 1) .\nx\nx\nx\nx\nx\n(If)(x) = f(\nThe partial derivative in the x-direction is\nm\no\n∂(If)\n1 (f( 2) - f(\n1) - (f( 3) - f(\n= b '\n1))( y 3 - y\n1))( y 2 - y 1)\n=\n,\n∂x\nA\n\nwhere we recall that A is twice the area of the triangle, i.e., A = (x2 -x1)(y3 -y1)-(x3 -x1)(y2 -y1).\nSimilarly, the derivative in the y-direction is\nm\no\n∂(If)\n'\n= c =\n(f( x 3) - f( x 1))( x 2 - x 1) - (f( x 2) - f( x 1))( x 3 - x 1) .\n∂y\nA\nIn general, a directional derivative in the direction s = (sx, sy) is\n∂(If)\n∂(If)\n∂(If)\n'\n= sx\n+ sy\n= sxb ' + syc .\n∂s\n∂x\n∂y\nBecause the gradient approximation is constructed from a linear function, the gradient estimate is\nconstant over the triangle. The approximation is first-order accurate.\n\nChapter 4\nElements of a Program and Matlab\nBasics\n4.1\nComputer Architecture and Computer Programming\n4.1.1\nVirtual Processor\nIt is convenient when programming a computer to have a mental model of the underlying architec\nture: the components or \"units,\" functions, and interconnections which ultimately implement the\nprogram. It is not important that the mental model directly correspond to the actual hardware of\nany real computer. But it is important that the mental model lead to the right decisions as regards\nhow to write correct and efficient programs.\nWe show in Figure 4.1 the architecture for a \"virtual computer.\" There are many ways in\nwhich we can extend or refine our model to more accurately represent either particular processes or\nparticular computers of interest: we might break down each unit into smaller units -- for example, a\nmemory hierarchy; we might consider additional, special-purpose, units -- for example for graphics\nand visualization; and we might replicate our virtual computer many times to represent (a system\nof) many interacting processes. We emphasize that if you put a screwdriver to computer case, you\nwould not find a one-to-one mapping from our virtual entities to corresponding hardware elements.\nBut you might come close.\nWe now describe the different elements. On the far left we indicate the memory. This memory\nis often hierarchical: faster and more expensive memory in a \"cache\"; slower and much more ex\ntensive \"RAM.\" (Note also there will be archival memory outside the processor accessed through\nI/O functions, as described shortly.) Next there is the arithmetic unit which performs the various\n\"basic\" operations on data -- for example, assignment, addition, multiplication, and comparison.\n(The adjective \"arithmetic\" for this unit is overly restrictive, but since in this course we are primar\nily focused on numerical methods the key operations are indeed arithmetic.) We also identify the\n\"instruction stack\" which contains the instructions necessary to implement the desired program.\nAnd finally there is the I/O (Input/Output) unit which controls communication between our pro\ncessor and external devices and other processes; the latter may take the form of files on archival\nmedia (such as disks), keyboards and other user input devices, sensors and actuators (say, on a\nrobot), and displays.\nWe note that all the components -- memory, arithmetic unit, instruction stack, I/O unit --\nDRAFT V1.2 (c) The Authors. License: Creative Commons BY-NC-SA 3.0.\n\nMemory\nI/O\nInstruction\nStack\nInterpreter\nArithmetic\nUnit\nflow\ncontrol\nother processes\nactuators, displays\nsensors, keyboards, ...\nfiles\nFigure 4.1: Virtual Processor\nare interconnected through buses which shuttle the necessary data between the different elements.\nThe arithmetic unit may receive instructions from the instruction stack and read and write data\nfrom memory; similarly, the instruction stack may ask the I/O unit to read data from a file to the\nmemory unit or say write data from memory to a display. And the arithmetic unit may effectively\ncommunicate directly with the instruction stack to control the flow of the program. These data\nbuses are of course a model for wires (or optical communication paths) in an actual hardware\ncomputer.\nThe \"I\" in Figure 4.1 stands for interpreter. The Interpreter takes a line or lines of a program\nwritten in a high-level programming or \"scripting\" language -- such as Matlab or Python -- from\nthe instruction stack, translates these instructions into machine code, and then passes these now\nmachine-actionable directives to the arithmetic unit for execution. (Some languages, such as C, are\nnot interpreted but rather compiled: the program is translated en masse into machine code prior\nto execution. As you might imagine, compiled codes will typically execute faster than interpreted\ncodes.)\nThere are typically two ways in which an interpreter can feed the arithmetic unit. The first\nway, more interactive with the user, is \"command-line\" mode: here a user enters each line, or small\nbatch of lines, from the keyboard to the I/O unit; the I/O unit in turn passes these lines to the\ninterpreter for processing. The second way, much more convenient for anything but the simplest of\ntasks, is \"script\" mode: the I/O unit transfers the entire program from a file prepared by the user\nto the instruction stack; the program is then executed proceeding from the first line to the last.\n(The latter is in fact a simplification, as we shall see when we discuss flow control and functions.)\nScript mode permits much faster execution, since the user is out of the loop; script mode also\npermits much faster development/adaptation, since the user can re-use the same script many times\n-- only changing data, or perhaps making incremental corrections/improvements or modifications.\n\n4.1.2\nThe Matlab Environment\nIn Matlab the user interface is the command window. The command window provides the prompt\n>> to let the user know that Matlab is ready to accept inputs. The user can either directly enter\nlines of Matlab code after the >> prompt in command-line mode; alternatively, in script mode,\nthe user can enter >> myscript.m to execute the entire program myscript.m. The suffix .m indicates\nthat the file contains a Matlab program; files with the .m suffix are affectionately known as \"m\nfiles.\" (We will later encounter Matlab data files, which take the .mat suffix.) Note that most\neasily we run Matlab programs and subprograms (such as functions, discussed shortly) from the\nfolder which contains these programs; however we can also set \"paths\" which Matlab will search\nto find (say) myscript.m.\nMatlab in fact provides an entire environment of which the command window is just one\n(albeit the most important) part. In addition to the command window, there is a \"current folder\"\nwindow which displays the contents of the current directory -- typically .m files and .mat files, but\nperhaps also other \"non-Matlab \" (say, document) files -- and provides tools for navigation within\nthe file system of the computer. The Matlab environment also includes an editor -- invoked by\nthe \"Edit\" pull-down menu -- which permits the user to create and modify .m files. Matlab also\nprovides several forms of \"manual\": doc invokes an extensive documentation facility window and\nsearch capability; and, even more useful, within the command window >>help keyword will bring\nup a short description of keyword (which typically but not always will be a Matlab \"built-in\"\nfunction). Similar environments, more or less graphical, exist for other (interpreted) programming\nlanguages such as Python.\nWe note that in actual practice we execute programs within programs within programs. We boot\nthe system to start the Operating System program; we launch Matlab from within in Operating\nSystem to enter the Matlab environment; and then within the Matlab environment we run a\nscript to execute our particular (numerical) program. It is the latter on which we have focused\nin our description above, though the other layers of the hierarchy are much better known to the\n\"general computer user.\" It is of course a major and complicated task to orchestrate these different\nprograms at different levels both as regards process control and also memory and file management.\nWe will illustrate how this is done at a much smaller scale when we discuss functions within the\nparticular Matlab context.\n4.2\nData Types (and Classes)\nAll data in the computer is stored as 0's and 1's -- binary digits. This is most convenient as\nbinary operations are very efficiently effected in terms of the necessary nonlinear circuit elements.\nThe basic unit of memory is the \"word-length\" of the machine -- the number of binary digits, or\n\"bits,\" which are used to represent data. Most machines these days are based on 32-bit or 64-bit\nwords (which are 4 Bytes and 8 Bytes, respectively); in some cases particular data types might be\nrepresented by two words (or more).\nBut obviously we will need to interpret these 0's and 1's in different ways: in some cases the\n0's and 1's might represent machines codes (instructions) which tell the arithmetic unit what to\nexecute; in other cases, the 0's and 1's might represent data on which the the instructions will\noperate (the \"operands\"). Furthermore, there are many different type of data: any piece of data is\ndefined not just by the 0's and 1's that make up the word, but also by the \"data type\" which tells\nthe computer how to interpret and operate upon the data. As regards the latter, we note that the\nsame set of 0's and 1's can mean something very different -- and be operated on in very different\nways -- depending on the data type associated with these 0's and 1's.\n\nThere are several important types within Matlab (and homologous types within other pro\ngramming languages). There are logical variables which are either 0 or 1 which correspond respec\ntively to (and in fact the data may be entered as) false or true . There is integer data -- a\nsigned whole number. There is character data, in which the 0's and 1's encode particular characters\nsuch as letters in the alphabet or numerals -- the famous ASCII code and recent extensions. And\nparticularly important for us, there are floating point numbers, which in Matlab are 64 bits and\nare called (for largely historical reasons) simply double. Representation of floating point numbers\n(FPNs) by a 64 bits is probably less obvious than representation of a whole number, and hence\nwe will discuss representation of FPNs, and also floating point operations, in a separate section.\nMatlab also supports a complex floating point type. These types are \"atomic\" in that they are\npart of the core Matlab scripting language.\nIn some programming languages the user is required upon creation of a variable to specify the\ndata type. (We define variables in the next section -- for now, think of a variable as the name\nof a particular piece of data.) Each variable must be an instance of one of the available (in our\ncase, Matlab ) data types. Matlab is much less picky than other programming languages -- a\nblessing and a curse -- and typically if no type is specified Matlab will simply assume a (double)\nfloating point number, which is hence the \"default.\"\nIt is, however, possible to specify that any particular variable is logical, with the logical\nfunction, an integer, with the (say) int32 command, a character, with the char command (or\nmore simply with quotes), and a floating point number, with the double command. We can also\ndetermine what type of data a particular variable is with the islogical, isinteger, ischar, and\nisfloat functions.\nWe already above and will frequently below refer to functions. We do not fully define functions\nuntil a later chapter, in which we learn how to create our own functions. For now, think of a function\nas a program which takes some (zero, one, two, or many) input arguments and yields some output;\nwe provide illustrations in the next section. All of the functions we describe in the preceding\nparagraph are \"built-in\" functions that are part of the core Matlab scripting language; we shall\nexercise these functions in the next section once we are armed with the assignment operation.\n(In fact, false (and true) are also built-in Matlab functions: false takes no arguments and\nreturns a logical zero.) Note the Matlab \"core\" is quite large compared to other languages such\nas Python, in which most functions must be explicitly brought in as modules. There are, however,\nofficial Matlab extensions to the core, known as \"toolkits.\" In actual practice, functions can yield\nmany outputs, not just a single output; we discuss this extension in a later chapter.\nWe note that often we might perform operations on data of different types. In that case we\nmight effect \"conversion\" before proceeding with the operation, or we might let the programming\nlanguage automatically perform \"coercion\" -- conversion to a common data type based on rules\nof precedence. For example, in Matlab , if we attempt to add an integer and a floating point\nnumber, Matlab will (effectively) first convert the integer variable to a floating point variable.\n(Note that even when we invoke the various round, fix, floor, and ceil Matlab functions to\nround a floating point number (the input) to an integer ( the output), the output is of data type\ndouble.) In most cases Matlab makes reasonable choices, though on occasion more direct control\nis warranted.\nFinally we note that there is another term used to describe the proper specification and inter\npretation of given data: \"class.\" Typically data type is part of the language whereas data classes\nare created by the user. And typically data type would refer to a word or maybe two words whereas\nclass would refer to a compound type of many words (each of which might be specified as a different\ndata type). Class also has a special significance in object-oriented programming: a class defines\nnot just a compound data type (an instance of which is known as an \"object\"), but also functions\nor \"methods\" on members of this class. Matlab supports object-oriented programming both ex\n\nplicitly and implicitly, however we will only briefly touch on object-oriented programming in this\ncourse, and primarily for purposes of interpretation of various operators.\nThis section is rather abstract simply because we do not yet know how to create data and\nhence we can not demonstrate any of the concepts. As already indicated, we shall illustrate the\nnotion of data types, the matlab functions used to define variables of a particular data type, and\nthe functions used to query variables as to their data type, once we learn how to create variables\n-- in the next section.\n4.3\nVariables and Assignment\nThe assignment statement is the most basic operation. We proceed by example (using the command-\nline input mode):\n>> pi_approx = 3.14159\npi_approx =\n3.1416\n>>\nwhere we enter the material after the prompt >> and Matlab responds as indicated in the lines\nbelow the prompt line. In general, Matlab will display the result of an operation in the command\nwindow unless we put a semi-colon at the end of the instruction.\nIt is important to understand what this statement actually does. The variable pi_approx is a\nname to which Matlab will associate a unique address -- a location in memory; hence the variable\npi_approx is in fact an address (a name), not a value. The assignment statement puts the value\n3.14159 at the address pi_approx. Again, pi_approx is the address, or reference, or pointer, or\nbox, which contains the value. If we change the value\n>>pi_approx = 3.14\npi_approx =\n3.14\n>>\nwe are simply replacing the earlier value 3.14159 at address pi_approx with the new value 3.14 at\nthe same address pi_approx.\nIn the above assignment statement the = is an operator (and an operator which is part of the core\nMatlab functionality). An operator is a function which takes one or two arguments and produces\nan output; operators, given the few operands, can be conveniently represented as a symbol. In the\nnext few sections we will introduce a number of useful operators. In terms of an operator, = looks\nto the right for the value and then places this value in the address indicated to the left.\nIn our assignment for pi_approx the way in which we have entered the number ensures that\npi_approx is of type floating point double. But we can be more explicit as in\n>> pi_approx = double(3.14159)\n\npi_approx =\n3.1416\n>> floatcheck = isfloat(pi_approx)\nfloatcheck =\n>>\nwhich confirms that the double function indeed produces a variable of data type double.\nWe emphasize that both double and isfloat are functions. The general syntax for a function\nis simple: the input or inputs are included in parentheses following the function name, and the\noutput (later, many outputs) -- the evaluation of the function -- is assigned to the variable to the\nleft of the =. For example, isfloat takes as input a variable -- here the input is pi_approx -- and\nreturns as output a logical variable which indicates whether the input is a floating point number --\nhere the output is a 1 (true), since pi_approx is indeed a floating point number (or more precisely,\nan instance of the floating point double data type).\nIt is worth dissecting the above example a bit further. In fact, the statement\n>> floatcheck = isfloat(pi_approx)\nfloatcheck = 1\n>>\nis a very simple example of a very powerful capability -- composition. In particular, in this case\nwhen = looks to the right it finds not a value but a function, isfloat; the function isfloat is\nthen evaluated and the output of isfloat ( a logical 1) is then taken as the (right) input to the =\n(assignment) operator; the = then looks to the left, floatcheck, to know where in memory to write\nthis value (a logical 1) (or to create a memory location with the \"name\" floatcheck, as needed).\nWe invite the reader to input a logical with logical and check that the result is logical with\nislogical, and an integer with int32 and check that the result is integer with isinteger. We will\ndiscuss characters and strings later in a separate section. Most often we will use the double data\ntype, which is the Matlab default and requires no special attention -- we just enter the number\nas 3.14159. We will also make extensive use of the logical data type.\n4.4\nThe Workspace and Saving/Loading Data\nIn the previous section, we created variables such as pi_approx and floatcheck. Where do these\nvariables go? These variables -- and all variables we, or the programs we launch from the command\nwindow, create -- go to what is known as the \"workspace.\" In some sense, the workspace is the\npart of the memory in Figure 4.1 (interpreted as the Matlab environment) which has already been\nallocated. In order to see all the variables in our workspace we can do >> who. Note that >> who\ndoes not evaluate the variables and hence does not provide the values; rather, it provides a list of\nall the variable names to which we have assigned data. (To determine the value of a particular\nvariable we would simply type >>variable.) Note that whos is the same as who but with additional\n\ninformation about size and data type (or \"class\") of each variable.\nIf we wish to delete all the variables in the workspace, and start anew, we would do clear. (This\nof course only affects the Matlab variables you have created, with no effect on the file system --\nsuch as the .m files you might have created.) Alternatively, you might wish to just delete certain\nvariables, say variable 1 and variable 2 , in which case we would do >> clear variable 1 variable 2 .\nFor smaller programs memory management is not an issue, but for larger programs it is important\nto clear or more generally allocate and de-allocate memory carefully.\nIt is often the case that we wish to save the results of our calculations for future use -- rather\nthan re-compute. This is done very simply in Matlab : to save variables variable 1 and variable 2\nto a data file save_for_later.mat we do save save_for_later variable 1 variable 2 . To reload\nthis data we simply do load save_for_later which will include the contents of save_for_later,\nin our case variable 1 and variable 2 , in the current workspace -- that is, in addition to the current\ncontents of your workspace. Note the .mat file is a Matlab specific data file which is the most\nconvenient within Matlab , but there are also many other (and more universal) formats in which\ndata can be saved.\n4.5\nArithmetic Operations\nWe now turn to arithmetic operations, typically performed in Matlab on floating point numbers\n(though the operators also work on integers and indeed logicals through coercion, as discussed\nabove).\nAs already indicated, an operator is a function, syntactically represented by a symbol, which\ntakes one or two input arguments, or parameters, or operands, and returns a result. The arithmetic\noperators are ^ (exponentiation), / (division), * (multiplication), + (addition), and - (subtraction).\nThese operations do the obvious thing, applied either to data or variables.\nWe consider addition: for data,\n>> 2 + 3\nans =\nor for variables\n>> x = 2; y = 3;\n>> x + y\nans =\n>>\n(Note the semi-colons suppress display of x and y; if we wish to confirm the value, we need only do\n(say) >> x without a semi-colon to evaluate x.) In more detail, the + operator takes the two values\nto the left and right and outputs as the answer (ans) the sum. The other arithmetic operators ^,\n/, *, and -, perform in a similar obvious fashion.\n\nWe note that in the above x + y is an expression -- here a single function, but more generally\na composition of many operations -- which is evaluated to yield the result ans. Note when we do\nan evaluation of an expression expr, Matlab \"finishes\" the statement for us as ans = expr -- in\nother words, Matlab assigns the result of the evaluation to a variable ans. We can in fact use this\nvariable ans subsequently, but this is highly frowned upon since, as you can imagine, it is quite\neasy for the generic ans to be changed in unanticipated or unnoticed ways.\nRather, if we wish to subsequently use the result of an evaluation, we should explicitly assign\nthe output to a variable, say z: we need only do\n>> z = x + y\nz = 5\n>>\nwhich is a composition of the addition ( +) operator with the assignment ( =) operator: we evaluate\nthe expression (or operation, or function) x + y and then assign the result of this evaluation to a\nvariable z.\nWe repeatedly above refer to the addition \"function.\" In fact, for most operators there is an\n\"output = function name (inputs)\" syntax which is equivalent to the operator syntax. For instance,\nwe may compute the sum of x and y as plus(x,y). Obviously the operator form is much easier\nand more readable, however the plus contains the actual code which implements addition and\nfurthermore provides a mechanism by which to change what we mean by addition for different data\ntypes (and in the object-oriented context, different classes). We do not recommend that you change\nthe definition of plus for double data types -- but in fact, it is quite easy to do, and could prove\nan effective form of industrial numerical sabotage.\nIt is instructive to consider the statement\n>> z = z + 1\nz = 6\n>>\nwhich in fact serves quite often in iterative procedures (typically for z an integer, even if represented\nin Matlab by a double). What does this statement do? First Matlab evaluates the expression\nz + 1 to obtain the value 6; then operator = assigns this value 6 to the address (variable) z.\nAlthough mathematically z = z + 1 appears nonsensical, it is important to remember that in\nz = z + 1 the = is the assignment operator and not an equal sign. (Of course, Matlab contributes\nto the confusion in very next line, z = 6, by using the = sign in the convention mathematical sense\nof equality.)\nUp to this point we have composed operators for which we did not need to worry about the\norder in which we performed the operations. For example, 3 + 4 + 5 can be evaluated either as\n(3 + 4) + 5 (i.e., 3 + 4 first, then + 5). (In fact, this is not quite true in finite precision, as we\ndiscuss in the next section.) On the other hand, 3*2^4 gives quite different results if we perform\neither the * first or the ^ first. Matlab thus provides rules of precedence for the order in which\noperators are evaluated: first the items in parentheses, from the inside out; then ^; then / and *;\nthen + and -. The mnemonic is PEDMAS (not very mnemonic, in fact). If the rules of precedence\ndo not not dictate a unique order then Matlab operates from left to right.\nThe easiest way to avoid misinterpretation of your intentions is to liberally use parentheses,\n\nand for readability to always include ample spaces within and between your parentheses. The\nevaluation of 3*2^4 gives us opportunity to introduce the notion of a bug. If you intended (3*2)^4\nbut simply wrote 3*2^4 Matlab would do something different from your intentions. This is not\nMatlab 's fault, but your fault. There are many kinds of bugs: a statement may in fact not\ncorrespond to valid Matlab syntax and the statement will not even be interpreted; a statement\nmay correspond to valid Matlab syntax but may do something other than intended by the user\n-- as in our 3*2^4 example; the statement may do what the users intends but in fact to achieve\nthe desired end the user's intentions are not correct -- this occurs quite frequently in the context\nof numerical computation.\n4.6 Floating Point Numbers (FPNs): Representation and Opera\ntions\n4.6.1\nFPN Truncation and Representation\nFloating point numbers represent a challenge both in how we represent these numbers and in how\nwe perform arithmetic operations on these numbers. To begin, we express a number x in base 2 as\n⎛\n⎞\ninf\nn\nx = σ1 ⎝\nbk2-k⎠ × 2σ2E ,\nk=0\nin which the bk are binary numbers -- 0 or 1, E is an integer, and σ1 and σ2 are signs -- ±1. We\nassume that we have normalized the expansion such that b0 = 1. (In fact, we may express x in say\nbase 10 rather than base 2; this in turn will lead to a different floating point format.)\nIn some cases, we may only require a finite sum -- a sum with a finite number of nonzero terms\n-- to represent x. For example, x = 2 may be expressed by the single non-zero term b0 = 1 (and\nE = +1). However more generally a finite number of non-zero bk will not suffice -- even 1/10\nleads to a repeating binary fraction. We thus must truncate the series to develop the floating point\nnumber (FPN) approximation of x:\n⎛\n⎞\nK\nn\n⎠ × 2σ2E'\nxFPN = σ1 ⎝\nb '\nk2-k\n.\nk=0\nHere b ' = bk, 1 ≤ k ≤ K -- we perform truncation of our series -- and E' is the minimum of E\nk\nand Emax -- we truncate the range of the exponent.\nWe now represent or encode xFPN in terms of (a finite number of) 0's and 1's. Towards this\nend we assign one bit each to the signs σ1 and σ2; we assign p = K bits for the binary numbers b '\nk,\n1 ≤ k ≤ K, to represent the mantissa (or significand); we assign pE bits to represent the exponent\nE (and hence Emax = 2pE ). (Our choice of base 2 makes the encoding of our approximation in 0's\nand 1's particularly simple.) In the 64-bit IEEE 754 binary double (now called binary64) floating\npoint format, p = 52 and pE = 10 (corresponding to Emax = 310 such that in total -- including the\nsign bits -- we require 2 + 52 + 10 = 64 bits. (The storage scheme actually implemented in practice\nis slightly different: we need not store the leading unity bit and hence we effectively realize p = 53;\nthe exponent sign σ2 is in fact represented as a shift.)\nThere are two primary sources or types of error in the approximation of x by xFPN: the first\nis FPN truncation of the mantissa to p bits; the second is the FPN truncation of the exponent to\npE bits. The former, FPN mantissa truncation, is generally rather benign given the rather large\nvalue of p. However, in some cases, FPN mantissa truncation errors can be seriously amplified by\n\narithmetic operations. The latter, FPN exponent truncation, takes the form of either overflow --\nexponents larger than 310, represented in Matlab as plus or minus Inf -- which is typically an\nindication of ill-posedness, or underflow -- exponents smaller than -310, represented in Matlab\nas 0 -- which is typically less of a concern.\nWe note that the word \"precision\" is typically reserved to indicate the number of bits or dig\nits with which a floating point number is approximated on any particular hardware (and IEEE\nformat); typically we focus on the mantissa. For example, 64-bit precision, or \"double-precision,\"\ncorresponds to 52 (or 53) binary digits of precision -- roughly 16 decimal digits of precision --\nin the mantissa. Precision can also be characterized in term of \"machine precision\" or \"machine\nepsilon\" which is essentially the (relative) magnitude of the FPN truncation error in the worst case:\nwe can find machine epsilon from the Matlab built-in function eps, as we will illustrate below.\nWe will define machine epsilon more precisely, and later construct a code to find an approximation\nto machine epsilon, once we have understood floating point arithmetic.\nOftentimes we will analyze a numerical scheme in hypothetical \"infinite-precision\" arithmetic\nin order to understand the errors due to numerical approximation and solution in the absence of\nfinite-precision FPN truncation effects. But we must always bear in mind that in finite precision\narithmetic additional errors will be incurred due to the amplification of FPN truncation errors by\nvarious arithmetic operations. We shortly discuss the latter in particular to identify the kinds of\noperations which we should, if possible, avoid.\nFinally, we remark that there are many ways in which we may choose to display a number say\nin the command window. How we display the number will not affect how the number is stored in\nmemory or how it is approximated in various operations. The reader can do >> help format to\nunderstand the different ways to control the length of the mantissa and the form of the exponent in\ndisplayed floating point numbers. (Confusingly, format in the context of how we display a number\ncarries a different meaning from format in the context of (IEEE) FPN protocol.)\n4.6.2\nArithmetic Operations\nWe shall focus on addition since in fact this particular (simple) operation is the cause of most\ndifficulties. We shall consider two numbers x1 and x2 which we wish to add: the first number\nhas mantissa m1 and exponent E1 and the second number has mantissa m2 and exponent E2. We\npresume that E1 > E2 (if not, we simply re-define \"first\" and \"second\").\n'\nFirst, we divide the first mantissa by 2E1-E2 to obtain m = m22-(E1-E2): in this form, x1 now\n'\nhas mantissa m2 and exponent E1 . (Note this division corresponds to a shift of the mantissa: to\n'\nobtain m2 we shift m1 by E1 - E2 places to the right -- and pad with leading zeros.) At this stage\n'\nwe have lost no precision. However, in actual practice we can only retain the first p bits of m2\n''\n(since we only have p bits available for a mantissa): we denote by m1 the truncation of m1 to fit\n''\nwithin our p-bit restriction. Finally, we perform our FPN sum z = x1 +x2: z has mantissa m1 +m2\nand exponent E1. (Our procedure here is a simplification of the actual procedure -- but we retain\nmost of the key features.)\nWe can immediately see the difficulty: as we shift m2 to the right we are losing E1 - E2 bits of\nprecision. If the two exponents E1 and E2 are very different, we could lost all the significant digits\nin x2. Armed with FPN we can in fact develop a simple definition of machine epsilon: the smallest\nepsilon such that 1 + epsilon = 1, where of course by + we now mean finite precision FPN\naddition. Later we will take advantage of this definition to write a short program which computes\nmachine epsilon; for our purposes here, we shall simply use the Matlab built-in function eps.\nIt is clear that finite-precision and infinite-precision arithmetic are different and will yield dif\nferent results -- the difference is commonly referred to as \"round-off\" error. Indeed, finite-precision\narthmetic does not even honor all the usual (e.g., commutative, associative) rules. We consider the\n\nexample (recall that in Matlab operations are performed from left to right in the absence of any\nprecedence rules):\n>> mach_eps = eps\nmach_eps =\n2.2204e-16\n>> (mach_eps/2 + 1 + mach_eps/2 - 1)/mach_eps\nans =\n>> (mach_eps/2 + mach_eps/2 + 1 - 1)/mach_eps\nans =\n>>\nClearly, in infinite precision arithmetic both expressions should evaluate to unity. However, in finite\nprecision the order matters: in the first expression by definition mach_eps/2 + 1 evaluates to 1; in\nthe second expression, mach_eps/2 + mach_eps/2 adds two numbers of identical exponent -- no\nloss in precision -- which are then large enough (just!) to survive addition to 1. This anomaly is\na \"bug\" but can also be a feature: we can sometimes order our operations to reduce the effect of\nround-off errors.\nBut there are situations which are rather difficult to salvage. In the following example we\napproximate the derivative of sin(x) by a forward first-order difference with increment dx which is\nincreasingly small:\n>> cos(pi/4)\nans =\n0.707106781186548\n>> dx = .01;\n>> deriv_dx = (sin(pi/4 + dx) - sin(pi/4))/dx\nderiv_dx =\n0.703559491689210\n>> dx = 1e-8;\n>> deriv_dx = (sin(pi/4 + dx) - sin(pi/4))/dx\n\nderiv_dx =\n0.707106784236800\n>> dx = 1e-20;\n>> deriv_dx = (sin(pi/4 + dx) - sin(pi/4))/dx\nderiv_dx =\n>>\nWe observe that what Newton intended -- and the error bound we presented in Chapter 3 -- is\nindeed honored: as dx tends to zero the finite difference (slope) approaches the derivative (cos(π/4)).\nBut not quite: as dx falls below machine precision, the numerator can no longer see the difference,\nand we obtain an O(1) error -- precisely in the limit in which we should see a more and more\naccurate answer. (As the reader can no doubt guess, pi, sin, and cos are all Matlab built-in\nfunctions.)\nThis is in fact very typical behavior. In order to make numerical errors small we must take\nsmaller increments or many degrees-of-freedom, however if we go \"too far\" then finite-precision\neffects unfortunately \"kick in.\" This trade-off could in fact be debilitating if machine precision\nwere not sufficiently small, and indeed in the early days of computing with only a relatively few\nbits to represent FPNs it was a struggle to balance numerical accuracy with finite precision round-\noff effects. These days, with the luxury of 64-bit precision, round-off errors are somewhat less of a\nconcern. However, there are situations in which round-off effects can become important.\nIn particular, we note that the problem is our derivative example is not just the numerator but\nalso the dx in the denominator. As a general rule, we wish to avoid -- where possible -- division\nby small numbers, which tends to amplify the effects of finite-precision truncation. (This relates\nto stability, which is an important theme which we will encounter in many, often related, guises\nin subsequent chapters.) We will see that even in much more sophisticated examples -- solution\nof large linear systems -- \"avoid division by small numbers\" remains an important guideline and\noften a feature (by construction) of good algorithms. The problem of course is aggravated when\nwe must perform many operations as opposed to just a few operations.\nWe have focused our attention on addition since, as indicated, this operation is often the prox\nimal cause of the round-off difficulties. Other operations are performed in the \"obvious\" way. For\nexample, to multiply two numbers, we multiply the mantissas and add the exponents and then\nre-adjust to conform to the necessary representation. Division and exponentiation follow similar\nrecipes. Obviously underflow and overflow can be undesired byproducts but these are typically\neasier to avoid and not \"fundamental.\"\n4.7\nRelational and Logical Operations\n4.7.1\nRelational Operations\nA relational operator performs some kind of comparison between two variables (typically floating\npoint double) and then returns a logical variable to indicate the outcome of the comparison. The\nrelational operators are equal, ==; not equal, ~=; less than, <; greater than, >; less than or equal, <=;\ngreater than or equal, >=. Note that the equal operator, ==, is now interpreted in the mathematical\nsense of = (vs. the Matlab assignment operator = which of course serves a different function).\n\nAs an example, we consider\n>> x = 4.6; y = 4.7;\n>> isless = x < y\nisless =\n>>\nHere Matlab first evaluates the expression x < y -- which, since x is less than y, is a true\nstatement, and hence returns a logical 1 -- and then assigns this value of 1 to the (logical) variable\nisless. (As we know, floating point numbers are truncated in finite precision arithmetic; since the\n< operates on the truncated form, of course the comparison is only good to machine precision.)\nWe can of course consider composition. Typically, composition of relational operations is by\nlogical operations, as we now discuss. (In fact, we can apply usual arithmetic to logical variables,\nwhich are converted to floating point for the purpose. This is often convenient, but must be used\nwith some care.)\n4.7.2\nLogical Operations\nIt would be possible to hi-jack operations such as + to perform Boolean operations on logical\nvariables, however Matlab prefers to reserve the usual arithmetic functions for these operators\napplied to logical variables. Hence we introduce new operators.\nThe three key logical operators are AND, indicated as &, OR, indicated as |, and NOT, indicated\nas ~. (There are also other options, such as the exclusive or, or XOR.) The AND and OR operators\ntake as (the two) operands logical variables and the result is of course also a logical variable. The\nNOT takes a single logical operand and the result is also a logical variable. As already indicated,\nthese logical operators are often composed with relational operators.\nThe AND, OR, and NOT behave in the expected fashion. The statement L3 = L1 & L2 yields\nL3 = 1 (true) only if both L1 and L2 are both == 1 (true), otherwise L3 = 0. The statement\nL3 = L1 | L2 yields L3 = 1 if either L1 == 1 or L2 == 1, otherwise L3 = 0 (note that if both\nL1 == 1 and L2 == 1, then L3 = 1); conversely, L3 = 0 only if both L1 == 0 and L2 == 0. Fi\nnally, the NOT: L3 = ~L1 yields L3 = 1 if L1 == 0 and L3 = 0 if L1 == 1.\nAs an example, we consider the AND and NOT:\n>> x = 4.6; y = 4.7;\n>> u = 3.1; v = 3.2;\n>> z = (x < y) & ~(u < v)\nz =\n>>\nwhich of course yields the correct result. Note the Matlab precedence convention is to evaluate\nrelational operators before logical operators and hence our parentheses in the above are redundant\n\n-- but better too many parentheses than too few. And another example,\n>> x = 4.6; y = 4.7;\n>> u = 3.1; v = 3.2;\n>> z = (x < y) | ~(u < v)\nz =\n>>\nnow with the OR and NOT.\nFinally, we mention that Matlab provides \"short-circuit\" versions of AND and OR, the oper\nators for which are given by && and ||, respectively. These short-circuit operators will not evaluate\nthe second operand (i.e., to the right) if the first operand (i.e., to the left) suffices to make the de\ncision. For example, in our OR example above, since x < y, z = (x < y) || ~(u < v) will only\nevaluate (x < y). This can lead to efficiencies -- if the second operand is much more expensive\nand or ensure that a (second) operand is only evaluated when it exists and is well-defined.\nLogical (and relational) operations play a key role in flow control -- in controlling the flow (or\n\"direction\") of the program based on the results generated by the program itself. In some sense it\nis these logical and relations operations and the enabled flow control which distinguishes a program\nexecuted by a computer from arithmetic performed on a calculator.\n4.8\nFlow Control\n4.8.1\nThe if Statement\nThe if statement is very simple. The general syntax is given by\nif logical expression 1\nBLOCK 1\nelseif logical expression 2\nBLOCK 2\nelse\nBLOCK 3\nend\nwhich is interpreted by Matlab as follows:\nif logical expression 1 evaluates to true, execute BLOCK 1 and go to end (and continue on\nwith the next line in the program);\nif logical expression 1 evaluates to false, but logical expression 2 evaluates to true, execute\nBLOCK 2 and go to end (and continue);\nif logical expression 1 is false and logical expression 2 is false, execute BLOCK 3 and go\nto end (and continue).\nNote several variants are possible: we may include multiple elseif statements between the\nBLOCK 1 and else; and we may omit the else and BLOCK 3 statements.\n\nIn the event that in fact there are many cases there is another Matlab statement which is no\ndoubt preferable to the if statement: the switch statement. We do not discuss the switch state\nment here, but rather use this opportunity to recall the very helpful help function: >> help switch\nwill provide you with a quick (but sufficient) description of the syntax and functionality of the\nswitch statement.\n4.8.2\nThe while Statement\nThe syntax of the while statement is\ninitialize var 1, var 2,. . .\nwhile relational or logical expression while (var 1, var 2,. . . )\nBLOCK % new values assigned to var 1, var 2, ...\nend\nThis statement is a loop which is controlled by the value of the logical variable which is the result of\nevaluation of relational_or_logical_expression_while. What makes the statement powerful\nis that relational_or_logical_expression_while may depend on var 1, var 2, . . . , the values\nof which are changed at each pass through the loop. In particular, the while is executed as follows:\nif relational or logical expression while (var 1, var 2, . . . ) is true, execute (the instruction lines\nin) BLOCK , otherwise go to end and continue with next line of program of which the while is\npart; repeat. Note that var 1, var 2, . . . must be initialized prior to entering the while loop.\nAs an example, we consider\n>> i = 0;\n>> sum_of_integers = 0;\n>> while i <= 3\nsum_of_integers = sum_of_integers + i;\ni = i + 1;\nend\n>> sum\nsum_of_integers =\n>>\nHere, relational or logical expression while (var 1) is the simple expression i <= 3, where i plays\nthe role of var 1. In fact, this particular sum is more easily performed with a for statement, as we\ndescribe shortly. The true value of the while is when the relational or logical expression is a more\ncomplicated function of the variables which are changed by the BLOCK and in particular when we\ndo not know a priori how many iterations through the loop will be required.\nFor example, we create the script machine eps.m\n% script to calculate machine epsilon\nmach_eps = 1;\nwhile (1 + mach_eps ~= 1)\nmach_eps = mach_eps/2.;\n\nend\nmach_eps\nin the editor. Note that as we start to construct slightly longer programs we will start to use script\nmode rather than command-line mode. The input is easier, as are debugging and modification, and\nof course re-use. In addition, the editor within Matlab recognizes various keywords and automat\nically formats statements for improved readability. Note also the comment line: any material on a\nline which follows a % will be ignored by the interpreter and serves only to educate the author and\nuser's as to the intent of the program or particular lines of the program.\nWe then enter in the command window\n>> machine_eps\nmach_eps =\n1.1102e-16\n>>\nwhich runs our script. Of course this code is just calculating for us machine precision, which agrees\nwith the Matlab eps to within the factor of two related to our stopping tolerance.\nFinally, we note that you may include a break in a BLOCK statement\nif (relational or logical expression break) break\nwhich will directly go to the end statement of the while loop quite independent of whether\nrelational_or_logical_expression_while (for the current values of var 1, var 2, . . . ) is true\nor false. Purists often try to avoid break statements, but pragmatists tolerate the occasional\nbreak statement. Too many break statements may be a symptom of poor program design or more\ngenerally passive-aggressive tendencies.\n4.8.3\nThe for Statement\nThe syntax for the for statement is\nfor VARCOUNTER = LIM 1 : INCREMENT : LIM 2\nBLOCK % no reassignment of VARCOUNTER\nend\nTypically LIM 1, INCREMENT, LIM 2 would be integers (even if of data type double), however\nthere are also many instances in which these variables could be (mathematically) non-integer. Note\nalso that INCREMENT can be positive or negative, and that if INCREMENT is not specified then\nMatlab chooses the default value INCREMENT = 1.\nThe execution of the for loop is simple: we execute BLOCK for VARCOUNTER = LIM 1 ; we\nupdate VARCOUNTER = VARCOUNTER + INCREMENT ; then, if VARCOUNTER <= LIM 2 ,\nrepeat. As for a while statement, we can interrupt the usual flow of the for loop with a break\nstatement. Note that if LIM 1 + INCREMENT is less than LIM 2 then BLOCK will never be\nexecuted.\nWe repeat our earlier example:\n\n>> sum_of_integers = 0;\n>> for i = 1:3\nsum_of_integers = sum_of_integers + 1;\nend\n>> sum_of_integers\nsum_of_integers =\n>>\nThere are many situations in numerical methods in which the for loop is the ideal construct. How\never, it is also true that in Matlab there are a number of functions related to array manipulation\nthat, although implicitly built upon a for construction, are typically more efficient than an explicit\nfor loop. We introduce some of these functions in the next section.\nFinally, we note that our for syntax here is not as general as provided for by Matlab .\nHowever, the more general syntax requires the notions of single-index or multi-index arrays, which\nwe have not yet introduced. Following the treatment of arrays the reader should do >> help for\nto understand the generalization: in effect, we can require VARCOUNTER to cycle through any\nparticular set of scalars (defined in a single-index array) or VARCOUNTER itself may even be a\nsingle-index array which cycles through a particular set of single-index arrays (defined in a double-\nindex array).\n\nChapter 5\nMatlab Arrays\n5.1\nSingle-Index Floating Point Arrays\n5.1.1\nThe Concept\nIt is often the case that we have an ordered set of, say n, \"elements\" of data which are somehow\nrelated. The index could represent directions in three space dimensions (k = 1, 2, 3 for x, y, z,\nrespectively) -- at which we store, in each array location, the corresponding coordinate of a point\n(an array of length 3); or the index could represent 15 different times -- at which we store, in\neach location, the time of the measurement, or perhaps the measurement itself (an array of length\n15). Note the index plays the role of independent variable and the array value plays the role of\ndependent variable. In all these cases we will often wish to operate on all n \"related elements\" in\na similar fashion. We would thus like a way to reference all the elements with a common name,\nand an easy way to reference different elements through this common name, in order to develop\nsuccinct, readable, and efficient code for implementing common operations on all the elements. In\nparticular, we would not want to write n lines of code each time we wished, say, to square each of\nthe n elements.\nA single-index array -- in this section, a floating point single-index array -- is the simplest\n\"class\" which achieves these objectives. We first introduce a variable name, array name, which\nshall be associated to all n elements of the array. We then index this array name in order to access\nany particular element of the array: in particular, array name(i) is the pointer to element i of the\narray. We emphasize that, as in the scalar case, array name(i) is not the value of element i of\nthe array but rather the location in memory at which we shall store the value of element i. For\nexample, array name(2) = 3.14159 would assign the value 3.14159 to the second element of the\narray. (We discuss more efficient assignment methods below.)\nConceptually, you may think of the array as stored at n contiguous locations in memory. Ele\nment 1 of the array is stored in array name(1), element 2 of the array is stored in array name(2),\n. . . , and element n of the array is stored in array name(n). In this (virtual) sense, it suffices to\n(say) pass to a function simply the variable array name -- which you may view as the address\nof the first element -- as the addresses of all the other elements of the array can then be readily\ndeduced from array name. (In actual practice, there is also some header information associated\nwith the array -- for example, in our single-index case, the length n.) Since many common array\noperations can be performed in Matlab with simple function calls -- or user-defined function\nDRAFT V1.2 (c) The Authors. License: Creative Commons BY-NC-SA 3.0.\n\ncalls -- at a high-level we can often deal exclusively with array name without explicit reference to\nparticular indices. (Of course, under the hood. . . )\n5.1.2\nAssignment and Access\nThe most explicit way to create a single-index array is by hand: X = [1,3,4] creates a single-\nindex array of length 3, with entries X(1) = 1, X(2) = 3, and X(3) = 4. To determine the\nlength of an array Matlab provides a function length. In our example\n>> X = [1,3,4]\nX =\n>> X(1)\nans = 1\n>> length(X)\nans =\n>>\nNote that this single-index array is a row single-index array. (We can also consider column single-\nindex arrays, in which the commas above are replaced by semi-colons: X = [1;3;4]. We reserve\ntreatment of rows and columns to our discussion of double-index arrays.)\nThe input process is facilitated by the colon operator. In particular, Z = [J:D:K] creates\nthe single-index array J, J+ D,...,J + m*D] for m = fix((K-J)/D), where fix is a Matlab\nfunction which rounds to the nearest integer towards zero. (Note that J:D:K is empty if D == 0,\nif D > 0 & J > K, or if D < 0 & J < K.) The default value of D is 1 and hence J:K is equivalent\nto J:1:K, as in the example\n>> firstfive = [1:5]\nfirstfive =\n>>\nYou will in fact recognize this colon construction from the for statement; and indeed the for\nstatement may take the form for VARCOUNTER = S where S is any single-index array.\nWe may assign an entire array,\n>> Y = X\n\nY =\n>>\nor we may assign or re-assign a particular element as, say,\n>> X(3) = 10;\n>> X\nX =\n>>\nwhich we see modifies X accordingly.\nOf course the point of an array is that we have a systematic numerical approach to indexing,\nand we may thus easily assign values with a for statement. We present two approaches. In the\nfirst, we zero out to initialize:\n>> Z = zeros(1,10);\n>> for i = 1:length(Z)\nZ(i) = i^2;\nend\n>> Z\nZ =\n>>\nNote that zeros(1,n) is a Matlab function which provides a (row) single-index array of all zeros\nof length n. (Note the first argument of zeros indicates that we wish to form a row single-index\narray; zeros(n, 1) would create a column single-index array of all zeros. We will understand\nzeros better once we discuss multi-index arrays.) This approach, of initialization, is preferred\nwhenever possible: it permits Matlab to be more efficient in memory allocation and management.\nIn the second approach, we concatenate:\n>> Z = [];\n>> for i = 1:10\nZ = [Z,i^2];\nend\n>> Z\nZ =\n\n>>\nHere Z = [] defines an array but the array is initially empty: we do this because we can not\n\"add to\" (append to, or concatenate to) an array which does not exist. Note that the expression\n[Z, i^2] evaluates to an array in which the first length(Z) elements are the elements of Z and the\nlast element is i^2. Thus at each iteration the length of Z grows. The above is less efficient than\nthe initialization approach, but very convenient in particular (for example, in a while statement)\nwhen we do not a priori know the number of elements in our (ultimate) array.\nAs our last point on assignment and access, we note that Matlab supports a very convenient\nform of indirect addressing. In particular, if we create a single-index array of integers indvec then\nwe can extract from (say) Z just those elements with indices in indvec:\n>> indvec = [1,3,5,9];\n>> U = Z(indvec)\nU =\n>>\nNote you may also apply indirect addressing on the left-hand side of the assignment statement, but\nsome care must be exercised as regards the \"shape\" (row vs. column) of the resulting single-index\narray.\nNote that in all these shortcuts there is always an equivalent underlying program (which is more\nor less how these shortcuts are implemented). For example, in the above, an array index argument\ntells Matlab to execute, effectively:\n>> U_too = zeros(1,length(indvec))\n>> for inew = 1:length(indvec)\nU_too(inew) = Z(indvec(inew));\nend\n>> U_too\nU_too =\n>>\nBut of course much better to encapsulate and re-use this feature within the Matlab syntax than\nto re-write this little loop on each occasion.\n5.1.3\n(Dotted) Arithmetic Operations\nIt is one of the major advantages of programming languages that as we develop more convenient data\nstructures (or types, or classes), in particular with many elements, we may also suitably define our\noperations to deal directly with these new entities -- as a whole, rather than explicitly manipulating\neach element. In this section we define for the case of single-index arrays the corresponding array\narithmetic operators.\n\nWe first discuss element-by-element operations. In these operations, we consider two arrays of\nthe same length and we apply the same arithmetic operation on each pair of elements which share\nthe same index. We begin with addition/subtraction (and multiplication by a scalar):\n>> P = [1, 4, 7]; Q = [2, -1, 1];\n>> R = P + 3.0*Q\nR =\n>>\nwhich is simply shorthand for the loop\n>> for i = 1:length(P)\nR_too(i) = P(i) + 3.0*Q(i);\nend\n>> R_too\nR_too =\n>>\nThe loop makes clear the interpretation of \"element by element,\" but obviously the one-line state\nment is much preferred.\nNote 3.0 is not an array, it is scalar, which scales all elements of the array Q in our above\nexample. This simple scaling feature can be very convenient in defining arrays of grid points or data\npoints (for example, in interpolation, differentiation, and integration). To wit, if we have an interval\nof length L and wish to create N segments of length L/N, we need only do >> xpts = (L/N)*[0:N].\nNote that xpts is of length (in the sense of number of elements in the array) N+1 since include both\nendpoints: xpts(1) = 0 and xpts(N+1) = L/N.\nFinally, we note one additional shortcut: if q is a scalar, then element-by-element addition to\nour vector P will add q to each element of P. To wit,\n>> q = 3;\n>> P + q\nans =\n>>\nWe might write the above more properly as\n>> P + q*ones(1,length(P))\n\nans =\n>>\nbut there is no need given Matlab 's automatic expansion of q when encountered in array addition.\nNote ones(1,n) is a Matlab function which creates a (row) single-index array of length n with\nall elements set to unity.\nTo implement element-by-element multiplication, division, and exponentiation we do\n>> PdotmultQ = P.*Q\nPdotmultQ =\n-4\n>> PdotdivideQ = P./Q\nPdotdivideQ =\n0.5000\n-4.0000\n7.0000\n>> PdotexpQ = P.^Q\nPdotexpQ =\n1.0000\n0.2500\n7.0000\n>>\nwhich is equivalent to\n>> for i = 1:length(P)\nPdotmultQ_too(i) = P(i)*Q(i);\nPdotdivideQ_too(i) = P(i)/Q(i);\nPdotexpQ_too(i) = P(i)^Q(i);\nend\n>> PdotmultQ_too\nPdotmultQ_too =\n-4\n>> PdotdivideQ_too\nPdotdivideQ_too =\n0.5000\n-4.0000\n7.0000\n\n>> PdotexpQ_too\nPdotexpQ_too =\n1.0000\n0.2500\n7.0000\n>>\nAs for addition, if we replace one of our vectors by a scalar, Matlab will expand out with a \"ones\"\nvector.\nWhy do we need the \"dot\" before the *, /, and ^ operators -- so-called \"dotted\" (or element-by\nelement) operators: dotted multiplication, dotted division, and dotted exponentiation? It turns out\nthat there are two types of entities which look very similar, respectively arrays and vectors (later\nmulti-index arrays and matrices): both are ordered sets of n floating point numbers. However, the\narithmetic operations are defined very differently for these two entities, respectively element-by\nelement operations for arrays and linear algebraic operations (e.g., inner products) for vectors. We\ncould easily define say * to perform element-by-element multiplication for objects which are defined\nas arrays, and to perform an inner product for objects defined as vectors. Unfortunately, although\nconceptually quite clean, this would be very cumbersome since often in one line we wish to treat a\nset of numbers as an array and in the next line we wish to treat the same set of numbers as a vector:\nthere would be much conversion and bookkeeping. Hence Matlab prefers a kind of \"superclass\"\nof array-and-vector (and matrix) entities, and hence perforce some new syntax to indicate whether\nwe wish to treat the array-and-vector as an array (with dotted element-by-element operators) or a\nvector (with undotted linear algebra operators). Note that we do not require dotted + (or dotted\n-) since element-by-element addition and vector addition in fact are equivalent. So there.\nWe note that there are many arithmetic operations on arrays in addition to element-by-element\noperations, many of which are available as Matlab functions. For example, we can easily perform\nthe sum of the first three integers (as we did earlier with a for loop) as\n>> ints = [1:3];\n>> sum(ints)\nans =\n>> mean(ints)\nans =\n>>\nwhere sum performs the sum of all the elements in an array (here ints) and mean calculates the\narithmetic mean of all the element in an array.\nFinally, we note here that the many Matlab built-in mathematical functions -- we have already\nencountered sin and cos, but there are many many more -- look for \"math function\" and \"special\nfunctions\" in the doc -- which also accept single-index (and in fact, double-index) arguments. For\nexample,\n\n>> xpts = (pi/4)*0.5*[0:2];\n>> sin_values = sin(xpts)\nsin_values =\n0.3827\n0.7071\n>>\nwith a single call provides the values of sin for all elements of xpts.\n5.1.4\nRelational and Logical (Array) Operations\nFor relational and logical operations we do not have the complication of array/vector conflation and\nhence we need no dots. In effect, when we apply any of our scalar relational/ logical operations to\npairs of vectors of the same length, Matlab returns a vector (of the same length as the operands)\nwhich is the result of the scalar relational/logical operation element-by-element.\nAs an example,\n>> x = [1.2, 3.3, 2.2]; y = [-0.1, 15.6, 2.0];\n>> z_1 = (x < y)\nz_1 =\n>> z_2 = (x > y)\nz_2 =\n>> z_3 = z_1 | ~z_2\nz_3 =\n>>\nSimilar example can be constructed for all of our relational operators and logical operators. Note\nthat z_1, z_2 and z_3 are logical arrays: each element is an instance of the logical data type.\nFor completeness, we indicate the implementation of the above as a for loop:\n>> for i = 1:length(x)\nz_1_too(i) = (x(i) < y(i));\nz_2_too(i) = (x(i) > y(i));\nz_3_too(i) = z_1_too(i) | ~ z_2_too(i) ;\nend\n>> z_1_too\n\nz_1_too =\n>> z_2_too\nz_2_too =\n>> z_3_too\nz_3_too =\n>>\nwhich is indeed equivalent, but tedious.\n5.1.5\n\"Data\" Operations\nThere are also a number of operations which albeit numerical are focused as much on the indices\nas the data -- and hence we include these under the heading \"data\" operations.\nA number of Matlab functions are available to reorder the elements or to identify distinguished\nelements: sort, min, and max are perhaps the most useful in this regard. We illustrate just one of\nthese functions, min:\n>> T = [4.5, -2.2, 6.3, 4.4];\n>> [minimum, minimizer] = min(T)\nminimum =\n-2.2000\nminimizer =\n>> minimum_too = min(T)\nminimum_too =\n>>\nwhich yields the obvious result. This is our first example of a function with two outputs: minimum\n-2.2000\n\nis the minimum of the array, and minimizer is the index of the minimizing element. Note also that\nif we just wish to obtain the first output we can abbreviate the call.\nPerhaps one of the most useful array data functions is the find function. Given a logical vector\nL, find(L) will return a vector which contains (in increasing order) the indices of all the elements\nof L which are nonzero (and are hence unity, since L is a logical array). (In fact, find can also be\napplied to a double array, but one must be careful about round-off effects.) As an example:\n>> L = logical([0,1,1,0,0,1]);\n>> islogical(L)\nans =\n>> ind_of_nonzero = find(L)\nind_of_nonzero =\n>>\nwhere we have also illustrated the construction of a logical vector. Note that the find function\neffectively implements the for loop\n>> ind_of_nonzero_too = [];\n>> for i = 1:length(L)\nif( L(i) ~= 0 )\nind_of_nonzero_too = [ind_of_nonzero_too,i];\nend\nend\n>> ind_of_nonzero_too\nind_of_nonzero_too =\n>>\nwhich demonstrates also an application of concatenation.\nThe function find is very useful in the context of comparisons. For example, we may wish to\nextract just those values of vector greater than some threshold:\n>> H = [0.2, 1.4, 6.7, -3.4, 4.2];\n>> log_H_thresh = (H > 1.2)\nlog_H_thresh =\n\n>> inds_H_thresh = find(log_H_thresh)\ninds_H_thresh =\n>> H(inds_H_thresh)\nans =\n1.4000\n6.7000\n4.2000\n>>\nWe can of course replace H > 1.2 in the above with any more complicated composition of relational\nand logical operators.\nWe could of course combine this as\n>> H ( find ( H > 1.2 ) )\nans =\n1.4000\n6.7000\n4.2000\n>>\nIn fact, Matlab accepts a further abbreviation as\n>> H ( H > 1.2 )\nans =\n1.4000\n6.7000\n4.2000\n>>\nin which a find is automatically applied to a logical index vector. Apparently this somewhat\nsyntactically sloppy approach is in fact the most efficient.\n5.2\nCharacters and Character Single-Index Arrays (Strings)\nOur focus is on numerical methods and hence we will not have too much demand for character\nand string processing. However, it is good to know the basics, and there are instances -- typically\nrelated to more sophisticated applications of software system management, \"codes that write codes\"\n(or less dramatically, codes some lines of which can be modified from case to case), and also\nsymbolic manipulation -- in which character concepts can play an important role. Note that\ncharacter manipulation and symbolic manipulation are very different: the former does not attribute\nany mathematical significance to characters; the latter is built upon the former but now adds\nmathematical rules of engagement. We consider here only character manipulation.\n\nA character variable (an instance of the character data type), say c, must represent a letter\nof numeral. As always, c ultimately must be stored (ultimately) by 0's and 1's. We thus need --\nas part of the data type definition -- an encoding of different characters in terms of 0's and 1's.\nThe most common such encoding, the original ASCII code, is a mapping from 8-bit words (binary\nnumbers) to the set of letters in the alphabet, numerals, punctuation marks, as well as some special\nor control characters. (There are now many \"extended\" ASCII codes which include symbols from\nlanguages other than English.)\nWe can create and assign a character variable as\n>> c = '3'\nc =\n>> c_ascii = int8(c)\nc_ascii =\n>> c_too = char(c_ascii)\nc_too =\n>>\nIn the first statment, we enter the single-character data with quotes -- which tells Matlab that\n3 is to be interpreted as a character and not a number. We can then obtain the ASCII code\nfor the number 3 -- which happens to be 51. We can then recreate the character variable c by\ndirectly appealing to the ASCII code with the char command. Obviously, quotes are easier than\nmemorizing the ASCII code.\nA \"string\" is simply a single-index array of character elements. We can input a string most\neasily with the quote feature:\n>> pi_approx_str = '3.1416'\npi_approx_str =\n3.1416\n>> pi_approx_str(2)\nans =\n.\n\n>> pi_approx_str + 1\nans =\n>>\nWe emphasize that pi_approx_str is not of type double and if we attempt to (say) add 1 to\npi_approx_str we get (effectively) nonsense: Matlab adds 1 to each element of the ASCII-\ntranslation of the our string according to the rules of single-index array addition.\nWe can readily concatenate strings, for example:\n>> leader = 'The value is '\nleader =\nThe value is\n>> printstatement = [leader,pi_approx_str,' .']\nprintstatement =\nThe value is 3.1416 .\n>>\nHowever, this is of limited use since typically we would know an approximation to π not as a string\nbut as double.\nFortunately, there are some simple conversion functions available in Matlab (and other pro\ngramming languages as well). The Matlab function num2str will take a floating point number\nand convert it to the corresponding string of characters; conversely, str2num will take a string (pre\nsumably of ASCII codes for numerals) and convert it to the corresponding floating point (double)\ndata type. So for example,\n>> pi_approx_double = str2num(pi_approx_str)\npi_approx_double =\n3.1416\n>> pi_approx_str_too = num2str(pi_approx_double)\npi_approx_str_too =\n3.1416\n>>\nThis can then be used to create a print statement based on a floating point value (e.g., obtained\n\nas part of our numerical calculations):\n>> printstatement_too = [leader,num2str(pi_approx_double),' .']\nprintstatement_too =\nThe value is 3.1416 .\n>>\nIn actual practice there are higher level printing functions (such as fprintf and sprintf) in\nMatlab built on the concepts described here. However, the above rather low-level constructs can\nalso serve, for example in developing a title for a figure which must change as (say) the time to\nwhich the plot corresponds changes.\n5.3\nDouble-Index Arrays\n5.3.1\nConcept\nDouble-index arrays (and more generally, multi-index arrays), are extremely important in the\nimplementation of numerical methods. However, conceptually, they are quite similar to single-\nindex arrays, and inasmuch this section can be rather short: we just consider the \"differential\ninnovation.\" In fact, as we will see shortly, a double-index array really is a single-index array as\nfar as internal representation in memory or \"address space\": the two indices are just a convenient\nway to access a single-index array.\nReference by two indices (or three indices,. . . ) can be convenient for a variety of reasons: in\na 10 × 10 structured rectilinear mesh, the two indices might represent the location of a point in a\n\"Cartesian\" grid -- at which we store, in each array location, say the value of the temperature field\n(a 10 × 10 array); in an unstructured three-dimensional mesh (or a Monte Carlo random sample),\nthe first index might represent the label/order of a point within a sample of say length 1000, and the\nsecond index might represent the spatial coordinate direction (e.g., 1, 2, 3 for the x, y, z directions)\n-- at which we store, in the array locations, the coordinate of the point (a 1000 × 3 array); and\nmost notably, the two indices might represent the rows and columns of an m×n matrix -- at which\nwe store the matrix values (an m × n array). (We discuss matrices in depth later.) Recall that\nthe indices play the role of the independent variable and the array values the role of the dependent\nvariable.\nFor a double-index array, just as for a single-index array, we first introduce a variable name,\narray name, but now this double-index array is associated to m × n elements: we may think of\na double-index arrays as m rows by n columns, as we shall visualize shortly. We then index this\narray name to access any particular element of the array: in particular, array name(i,j) is the\npointer to element i, j of the array. As always, the pointer is the location in memory at which we\nstore the value of the array.\nIn fact, even this double-index array is stored at contiguous locations in memory. (It is in\nthis sense that a double-index array is internally equivalent to a single-index array; we shall take\nadvantage of this equivalence later.) Matlab stores a double-index array as \"first address fastest\":\narray name(1,1),...,array name(m,1),array name(1,2),...,array name(m,2),...,\narray name(m,n). As for the single-index case, it suffices to to pass to a function simply the\nvariable array name -- the address of the first element -- as the addresses of all other elements can\nthen be readily deduced (in practice, thanks to appropriate header information). And of course,\n\nas for a single-index array, we will endeavor to similarly define operations on the entire array, as\nrepresented by array name, rather than treat each index separately.\nA note on nomenclature: we can also think of single-index and double-index arrays as \"one\ndimensional\" and \"two-dimensional\" arrays. However, we will reserve \"dimension\" for the linear\nalgebra sense: a vector with n entries is a member of n-dimensional space. Hence the linear algebra\n\"dimension\" is analogous to the Matlab length. (And just to make sure this paragraph, in\nattempting to avoid confusion, is sufficiently confusing: to avoid confusion of Matlab length\nwith the linear algebra \"length\" of a vector we shall refer to the latter as the \"norm\" of the vector.\nWe return to this point in Unit 3.)\n5.3.2\nAssignment and Access\nWe start with a simple example and then explain the syntax.\n>> A = [1,2,3;4,5,6]\nA =\n>> size_of_A = size(A)\nsize_of_A =\n>> A(2,2)\nans =\n>>\nWe see that a comma separates elements within a row, and a semicolon separates different rows.\nThe size function returns a single-index array of length 2: the first element is the number of rows\n-- the limit for the first index -- and the second element is the number of columns -- the limit for\nthe second index. Finally, we see that we can access individual elements of A as (say) A(2,2). Of\ncourse our interpretation as rows and columns is just an artifice -- but a very useful artifice which\nwe invoke on many many occasions -- for visualization and interpretation.\nOur row single-index array is special case of double-index array:\n>> X = [1,3,4]\nX =\n\n>> size(X)\nans =\n>> X(1,3)\nans =\n>>\nAnd we can now systematically introduce a column single-index array as\n>> X_col = [1;3;4]\nX_col =\n>> size(X_col)\nans =\n>> X_col(3,1)\nans =\n>>\nNote in this case each row is of length 1 so we require no comma delimiters. Note operations in\nMatlab require arrays of similar size, so always make sure that pairs of single-index array operands\nare both row arrays or both column arrays. This is best ensured by initialization of the array with\nzeros and consistent assignment.\nThe transpose operation is very convenient: it \"flips\" the two indices. Hence\n>> A_transp = A'\nA_transp =\n\n>> X'\nans =\n>> size(X')\nans =\n>>\nRows become columns and columns become rows. (In fact, the transpose operator is a special case\nof a more general Matlab function reshape which allows us to \"resize\" an array.)\nAs always, the reader should mentally note the more expanded code which effects any particular\noperation to make sure the operation is well understood: in this case\n>> for i = 1:size(A,1)\nfor j = 1:size(A,2)\nA_transp_too(j,i) = A(i,j);\nend\nend\n>> A_transp_too\nA_transp_too =\n>>\nNote that size(A,1) and size(A,2) conveniently return the first element and second element of\nsize(A).\nAs for single-index arrays, we can directly assign an entire double-index array: B = A creates a\nnew array B identical to A in terms of size as well as values; we may also assign or re-assign any\nparticular element of the array as selected by the index -- for example, B(1,1) = 0. Oftentimes\nwe can create the desired array as an assignment plus modification of an existing array.\nWe may also create an array with a \"double\" for loop:\n>> m = 2;n = 3;\n>> A = zeros(m,n);\n>> for i = 1:size(A,1)\nfor j = 1:size(A,2)\n\nA_too(i,j) = j + (i-1)*size(A,2);\nend\nend\n>> A_too\nA_too =\n>>\nNote initialization of multi-index arrays is particularly important since these arrays tend to be\nlarger and memory management even more of an issue.\nHowever, concatenation also works for multi-index arrays and can be very effective.\n>> R1 = [1,2,3]; R2 = [4,5,6];\n>> C1 = [1;4]; C2 = [2;5]; C3 = [3;6];\n>> A_too_too = [R1; R2]\nA_too_too =\n>> A_too_too_too = [C1,C2,C3]\nA_too_too_too =\n>> A_four_times = [A_too, A_too; A_too, A_too]\nA_four_times =\n>> A_four_times_also = [[A_too;A_too],[A_too;A_too]]\nA_four_times_also =\n\n>> A_four_times_expand_by_one = [A_four_times,[C1;C2]; [R1,R2],0]\nA_four_times_expand_by_one =\n>>\nThe general procedures for concatenation are somewhat difficult to succinctly describe -- we must\nalways combine entities that \"match\" in the direction in which we concatenate -- but the cases\nabove include most instances relevant in numerical methods.\nWe can also do indirect addressing for double-index arrays, as we illustrate on our array\nA_four_times. In particular, let ind1vec and {ind2vec be single-index arrays of length size\n(A_four_times,1) and size(A_four_times,2), respectively, given by (say)\n>> ind1vec = [2,3]\nind1vec =\n>> ind2vec = [2:4]\nind2vec =\n>>\nThen\n>> extracted = A_four_times(ind1vec,ind2vec)\nextracted =\n>>\nwhich in fact is implement as\n>> for i = 1:length(ind1vec)\nfor j = 1:length(ind2vec)\nextracted_too(i,j) = A_four_times(ind1vec(i),ind2vec(j));\n\nend\nend\n>> extracted_too\nextracted_too =\n>>\nThis can be very useful for extracting rows and columns, as we now describe.\nIn particular, to extract say row 1 or column 2 of A, we need only do\n>> R1_too = A(1,1:size(A,2))\nR1_too =\n>> C2_too = A(1:size(A,1),2)\nC2_too =\n>>\nIn fact, Matlab conveniently provides a function end which, when it appears in the place of kth\nindex (k = 1 or k = 2), evaluates to (say for our array A) size(A,k). We then can write more\nsuccinctly\n>> R1_too_too = A(1,1:end)\nR1_too_too =\n>> R1_too_too_too = A(1,:)\nR1_too_too_too =\n>>\nwhere in the last line we see that Matlab admits even further abbreviation: a colon in the place\nof an index is interpreted as 1:end for that index.\nFinally, there is simple way to create a single-index array from a multi-index array:\n\n>> A_single_index = A(:)\nA_single_index =\n>>\nNote that it is probably not a good idea to take advantage of the single-index form above as the\nshape of this single-index array is rather sensitive to how we specify the index argument. (The\ncolon translation is not unique for a single-index array and in fact is interpreted as a particular\nchoice of reshape.) We introduce the above just to illustrate the concept of \"all arrays are really\nsingle-index arrays\" and \"first index fastest (or column major)\" ordering, and also because the\nsingle-index reshape is convenient sometimes for certain global operations (see below).\n5.3.3\nOperations\nAs regards arithmetic operations, multi-index arrays \"behave\" in exactly the same fashion as single-\nindex arrays: -, +, .*, ./, .^ all perform the necessary element-by-element operations. Indeed,\nin these operations, the double-index array is essentially treated as a single-index array. (Note that\nfor example 3.2*A multiplies each element of A by 3.2.)The same is true for relational and logical\noperations (as well as find): the operations are performed element by element and the output is a\nmulti-index array of the same size as the two operands.\nFor data operations, there are more options. Whenever possible, the easiest is to effect the\noperation in terms of single-index arrays. The colon operator permits us to find the minimum over\n(say) the first row as\n>> min(A(1,:))\nans =\n>>\nor in a similar fashion the minimum over any given column.\nIf we wish to find the minimum over all elements of the entire array, we can interpret the\nmulti-index array in its \"underlying\" single-index form: for example,\n>> A = [1,2,3;4,5,6]\nA =\n\n>> min(A(:))\nans =\n>>\nIn most cases, the above simple constructs suffice.\nHowever, it is also easy to apply (say) the min function over the first index to yield a row array\nwhich contains the minimum over each column, or to perform the min function over the second\nindex to yield a column array which contains the minimum over each row:\n>> min(A,[],1)\nans =\n>> min(A,[],2)\nans =\n>>\nNote the second null argument in min above will be explained shortly, when we discuss functions\nin greater detail. Essentially, min takes three arguments, but the second argument is optional and\nhence if it is not set then Matlab will not complain. Nulls are useful for optional inputs or for\ninputs which can be set to default values.\nIn general the default with Matlab -- when \"single-index\" functions are applied to multi-index\narrays -- is to perform the operation over columns to yield a row:\n>> min(A)\nans =\n>>\nNote that min(A) is not the same as A(:) in that A is of size A where A(:) is automatically\n\"reshaped\" to be a single-index array.\nFinally, this seems a good place to note that there are many thousands of Matlab functions\nand for each oftentimes quite a few options and optional arguments. If you find that you are doing\na particular relatively simple operation many times -- or a rather complicated operation perhaps\nonly a few times -- it is perhaps worthwhile to search for a syntactically succinct and efficient\n\nMatlab built-in function which might do the trick. However, in many other cases it will be more\neffective to write your own code. Matlab built-in functions are a means and not an end.\n5.4\nLine Plotting\nWe include line plotting in this chapter as we now have the necessary pieces: single-index arrays,\nand characters. We do not present all the various options since these can readily be found by\n>> help plot or the documentation. However, we do provide a template which you can use and\nadapt accordingly.\n%A sample plotting script - by Justin Miller\n%----------- linear-linear plotting, sine and cosines --------------\nL = 2*pi;\n%Define the ending angle\nN = 100;\n%Define number of angle segments\nxpts = (L/N)*[0:N];\n%Define a set of angles for plotting (in radians)\n%This could also be done using\n%xpts = linspace(0,L,N+1);\nsin_values = sin(xpts);\n%Sine vector of each angle\ncos_values = cos(xpts);\n%Cosine vector of each angle\nfigure\n%Create a figure window to draw the plots\nplot(xpts,sin_values,'b-')\n%Plot the sine values in a blue line\nhold on\n%Hold the current figure when plotting\n%the next figure\nplot(xpts,cos_values,'r--')\n%Plot the cosine values in a red dashed line\nh_sincos_plot = gcf;\n%Get the handle of the current figure\nha_sincos_axis = gca;\n%Get the handle of the current axis\naxis([0,xpts(end),-1.1,1.1])\n%Set the x and y axes [xmin,xmax,ymin,ymax]\nset(ha_sincos_axis,'XTick',0:pi/2:2*pi) %Set the location of the x tick marks\nset(ha_sincos_axis,'YTick',-1:0.2:1)\n%Set the location of the y tick marks\nset(ha_sincos_axis,'XTickLabel',{'0','pi/2','pi','3*pi/2','2*pi'})\n%Set the names of each x tick mark\nxlabel('Angle (radians)')\n%Give a label name to the x axis\nylabel('Trigonomic output')\n%Give a label name to the y axis\ntitle(['Plot of sin and cos from x = ',num2str(xpts(1)), ...\n\n' to x = ',num2str(xpts(end))])\n%Give the figure a title\nlegend('sin','cos','location','best') %Provide a legend and tell matlab to place\n%it in the best location\nsaveas(h_sincos_plot,'sin_cos.fig') %Take the figure specified by handle\n%\"h_sincos_plot\" and save it\n%as \"sin_cos.fig\" in the working directory\n%----------- log-linear plotting, exponential --------------\nclear all\nL = 5;\nN = 100;\nx = (L/N)*[0:N];\ny = 2*exp(x);\nfigure\nsemilogy(x,y,'b-')\n%Create a plot where only the y axis is in log scale\n%semilogx would plot only the x axis in log scale\nxlabel('x')\nylabel('y')\ntitle(['Log-Linear plot of y = 2*exp(x) from x = ',num2str(x(1)), ...\n' to x = ',num2str(x(end))])\nsaveas(gcf,'exp.fig')\n%----------- log-log plotting, polynomials --------------\nclear all\nL = 10^2;\nN = 100;\nx= (L/N)*[0:N];\ny = 2*(x.^3);\nfigure\nloglog(x,y,'b-')\n%Create a plot where both axes are in log scale\nxlabel('x')\nylabel('y')\n\ntitle(['Log-Log plot of y = 2x^3 from x = ',num2str(x(1)), ...\n' to x = ',num2str(x(end))])\nsaveas(gcf,'poly.fig')\nMatlab also has extensive \"3-D\" plotting capabilities.\n\nChapter 6\nFunctions in Matlab\n6.1\nThe Advantage: Encapsulation and Re-Use\nAs you know, a mathematical function is a \"rule\" which given some inputs (or arguments), returns\nan output or outputs. A Matlab function (or a function in any programming language), is very\nsimilar: the function, given some inputs/arguments, returns an output or outputs. There are two\nmain reasons that functions are so important and useful as a programming construct: re-use and\nencapsulation. First, re-use: if we perform a particular set of operations -- for example, calculation\nof sin(x) for given x -- we prefer not to re-write this same code over and over again. Rather, we\nwrite it once and then use it over and over again, with enormous savings. Second, encapsulation: a\nuser can take advantage of the function, and the \"function\" it performs -- from inputs to outputs --\nwithout knowing how this function has been implemented or what is \"inside\" the code; from another\nperspective, what happens inside the function does not affect the user's higher level objectives --\nthe output is the entire \"effect\" (we discuss this further below).\nWe have already taken extensive advantage of both re-use and encapsulation: we have used\nmany Matlab built-in functions in all of our examples above; and we have used these functions\nnot only without knowing \"what is inside\" but in fact without even knowing how a function is\ndefined syntactically. In actual practice, it would not be good to proceed in quite such a trusting\nfashion.\n6.2\nAlways Test a Function\nFunctions have serious implications as regards the correctness of results and the control of errors.\nFrom the positive side, the fact that the program is re-used many times, and developed once\nintentionally for re-use, means that typically most bugs will have been identified and fixed. From\nthe negative side, encapsulation means that the user typically will not know what is inside, and\nhence can not personally vouch for correctness. The latter is, fortunately, quite easy to address in\na reasonable if not rigorous fashion: confronted with any new function, it is alway worthwhile to\nconsider several test cases -- for which you know the answer -- to confirm correct behavior; the\nmore authoritative the source, the more the function has been used, the simpler the task, perhaps\nthe less tests required. But remember that you are not just testing the code, you are also testing\nyour understanding of the inputs and outputs.\nDRAFT V1.2 (c) The Authors. License: Creative Commons BY-NC-SA 3.0.\n\nNote that is often difficult to find a test case in which we know the answer. In particular in\nthe numerical context there is an artifice by which to side-step this issue. In particular, it is often\npossible to posit the answer and then easily determine the question (which yields this answer).\nFor example, if we wish to test a code which finds the roots of a fourth-order polynomial, for any\nparticular fourth-order polynomial it is not easy to deduce the correct answer (or we would not\nneed the code in the first place). However, it is easy to posit the four roots -- the answer -- and\nmultiply out to obtain the polynomial with these roots -- the question. We then test the code by\ngoing backwards (in fact forwards), and verifying that the question leads to the answer. Note such\na test does not confirm that the code works in all cases; in fact, we have only confirmed one case.\nThe numerical approach (or even the logic of the code) could thus be flawed in certain or even many\ninstances. However, we have confirmed that we are using the code correctly, that we understand\nwhat in principle should happen, and that in at least one (or several) nontrivial cases that what\nshould happen does indeed happen. You should always test a new function in this fashion.\nWe emphasize that our discussion here applies both to the many Matlab \"built-in\" functions\n-- functions bundled with the Matlab core -- and any third-party of user-defined function. Also\nin the remainder of this chapter many of the details are relevant both to built-in and user functions\n-- for example, how to call a multi-output, multi-input function; however some details, such as\nhow to create a function, are obviously only important for user-defined functions.\n6.3\nWhat Happens in a Function Stays in a Function\nWhen we launch a script (or a function) from the command window we may view this program\nas the \"main\" program (to use a somewhat archaic term). The (command-window) workspace of\nthis main program is the set of variables of which the main program is aware (and which have\nbeen assigned at some point during the execution). When this main program calls a function, say\nfunction name, we can view the process as the creation of a second virtual processor, as shown\nin Figure 6.1 2. In particular, it is critical to note that the two workspaces -- the variables\nassigned by the main program and by function name -- are distinct: the main program is unaware\nof the variables in workspace function name and function name is unaware of the variables in\nworkspace command-window. The only connection between these two virtual processes are the\ninputs and outputs: function name receives the inputs from the main program, and the main\nprogram receives the outputs from function name; note the direction of the arrows -- inputs are not\naffected by function name. Furthermore, workspace function name will disappear when execution\nof function name is completed and there will be no permanent record of workspace function name\n(unless of course you have written data to a file).\nWe make several comments. First, there are in fact ways to share variables between the\nworkspaces (global variables), however it is best to avoid global variables if possible since with\nproliferation they become a sort of programming duct tape. Second, although our picture is for a\nmain program and a function, the same picture applies when one function calls another function\n(which may call another function, . . . ). In such a case the left virtual processor is associated to\nthe \"calling program\" more generally (e.g., a calling function) and the right virtual processor is\nassociated to the \"called function.\" Again, the critical point is that the workspaces of these two\nfunctions are distinct. Third, our picture of Figure 6.1 2 is a good mental model, but not necessarily\nrepresentative of actual implementation. It is perhaps more realistic to envision an operation in\nwhich the \"state\" of the calling program is saved, the called function \"takes over\" the processor,\nand then the calling program is moved back in when the called function has returned control. This\npicture suggests that it is rather expensive to call a function, and that is indeed the case in partic\nular in Matlab ; for this reason, it is good to construct functions which, within their designated\n\nMemory\nI/O\nInstruction\nStack\nInterpreter\nArithmetic\nUnit\nflow\ncontrol\nMemory\nI/O\nInstruction\nStack\nInterpreter\nArithmetic\nUnit\nflow\ncontrol\ninputs\noutputs\nmain program\nmain program\nfunction_name\nfunction_name\nworkspace_command-window\nworkspace_command-window\nworkspace_\nworkspace_function_name\nfunction_name\nFigure 6.1: Two Virtual Processors\ntask, compute as much data as possible with each call -- for example, operate on arrays rather\nthan scalars -- so as to minimize the number of calls. (Note this is not a recommendation to put\nmany different unrelated tasks or many lines of instructions within a single function since obviously\nthis compromises re-use, encapsulation, and efficiency. You do not want to do too much; you just\nwant to operate on as much data as possible.) We discuss this further below.\n6.4\nSyntax: Inputs (Parameters) and Outputs\nDifferent languages require different syntax for the definition and use (call) of a function. We\nfirst consider the former and then the latter. By way of example, we present below the function\nx_to_the_2p which given x evaluates the function (in this case, literally a mathematical function)\n2p\nx\n.\nfunction [ value ] = x_to_the_2p( x, p )\nvalue = x.^(2*p);\nend\nThe first line declares that this script is a function, that the output will be returned in a variable\nvalue, that the function name -- and also the name of the .m file in which the function is stored\n-- is x_to_the_2p, and that the function takes two arguments, x and p. Next follows the body of\nthe function which produces the output, value. The function closes with an end statement.\nWe note that our little function takes a single-index (or even multi-index) array as input. In\ngeneral, as described above, function calls can be expensive, and hence it is best to generate as\nmuch data as possible with each call so as to minimize the number of calls required. For that\nreason, it is often advantageous to define functions such that the (appropriate) inputs and outputs\nare arrays rather than scalars. (In our example above, value will be of the same size as x. This is\nrealized automatically through the assignment statement.) Of course scalars will be a special case\nof arrays and hence the function may still be called with scalar arguments.\n\nMore generally the syntax for a function with J inputs and K outputs is\nfunction [output 1, output 2, . . . , output K ] = function name(input 1, input 2, ..., input J )\nBODY of FUNCTION\nend\nNote that we may have not only multiple inputs but also multiple outputs. All outputs must\nbe defined within the BODY of FUNCTION or Matlab will complain.\nThe operation of the function is fairly clear. First our little example (which we call here from the\ncommand window, but of course could also be called from a \"main\" program or another function\nprogram):\n>> clear all\n>> y = x_to_the_2p( [1,2], 2)\ny =\n>> value\n??? Undefined function or variable 'value'.\n>>\nNote in the above our function is evaluated and the output assigned to the variable y. The variable\nvalue is internal to the function and the calling program -- in this case the function is called from\nthe command-line mode and hence the calling program variables are simply the workspace -- has\nno knowledge of this \"dummy\" variable.\nMore generally, we call a function with J outputs and K inputs as [output 1, output 2, . . . ,\noutput J ] = function name(input 1, input 2, . . . , input J ); . (Note that if we omit the semi\ncolon then our outputs will all be displayed in the command window.) Upon being called by\nthe calling program, function name executes BODY of FUNCTION for the values of the input\narguments passed to function name and then upon reaching the end statement function name\nreturns the outputs -- and control -- to the calling program. Note is possible to force an early\nreturn of a function (to the calling program) before the end statement is encountered with a return\nstatement within the BODY of FUNCTION .\nIt is possible to request only the first K ' outputs as [output 1, output 2, . . . , output K ' ] =\nfunction name(input 1, input 2, . . . , input J );. Particularly useful is the case in which you only\nrequire the first output, as in this case you can directly use the function through composition within\na larger expression with the intermediary of assignment. Up to this point, with the exception of min,\nwe have considered only single-output functions (or in any event only asked for the first output) in\nour examples -- and for precisely this composition reason. Another example here:\n>> z = x_to_the_2p( [1,2], 2) + [2,3]\nz =\n>>\n\nNote it is important to distinguish between multiple outputs and arrays. An array corresponds to\na particular output, not multiple outputs; in our example above, there is a single output, which\nhappens to be a single-index array of length 2.\nIt is also possible to call a function without all inputs specified, either with [] (null) entries\n'\nor simply with a truncated list -- the first J inputs. However, in this case, it is important that\nwithin the function all inputs that will be encountered are defined. In this regard, the Matlab\nfunction isempty is useful (for nulls) and the Matlab nargin is useful (for truncated argument\nlists) in order to detect any \"unset\" inputs which must be assigned to default values. (Note different\nprogramming languages have different mechanisms for dealing with defaults.)\n6.5\nFunctions of Functions: Handles\nIt is often the case that we wish to pass a function to a function: in other words, we wish a called\nfunction to be able to operate not just on different data but also on different \"input functions.\" To\nmake matters more concrete (and avoid using the word function too many times with reference to\ndifferent entities), consider the function f_o_diff:\nfunction [ value ] = f_o_diff ( func, x, delta_x )\nvalue = (func (x + delta_x) - func (x))./delta_x;\nend\nThis little function calculates the first-order finite difference approximation to a function func\nat the point x for a given segment-length delta_x. Obviously we could include the definition of\nfunc within f_o_diff, but then we would need to have a different derivative function for each\nfunction we wished to differentiate. In contrast, f_o_diff can be re-used for any function func\n-- clearly much preferred. (Note we could now perform a much more systematic investigation of\nround-off error; in our earlier discussion we were not yet armed with functions, or arrays.)\nTo call f_o_diff from a calling program is quite simple with only one wrinkle within the\nMatlab syntax. In particular, to pass the input function func from the calling program to the\ncalled function (f_o_diff) we do not wish to actually pass the function but rather a kind of\npointer -- or handle -- to where these instructions are stored for use by any (calling) program.\n(The description here is virtual -- a mental model which provides the right intuition. In general,\nwhat and how a programming language passes within a function call can be a rather complicated\nissue.) To create a handle for the function func -- in other words, to find the pointer to (say) the\nbeginning of the set of instructions which define func -- we put an \"at sign\" (@) in front of func\nas in @func. So for example, to apply f_o_diff to the Matlab function sin we can either do\n>> sin_handle = @sin;\n>> fprime = f_o_diff( sin_handle, [pi/4, pi/2], .01)\nfprime =\n0.7036\n-0.0050\n>>\nof more directly\n\n>> fprime_too = f_o_diff( @sin, [pi/4, pi/2], .01)\nfprime_too = 0.7036 -0.0050\n>>\nNote handles can also be created for other kinds of objects, for example (graphics) figures.\nIt is often the case that a function func we wish to pass to (say) function name is somehow\nmore general -- defined with respect to more inputs -- than the functions which function name\nexpects. In Matlab there is an easy way to deal with this common occurrence, which we now\ndiscuss.\n6.6\nAnonymous (or In-Line) Functions\nA Matlab \"anonymous\" (or in-line) function is a one-liner with a single output and multiple\ninputs that can be defined directly in the command window or indeed on the fly in any program\n(possibly another function). An anonymous function has a very important property: any variables\nnot defined as inputs will be assigned the current values -- at the time the anonymous function\nis created -- within the \"variable space\" (e.g., workspace) of the calling program (e.g., command\nwindow).\nWe provide a concrete example. In particular, we define an anonymous function\np = 2;\nx_to_the_2p_anon = @(x) x_to_the_2p(x,p);\nwhich is identical to x_to_the_2p but now a function of single variable, x, rather than two variables.\nThe value of p is frozen to 2, though of course more generally we can replace p = 2 with any\nexpression by which to evaluate p in terms of other variables.\nTo call our anonymous function, we do (following the definition above):\n>> x_to_the_2p_anon([1,2])\nans =\n>>\nThe above appears rather pointless, but it serves an important role in passing functions to other\nfunctions -- in particular in the context of Matlab in which there are many built-in's that require\nfunction inputs of a particular form.\nLet's say that we wish to apply our function f_o_diff to our function x_to_the_2p. But\nf_o_diff is expecting a function of a single input, x, whereas x_to_the_2p has two inputs -- and\ntwo necessary inputs, since without p we can not evaluate x_to_the_2p. This conundrum is easily\nresolved with inline functions:\n>> p = 2;\n>> x_to_the_2p_anon = @(x) x_to_the_2p(x,p);\n>> z = f_o_diff( x_to_the_2p_anon, [1,2], .01 )\n\nz =\n4.0604\n32.2408\n>>\nNote that for an in-line function the function \"name\" is in fact the function handle (hence we need\nno @ in front of the x_to_the_2p_anon in the above) -- the name and handle for a single-line\nfunction coalesce.\n6.7\nString Inputs and the eval Function\nWe note that on occasion we do want the actual function to change -- the instructions to be\nevaluated to change -- as we change the inputs. This can be done with the eval function. The\nfunction eval takes as input a string and returns the evaluation of this string given current values\nfor the various variables present in the string; in essence, eval is in the interpreter.\nFor example, we can create the function\nfunction [ value ] = f_o_diff_eval ( fstring, x, delta_x )\nz = x;\nf_x = eval(fstring);\nz = x + delta_x;\nf_x_plus = eval(fstring);\nvalue = (f_x_plus - f_x)./delta_x;\nend\nwhich is our finite difference function but now with a string input fstring to specify the function\nto be differentiated. Note that eval(fstring) will simply evaluate the expression fstring given\nthe current values of the workspace f o diff eval.\nWe now call f_o_diff_eval:\n>> fstring = 'z.^4';\n>> f_o_diff_eval(fstring,[1,2],.01)\nans =\n4.0604\n32.2408\n>>\nwhich gives us the same result as previously. Note that f_x = eval(fstring) in f_o_diff_eval\nfor fstring as given is equivalent to f_x = z.^4 but since in the previous line we set z = x then\nf_x is assigned x.^4 as desired. Similarly, two lines down, f_x_plus is assigned the appropriate\nvalue since we have changed z to be z = x + delta_x. The user can now specify any desired\nfunction (expressed in terms of z) without creating a Matlab function (or anonymous function).\nIn actual practice there are certainly better ways to accomplish these goals. The purpose of\nthis little section is only to illustrate that on occasions in which we would like to adapt the actual\n\ncode there are some simple ways to implement this feature.\n\nChapter 7\nIntegration\n7.1\nIntegration of Univariate Functions\nOur objective is to approximate the value of the integral\nb\nI =\nf(x) dx ,\na\nfor some arbitrary univariate function f(x). Our approach to this integration problem is to ap\nproximate function f by an interpolant If and to exactly integrate the interpolant, i.e.\nN-1\nN-1\nn\nn\nI =\nf(x) dx ≈\n(If)(x) dx ≡ Ih .\n(7.1)\nSi\nSi\ni=1\ni=1\nRecall that in constructing an interpolant, we discretize the domain [a, b] into N -1 non-overlapping\nsegments, delineated by segmentation points xi, i = 1, . . . , N, as illustrated in Figure 7.11 Then,\nwe construct a polynomial interpolant on each segment using the function values at the local\nm\ninterpolation points, x , m = 1, . . . , M. These local interpolation points can be mapped to global\nfunction evaluation points, xi, i = 1, . . . , Neval. The quality of the interpolant is dictated by its type\nand the segment length h, which in turn governs the quality of the integral approximation, Ih. The\nsubscript h on Ih signifies that the integration is performed on a discretization with a segment length\nh. This integration process takes advantage of the ease of integrating the polynomial interpolant\non each segment.\nRecalling that the error in the interpolation decreases with h, we can expect the approximation\nof the integral Ih to approach the true integral I as h goes to 0. Let us formally establish the\nrelationship between the interpolation error bound, emax = maxi ei, and the integration error,\n1For simplicity, we assume h is constant throughout the domain.\nZ\nZ\nZ\nDRAFT V1.2 (c) The Authors. License: Creative Commons BY-NC-SA 3.0.\n\nx1\nx2\nx3\nx4\nx5\nS2\ndiscretization\nx1\nx2\nx3\nlocal segment S2\nx1\nx2\nx3\nx4\nx5\nx6\nx7\nx8\nx9\nfunction evaluation points\nFigure 7.1: Discretization of a 1d domain into N - 1 (here N = 5) segments of length h.\n|I - Ih|.\nN-1\nn\n|I - Ih| =\n(f(x) - (If)(x)) dx\n(7.2)\nSi\ni=1\nN-1\nn\n≤\n|f(x) - (If)(x)| dx\n(7.3)\nSi\ni=1\nN-1\nn\n≤\nei dx\n(local interpolation error bound on Si)\n(7.4)\nSi\ni=1\nN-1\nn\n≤\nei h\n(definition of h)\n(7.5)\ni=1\nN-1\nn\n≤ emax\nh\n(definition of emax)\n(7.6)\ni=1\n= (b - a)emax .\n(7.7)\nWe make a few observations. First, the global error in the integral is a sum of the local error\ncontributions. Second, since all interpolation schemes considered in Section 2.1 are convergent\n(emax → 0 as h → 0), the integration error also vanishes as h goes to zero. Third, while this\nbound applies to any integration scheme based on interpolation, the bound is not sharp; i.e., some\nintegration schemes would display better convergence with h than what is predicted by the theory.\nRecall that the construction of a particular interpolant is only dependent on the location of the\ninterpolation points and the associated function values, ( xi, f( xi)), i = 1, . . . , Neval, where Neval is\nthe number of the (global) function evaluation points. As a result, the integration rules based on\nthe interpolant is also only dependent on the function values at these Neval points. Specifically, all\n\nZ\n\nZ\n\nZ\n\nintegration rules considered in this chapter are of the form\nNeval\nn\nIh =\nwif( xi) ,\ni=1\nwhere wi are the weights associated with each point and are dependent on the interpolant from\nwhich the integration rules are constructed. In the context of numerical integration, the function\nevaluation points are called quadrature points and the associated weights are called quadrature\nweights. The quadrature points and weights together constitute a quadrature rule. Not too sur\nprisingly considering the Riemann integration theory, the integral is approximated as a linear\ncombination of the function values at the quadrature points.\nLet us provide several examples of integration rules.\nExample 7.1.1 rectangle rule, left\nThe first integration rule considered is a rectangle rule based on the piecewise-constant, left-\nendpoint interpolation rule considered in Example 2.1.1. Recall the interpolant over each segment\nis obtained by approximating the value of the function by a constant function that matches the\nvalue of the function at the left endpoint, i.e., the interpolation point is x 1 = xi on segment\nSi = [xi, xi+1]. The resulting integration formula is\nN-1\nN-1\nN-1\nn\nn\nn\nIh =\n(If)(x) dx =\nf(xi) dx =\nhf(xi) ,\nSi\nSi\ni=1\ni=1\ni=1\nwhere the piecewise-constant function results in a trivial integration. Recalling that the global\nfunction evaluation points, xi, are related to the segmentation points, xi, by\nx i = xi,\ni = 1, . . . , N - 1 ,\nwe can also express the integration rule as\nN-1\nn\nIh =\nhf( xi) .\ni=1\nFigure 7.2(a) illustrates the integration rule applied to f(x) = exp(x) over [0, 1] with N = 5. Recall\nthat for simplicity we assume that all intervals are of the same length, h ≡ xi+1 -xi, i = 1, . . . , N -1.\nLet us now analyze the error associated with this integration rule. From the figure, it is clear\nthat the error in the integrand is a sum of the local errors committed on each segment. The local\nerror on each segment is the triangular gap between the interpolant and the function, which has\nthe length of h and the height proportional to f ' h. Thus, the local error scales as f ' h2 . Since there\nare (b - a)/h segments, we expect the global integration error to scale as\n'\n|I - Ih| ∼ f ' h2(b - a)/h ∼ hf .\nMore formally, we can apply the general integration error bound, Eq. (7.7), to obtain\n|I - Ih| ≤ (b - a)emax = (b - a)h max |f ' (x)| .\nx∈[a,b]\nIn fact, this bound can be tightened by a constant factor, yielding\nh\n|I - Ih| ≤ (b - a)\nmax |f ' (x)| .\n2 x∈[a,b]\nZ\nZ\n\n0.2\n0.4\n0.6\n0.8\n0.5\n1.5\n2.5\n\nintegral\nquadrature points\nfunction\n(a) integral\n-2\n-1\n-1.00\n1/h\n|I - Ih|\n(b) error\nFigure 7.2: Rectangle, left-endpoint rule.\nFigure 7.2(b) captures the convergence behavior of the scheme applied to the exponential function.\nAs predicted by the theory, this integration rule is first-order accurate and the error scales as O(h).\n'\nNote also that the approximation Ih underestimates the value of I if f > 0 over the domain.\nBefore we proceed to a proof of the sharp error bound for a general f, let us analyze the\nintegration error directly for a linear function f(x) = mx + c. In this case, the error can be\nexpressed as\nN-1\nN-1\nn\nn\nxi+1\n|I - Ih| =\nf(x) - (If)(x) dx =\n(mx - c) - (mxi - c) dx\nSi\nxi\ni=1\ni=1\nN-1\nN-1\nn\nxi+1\nn\n=\nm · (x - xi) dx =\n1 m(xi+1 - xi)2\nxi\ni=1\ni=1\nN-1\nn\n= mh\nh = mh(b - a) ,\ni=1\nNote that the integral of m · (x - xi) over Si is precisely equal to the area of the missing triangle,\nwith the base h and the height mh. Because m = f ' (x), ∀ x ∈ [a, b], we confirm that the general\nerror bound is correct, and in fact sharp, for the linear function. Let us now prove the result for a\ngeneral f.\nProof. By the fundamental theorem of calculus, we have\nx\nf(x) - (If)(x) =\nf ' (ξ) dξ,\nx ∈ Si = [xi, xi+1] .\nxi\nZ\nZ\nZ\nZ\n\nIntegrating the expression over segment Si and using the mean value theorem,\nx\nxi+1\nf(x) - (If)(x) dx =\nf ' (ξ) dξ dx\nSi\nxi\nxi\nxi+1\n=\n(x - xi) f ' (z) dx\n(mean value theorem, for some z ∈ [xi, x])\nxi\n= 1(xi+1 - xi)2 f ' (z)\n1 h2\n≤\nmax\n|f ' (x)| .\nx∈[xi,xi+1]\nSumming the local contributions to the integral error,\nN-1\nN-1\nn\nn 1\nh\nh2\n|I - Ih| =\nf(x) - (If)(x) dx ≤\nmax\n|f ' (x)| ≤ (b - a)\nmax |f ' (x)| .\nx∈[xi,xi+1]\n2 x∈[a,b]\nSi\ni=1\ni=1\nExample 7.1.2 rectangle rule, right\nThis integration rule is based on the piecewise-constant, right-endpoint interpolation rule considered\nin Example 2.1.2, in which the interpolation point is chosen as x1 = xi+1 on segment Si = [xi, xi+1].\nThis results in the integration formula\nN-1\nN-1\nN-1\nn\nn\nn\nIh =\n(If)(x) dx =\nf(xi+1) dx =\nhf(xi+1) .\nSi\nSi\ni=1\ni=1\ni=1\nRecalling that global function evaluation points are related to the segmentation points by xi = xi+1,\ni = 1, . . . , N - 1, we also have\nN-1\nn\nIh =\nhf( xi) .\ni=1\nWhile the form of the equation is similar to the rectangle rule, left, note that the location of\nthe quadrature points xi, i = 1, . . . , N - 1 are different. The integration process is illustrated in\nFigure 7.1.2\nThis rule is very similar to the rectangle rule, left. In particular, the integration error is bounded\nby\nh\n|I - Ih| ≤ (b - a)\nmax |f ' (x)| .\n2 x∈[a,b]\nThe expression shows that the scheme is first-order accurate, and the rule integrates constant\nfunction exactly. Even though the error bounds are identical, the left- and right-rectangle rules\nin general give different approximations. In particular, the right-endpoint rule overestimates I if\n'\nf > 0 over the domain. The proof of the error bound identical to that of the left-rectangle rule.\nWhile the left- and right-rectangle rule are similar for integrating a static function, they exhibit\nfundamentally different properties when used to integrate an ordinary differential equations. In\nZ\nZ\nZ\nZ\n\nZ\nZ\nZ\n\n0.2\n0.4\n0.6\n0.8\n0.5\n1.5\n2.5\n\nintegral\nquadrature points\nfunction\nFigure 7.3: Rectangle, right-endpoint rule.\nparticular, the left- and right-integration rules result in the Euler forward and backward schemes,\nrespectively. These two schemes exhibit completely different stability properties, which will be\ndiscussed in chapters on Ordinary Differential Equations.\nExample 7.1.3 rectangle rule, midpoint\nThe third integration rule considered is based on the piecewise-constant, midpoint interpolation\nrule considered in Example 2.1.3. Choosing the midpoint x 1 = (xi + xi+1) as the interpolation\npoint for each Si = [xi, xi+1], the integration formula is given by\nN-1\nN -1\nN-1\nn\nn\nn\nxi + xi+1\nxi + xi+1\nIh =\n(If)(x)dx =\nf\ndx =\nhf\n.\nSi\nSi\ni=1\ni=1\ni=1\nRecalling that the global function evaluation point of the midpoint interpolation is related to the\nsegmentation points by xi = (xi + xi+1)/2, i = 1, . . . , N - 1, the quadrature rule can also be\nexpressed as\nN-1\nn\nhf( xi) .\ni=1\nThe integration process is illustrated in Figure 7.4(a).\nThe error analysis for the midpoint rule is more involved than that of the previous methods.\nIf we apply the general error bound, Eq. (7.7), along with the interpolation error bounds for the\nmidpoint rule, we obtain the error bound of\nh\n|I - Ih| ≤ (b - a) emax ≤ (b - a)\nmax |f ' (x)| .\n2 x∈[a,b]\nHowever, this bound is not sharp. The sharp error bound for the rectangle, midpoint integration\nrule is given by\n|I - Ih| ≤\n(b - a) h2 max |f '' (x)| .\nx∈[a,b]\nThus, the rectangle, midpoint rule is second-order accurate. The higher accuracy and convergence\nrate of the midpoint rule are captured in the error convergence plot in Figure 7.4(b).\nZ\nZ\n\n0.2\n0.4\n0.6\n0.8\n0.5\n1.5\n2.5\n\nintegral\nquadrature points\nfunction\n(a) integral\n-5\n-4\n-3\n-2\n-1\n-1.00\n1/h\n|I - Ih|\n\nrectangle, left\nrectangle, right\nrectangle, middle\n(b) error\nFigure 7.4: Rectangle, midpoint rule.\nBefore we prove the error bound for a general f, let us show that the rectangle rule in fact\nintegrates a linear function f(x) = mx + c exactly. The integration error for a linear function can\nbe expressed as\nN-1\nN-1\nn\nn\nxi+1\nxi + xi+1\nI - Ih =\nf(x) - (If)(x)dx =\nf(x) - f\ndx\nSi\nxi\ni=1\ni=1\nN-1\nn\nxi+1\nxi + xi+1\n=\n(mx + c) - m\n+ c dx\nxi\ni=1\nN-1\nn\nxi+1\nxi + xi+1\n=\nm x -\ndx .\nxi\ni=1\nFor convenience, let us denote the midpoint of integral by xc, i.e., xc = (xi + xi+1)/2. This allows\nus to express the two endpoints as xi = xc - h/2 and xi+1 = xc + h/2. We split the segment-wise\nintegral at each midpoint, yielding\nxi+1\nxc+h/2\nxi + xi+1\nm x -\ndx =\nm(x - xc) dx\nxi\nxc-h/2\nxc\nxc+h/2\n=\nm(x - xc) dx +\nm(x - xc) dx = 0 .\nxc-h/2\nxc\nThe first integral corresponds to the (signed) area of a triangle with the base h/2 and the height\n-mh/2. The second integral corresponds to the area of a triangle with the base h/2 and the height\nmh/2. Thus, the error contribution of these two smaller triangles on Si cancel each other, and the\nmidpoint rule integrates the linear function exactly.\nZ\nZ\n\nZ\n\n!\nZ\n\nZ\n\nZ\nZ\nZ\n\nProof. For convenience, let us denote the midpoint of segment Si by xmi . The midpoint approxi\nmation of the integral over Si is\nxi+1\nxi+1\nIh\nn =\nf(xmi ) dx =\nf(xmi ) + m(x - xmi ) dx ,\nxi\nxi\nfor any m. Note that the addition of he linear function with slope m that vanishes at xmi does not\nalter the value of the integral. The local error in the approximation is\nxi+1\n|In - Ih\nn| =\nf(x) - f(xmi ) - m(x - xmi ) dx .\nxi\nRecall the Taylor series expansion,\nf(x) = f(xmi ) + f ' (xmi )(x - xmi ) + 1 f '' (ξi)(x - xmi )2 ,\nfor some ξi ∈ [xmi , x] (or ξi ∈ [x, xm,n] if x < xmi ). Substitution of the Taylor series representation\nof f and m = f ' (xmi ) yields\nxi+1\nxi+1\n|In - Ih\nn| =\nf '' (ξi)(x - xmi )2 =\nf '' (ξi)(x - xmi )3\n=\nh3 |f '' (ξi)| .\nxi\nx=xi\nSumming the local contributions to the integration error, we obtain\nN-1\nn 1\n|I - Ih| ≤\nh3|f '' (ξi)| ≤\n(b - a)h2 max |f '' (x)| .\nx∈[a,b]\ni=1\nThe rectangle, midpoint rule belongs to a family of Newton-Cotes integration formulas, the\nintegration rules with equi-spaced evaluation points. However, this is also an example of Gauss\nquadrature, which results from picking weights and point locations for optimal accuracy. In partic\nular, k point Gauss quadrature achieves the order 2k convergence in one dimension. The midpoint\nrule is a one-point Gauss quadrature, achieving the second-order accuracy.\nExample 7.1.4 trapezoidal rule\nThe last integration rule considered is the trapezoidal rule, which is based on the linear interpolant\nformed by using the interpolation points x 1 = xi and x 2 = xi+1 on each segment Si = [xi, xi+1].\nZ\nZ\n\nZ\n\nZ\n\n\"\n\n#\n\n0.2\n0.4\n0.6\n0.8\n0.5\n1.5\n2.5\n\nintegral\nquadrature points\nfunction\n(a) integral\n-5\n-4\n-3\n-2\n-1\n-1.00\n-2.00\n1/h\n|I - Ih|\n\nrectangle, left\nrectangle, middle\ntrapezoid\n(b) error\nFigure 7.5: Trapezoidal rule.\nThe integration formula is given by\nN-1\nN-1\nn\nn\nf(xi+1) - f(xi)\nIh =\n(If)(x) dx =\nf(xi) +\n(x - xi)\nh\nSi\nSi\ni=1\ni=1\nN-1\nn\n=\nf(xi)h +\n(f(xi+1) - f(xi))h\ni=1\nN-1\nn 1\n=\nh(f(xi) + f(xi+1)) .\ni=1\nAs the global function evaluation points are related to the segmentation points by xi = xi, i =\n1, . . . , N, the quadrature rule can also be expressed as\nN-1\nn 1\nIh =\nh(f( xi) + f( xi)) ,\ni=1\nRearranging the equation, we can write the integration rule as\nN -1\nN-1\nn\nn\n\nIh =\nh(f( xi) + f( xi)) = hf( x1) +\nhf( xi) + hf( xN ) .\ni=1\ni=2\nNote that this quadrature rule assigns a different quadrature weight to the quadrature points on the\ndomain boundary from the points in the interior of the domain. The integration rule is illustrated\nin Figure 7.5(a).\nUsing the general integration formula, Eq. (7.7), we obtain the error bound\nh2\n|I - Ih| ≤ (b - a)emax = (b - a)\nmax |f '' (x)| .\n8 x∈[a,b]\nZ\n\"\n\n#\n\nZ\n\nThis bound can be tightened by a constant factor, yielding\nh2\n|I - Ih| ≤ (b - a)emax = (b - a)\nmax |f '' (x)| ,\n12 x∈[a,b]\nwhich is sharp. The error bound shows that the scheme is second-order accurate.\nProof. To prove the sharp bound of the integration error, recall the following intermediate result\nfrom the proof of the linear interpolation error, Eq. (2.3),\nf(x) - (If)(x) = 1 f '' (ξi)(x - xi)(x - xi+1) ,\nfor some ξi ∈ [xi, xi+1]. Integrating the expression over the segment Si, we obtain the local error\nrepresentation\nxi+1\nxi+1\nIn - In =\nf(x) - (If)(x) dx =\n1 f '' (ξi)(x - xi)(x - xi+1)dx\nh\nxi\nxi\n'' (ξi)(xn\n'' (ξi)h3\n= 1 f\n- xi+1)3 = - 1 f\n.\nSumming the local errors, we obtain the global error bound\nN\nn\n|I - Ih| =\nf '' (ξi)h3 ≤\n(b - a)h2 max |f '' (x)| .\nx∈[a,b]\ni=1\nBefore concluding this section, let us make a few remarks regarding integration of a non-smooth\nfunction. For interpolation, we saw that the maximum error can be no better than hr, where r is the\nhighest order derivative that is defined everywhere in the domain. For integration, the regularity\nrequirement is less stringent. To see this, let us again consider our discontinuous function\nf(x) =\n⎧\n⎪\n⎪\n⎨\n⎪\n⎪\n⎩\nsin(πx),\nx ≤ 3\n.\n2 sin(πx), x > 3\nThe result of applying the midpoint integration rule with eight intervals is shown in Fig\nure 7.6(a). Intuitively, we can see that the area covered by the approximation approaches that\nof the true area even in the presence of the discontinuity as h → 0. Figure 7.6(b) confirms that\nthis indeed is the case. All schemes considered converge at the rate of h1 . The convergence rate\nfor the midpoint and trapezoidal rules are reduced to h1 from h2 . Formally, we can show that the\nintegration schemes converge at the rate of min(k, r + 1), where k is the order of accuracy of the\nintegration scheme for a smooth problem, and r is the highest-order derivative of f that is defined\neverywhere in the domain.\nZ\nZ\n\n0.2\n0.4\n0.6\n0.8\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n\nintegral\nquadrature points\nfunction\n-4\n-3\n-2\n-1\n-1.00\n1/h\n|I - Ih|\n\nrectangle, left\nrectangle, middle\ntrapezoid\n(a) integral\n(b) error\nFigure 7.6: Integration of a non-smooth function.\n7.2\nIntegration of Bivariate Functions\nHaving interpolated bivariate functions, we now consider integration of bivariate functions. We\nwish to approximate\nI =\nf(x, y) dx dy .\nD\nFollowing the approach used to integrate univariate functions, we replace the function f by its\ninterpolant and integrate the interpolant exactly.\nWe triangulate the domain D as shown in Figure 2.15 for constructing interpolants. Then, we\napproximate the integral as the sum of the contributions from the triangles, {Ri}N\ni=1, i.e.\nn\nn\nN\nN\nI =\nf(x, y) dx dy ≈\n(If)(x, y) dx dy ≡ Ih .\nRi\nRi\ni=1\ni=1\nWe now consider two examples of integration rules.\nExample 7.2.1 midpoint rule\nThe first rule is the midpoint rule based on the piecewise-constant, midpoint interpolant. Recall,\nthe interpolant over Ri is defined by the function value at its centroid,\nc\n(If)(x) = f(x i) = f(xi ),\n∀ x ∈ Rn ,\nwhere the centroid is given by averaging the vertex coordinates,\nc\nx i = x =\ni\nn\n3 i=1\nxi .\nThe integral is approximated by\nn\nn\nn\nN\nN\nN\nIh =\n(If)(x, y) dx dy =\nf( xi, y i) dx dy =\nAi f( xi, y i) ,\nRi\nRi\ni=1\ni=1\ni=1\nZZ\nZZ\nZZ\nZZ\nZZ\n\n-2\n-1\n-5\n-4\n-3\n-2\n2.00\nh\n|I - Ih|\n(a) integral\n(b) error\nx\nFigure 7.7: Midpoint rule.\nwhere we have used the fact\ndx dy = Ai ,\nRi\nwith Ai denoting the area of triangle Ri. The integration process is shown pictorially in Fig\nure 7.7(a). Note that this is a generalization of the midpoint rule to two dimensions.\nThe error in the integration is bounded by\ne ≤ Ch2IV2fIF .\nThus, the integration rule is second-order accurate. An example of error convergence is shown\nFigure 7.7(b), where the triangles are uniformly divided to produce a better approximation of the\nintegral. The convergence plot confirms the second-order convergence of the scheme.\nSimilar to the midpoint rule in one dimension, the midpoint rule on a triangle also belongs\nin the family of Gauss quadratures. The quadrature points and weights are chosen optimally to\nachieve as high-order convergence as possible.\nExample 7.2.2 trapezoidal rule\nThe trapezoidal-integration rule is based on the piecewise-linear interpolant. Because the integral\nof a linear function defined on a triangular patch is equal to the average of the function values at\nits vertices times the area of the triangle, the integral simplifies to\n⎡\n⎤\nN\nn\nn\nm\n⎣1\nf(\n⎦\nIh\nAi\n)\n=\ni\n,\ni=1\nm=1\nx\ni ,\nx\ni , 3\ni\nx\nwhere {\nin Figure 7.8(a) .\n} are the vertices of the triangle Ri. The integration process is graphically shown\nThe error in the integration is bounded by\ne ≤ Ch2IV2fIF .\nThe integration rule is second-order accurate, as confirmed by the convergence plot shown in Fig\nure 7.8(b).\nZZ\n\n-2\n-1\n-5\n-4\n-3\n-2\n2.00\nh\n|I - Ih|\n\nmidpoint\ntrapezoid\n(a) integral\n(b) error\nFigure 7.8: Trapezoidal rule.\nThe integration rules extend to higher dimensions in principle by using interpolation rules for\nhigher dimensions. However, the number of integration points increases as (1/h)d, where d is the\nphysical dimension. The number of points increases exponentially in d, and this is called the curse\nof dimensionality. An alternative is to use a integration process based on random numbers, which\nis discussed in the next unit.\n7.3\nGauss Quadrature\nIn the previous sections, we mentioned that the midpoint rule -- which exhibit second-order con\nvergence using just one quadrature point -- is an example of Gauss quadrature rules. The Gauss\nquadrature rules are obtained by choosing both the quadrature points and weights in an \"optimal\"\nmanner. This is in contrast to Newton-Cotes rules (e.g. trapezoidal rule), which is based on equally\nspaced points. The \"optimal\" rule refers to the rule that maximizes the degree of polynomial in\ntegrated exactly for a given number of points. In one dimension, the n-point Gauss quadrature\nintegrates 2n - 1 degree polynomial exactly. This may not be too surprising because 2n - 1 de\ngree polynomial has 2n degrees of freedom, and n-point Gauss quadrature also gives 2n degrees of\nfreedom (n points and n weights).\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n2.086 Numerical Computation for Mechanical Engineers\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "V1.2 Errata  from Math, Numerics, & Programming",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-086-numerical-computation-for-mechanical-engineers-fall-2012/3aa46ba50b08b5e3bd99f4761e32921f_MIT2_086F12_notes_errata.pdf",
      "content": "V1.2\nMath, Numerics, & Programming (for Mechanical Engineers)\nby\nMasayuki Yano, James Douglass Penn, George Konidaris, and Anthony T Patera\nERRATA\n1. On page 172 of the text, in equation (10.1), in the line before equation (10.1), and in the\ntwo lines after equation (10.1), the θˆ should be θˆn, where θˆn is our estimate for θ (i.e., a\nrealization of Θe n.\n2. In Unit III of the text, page 280, the phrase \"explicit expression for the parameter β0\" should\nbe instead \"explicit expression for the least squares estimate for βtrue , βˆ0\"; then, the next\nfour occurrences of β0 on this page should be changed to βˆ0; finally, the last occurrence of β0\non this page (inside the N , indicating the normal density mean) should be βtrue . As always,\nwe must distinguish between the true value of the coefficient and the least squares solution\nwhich is an estimate for the true value. On the next page, page 281, all the hats are in the\ngood places.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n2.086 Numerical Computation for Mechanical Engineers\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Unit 2: Monte Carlo Methods from Math, Numerics, and Programming (for Mechanical Engineers). V1.2, September 2012.",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-086-numerical-computation-for-mechanical-engineers-fall-2012/620181b7e657843652addefc39074e37_MIT2_086F12_notes_unit2.pdf",
      "content": "DRAFT V1.2\nFrom\nMath, Numerics, & Programming\n(for Mechanical Engineers)\nMasayuki Yano\nJames Douglass Penn\nGeorge Konidaris\nAnthony T Patera\nSeptember 2012\n(c) The Authors. License: Creative Commons Attribution-Noncommercial-Share Alike 3.0\n(CC BY-NC-SA 3.0), which permits unrestricted use, distribution, and reproduction\nin any medium, provided the original authors and MIT OpenCourseWare source\nare credited; the use is non-commercial; and the CC BY-NC-SA license is\nretained. See also http://ocw.mit.edu/terms/.\n\nContents\nII\nMonte Carlo Methods.\n8 Introduction\n8.1 Statistical Estimation and Simulation . . . . . . . . . . . . . . . . . . . . . . . . . . 117\n8.1.1\nRandom Models and Phenomena . . . . . . . . . . . . . . . . . . . . . . . . . 117\n8.1.2\nStatistical Estimation of Parameters/Properties of Probability Distributions . 118\n8.1.3\nMonte Carlo Simulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119\n8.2 Motivation: An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120\n9 Introduction to Random Variables\n9.1 Discrete Random Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123\n9.1.1\nProbability Mass Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123\n9.1.2\nTransformation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\n9.2 Discrete Bivariate Random Variables (Random Vectors) . . . . . . . . . . . . . . . . 133\n9.2.1\nJoint Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133\n9.2.2\nCharacterization of Joint Distributions . . . . . . . . . . . . . . . . . . . . . . 134\n9.3 Binomial Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\n9.4 Continuous Random Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146\n9.4.1\nProbability Density Function; Cumulative Distribution Function . . . . . . . 146\n9.4.2\nTransformations of Continuous Random Variables . . . . . . . . . . . . . . . 151\n9.4.3\nThe Central Limit Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154\n9.4.4\nGeneration of Pseudo-Random Numbers . . . . . . . . . . . . . . . . . . . . . 155\n9.5 Continuous Random Vectors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157\n10 Statistical Estimation: Bernoulli (Coins)\n10.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167\n10.2 The Sample Mean: An Estimator / Estimate . . . . . . . . . . . . . . . . . . . . . . 167\n10.3 Confidence Intervals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171\n10.3.1 Definition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171\n10.3.2 Frequentist Interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\n10.3.3 Convergence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174\n10.4 Cumulative Sample Means\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174\n11 Statistical Estimation: the Normal Density\n12 Monte Carlo: Areas and Volumes\n12.1 Calculating an Area . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181\n12.1.1 Objective . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181\n12.1.2 A Continuous Uniform Random Variable . . . . . . . . . . . . . . . . . . . . 181\n12.1.3 A Bernoulli Random Variable . . . . . . . . . . . . . . . . . . . . . . . . . . . 182\n\n12.1.4 Estimation: Monte Carlo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182\n12.1.5 Estimation: Riemann Sum . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184\n12.2 Calculation of Volumes in Higher Dimensions . . . . . . . . . . . . . . . . . . . . . . 187\n12.2.1 Three Dimensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187\nMonte Carlo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\nRiemann Sum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\n12.2.2 General d-Dimensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191\n13 Monte Carlo: General Integration Procedures\n14 Monte Carlo: Failure Probabilities\n14.1 Calculating a Failure Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\n14.1.1 Objective . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\n14.1.2 An Integral . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196\n14.1.3 A Monte Carlo Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196\n\nUnit II\nMonte Carlo Methods.\n\nChapter 8\nIntroduction\n8.1\nStatistical Estimation and Simulation\n8.1.1\nRandom Models and Phenomena\nIn science and engineering environments, we often encounter experiments whose outcome cannot\nbe determined with certainty in practice and is better described as random. An example of such a\nrandom experiment is a coin flip. The outcome of flipping a (fair) coin is either heads (H) or tails\n(T), with each outcome having equal probability. Here, we define the probability of a given outcome\nas the frequency of its occurrence if the experiment is repeated a large number of times.1 In other\nwords, when we say that there is equal probability of heads and tails, we mean that there would\nbe an equal number of heads and tails if a fair coin is flipped a large (technically infinite) number\nof times. In addition, we expect the outcome of a random experiment to be unpredictable in some\nsense; a coin that consistently produces a sequence HTHTHTHT or HHHTTTHHHTTT can be\nhardly called random. In the case of a coin flip, we may associate this notion of unpredictability or\nrandomness with the inability to predict with certainty the outcome of the next flip by knowing\nthe outcomes of all preceding flips. In other words, the outcome of any given flip is independent of\nor unrelated to the outcome of other flips.2\nWhile the event of heads or tails is random, the distribution of the outcome over a large number\nof repeated experiments (i.e. the probability density) is determined by non-random parameters. In\nthe case of a coin flip, the sole parameter that dictates the probability density is the probability of\nheads, which is 1/2 for a fair coin; for a non-fair coin, the probability of heads is (by definition)\ndifferent from 1/2 but is still some fixed number between 0 and 1.\nNow let us briefly consider why the outcome of each coin flip may be considered random. The\noutcome of each flip is actually governed by a deterministic process. In fact, given a full description\nof the experiment -- the mass and moment of inertia of the coin, initial launch velocity, initial\nangular momentum, elasticity of the landing surface, density of the air, etc -- we can, in principle,\npredict the outcome of our coin flip by solving a set of deterministic governing equations -- Euler's\nequations for rigid body dynamics, the Navier-Stokes equations for aerodynamics, etc. However,\n1We adhere to the frequentistic view of probability throughout this unit. We note that the Baysian view is an\nalternative, popular interpretation of probability.\n2We will study this notion of independence (in a strict mathematical sense) in more detail in Chapter 9. Here, we\nsimply use the idea to illustrate the concept of randomness, but caution that the independence or uncorrelatedness\nof the outcome is not a requirement of a random experiment.\nDRAFT V1.2 (c) The Authors. License: Creative Commons BY-NC-SA 3.0.\n\neven for something as simple as flipping a coin, the number of variables that describe the state of\nthe system is very large. Moreover, the equations that relate the state to the final outcome (i.e.\nheads or tails) are complicated and the outcome is very sensitive to the conditions that govern\nthe experiments. This renders detailed prediction very difficult, but also suggests that a random\nmodel -- which considers just the outcome and not the myriad \"uncontrolled\" ways in which we\ncan observe the outcome -- may suffice.\nAlthough we will use a coin flip to illustrate various concepts of probability throughout this\nunit due to its simplicity and our familiarity with the process, we note that random experiments\nare ubiquitous in science and engineering. For example, in studying gas dynamics, the motion of\nthe individual molecules is best described using probability distributions. Recalling that 1 mole of\ngas contains approximately 6 × 1023 particles, we can easily see that deterministic characterization\nof their motion is impractical. Thus, scientists describe their motion in probabilistic terms; in fact,\nthe macroscale velocity and temperature are parameters that describe the probability distribution\nof the particle motion, just as the fairness of a given coin may be characterized by the probability\nof a head. In another instance, an engineer studying the effect of gust on an airplane may use\nprobability distributions to describe the change in the velocity field affected by the gust. Again,\neven though the air motion is well-described by the Navier-Stokes equations, the highly sensitive\nnature of turbulence flows renders deterministic prediction of the gust behavior impractical. More\nimportantly, as the engineer is most likely not interested in the detailed mechanics that governs\nthe formation and propagation of the gust and is only interested in its effect on the airplane (e.g.,\nstresses), the gust velocity is best described in terms of a probability distribution.\n8.1.2 Statistical Estimation of Parameters/Properties of Probability Distribu\ntions\nStatistical estimation is a process through which we deduce parameters that characterize the be\nhavior of a random experiment based on a sample -- a set of typically large but in any event finite\nnumber of outcomes of repeated random experiments.3 In most cases, we postulate a probability\ndistribution -- based on some plausible assumptions or based on some descriptive observations such\nas crude histogram -- with several parameters; we then wish to estimate these parameters. Alter\nnatively, we may wish to deduce certain properties -- for example, the mean -- of the distribution;\nthese properties may not completely characterize the distribution, but may suffice for our predic\ntive purposes. (In other cases, we may need to estimate the full distribution through an empirical\ncumulative distribution function; We shall not consider this more advanced case in this text.) In\nChapter 9, we will introduce a variety of useful distributions, more precisely parametrized discrete\nprobability mass functions and continuous probability densities, as well as various properties and\ntechniques which facilitate the interpretation of these distributions.\nLet us illustrate the statistical estimation process in the context of a coin flip. We can flip\na coin (say) 100 times, record each observed outcome, and take the mean of the sample -- the\nfraction which are heads -- to estimate the probability of heads. We expect from our frequentist\ninterpretation that the sample mean will well approximate the probability of heads. Note that,\nwe can only estimate -- rather than evaluate -- the probability of heads because evaluating the\nprobability of heads would require, by definition, an infinite number of experiments. We expect\nthat we can estimate the probability of heads -- the sole parameter dictating the distribution of\nour outcome -- with more confidence as the sample size increases. For instance, if we wish to verify\nthe fairness of a given coin, our intuition tells us that we are more likely to deduce its fairness (i.e.\nthe probability of heads equal to 0.5) correctly if we perform 10 flips than 3 flips. The probability\nof landing HHH using a fair coin in three flips -- from which we might incorrectly conclude the\n3We will provide a precise mathematical definition of sample in Chapter 10.\n\ncoin as unfair -- is 1/8, which is not so unlikely, but that of landing HHHHHHHHHH in 10 flips is\nless than 1 in 1000 trials, which is very unlikely.\nIn Chapters 10 and 11, we will introduce a mathematical framework that not only allows us to\nestimate the parameters that characterize a random experiment but also quantify the confidence\nwe should have in such characterization; the latter, in turn, allows us to make claims -- such as the\nfairness of a coin -- with a given level of confidence. We consider two ubiquitous cases: a Bernoulli\ndiscrete mass density (relevant to our coin flipping model, for example) in Chapter 10; and the\nnormal density in Chapter 11.\n8.1.3\nMonte Carlo Simulation\nSo far, we have argued that a probability distribution may be effectively used to characterize the\noutcome of experiments whose deterministic characterization is impractical due to a large number\nof variables governing its state and/or complicated functional dependencies of the outcome on\nthe state. Another instance in which a probabilistic description is favored over a deterministic\ndescription is when their use is computationally advantageous even if the problem is deterministic.\nOne example of such a problem is determination of the area (or volume) of a region whose\nboundary is described implicitly. For example, what is the area of a unit-radius circle? Of course,\nwe know the answer is π, but how might we compute the area if we did not know that A = πr2?\nOne way to compute the area may be to tessellate (or discretize) the region into small pieces and\nemploy the deterministic integration techniques discussed in Chapter 7. However, application of\nthe deterministic techniques becomes increasingly difficult as the region of interest becomes more\ncomplex. For instance, tessellating a volume intersected by multiple spheres is not a trivial task.\nMore generally, deterministic techniques can be increasingly inefficient as the dimension of the\nintegration domain increases.\nMonte Carlo methods are better suited for integrating over such a complicated region. Broadly,\nMonte Carlo methods are a class of computational techniques based on synthetically generating\nrandom variables to deduce the implication of the probability distribution. Let us illustrate the\nidea more precisely for the area determination problem. We first note that if our region of interest\nis immersed in a unit square, then the area of the region is equal to the probability of a point drawn\nrandomly from the unit square residing in the region. Thus, if we assign a value of 0 (tail) and 1\n(head) to the event of drawing a point outside and inside of the region, respectively, approximating\nthe area is equivalent to estimating the probability we land inside (a head). Effectively, we have\nturned our area determination problem into an statistical estimation problem; the problem is now\nno different from the coin flip experiment, except the outcome of each \"flip\" is determined by\nperforming a (simple) check that determines if the point drawn is inside or outside of the region.\nIn other words, we synthetically generate a random variable (by performing the in/out check on\nuniformly drawn samples) and deduce the implication on the distribution (in this case the area,\nwhich is the mean of the distribution). We will study Monte-Carlo-based area integration techniques\nin details in Chapter 12.\nThere are several advantages to using Monte Carlo methods compared to deterministic inte\ngration approaches. First, Monte Carlo methods are simple to implement: in our case, we do not\nneed to know the domain, we only need to know whether we are in the domain. Second, Monte\nCarlo methods do not rely on smoothness for convergence -- if we think of our integrand as 0\nand 1 (depending on outside or inside), our problem here is quite non-smooth. Third, although\nMonte Carlo methods do not converge particularly quickly, the convergence rate does not degrade\nin higher dimensions -- for example, if we wished to estimate the volume of a region in a three-\ndimensional space. Fourth, Monte Carlo methods provide a result, along with a simple built-in\nerror estimator, \"gradually\" -- useful, if not particularly accurate, answers are obtained early on\n\nin the process and hence inexpensively and quickly. Note for relatively smooth problems in smooth\ndomains Monte Carlo techniques are not a particularly good idea. Different methods work better\nin different contexts.\nMonte Carlo methods -- and the idea of synthetically generating a distribution to deduce its\nimplication -- apply to a wide range of engineering problems. One such example is failure analysis.\nIn the example of an airplane flying through a gust, we might be interested in the stress on the spar\nand wish to verify that the maximum stress anywhere in the spar does not exceed the yield strength\nof the material -- and certainly not the fracture strength so that we may prevent a catastrophic\nfailure. Directly drawing from the distribution of the gust-induced stress would be impractical;\nthe process entails subjecting the wing to various gust and directly measuring the stress at various\npoints. A more practical approach is to instead model the gust as random variables (based on\nempirical data), propagate its effect through an aeroelastic model of the wing, and synthetically\ngenerate the random distribution of the stress. To estimate the properties of the distribution --\nsuch as the mean stress or the probability of the maximum stress exceeding the yield stress -- we\nsimply need to use a large enough set of realizations of our synthetically generated distribution.\nWe will study the use of Monte Carlo methods for failure analysis in Chapter 14.\nLet us conclude this chapter with a practical example of area determination problem in which\nthe use of Monte Carlo methods may be advantageous.\n8.2\nMotivation: An Example\nA museum has enlisted a camera-equipped mobile robot for surveillance purposes. The robot will\nnavigate the museum's premises, pausing to take one or more 360 degree scans in each room.\nFigure 8.1 shows a typical room filled with various stationary obstructions (in black). We wish to\ndetermine the vantage point in each room from which the robot will have the most unobstructed\nview for its scan by estimating the visible area (in white) for each candidate vantage point. We may\nalso wish to provide the robot with an \"onboard\" visible area estimator for purposes of real-time\nadaptivity, for example, if the room configuration is temporarily modified. This is a good candidate\nfor Monte Carlo: the domain is complex and non-smooth; we would like quick results based on\nrelatively few evaluations; and we wish to somehow certify the accuracy of our prediction. (In\nactual practice, the computation would be performed over a three-dimensional museum room -- a\nfurther reason to consider Monte Carlo.)\nWe first define, for any vantage point xV and any surveillance point (to be watched) in the\nroom xW , the line segment S(xV , xW ) that connects xV and xW . We can then express the area\nvisible from a vantage point xV as the integral\n\nA(xV ) =\ndxW ,\n(8.1)\nxW ∈R such that S(xV ,xW )∩O=∅\nwhere R is the room and O is the collection of obstructions. The visible area is thus defined as\nthe integral over all points in the room such that the line segment S(xV , xW ) between xV and xW\ndoes not intersect an obstruction (or, equivalently, such that the intersection of sets S and O is the\nnull set).\n?\nThere are many ways to do the visibility test S(xV , xW )∩O = ∅, but perhaps the method most\namenable to mobile robotics is to use an \"occupancy grid,\" a discretization of the map in which\neach cell's value corresponds to the likelihood that the cell is empty or occupied. We begin by\nconverting our map of the room to an \"occupancy grid,\" a discretization of the map in which each\ncell's value corresponds to the likelihood that the cell is empty or occupied. In our case, because we\nknow ahead of time the layout of the room, a given cell contains either a zero if the cell is empty,\n\nFigure 8.1: A surveillance robot scanning a room. Obstructions (in black) divide the space into\nvisible area (in white) and non-visible area (in gray).\nx∗\ny∗\nFigure 8.2: Occupancy grid.\nor a one if it is occupied. Figure 8.2 shows a visualization of a fairly low-resolution occupancy grid\nfor our map, where occupied cells are shown in black.\nWe can use the occupancy grid to determine the visibility of a point xW in the room from a\ngiven vantage point xV . To do this, we draw a line between the two points, determine through\nwhich cells the line passes and then check the occupancy condition of each of the intervening cells.\nIf all of the cells are empty, the point is visible. If any of the cells are occupied, the point is not\nvisible. Figure 8.3 shows examples of visible and non-visible cells. Once we have a method for\ndetermining if a point is visible or non-visible, we can directly apply our Monte Carlo methods for\nthe estimation of area.\n\nx∗\ny∗\nFigure 8.3: Visibility checking of two points from a single vantage point. Visible cells marked in\nblue, non-visible cells marked in red.\n\nChapter 9\nIntroduction to Random Variables\n9.1\nDiscrete Random Variables\n9.1.1\nProbability Mass Functions\nIn this chapter, we develop mathematical tools for describing and analyzing random experiments,\nexperiments whose outcome cannot be determined with certainty. A coin flip and a roll of a die\nare classical examples of such experiments. The outcome of a random experiment is described by\na random variable X that takes on a finite number of values,\nx1, . . . , xJ ,\nwhere J is the number of values that X takes. To fully characterize the behavior of the random\nvariable, we assign a probability to each of these events, i.e.\nX = xj ,\nwith probability pj ,\nj = 1, . . . , J .\nThe same information can be expressed in terms of the probability mass function (pmf), or discrete\ndensity function, fX , that assigns a probability to each possible outcome\nfX (xj ) = pj ,\nj = 1, . . . , J .\nIn order for fX to be a valid probability density function, {pj } must satisfy\n0 ≤ pj ≤ 1,\nj = 1, . . . , J ,\nJ\nJ\npj = 1 .\nj=1\nThe first condition requires that the probability of each event be non-negative and be less than or\nequal to unity. The second condition states that {x1, . . . , xJ } includes the set of all possible values\nthat X can take, and that the sum of the probabilities of the outcome is unity. The second condition\nfollows from the fact that events xi, i = 1, . . . , J, are mutually exclusive and exhaustive. Mutually\nexclusive means that X cannot take on two different values of the xi's in any given experiment.\nExhaustive means that X must take on one of the J possible values in any given experiment.\nDRAFT V1.2 (c) The Authors. License: Creative Commons BY-NC-SA 3.0.\n\nNote that for the same random phenomenon, we can choose many different outcomes; i.e. we\ncan characterize the phenomenon in many different ways. For example, xj = j could simply be\na label for the j-th outcome; or xj could be a numerical value related to some attribute of the\nphenomenon. For instance, in the case of flipping a coin, we could associate a numerical value of\n1 with heads and 0 with tails. Of course, if we wish, we could instead associate a numerical value\nof 0 with heads and 1 with tails to describe the same experiment. We will see examples of many\ndifferent random variables in this unit.\nLet us define a few notions useful for characterizing the behavior of the random variable. The\nexpectation of X, E[X], is defined as\nJ\nJ\nE[X] =\nxj pj .\n(9.1)\nj=1\nThe expectation of X is also called the mean. We denote the mean by μ or μX , with the second\nnotation emphasizing that it is the mean of X. Note that the mean is a weighted average of the\nvalues taken by X, where each weight is specified according to the respective probability. This is\nanalogous to the concept of moment in mechanics, where the distances are provided by xj and the\nweights are provided by pj ; for this reason, the mean is also called the first moment. The mean\ncorresponds to the centroid in mechanics.\nNote that, in frequentist terms, the mean may be expressed as the sum of values taken by X\nover a large number of realizations divided by the number of realizations, i.e.\nJ\nJ\n(Mean) =\nlim\nxj · (# Occurrences of xj ) .\n(# Realizations)→inf (# Realizations) j=1\nRecalling that the probability of a given event is defined as\n(# Occurrences of xj )\npj =\nlim\n,\n(# Realizations)→inf\n(# Realizations)\nwe observe that\nJ\nJ\nE[X] =\nxj pj ,\nj=1\nwhich is consistent with the definition provided in Eq. (9.1). Let us provide a simple gambling\nscenario to clarity this frequentist interpretation of the mean. Here, we consider a \"game of chance\"\nthat has J outcomes with corresponding probabilities pj , j = 1, . . . , J; we denote by xj the (net)\npay-off for outcome j. Then, in nplays plays of the game, our (net) income would be\nJ\nJ\nxj · (# Occurrences of xj ) ,\nj=1\nwhich in the limit of large nplays (= # Realizations) yields nplays · E[X]. In other words, the mean\nE[X] is the expected pay-off per play of the game, which agrees with our intuitive sense of the\nmean.\nThe variance, or the second moment about the mean, measures the spread of the values about\nthe mean and is defined by\nJ\nJ\nVar[X] ≡ E[(X - μ)2] =\n(xj - μ)2 pj .\nj=1\n\nWe denote the variance as σ2 . The variance can also be expressed as\nJ\nJ\nJ\nJ\nVar[X] = E[(X - μ)2] =\n(xj - μ)2 pj =\n(xj - 2xj μ + μ 2)pj\nj=1\nj=1\nJ\nJ\nJ\nJ\nJ\nJ\n=\nxj pj -2μ\nxj pj +μ\npj = E[X2] - μ .\nj=1\nj=1\nj=1\n\nE[X2]\nμ\nNote that the variance has the unit of X squared. Another useful measure of the expected spread\nof the random variable is standard deviation, σ, which is defined by\n\nσ =\nVar[X] .\nWe typically expect departures from the mean of many standard deviations to be rare. This is\nparticularly the case for random variables with large range, i.e. J large. (For discrete random\nvariables with small J, this spread interpretation is sometimes not obvious simply because the\nrange of X is small.) In case of the aforementioned \"game of chance\" gambling scenario, the\nstandard deviation measures the likely (or expected) deviation in the pay-off from the expectation\n(i.e. the mean). Thus, the standard deviation can be related in various ways to risk; high standard\ndeviation implies a high-risk case with high probability of large payoff (or loss).\nThe mean and variance (or standard deviation) provide a convenient way of characterizing the\nbehavior of a probability mass function. In some cases the mean and variance (or even the mean\nalone) can serve as parameters which completely determine a particular mass function. In many\nother cases, these two properties may not suffice to completely determine the distribution but can\nstill serve as useful measures from which to make further deductions.\nLet us consider a few examples of discrete random variables.\nExample 9.1.1 rolling a die\nAs the first example, let us apply the aforementioned framework to rolling of a die. The random\nvariable X describes the outcome of rolling a (fair) six-sided die. It takes on one of six possible\nvalues, 1, 2, . . . , 6. These events are mutually exclusive, because a die cannot take on two different\nvalues at the same time. Also, the events are exhaustive because the die must take on one of the\nsix values after each roll. Thus, the random variable X takes on one of the six possible values,\nx1 = 1, x2 = 2, . . . , x6 = 6 .\nA fair die has the equal probability of producing one of the six outcomes, i.e.\nX = xj = j,\nwith probability ,\nj = 1, . . . , 6 ,\nor, in terms of the probability mass function,\nfX (x) = ,\nx = 1, . . . , 6 .\nAn example of outcome of a hundred die rolls is shown in Figure 9.1(a). The die always takes\non one of the six values, and there is no obvious inclination toward one value or the other. This is\nconsistent with the fact that any one of the six values is equally likely. (In practice, we would like to\nthink of Figure 9.1(a) as observed outcomes of actual die rolls, i.e. data, though for convenience here\nwe use synthetic data through random number generation (which we shall discuss subsequently).)\n\nrealizations\nx\n\nx\nμ\nμ ± σ\n0.05\n0.1\n0.15\n0.2\n0.25\nfX(x)\nx\n\npmf\nfrequency\n(a) realization\n(b) pmf\nFigure 9.1: Illustration of the values taken by a fair six-sided die and the probability mass function.\nFigure 9.1(b) shows the probability mass function, fX , of the six equally likely events. The figure\nalso shows the relative frequency of each event -- which is defined as the number of occurrences of\nthe event normalized by the total number of samples (which is 100 for this case) -- as a histogram.\nEven for a relatively small sample size of 100, the histogram roughly matches the probability mass\nfunction. We can imagine that as the number of samples increases, the relative frequency of each\nevent gets closer and closer to its value of probability mass function.\nConversely, if we have an experiment with an unknown probability distribution, we could infer\nits probability distribution through a large number of trials. Namely, we can construct a histogram,\nlike the one shown in Figure 9.1(b), and then construct a probability mass function that fits the\nhistogram. This procedure is consistent with the frequentist interpretation of probability: the\nprobability of an event is the relative frequency of its occurrence in a large number of samples.\nThe inference of the underlying probability distribution from a limited amount of data (i.e. a small\nsample) is an important problem often encountered in engineering practice.\nLet us now characterize the probability mass function in terms of the mean and variance. The\nmean of the distribution is\nJ\nJ\nμ = E[X] =\nxj pj =\nj ·\n=\n.\nj=1\nj=1\nThe variance of the distribution is\nJ\nJ\nσ2 = Var[X] = E[X2] - μ\nxj pj - μ =\nj2 ·\n-\n=\n-\n=\n≈ 2.9167 ,\nj=1\nj=1\nand the standard deviation is\n\nσ =\nVar[X] =\n≈ 1.7078 .\n·\n\nExample 9.1.2 (discrete) uniform distribution\nThe outcome of rolling a (fair) die is a special case of a more general distribution, called the\n(discrete) uniform distribution. The uniform distribution is characterized by each event having the\nequal probability. It is described by two integer parameters, a and b, which assign the lower and\nupper bounds of the sample space, respectively. The distribution takes on J = b - a + 1 values.\nFor the six-sided die, we have a = 1, b = 6, and J = b - a + 1 = 6. In general, we have\nxj = a + j - 1,\nj = 1, . . . , J ,\nfdisc.uniform(x) = 1 .\nJ\nThe mean and variance of a (discrete) uniform distribution are given by\na + b\nJ2 - 1\nμ =\nand σ2 =\n.\nWe can easily verify that the expressions are consistent with the die rolling case with a = 1, b = 6,\nand J = 6, which result in μ = 7/2 and σ2 = 35/12.\nProof. The mean follows from\nμ = E[X] = E[X - (a - 1) + (a - 1)] = E[X - (a - 1)] + a - 1\nJ\nJ\nJ\nJ 1\n1 J(J + 1)\n=\n(xj - (a - 1))pj + a - 1 =\nj\n+ a - 1 =\n+ a - 1\nJ\nJ\nj=1\nj=1\nb - a + 1 + 1\nb + a\n=\n+ a - 1 =\n.\nThe variance follows from\nσ2 = Var[X] = E[(X - E[X])2] = E[((X - (a - 1)) - E[X - (a - 1)])2]\n= E[(X - (a - 1))2] - E[X - (a - 1)]2\n⎡\n⎤2\nJ\nJ\nJ\nJ\n=\n(xj - (a - 1))2 pj - ⎣\n(xj - (a - 1))pj ⎦\nj=1\nj=1\n⎡\n⎤2\nJ\nJ\nJ\nj2 1\nJ\n1 J(J + 1)(2J + 1)\n1 J(J + 1) 2\n=\n- ⎣\njpj ⎦ =\n-\nJ\nJ\nJ\nj=1\nj=1\nJ2 - 1\n(b - a + 1)2 - 1\n=\n=\n.\n·\nExample 9.1.3 Bernoulli distribution (a coin flip)\nConsider a classical random experiment of flipping a coin. The outcome of a coin flip is either a\nhead or a tail, and each outcome is equally likely assuming the coin is fair (i.e. unbiased). Without\n\n(\nloss of generality, we can associate the value of 1 (success) with head and the value of 0 (failure)\nwith tail. In fact, the coin flip is an example of a Bernoulli experiment, whose outcome takes on\neither 0 or 1.\nSpecifically, a Bernoulli random variable, X, takes on two values, 0 and 1, i.e. J = 2, and\nx1 = 0 and x2 = 1.\nThe probability mass function is parametrized by a single parameter, θ ∈ [0, 1], and is given by\n1 - θ,\nx = 0\n(x) = fBernoulli(x; θ) ≡\nfXθ\nθ,\nx = 1 .\nIn other words, θ is the probability that the random variable Xθ takes on the value of 1. Flipping\nof a fair coin is a particular case of a Bernoulli experiment with θ = 1/2. The θ = 1/2 case is also a\nspecial case of the discrete uniform distribution with a = 0 and b = 1, which results in J = 2. Note\nthat, in our notation, fXθ is the probability mass function associated with a particular random\nwhereas fBernoulli(·; θ) is\nvariable Xθ,\na family of distributions that describe Bernoulli random\nvariables. For notational simplicity, we will not explicitly state the parameter dependence of Xθ on\nθ from hereon, unless the explicit clarification is necessary, i.e. we will simply use X for the random\nvariable and fX for its probability mass function. (Also note that what we call a random variable\nis of course our choice, and, in the subsequent sections, we often use variable B, instead of X, for\na Bernoulli random variable.)\nExamples of the values taken by Bernoulli random variables with θ = 1/2 and θ = 1/4 are\nshown in Figure 9.2. As expected, with θ = 1/2, the random variable takes on the value of 0 and 1\nroughly equal number of times. On the other hand, θ = 1/4 results in the random variable taking\non 0 more frequently than 1.\nThe probability mass functions, shown in Figure 9.2, reflect the fact that θ = 1/4 results in X\ntaking on 0 three times more frequently than 1. Even with just 100 samples, the relative frequency\nhistograms captures the difference in the frequency of the events for θ = 1/2 and θ = 1/4. In\nfact, even if we did not know the underlying pmf -- characterized by θ in this case -- we can infer\nfrom the sampled data that the second case has a lower probability of success (i.e. x = 1) than\nthe first case. In the subsequent chapters, we will formalize this notion of inferring the underlying\ndistribution from samples and present a method for performing the task.\nThe mean and variance of the Bernoulli distribution are given by\nE[X] = θ and Var[X] = θ(1 - θ) .\nNote that lower θ results in a lower mean, because the distribution is more likely to take on the\nvalue of 0 than 1. Note also that the variance is small for either θ → 0 or θ → 1 as in these cases\nwe are almost sure to get one or the other outcome. But note that (say) σ/E(X) scales as 1/ (θ)\n(recall σ is the standard deviation) and hence the relative variation in X becomes more pronounced\nfor small θ: this will have important consequences in our ability to predict rare events.\nProof. Proof of the mean and variance follows directly from the definitions. The mean is given by\nJ\nJ\nμ = E[X] =\nxjpj = 0 · (1 - θ) + 1 · θ = θ .\nj=1\n\nrealizations\nx\n\nx\nμ\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nfX(x)\nx\n\npmf\nfrequency\n(a) realization, θ = 1/2\n(b) pmf, θ = 1/2\nrealizations\nx\n\nx\nμ\n0.2\n0.4\n0.6\n0.8\nfX(x)\nx\n\npmf\nfrequency\n(c) realization, θ = 1/4\n(d) pmf, θ = 1/4\nFigure 9.2: Illustration of the values taken by Bernoulli random variables and the probability mass\nfunctions.\n\nThe variance is given by\nJ\nJ\nVar[X] = E[(X - μ)2] =\n(xj - μ)2 pj = (0 - θ)2 · (1 - θ) + (1 - θ)2 · θ = θ(1 - θ) .\nj=1\n·\nBefore concluding this subsection, let us briefly discuss the concept of \"events.\" We can define\nan event of A or B as the random variable X taking on one of some set of mutually exclusive\noutcomes xj in either the set A or the set B. Then, we have\nP (A or B) = P (A ∪ B) = P (A) + P (B) - P (A ∩ B).\nThat is, probability of event A or B taking place is equal to double counting the outcomes xj in\nboth A and B and then subtracting out the outcomes in both A and B to correct for this double\ncounting. Note that, if A and B are mutually exclusive, we have A ∩ B = ∅ and P (A ∩ B) = 0.\nThus the probability of A or B is\nP (A or B) = P (A) + P (B),\n(A and B mutually exclusive).\nThis agrees with our intuition that if A and B are mutually exclusive, we would not double count\noutcomes and thus would not need to correct for it.\n9.1.2\nTransformation\nRandom variables, just like deterministic variables, can be transformed by a function. For example,\nif X is a random variable and g is a function, then a transformation\nY = g(X)\nproduces another random variable Y . Recall that we described the behavior of X that takes on\none of J values by\nX = xj\nwith probability pj ,\nj = 1, . . . , J .\nThe associated probability mass function was fX (xj ) = pj , j = 1, . . . , J. The transformation\nY = g(X) yields the set of outcomes yj, j = 1, . . . , J, where each yj results from applying g to xj ,\ni.e.\nyj = g(xj ),\nj = 1, . . . , J .\nThus, Y can be described by\nY = yj = g(xj ) with probability pj ,\nj = 1, . . . , J .\nWe can write the probability mass function of Y as\nfY (yj) = fY (g(xj )) = pj\nj = 1, . . . , J .\n\n(\nWe can express the mean of the transformed variable in a few different ways:\nJ\nJ\nJ\nJ\nJ\nJ\nE[Y ] =\nyj fY (yj ) =\nyj pj =\ng(xj )fX (xj) .\nj=1\nj=1\nj=1\nThe first expression expresses the mean in terms of Y only, whereas the final expression expresses\nE[Y ] in terms of X and g without making a direct reference to Y .\nLet us consider a specific example.\nExample 9.1.4 from rolling a die to flipping a coin\nLet us say that we want to create a random experiment with equal probability of success and failure\n(e.g. deciding who goes first in a football game), but all you have is a die instead of a coin. One way\nto create a Bernoulli random experiment is to roll the die, and assign \"success\" if an odd number\nis rolled and assign \"failure\" if an even number is rolled.\nLet us write out the process more formally. We start with a (discrete) uniform random variable\nX that takes on\nxj = j,\nj = 1, . . . , 6 ,\nwith probability pj = 1/6, j = 1, . . . , 6. Equivalently, the probability density function for X is\nfX (x) = 6,\nx = 1, 2, . . . , 6 .\nConsider a function\ng(x) =\n0,\n1,\nx ∈ {1, 3, 5}\nx ∈ {2, 4, 6} .\n/\n/\nLet us consider a random variable Y = g(X). Mapping the outcomes of X, x1, . . . , x6, to y1, . . . , y6,\nwe have\n/y = g(x1) = g(1) = 0 ,\n/y = g(x2) = g(2) = 1 ,\n/y = g(x3) = g(3) = 0 ,\n/y = g(x4) = g(4) = 1 ,\n/y = g(x5) = g(5) = 0 ,\n/y = g(x6) = g(6) = 1 .\nWe could thus describe the transformed variable Y as\n/\nY = y\nwith probability pj = 1/6,\nj = 1, . . . , 6 .\nj\n/\n/\n/\n/\n/\n/\nHowever, because y = y = y5 and y = y = y6, we can simplify the expression. Without loss\nof generality, let us set\n/\n/\n/\n/\n/\n/\ny1 = y = y = y5 = 0 and y2 = y = y = y6 = 1 .\nWe now combine the frequentist interpretation of probability with the fact that x1, . . . , x6 are\nmutually exclusive. Recall that to a frequentist, P (Y = y1 = 0) is the probability that Y takes on\n0 in a large number of trials. In order for Y to take on 0, we must have x = 1, 3, or 5. Because\n(\n\n(\nfX(1)=1/6\n1/6\n1/6\n1/6\n1/6\n1/6\nfY(0)=1/2\nfY(1)=1/2\nx\ny = g(x)\nFigure 9.3: Transformation of X associated with a die roll to a Bernoulli random variable Y .\nX taking on 1, 3, and 5 are mutually exclusive events (e.g. X cannot take on 1 and 3 at the same\ntime), the number of occurrences of y = 0 is equal to the sum of the number of occurrences of\nx = 1, x = 3, and x = 5. Thus, the relative frequency of Y taking on 0 -- or its probability -- is\nequal to the sum of the relative frequencies of X taking on 1, 3, or 5. Mathematically,\nP (Y = y1 = 0) = P (X = 1) + P (X = 3) + P (X = 5) =\n+\n+\n=\n.\nSimilarly, because X taking on 2, 4, and 6 are mutually exclusive events,\nP (Y = y2 = 1) = P (X = 2) + P (X = 4) + P (X = 6) =\n+\n+\n=\n.\nThus, we have\n0,\nwith probability 1/2\nY =\n1,\nwith probability 1/2 ,\nor, in terms of the probability density function,\nfY (y) = ,\ny = 0, 1 .\nNote that we have transformed the uniform random variable X by the function g to create a\nBernoulli random variable Y . We emphasize that the mutually exclusive property of x1, . . . , x6 is the\nkey that enables the simple summation of probability of the events. In essence, (say), y = 0 obtains\nif x = 1 OR if x = 3 OR if x = 5 (a union of events) and since the events are mutually exclusive\nthe \"number of events\" that satisfy this condition -- ultimately (when normalized) frequency or\nprobability -- is the sum of the individual \"number\" of each event. The transformation procedure\nis illustrated in Figure 9.3.\nLet us now calculate the mean of Y in two different ways. Using the probability density of Y ,\nwe can directly compute the mean as\nJ\nE[Y ] =\nyj fY (yj ) = 0 ·\n+ 1 ·\n=\n.\nj=1\n(\n\nOr, we can use the distribution of X and the function g to compute the mean\nJ\nE[Y ] =\ng(xj )fX (xj ) = 0 ·\n+ 1 ·\n+ 0 ·\n+ 1 ·\n+ 0 ·\n+ 1 ·\n=\n.\nj=1\nClearly, both methods yield the same mean.\n·\n9.2\nDiscrete Bivariate Random Variables (Random Vectors)\n9.2.1\nJoint Distributions\nSo far, we have consider scalar random variables, each of whose outcomes is described by a single\nvalue. In this section, we extend the concept to random variables whose outcome are vectors. For\nsimplicity, we consider a random vector of the form\n(X, Y ) ,\nwhere X and Y take on JX and JY values, respectively. Thus, the random vector (X, Y ) takes\non J = JX · JY values. The probability mass function associated with (X, Y ) is denoted by fX,Y .\nSimilar to the scalar case, the probability mass function assigns a probability to each of the possible\noutcomes, i.e.\nfX,Y (xi, yj ) = pij ,\ni = 1, . . . , JX ,\nj = 1, . . . , JY .\nAgain, the function must satisfy\n0 ≤ pij ≤ 1,\ni = 1, . . . , JX ,\nj = 1, . . . , JY ,\nJY\nJX\nJ J\npij = 1 .\nj=1 i=1\nBefore we introduce key concepts that did not exist for a scalar random variable, let us give a\nsimple example of joint probability distribution.\nExample 9.2.1 rolling two dice\nAs the first example, let us consider rolling two dice. The first die takes on xi = i, i = 1, . . . , 6,\nand the second die takes on yj = j, j = 1, . . . , 6. The random vector associated with rolling the\ntwo dice is\n(X, Y ) ,\nwhere X takes on JX = 6 values and Y takes on JY = 6 values. Thus, the random vector (X, Y )\ntakes on J = JX · JY = 36 values. Because (for a fair die) each of the 36 outcomes is equally likely,\nthe probability mass function fX,Y is\nfX,Y (xi, yj ) =\n,\ni = 1, . . . , 6,\nj = 1, . . . , 6 .\nThe probability mass function is shown graphically in Figure 9.4.\n·\n\nx\ny\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\nFigure 9.4: The probability mass function for rolling two dice.\n.\n9.2.2\nCharacterization of Joint Distributions\nNow let us introduce a few additional concepts useful for describing joint distributions. Throughout\nthis section, we consider a random vector (X, Y ) with the associated probability distribution fX,Y .\nFirst is the marginal density, which is defined as\nJY\nJ\nfX (xi) =\nfX,Y (xi, yj ),\ni = 1, . . . , JX .\nj=1\nIn words, marginal density of X is the probability distribution of X disregarding Y . That is, we\nignore the outcome of Y , and ask ourselves the question: How frequently does X take on the value\nxi? Clearly, this is equal to summing the joint probability fX,Y (xi, jj ) for all values of yj . Similarly,\nthe marginal density for Y is\nJX\nJ\nfY (yj ) =\nfX,Y (xi, yj ),\nj = 1, . . . , JY .\ni=1\nAgain, in this case, we ignore the outcome of X and ask: How frequently does Y take on the value\nyj ? Note that the marginal densities are valid probability distributions because\nJY\nJX\nJY\nJ\nJ J\nfX (xi) =\nfX,Y (xi, yj ) ≤\nfX,Y (xk, yj ) = 1,\ni = 1, . . . , JX ,\nj=1\nk=1 j=1\nand\nJX\nJX\nJY\nJ\nJ J\nfX (xi) =\nfX,Y (xi, yj ) = 1 .\ni=1\ni=1 j=1\nThe second concept is the conditional probability, which is the probability that X takes on the\nvalue xi given Y has taken on the value yj . The conditional probability is denoted by\nfX|Y (xi|yj ),\ni = 1, . . . , JX ,\nfor a given yj .\n\nThe conditional probability can be expressed as\nfX,Y (xi, yj )\nfX|Y (xi|yj ) =\n.\nfY (yj )\nIn words, the probability that X takes on xi given that Y has taken on yj is equal to the probability\nthat both events take on (xi, yj ) normalized by the probability that Y takes on yj disregarding xi.\nWe can consider a different interpretation of the relationship by rearranging the equation as\nfX,Y (xi, yj ) = fX|Y (xi|yj )fY (yj )\n(9.2)\nand then summing on j to yield\nJY\nJY\nJ\nJ\nfX (xi) =\nf(xi, yj ) =\nfX|Y (xi|yj )fY (yj ) .\nj=1\nj=1\nIn other words, the marginal probability of X taking on xi is equal to the sum of the probabilities of\nX taking on xi given Y has taken on yj multiplied by the probability of Y taking on yj disregarding\nxi.\nFrom (9.2), we can derive Bayes' law (or Bayes' theorem), a useful rule that relates conditional\nprobabilities of two events. First, we exchange the roles of x and y in (9.2), obtaining\nfY,X (yj , xi) = fY |X (yj |xi)fX (xi).\nBut, since fY,X (yj , xi) = fX,Y (xi, yj ),\nfY |X (yj |xi)fX (xi) = fX|Y (xi|yj )fY (yj ),\nand rearranging the equation yields\nfX|Y (xi|yj )fY (yj )\nfY |X (yj |xi) =\n.\n(9.3)\nfX (xi)\nEquation (9.3) is called Bayes' law. The rule has many useful applications in which we might know\none conditional density and we wish to infer the other conditional density. (We also note the the\norem is fundamental to Bayesian statistics and, for example, is exploited in estimation and inverse\nproblems -- problems of inferring the underlying parameters of a system from measurements.)\nExample 9.2.2 marginal and conditional density of rolling two dice\nLet us revisit the example of rolling two dice, and illustrate how the marginal density and conditional\ndensity are computed. We recall that the probability mass function for the problem is\nfX,Y (x, y) =\n,\nx = 1, . . . , 6, y = 1, . . . , 6 .\nThe calculation of the marginal density of X is illustrated in Figure 9.5(a). For each xi,\ni = 1, . . . , 6, we have\nJ\nfX (xi) =\nfX,Y (xi, yj ) =\n+\n+\n+\n+\n+\n= ,\ni = 1, . . . , 6 .\nj=1\nWe can also deduce this from intuition and arrive at the same conclusion. Recall that marginal\ndensity of X is the probability density of X ignoring the outcome of Y . For this two-dice rolling\n\nx\ny\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/6\n1/6\n1/6\n1/6\n1/6\n1/6\nx\ny\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/6\n1/6\n1/6\n1/6\n1/6\n1/6\n(a) marginal density, fX\n(b) marginal density, fY\nFigure 9.5: Illustration of calculating marginal density fX (x = 2) and fY (y = 3).\nexample, it simply corresponds to the probability distribution of rolling a single die, which is clearly\nequal to\nfX (x) = ,\nx = 1, . . . , 6 .\nSimilar calculation of the marginal density of Y , fY , is illustrated in Figure 9.5(b). In this case,\nignoring the first die (X), the second die produces yj = j, j = 1, . . . , 6, with the equal probability\nof 1/6.\nLet us now illustrate the calculation of conditional probability. As the first example, let us\ncompute the conditional probability of X given Y . In particular, say we are given y = 3. As\nshown in Figure 9.6(a), the joint probability of all outcomes except those corresponding to y = 3\nare irrelevant (shaded region). Within the region with y = 3, we have six possible outcomes, each\nwith the equal probability. Thus, we have\nfX|Y (x|y = 3) = ,\nx = 1, . . . , 6 .\nNote that, we can compute this by simply considering the select set of joint probabilities fX,Y (x, y =\n3) and re-normalizing the probabilities by their sum. In other words,\nfX,Y (x, y = 3)\nfX,Y (x, y = 3)\nfX|Y (x|y = 3) = 6\n=\n,\nfX,Y (xi, y = 3)\nfY (y = 3)\ni=1\nwhich is precisely equal to the formula we have introduced earlier.\nSimilarly, Figure 9.6(b) illustrates the calculation of the conditional probability fY |X (y, x = 2).\nIn this case, we only consider joint probability distribution of fX,Y (x = 2, y) and re-normalize the\ndensity by fX (x = 2).\n·\nA very important concept is independence. Two events are said to be independent if the\noccurrence of one event does not influence the outcome of the other event. More precisely, two\nrandom variables X and Y are said to be independent if their probability density function satisfies\nfX,Y (xi, yj ) = fX (xi) · fY (yj ),\ni = 1, . . . , JX ,\nj = 1, . . . , JY .\n\n1/6\n1/6\n1/6\n1/6\n1/6\n1/6\nx\ny\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/6\n1/6\n1/6\n1/6\n1/6\n1/6\nx\ny\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n(a) conditional density, fX|Y (x|y = 3)\n(b) conditional density, fY |X (y|x = 2)\nFigure 9.6: Illustration of calculating conditional density fX|Y (x|y = 3) and fY |X (y|x = 2).\nThe fact that the probability density is simply a product of marginal densities means that we can\ndraw X and Y separately according to their respective marginal probability and then form the\nrandom vector (X, Y ).\nUsing conditional probability, we can connect our intuitive understanding of independence with\nthe precise definition. Namely,\nfX,Y (xi, yj )\nfX (xi)fY (yj )\nfX|Y (xi|yj ) =\n=\n= fX (xi) .\nfY (yj )\nfY (yj )\nThat is, the conditional probability of X given Y is no different from the probability that X takes\non x disregarding y. In other words, knowing the outcome of Y adds no additional information\nabout the outcome of X. This agrees with our intuitive sense of independence.\nWe have discussed the notion of \"or\" and related it to the union of two sets. Let us now briefly\ndiscuss the notion of \"and\" in the context of joint probability. First, note that fX,Y (x, y) is the\nprobability that X = x and Y = y, i.e. fX,Y (x, y) = P (X = x and Y = y). More generally,\nconsider two events A and B, and in particular A and B, which is the intersection of A and B,\nA ∩ B. If the two events are independent, then\nP (A and B) = P (A)P (B)\nand hence fX,Y (x, y) = fX (x)fY (y) which we can think of as probability of P (A ∩ B). Pictorially,\nwe can associate event A with X taking on a specified value as marked in Figure 9.5(a) and event\nB with Y taking on a specified value as marked in Figure 9.5(b). The intersection of A and B is the\nintersection of the two marked regions, and the joint probability fX,Y is the probability associated\nwith this intersection.\nTo solidify the idea of independence, let us consider two canonical examples involving coin flips.\nExample 9.2.3 independent events: two random variables associated with two inde\npendent coin flips\nLet us consider flipping two fair coins. We associate the outcome of flipping the first and second\ncoins with random variables X and Y , respectively. Furthermore, we associate the values of 1 and\n\nx\ny\n1/4\n1/4\n1/4\n1/4\nfY(0)=1/2\nfY(1)=1/2\nfX(0)=1/2\nfX(1)=1/2\nFigure 9.7: The probability mass function for flipping two independent coins.\n0 to head and tail, respectively. We can associate the two flips with a random vector (X, Y ), whose\npossible outcomes are\n(0, 0),\n(0, 1),\n(1, 0),\nand (1, 1) .\nIntuitively, the two variables X and Y will be independent if the outcome of the second flip,\ndescribed by Y , is not influenced by the outcome of the first flip, described by X, and vice versa.\nWe postulate that it is equally likely to obtain any of the four outcomes, such that the joint\nprobability mass function is given by\nfX,Y (x, y) = ,\n(x, y) ∈{(0, 0), (0, 1), (1, 0), (1, 1)} .\nWe now show that this assumption implies independence, as we would intuitively expect. In\nparticular, the marginal probability density of X is\nfX (x) = ,\nx ∈{0, 1} ,\nsince (say) P (X = 0) = P ((X, Y ) = (0, 0)) + P ((X, Y ) = (0, 1)) = 1/2. Similarly, the marginal\nprobability density of Y is\nfY (y) = ,\ny ∈{0, 1} .\nWe now note that\nfX,Y (x, y) = fX (x) · fY (y) = ,\n(x, y) ∈{(0, 0), (0, 1), (1, 0), (1, 1)} ,\nwhich is the definition of independence.\nThe probability mass function of (X, Y ) and the marginal density of X and Y are shown in\nFigure 9.7. The figure clearly shows that the joint density of (X, Y ) is the product of the marginal\ndensity of X and Y . Let us show that this agrees with our intuition, in particular by considering\nthe probability of (X, Y ) = (0, 0). First, the relative frequency that X takes on 0 is 1/2. Second, of\nthe events in which X = 0, 1/2 of these take on Y = 0. Note that this probability is independent\nof the value that X takes. Thus, the relative frequency of X taking on 0 and Y taking on 0 is 1/2\nof 1/2, which is equal to 1/4.\n\n(\n(\nx\ny\n1/2\n1/2\nFigure 9.8: The probability mass function for flipping two independent coins.\nWe can also consider conditional probability of an event that X takes on 1 given that Y takes\non 0. The conditional probability is\nfX,Y (x = 1, y = 0)\n1/4\nfX|Y (x = 1|y = 0) =\n=\n=\n.\nfY (y = 0)\n1/2\nThis probability is equal to the marginal probability of fX (x = 1). This agrees with our intuition;\ngiven that two events are independent, we gain no additional information about the outcome of X\nfrom knowing the outcome of Y .\n·\nExample 9.2.4 non-independent events: two random variables associated with a single\ncoin flip\nLet us now consider flipping a single coin. We associate a Bernoulli random variables X and Y\nwith\nX =\n1,\nhead\nand Y =\n1,\ntail\n.\n0,\ntail\n0,\nhead\nNote that a head results in (X, Y ) = (1, 0), whereas a tail results in (X, Y ) = (0, 1). Intuitively,\nthe random variables are not independent, because the outcome of X completely determines Y , i.e.\nX + Y = 1.\nLet us show that these two variables are not independent. We are equally like to get a head,\n(1, 0), or a tail, (0, 1). We cannot produce (0, 0), because the coin cannot be head and tail at the\nsame time. Similarly, (1, 1) has probably of zero. Thus, the joint probability density function is\n⎧\n⎪\n⎨,\n(x, y) = (0, 1)\n,\n(x, y) = (1, 0)\nfX,Y (x, y) = ⎪\n⎩ 0,\n(x, y) = (0, 0) or (x, y) = (1, 1) .\nThe probability mass function is illustrated in Figure 9.8.\nThe marginal density of each of the event is the same as before, i.e. X is equally likely to take\non 0 or 1, and Y is equally like to take on 0 or 1. Thus, we have\nfX (x) = ,\nx ∈{0, 1}\nfY (y) = ,\ny ∈{0, 1} .\n(\n(\n\nFor (x, y) = (0, 0), we have\nfX,Y (x, y) = 0\n= fX (x) · fY (y) .\n= 4\nSo, X and Y are not independent.\nWe can also consider conditional probabilities. The conditional probability of x = 1 given that\ny = 0 is\nfX,Y (x = 1, y = 0)\n1/2\nfX|Y (x = 1|y = 0) =\n=\n= 1 .\nfY (y = 0)\n1/2\nIn words, given that we know Y takes on 0, we know that X takes on 1. On the other hand, the\nconditional probability of x = 1 given that y = 1 is\nfX,Y (x = 0, y = 0)\nfX|Y (x = 0|y = 0) =\n=\n= 0 .\nfY (y = 0)\n1/2\nIn words, given that Y takes on 1, there is no way that X takes on 1. Unlike the previous example\nthat associated (X, Y ) with two independent coin flips, we know with certainty the outcome of X\ngiven the outcome of Y , and vice versa.\n·\nWe have seen that independence is one way of describing the relationship between two events.\nIndependence is a binary idea; either two events are independent or not independent. Another\nconcept that describes how closely two events are related is correlation, which is a normalized\ncovariance. The covariance of two random variables X and Y is denoted by Cov(X, Y ) and defined\nas\nCov(X, Y ) ≡ E[(X - μX )(Y - μY )] .\nThe correlation of X and Y is denoted by ρXY and is defined as\nCov(X, Y )\nρXY =\n,\nσX σY\nwhere we recall that σX and σY are the standard deviation of X and Y , respectively. The correlation\nindicates how strongly two random events are related and takes on a value between -1 and 1. In\nparticular, two perfectly correlated events take on 1 (or -1), and two independent events take on\n0.\nTwo independent events have zero correlation because\nJY\nJX\nJ J\nCov(X, Y ) = E[(X - μX )(Y - μY )] =\n(xi - μX )(yj - μY )fX,Y (xi, yj )\nj=1 i=1\nJY\nJX\nJ J\n=\n(xi - μX )(yj - μY )fX (xi)fY (yj )\nj=1 i=1\n⎡\n⎤⎡\n⎤\nJY\nJX\nJ\nJ\n= ⎣\n(yj - μY )fY (yj )⎦ · ⎣\n(xi - μX )fX (xi)⎦\nj=1\ni=1\n= E[Y - μY ] · E[X - μX ] = 0 · 0 = 0 .\nThe third inequality follows from the definition of independence, fX,Y (xi, yj ) = fX (xi)fY (yj ).\nThus, if random variables are independent, then they are uncorrelated. However, the converse is\nnot true in general.\n\n9.3\nBinomial Distribution\nIn the previous section, we saw random vectors consisting of two random variables, X and Y . Let\nus generalize the concept and introduce a random vector consisting of n components\n(X1, X2, . . . , Xn) ,\nwhere each Xi is a random variable. In particular, we are interested in the case where each Xi is\na Bernoulli random variable with the probability of success of θ. Moreover, we assume that Xi,\ni = 1, . . . , n, are independent. Because the random variables are independent and each variable has\nthe same distribution, they are said to be independent and identically distributed or i.i.d. for short.\nIn other words, if a set of random variables X1, . . . , Xn is i.i.d., then\nfX1,X2,...,Xn (x1, x2, . . . , xn) = fX (x1) · fX (x2) · · · fX (xn) ,\nwhere fX is the common probability density for X1, . . . , Xn. This concept plays an important\nrole in statistical inference and allows us to, for example, make a probabilistic statement about\nbehaviors of random experiments based on observations.\nNow let us transform the i.i.d. random vector (X1, . . . , Xn) of Bernoulli random variables to a\nrandom variable Z by summing its components, i.e.\nn\nJ\nZn =\nXi .\ni=1\n(More precisely we should write Zn,θ since Z depends on both n and θ.) Note Zn is a function of\n(X1, X2, . . . , Xn), and in fact a simple function -- the sum. Because Xi, i = 1, . . . , n, are random\nvariables, their sum is also a random variable. In fact, this sum of Bernoulli random variable\nis called a binomial random variable. It is denoted by Zn ∼B(n, θ) (shorthand for fZn,θ (z) =\nfbinomial(z; n, θ)), where n is the number of Bernoulli events and θ is the probability of success of\neach event. Let us consider a few examples of binomial distributions.\nExample 9.3.1 total number of heads in flipping two fair coins\nLet us first revisit the case of flipping two fair coins. The random vector considered in this case is\n(X1, X2) ,\nwhere X1 and X2 are independent Bernoulli random variables associated with the first and second\nflip, respectively. As in the previous coin flip cases, we associate 1 with heads and 0 with tails.\nThere are four possible outcome of these flips,\n(0, 0),\n(0, 1),\n(1, 0),\nand (1, 1) .\nFrom the two flips, we can construct the binomial distribution Z2 ∼B(2, θ = 1/2), corresponding to\nthe total number of heads that results from flipping two fair coins. The binomial random variable\nis defined as\nZ2 = X1 + X2 .\nCounting the number of heads associated with all possible outcomes of the coin flip, the binomial\nrandom variable takes on the following value:\nFirst flip\nSecond flip\nZ2\n\nBecause the coin flips are independent and each coin flip has the probability density of fXi (x) = 1/2,\nx = 0, 1, their joint distribution is\nfX1,X2 (x1, x2) = fX1 (x1) · fX2 (x2) =\n·\n= ,\n(x1, x2) ∈{(0, 0), (0, 1), (1, 0), (1, 1)} .\nIn words, each of the four possible events are equally likely. Of these four equally likely events,\nZ2 ∼B(2, 1/2) takes on the value of 0 in one event, 1 in two events, and 2 in one event. Thus, the\nbehavior of the binomial random variable Z2 can be concisely stated as\n⎧\n⎪\n⎨\n⎪\n⎩\n0,\nwith probability 1/4\nZ2 =\n1,\nwith probability 1/2 (= 2/4)\n2,\nwith probability 1/4 .\nNote this example is very similar to Example 9.1.4: Z2, the sum of X1 and X2, is our g(X); we\nassign probabilities by invoking the mutually exclusive property, OR (union), and summation. Note\nthat the mode, the value that Z2 is most likely to take, is 1 for this case. The probability mass\nfunction of Z2 is given by\n⎧\n⎪\n⎨\n⎪\n⎩\n1/4,\nx = 0\nfZ2 (x) =\n1/2,\nx = 1\n1/4,\nx = 2 .\n·\nExample 9.3.2 total number of heads in flipping three fair coins\nLet us know extend the previous example to the case of flipping a fair coin three times. In this\ncase, the random vector considered has three components,\n(X1, X2, X3) ,\nwith each X1 being a Bernoulli random variable with the probability of success of 1/2. From the\nthree flips, we can construct the binomial distribution Z3 ∼B(3, 1/2) with\nZ3 = X1 + X2 + X3 .\nThe all possible outcomes of the random vector and the associated outcomes of the binomial\ndistribution are:\nFirst flip\nSecond flip\nThird flip\nZ3\nBecause the Bernoulli random variables are independent, their joint distribution is\nfX1,X2,X3 (x1, x2, x3) = fX1 (x1) · fX2 (x2) · fX3 (x3) =\n·\n·\n=\n.\nIn other words, each of the eight events is equally likely. Of the eight equally likely events, Z3 takes\non the value of 0 in one event, 1 in three events, 2 in three events, and 3 in one event. The behavior\n\nof the binomial variable Z3 is summarized by\n0,\nwith probability 1/8\n1,\nwith probability 3/8\n2,\nwith probability 3/8\n3,\nwith probability 1/8 .\nZ3 =\n⎧\n⎪\n⎨\n⎪\n⎪\n⎩\nThe probability mass function (for θ = 1/2) is thus given by\nfZ3 (x) =\n⎧\n⎪\n⎪\n⎨\n⎪\n⎪\n⎩\n1/8,\nx = 0\n3/8,\nx = 1\n3/8,\nx = 2\n1/8,\nx = 3 .\n·\nExample 9.3.3 total number of heads in flipping four fair coins\nWe can repeat the procedure for four flips of fair coins (n = 4 and θ = 1/2). In this case, we\nconsider the sum of the entries of a random vector consisting of four Bernoulli random variables,\n(X1, X2, X3, X4). The behavior of Z4 = B(4, 1/2) is summarized by\n⎧\n⎪\n⎪\n⎪\n⎨\n⎪\n⎪\n⎩\n0,\nwith probability 1/16\n1,\nwith probability 1/4\nZ4 =\n2,\nwith probability 3/8\n3,\nwith probability 1/4\n4,\nwith probability 1/16 .\nNote that Z4 is much more likely to take on the value of 2 than 0, because there are many equally-\nlikely events that leads to Z4 = 2, whereas there is only one event that leads to Z4 = 0. In general,\nas the number of flips increase, the deviation of Zn ∼B(n, θ) from nθ becomes increasingly unlikely.\n·\nFigure 9.9 illustrates the values taken by binomial random variables for n = 2 and n = 4, both\nwith θ = 1/2. The histogram confirms that the distribution is more likely to take on the values\nnear the mean because there are more sequences of the coin flips that realizes these values. We\nalso note that the values become more concentrated near the mean, nθ, relative to the range of the\nvalues it can take, [0, n], as n increases. This is reflected in the decrease in the standard deviation\nrelative to the width of the range of the values Zn can take.\nIn general, a binomial random variable Zn ∼B(n, θ) behaves as\n\nn\nZn = k,\nwith probability\nθk(1 - θ)n-k ,\nk\n\nn\nwhere k = 1, . . . , n. Recall that\nis the binomial coefficient, read \"n choose k: the number\nk\nof ways of picking k unordered outcomes from n possibilities. The value can be evaluated as\n\nn\nk\n\n≡\nn!\n(n - k)!k! ,\n(9.4)\n\nrealizations\nx\n\nx\nμ\nμ ± σ\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nfX(x)\nx\n\npmf\nfrequency\n(a) realization, n = 2, θ = 1/2\n(b) pmf, n = 2, θ = 1/2\nrealizations\nx\n\nx\nμ\nμ ± σ\n0.1\n0.2\n0.3\n0.4\n0.5\nfX(x)\nx\n\npmf\nfrequency\n(c) realization, n = 4, θ = 1/2\n(d) pmf, n = 4, θ = 1/2\nFigure 9.9: Illustration of the values taken by binomial random variables.\n\nwhere ! denotes the factorial.\nWe can readily derive the formula for B(n, θ). We think of n tosses as a binary number with n\nbits, and we ask how many ways k ones can appear. We can place the first one in n different places,\nthe second one in n - 1 different places, . . . , which yields n!/(n - k)! possibilities. But since we are\njust counting the number of ones, the order of appearance does not matter, and we must divide\nn!/(n - k)! by the number of different orders in which we can construct the same pattern of k ones\n-- the first one can appear in k places, the second one in k - 1 places, . . . , which yields k!. Thus\nthere are \"n choose k\" ways to obtain k ones in a binary number of length n, or equivalently \"n\nchoose k\" different binary numbers with k ones. Next, by independence, each pattern of k ones (and\nhence n - k zeros) has probability θk(1 - θ)n-k . Finally, by the mutually exclusive property, the\nprobability that Zn = k is simply the number of patterns with k ones multiplied by the probability\nthat each such pattern occurs (note the probability is the same for each such pattern).\nThe mean and variance of a binomial distribution is given by\nE[Zn] = nθ and Var[Zn] = nθ(1 - θ) .\nProof. The proof for the mean follows from the linearity of expectation, i.e.\nn\n⎤\nJ\n⎡\nJ\nJ\nn\nn\ni=1\ni=1\ni=1\nNote we can readily prove that the expectation of the sum is the sum of the expectations. We\nconsider the n-dimensional sum over the joint mass function of the Xi weighted -- per the definition\nof expectation -- by the sum of the Xi, i = 1, . . . , n. Then, for any given Xi, we factorize the joint\nmass function: n - 1 of the sums then return unity, while the last sum gives the expectation of Xi.\nThe proof for variance relies on the pairwise independence of the random variables\n⎣\n⎦ =\nE[Zn] = E\nXi\nE[Xi] =\nθ = nθ .\n⎤\nJ\n⎡\nn\n⎧\n⎪\n⎨\n⎫\n⎪\n⎬\n⎤\nJ\n⎡\nn\n⎧\n⎨\n⎫\n⎬\n⎞\n⎛\n⎢⎢⎣\n⎥⎥⎦\n⎢⎣\n⎥⎦\nVar[Zn] = E[(Zn - E[Zn])2] = E\n⎝\n⎪\n⎩\nXi⎠ - nθ\n(Xi - θ)\n= E\n⎪\n⎭\n⎩\n⎭\ni=1\ni=1\n⎤\nJ\nJ\nJ\n⎡\nn\nn\nn\n⎢⎢⎢⎣\n⎥⎥⎥⎦\n(Xi - θ)2 +\n(Xi - θ)(Xj - θ)\n= E\ni=1\ni=1 j=1\nj=i\nH\nE[(Xi - θ)2] +\nJ\nJ\nJ\nn\nn\nn\ni=1\ni=1 j=1\nj=i\nH\n\nE[(Xi - θ)(Xj - θ)]\n=\nJ\nJ\nn\nn\n=\nVar[Xi] =\nθ(1 - θ) = nθ(1 - θ) .\ni=1\ni=1\nThe cross terms cancel because coin flips are independent.\n√\nNote that the variance scales with n, or, equivalently, the standard deviation scales with\nn. This\nturns out to be the key to Monte Carlo methods -- numerical methods based on random variables\n-- which is the focus of the later chapters of this unit.\n\nLet us get some insight to how the general formula works by applying it to the binomial\ndistribution associated with flipping coins three times.\nExample 9.3.4 applying the general formula to coin flips\nLet us revisit Z3 = B(3, 1/2) associated with the number of heads in flipping three coins. The\nprobability that Z3 = 0 is, by substituting n = 3, k = 0, and θ = 1/2,\n3-0\nn\n3!\nfZ3 (0) =\nθk(1 - θ)n-k =\n1 -\n=\n=\n,\nk\n0!(3 - 0)!\nwhich is consistent with the probability we obtained previously. Let us consider another case: the\nprobability of Z3 = 2 is\n3-2\nn\n3!\nfZ3 (2) =\nθk(1 - θ)n-k =\n1 -\n=\n=\n.\nk\n2!(3 - 2)!\nNote that the θk(1 - θ)n-k is the probability that the random vector of Bernoulli variables\n(X1, X2, . . . , Xn) ,\nrealizes X1 = X2 = . . . = Xk = 1 and Xk+1 = . . . = Xn = 0, and hence Zn = k. Then, we multiply\nthe probability with the number of different ways that we can realize the sum Zn = k, which is\nequal to the number of different way of rearranging the random vector. Here, we are using the\nfact that the random variables are identically distributed. In the special case of (fair) coin flips,\nθk(1 - θ)n-k = (1/2)k(1 - 1/2)n-k = (1/2)n, because each random vector is equally likely.\n·\n9.4\nContinuous Random Variables\n9.4.1\nProbability Density Function; Cumulative Distribution Function\nLet X be a random variable that takes on any real value in (say) an interval,\nX ∈ [a, b] .\nThe probability density function (pdf) is a function over [a, b], fX (x), such that\nfX (x) ≥ 0,\n∀x ∈ [a, b] ,\nb\nfX (x) dx = 1 .\na\nNote that the condition that the probability mass function sums to unity is replaced by an integral\ncondition for the continuous variable. The probability that X take on a value over an infinitesimal\ninterval of length dx is\nP (x ≤ X ≤ x + dx) = fX (x) dx ,\nor, over a finite subinterval [a/, b/] ⊂ [a, b],\nb'\nP (a/ ≤ X ≤ b/) =\nfX (x) dx .\n'\na\n\n!\n\n!\n\n!\n\n!\n\nZ\nZ\n\nIn other words, the probability that X takes on the value between a/ and b/ is the integral of the\nprobability density function fX over [a/, b/].\nA particular instance of this is a cumulative distribution function (cdf), FX (x), which describes\nthe probability that X will take on a value less than x, i.e.\nx\nFX (x) =\nfX (x) dx .\na\n(We can also replace a with -inf if we define fX (x) = 0 for -inf < x < a.) Note that any cdf\nsatisfies the conditions\na\nb\nFX (a) =\nfX (x) dx = 0 and FX (b) =\nfX (x) dx = 1 .\na\na\nFurthermore, it easily follows from the definition that\nP (a/ ≤ X ≤ b/) = FX (b/) - FX (a/).\nThat is, we can compute the probability of X taking on a value in [a/, b/] by taking the difference\nof the cdf evaluated at the two end points.\nLet us introduce a few notions useful for characterizing a pdf, and thus the behavior of the\nrandom variable. The mean, μ, or the expected value, E[X], of the random variable X is\nb\nμ = E[X] =\nf(x) x dx .\na\nThe variance, Var(X), is a measure of the spread of the values that X takes about its mean and is\ndefined by\nb\nVar(X) = E[(X - μ)2] =\n(x - μ)2f(x) dx .\na\nThe variance can also be expressed as\nb\nVar(X) = E[(X - μ)2] =\n(x - μ)2f(x) dx\na\nb\nb\nb\n=\nx 2f(x) dx - 2μ\nxf(x) dx +μ\nf(x) dx\na\na\na\nμ\n= E[X2] - μ .\nThe α-th quantile of a random variable X is denoted by zα and satisfies\nFX ( zα) = α.\nIn other words, the quantile zα partitions the interval [a, b] such that the probability of X taking\non a value in [a, z α] is α (and conversely P ( zα ≤ X ≤ b) = 1 - α). The α = 1/2 quantile is the\nmedian.\nLet us consider a few examples of continuous random variables.\nZ\nZ\nZ\nZ\nZ\nZ\nZ\n{z\n}\nZ\nZ\n|\n\n-1\n-0.5\n0.5\n1.5\n2.5\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n\na=0.0, b=1.0\na=-0.5, b=2.0\n-1\n-0.5\n0.5\n1.5\n2.5\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n\na=0.0, b=1.0\na=-0.5, b=2.0\n(a) probability density function\n(b) cumulative density function\nFigure 9.10: Uniform distributions\nExample 9.4.1 Uniform distribution\nLet X be a uniform random variable. Then, X is characterized by a constant pdf,\nfX (x) = funiform(x; a, b) ≡\n.\nb - a\nNote that the pdf satisfies the constraint\nb\nb\nb\nfuniform(x; a, b) dx =\nfX (x) dx =\ndx = 1 .\nb - a\na\na\na\nFurthermore, the probability that the random variable takes on a value in the subinterval [a/, b/] ∈\n[a, b] is\nb '\nb '\nb '\nb/ - a/\nfuniform(x; a, b) dx =\nP (a/ ≤ X ≤ b/) =\nfX (x) dx =\ndx =\n.\n'\n'\n' b - a\nb - a\na\na\na\nIn other words, the probability that X ∈ [a/, b/] is proportional to the relative length of the interval\nas the density is equally distributed. The distribution is compactly denoted as U(a, b) and we\nwrite X ∼U(a, b). A straightforward integration of the pdf shows that the cumulative distribution\nfunction of X ∼U(a, b) is\nFX (x) = F uniform(x; a, b) ≡ x - a .\nb - a\nThe pdf and cdf for a few uniform distributions are shown in Figure 9.10.\nAn example of the values taken by a uniform random variable U(0, 1) is shown in Figure 9.11(a).\nBy construction, the range of values that the variable takes is limited to between a = 0 and b = 1.\nAs expected, there is no obvious concentration of the values within the range [a, b]. Figure 9.11(b)\nshows a histrogram that summarizes the frequency of the event that X resides in bins [xi, xi + δx],\ni = 1, . . . , nbin. The relative frequency of occurrence is normalized by δx to be consistent with\nthe definition of the probability density function. In particular, the integral of the region filled\nby the histogram is unity. While there is some spread in the frequencies of occurrences due to\nZ\nZ\nZ\nZ\nZ\nZ\n\n\"\n#\n-0.2\n0.2\n0.4\n0.6\n0.8\nrealizations\nx\n\nx\nμ\nμ ± σ\n0.5\n1.5\n-0.2\n0.2\n0.4\n0.6\n0.8\nfX(x)\nx\n\npdf\nfrequency\n(a) realization\n(b) probability density\nFigure 9.11: Illustration of the values taken by an uniform random variable (a = 0, b = 1).\nthe relatively small sample size, the histogram resembles the probability density function. This is\nconsistent with the frequentist interpretation of probability.\nThe mean of the uniform distribution is given by\nb\nb\nE[X] =\nxfX (x) dx =\nx\ndx =\n(a + b) .\nb - a\na\na\nThis agrees with our intuition, because if X is to take on a value between a and b with equal\nprobability, then the mean would be the midpoint of the interval. The variance of the uniform\ndistribution is\nb\nVar(X) = E[X2] - (E[X])2 =\nx 2fX (x) dx -\n1(a + b)\na\nb\n=\nx\ndx -\n1(a + b)\n= 1 (b - a)2 .\nb - a\na\n·\nExample 9.4.2 Normal distribution\nLet X be a normal random variable. Then the probability density function of X is of the form\nfX (x) = fnormal(x; μ, σ2) ≡\n(x - μ)2\n√\nexp -\n.\n2σ2\n2πσ\nThe pdf is parametrized by two variables, the mean μ and the variance σ2 . (More precisely we\nwould thus write Xμ,σ2 .) Note that the density is non-zero over the entire real axis and thus in\nprinciple X can take on any value. The normal distribution is concisely denoted by X ∼N (μ, σ2).\nThe cumulative distribution function of a normal distribution takes the form\nFX (x) = F normal(x; μ, σ2) ≡ 1\nx - μ\n1 + erf\n√\n,\n2σ\nZ\nZ\nZ\n\nZ\n\n!\n\n-10\n-5\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n\nμ=0.0, σ2=1.0\nμ=0.0, σ2=0.5\nμ=0.0, σ2=4.0\nμ=4.0, σ2=4.0\n-10\n-5\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n\nμ=0.0, σ2=1.0\nμ=0.0, σ2=0.5\nμ=0.0, σ2=4.0\nμ=4.0, σ2=4.0\n(a) probability density function\n(b) cumulative density function\nFigure 9.12: Normal distributions\nwhere erf is the error function, given by\nx\nerf(x) =\ne -z dz .\nπ\nWe note that it is customary to denote the cdf for the standard normal distribution (i.e. μ = 0,\nσ2 = 1) by Φ, i.e.\nΦ(x) = F normal(x; μ = 0, σ2 = 1).\nWe will see many use of this cdf in the subsequent sections. The pdf and cdf for a few normal\ndistributions are shown in Figure 9.12.\nAn example of the values taken by a normal random variable is shown in Figure 9.13. As\nalready noted, X can in principle take on any real value; however, in practice, as the Gaussian\nfunction decays quickly away from the mean, the probability of X taking on a value many standard\ndeviations away from the mean is small. Figure 9.13 clearly illustrates that the values taken by\nX is clustered near the mean. In particular, we can deduce from the cdf that X takes on values\nwithin σ, 2σ, and 3σ of the mean with probability 68.2%, 95.4%, and 99.7%, respectively. In other\nwords, the probability of X taking of the value outside of μ ± 3σ is given by\nμ+3σ\nfnormal(x; μ, σ2) dx ≡ 1 - (F normal(μ + 3σ; μ, σ2) - F normal(μ - 3σ; μ, σ2)) ≈ 0.003 .\n1 -\nμ-3σ\nWe can easily compute a few quantiles based on this information. For example,\nz 0.841 ≈ μ + σ,\nz 0.977 ≈ μ + 2σ,\nand z 0.9985 ≈ μ + 3σ.\nIt is worth mentioning that z0.975 ≈ μ + 1.96σ, as we will frequently use this constant in the\nsubsequent sections.\n·\nAlthough we only consider either discrete or continuous random variables in this notes, random\nvariables can be mixed discrete and continuous in general. Mixed discrete-continuous random\nvariables are characterized by the appearance of discontinuities in their cumulative distribution\nfunction.\nZ\nZ\n\n-4\n-3\n-2\n-1\nrealizations\nx\n\nx\nμ\nμ ± σ\n0.1\n0.2\n0.3\n0.4\n0.5\n-4\n-3\n-2\n-1\nfX(x)\nx\n\npdf\nfrequency\n(a) realization\n(b) probability density\nFigure 9.13: Illustration of the values taken by a normal random variable (μ = 0, σ = 1).\n9.4.2\nTransformations of Continuous Random Variables\nJust like discrete random variables, continuous random variables can be transformed by a function.\nThe transformation of a random variable X by a function g produces another random variable, Y ,\nand we denote this by\nY = g(X) .\nWe shall consider here only monotonic functions g.\nRecall that we have described the random variable X by distribution\nP (x ≤ X ≤ x + dx) = fX (x) dx .\nThe transformed variable follows\nP (y ≤ Y ≤ y + dy) = fY (y) dy .\nSubstitution of y = g(x) and dy = g/(x)dx and noting g(x) + g/(x)dx = g(x + dx) results in\nfY (y) dy = P (g(x) ≤ g(X) ≤ g(x) + g/(x) dx) = P (g(x) ≤ g(X) ≤ g(x + dx))\n= P (x ≤ X ≤ x + dx) = fX (x) dx .\nIn other words, fY (y)dy = fX (x) dx. This is the continuous analog to fY (yj ) = pj = fX (xj ) in the\ndiscrete case.\nWe can manipulate the expression to obtain an explicit expression for fY in terms of fX and g.\nFirst we note (from monotonicity) that\ndg-1\ny = g(x)\n⇒\nx = g -1(y) and dx =\ndy .\ndy\nSubstitution of the expressions in fY (y)dy = fX (x) dx yields\ndg-1\nfY (y) dy = fX (x) dx = fX (g -1(y)) ·\ndy\ndy\n\n(\n\n(\nor,\ndg-1\nfY (y) = fX (g -1(y)) ·\n.\ndy\nConversely, we can also obtain an explicit expression for fX in terms of fY and g. From y = g(x)\nand dy = g/(x) dx, we obtain\nfX (x) dx = fY (y) dy = fY (g(x)) · g/(x) dx\n⇒\nfX (x) = fY (g(x)) · g/(x) .\nWe shall consider several applications below.\nAssuming X takes on a value between a and b, and Y takes on a value between c and d, the\nmean of Y is\nd\nb\nE[Y ] =\nyfY (y) dy =\ng(x)fX (x) dx ,\nc\na\nwhere the second equality follows from fY (y) dy = fX (x) dx and y = g(x).\nExample 9.4.3 Standard uniform distribution to a general uniform distribution\nAs the first example, let us consider the standard uniform distribution U ∼U(0, 1). We wish to\ngenerate a general uniform distribution X ∼U(a, b) defined on the interval [a, b]. Because a uniform\ndistribution is uniquely determined by the two end points, we simply need to map the end point 0\nto a and the point 1 to b. This is accomplished by the transformation\ng(u) = a + (b - a)u .\nThus, X ∼U(a, b) is obtained by mapping U ∼U(0, 1) as\nX = a + (b - a)U .\nProof. Proof follows directly from the transformation of the probability density function. The\nprobability density function of U is\n1,\nu ∈ [0, 1]\nfU (u) =\n.\n0,\notherwise\nThe inverse of the transformation x = g(u) = a + (b - a)u is\nx - a\ng -1(x) =\n.\nb - a\nFrom the transformation of the probability density function, fX is\ndg-1\nx - a\nfX (x) = fU (g -1(x)) ·\n= fU\n·\n.\ndx\nb - a\nb - a\nWe note that fU evaluates to 1 if\nx - a\n0 ≤\n≤ 1\n⇒\na ≤ x ≤ b ,\nb - a\nand fU evaluates to 0 otherwise. Thus, fX simplifies to\nb-a ,\nx ∈ [a, b]\nfX (x) =\n0,\notherwise ,\nwhich is precisely the probability density function of U(a, b).\nZ\nZ\n(\n\n(\n\n·\nExample 9.4.4 Standard uniform distribution to a discrete distribution\nThe uniform distribution can also be mapped to a discrete random variable. Consider a discrete\nrandom variable Y takes on three values (J = 3), with\ny1 = 0,\ny2 = 2,\nand y3 = 3\nwith probability\nfY (y) =\n⎧\n⎪\n⎪\n⎨\n⎪\n⎪\n⎩\n1/2,\ny1 = 0\n1/4,\ny2 = 2\n.\n1/4,\ny3 = 3\nTo generate Y , we can consider a discontinuous function g. To get the desired discrete probability\ndistribution, we subdivide the interval [0, 1] into three subintervals of appropriate lengths. In\nparticular, to generate Y , we consider\n⎧\n⎪\n⎨\n⎪\n⎩\n0,\nx ∈ [0, 1/2)\ng(x) =\n2,\nx ∈ [1/2, 3/4)\n.\n3,\nx ∈ [3/4, 1]\nIf we consider Y = g(U), we have\n⎧\n⎪\n⎨\n⎪\n⎩\n0,\nU ∈ [0, 1/2)\nY =\n2,\nU ∈ [1/2, 3/4)\n.\n3,\nU ∈ [3/4, 1]\nBecause the probability that the standard uniform random variable takes on a value within a\nsubinterval [a/, b/] is equal to\nb/ - a/\n/\nP (a/ ≤ U ≤ b/) =\n= b/ - a ,\n1 - 0\nthe probability that Y takes on 0 is 1/2-0 = 1/2, on 2 is 3/4-1/2 = 1/4, and on 3 is 1-3/4 = 1/4.\nThis gives the desired probability distribution of Y .\n·\nExample 9.4.5 Standard normal distribution to a general normal distribution\nSuppose we have the standard normal distribution Z ∼N (0, 1) and wish to map it to a general\nnormal distribution X ∼N (μ, σ2) with the mean μ and the variance σ. The transformation is\ngiven by\nX = μ + σZ .\nConversely, we can map any normal distribution to the standard normal distribution by\nX - μ\nZ =\n.\nσ\n\nProof. The probability density function of the standard normal distribution Z ∼N (0, 1) is\nz\nfZ (z) = √\nexp -\n.\n2π\nUsing the transformation of the probability density and the inverse mapping, z(x) = (x - μ)/σ, we\nobtain\ndz\nx - μ\nfX (x) = fZ (z(x))\n= fZ\n·\n.\ndx\nσ\nσ\nSubstitution of the probability density function fZ yields\nx - μ\n(x - μ)2\nfX (x) = √\nexp -\n·\n= √\nexp -\n,\n2π\nσ\nσ\n2πσ\n2σ2\nwhich is exactly the probability density function of N (μ, σ2).\n·\nExample 9.4.6 General transformation by inverse cdf, F -1\nIn general, if U ∼U(0, 1) and FZ is the cumulative distribution function from which we wish to\ndraw a random variable Z, then\nZ = F -1(U)\nZ\nhas the desired cumulative distribution function, FZ .\nProof. The proof is straightforward from the definition of the cumulative distribution function, i.e.\nP (Z ≤ z) = P (F -1(U) ≤ z) = P (U ≤ FZ (z)) = FZ (z).\nZ\nHere we require that FZ is monotonically increasing in order to be invertible.\n·\n9.4.3\nThe Central Limit Theorem\nThe ubiquitousness of the normal distribution stems from the central limit theorem. (The normal\ndensity is also very convenient, with intuitive location (μ) and scale (σ2) parameters.) The central\nlimits theorem states that the sum of a sufficiently larger number of i.i.d. random variables tends\nto a normal distribution. In other words, if an experiment is repeated a larger number of times, the\noutcome on average approaches a normal distribution. Specifically, given i.i.d. random variables\nXi, i = 1, . . . , N, each with the mean E[Xi] = μ and variance Var[Xi] = σ2, their sum converges to\nN\nJ\nXi →N (μN, σ2N),\nas N →inf .\ni=1\n\n!\n\n!\n\n!\n\n(\n-4\n-3\n-2\n-1\n0.1\n0.2\n0.3\n0.4\n0.5\n\nN=1\nN=2\nN=3\nnormal\n-3\n-2\n-1\n0.1\n0.2\n0.3\n0.4\n0.5\n\nN=1\nN=2\nN=3\nnormal\n(a) Sum of uniform random variables\n(b) Sum of (shifted) Bernoulli random variables\nFigure 9.14: Illustration of the central limit theorem for continuous and discrete random variables.\n(There are a number of mathematical hypotheses which must be satisfied.)\nTo illustrate the theorem, let us consider the sum of uniform random variables Xi ∼U(-1/2, 1/2).\nThe mean and variance of the random variable are E[Xi] = 0 and Var[Xi] = 1/3, respectively. By\ncentral limit theorem, we expect their sum, ZN , to approach\nN\nJ\nZN ≡\nXi →N (μN, σ2N) = N (0, N/3) as N →inf .\ni=1\nThe pdf of the sum Zi, i = 1, 2, 3, and the normal distribution N (0, N/3)|N =3 = N (0, 1) are shown\nin Figure 9.14(a). Even though the original uniform distribution (N = 1) is far from normal and\nN = 3 is not a large number, the pdf for N = 3 can be closely approximated by the normal\ndistribution, confirming the central limit theorem in this particular case.\nThe theorem also applies to discrete random variable. For example, let us consider the sum of\n(shifted) Bernoulli random variables,\n-1/2,\nwith probability 1/2\nXi =\n.\n1/2,\nwith probability 1/2\nNote that the value that X takes is shifted by -1/2 compared to the standard Bernoulli random\nvariable, such that the variable has zero mean. The variance of the distribution is Var[Xi] = 1/4.\nAs this is a discrete distribution, their sum also takes on discrete values; however, Figure 9.14(b)\nshows that the probability mass function can be closely approximated by the pdf for the normal\ndistribution.\n9.4.4\nGeneration of Pseudo-Random Numbers\nTo generate a realization of a random variable X computationally, we can use a pseudo-random\nnumber generator. Pseudo-random number generators are algorithms that generate a sequence\nof numbers that appear to be random. However, the actual sequence generated is completely\ndetermined by a seed -- the variable that specifies the initial state of the generator. In other words,\n\ngiven a seed, the sequence of the numbers generated is completely deterministic and reproducible.\nThus, to generate a different sequence each time, a pseudo-random number generator is seeded\nwith a quantity that is not fixed; a common choice is to use the current machine time. However,\nthe deterministic nature of the pseudo-random number can be useful, for example, for debugging\na code.\nA typical computer language comes with a library that produces the standard continuous uni\nform distribution and the standard normal distribution. To generate other distributions, we can\napply the transformations we considered earlier. For example, suppose that we have a pseudo\nrandom number generator that generates the realization of U ∼U(0, 1),\nu1, u2, . . . .\nThen, we can generate a realization of a general uniform distribution X ∼U(a, b),\nx1, x2, . . . ,\nby using the transformation\nxi = a + (b - a)ui,\ni = 1, 2, . . . .\nSimilarly, we can generate given a realization of the standard normal distribution Z ∼N (0, 1),\nz1, z2, . . . , we can generate a realization of a general normal distribution X ∼N (μ, σ2), x1, x2, . . . ,\nby\nxi = μ + σzi,\ni = 1, 2, . . . .\nThese two transformations are perhaps the most common.\nFinally, if we wish to generate a discrete random number Y with the probability mass function\n⎧\n⎪\n⎪\n⎨\n⎪\n⎩\n1/2,\ny1 = 0\nfY (y) =\n1/4,\ny2 = 2\n,\n1/4,\ny3 = 3\nwe can map a realization of the standard continuous uniform distribution U ∼U(0, 1), u1, u2, . . . ,\naccording to\n⎧\n⎪\n⎨\n⎪\n⎩\n0,\nui ∈ [0, 1/2)\nyi =\n2,\nui ∈ [1/2, 3/4)\ni = 1, 2, . . . .\n3,\nui ∈ [3/4, 1]\n(Many programming languages directly support the uniform pmf.)\nMore generally, using the procedure described in Example 9.4.6, we can sample a random vari\nable Z with cumulative distribution function FZ by mapping realizations of the standard uniform\ndistribution, u1, u2, . . . according to\nzi = FZ\n-1(ui),\ni = 1, 2, . . . .\nWe note that there are other sampling techniques which are even more general (if not always\nefficient), such as \"acceptance-rejection\" approaches.\n\n9.5\nContinuous Random Vectors\nFollowing the template used to extend discrete random variables to discrete random vectors, we\nnow introduce the concept of continuous random vectors. Let X = (X1, X2) be a random variable\nwith\na1 ≤ X1 ≤ b1\na2 ≤ X2 ≤ b2 .\nThe probability density function (pdf) is now a function over the rectangle\nR ≡ [a1, b1] × [a2, b2]\nand is denoted by\nfX1,X2 (x1, x2) (or, more concisely, fX (x1, x2)) .\nThe pdf must satisfy the following conditions:\nfX (x1, x2) ≥ 0,\n∀ (x1, x2) ∈ R\nb1\nb2\nfX (x1, x2) = 1 .\na1\na2\nThe value of the pdf can be interpreted as a probability per unit area, in the sense that\nP (x1 ≤ X1 ≤ x1 + dx1, x2 ≤ X2 ≤ x2 + dx2) = fX (x1, x2) dx1 dx2 ,\nand\nP (X ∈ D) =\nfX (x1, x2) dx1 dx2 ,\nD\n\nwhere\nrefers to the integral over D ⊂ R (a subset of R).\nD\nLet us now revisit key concepts used to characterize discrete joint distributions in the continuous\nsetting. First, the marginal density function of X1 is given by\nb2\nfX1 (x1) =\nfX1,X2 (x1, x2) dx2 .\na2\nRecall that the marginal density of X1 describes the probability distribution of X1 disregarding the\nstate of X2. Similarly, the marginal density function of X2 is\nb1\nfX2 (x2) =\nfX1,X2 (x1, x2) dx1 .\na1\nAs in the discrete case, the marginal densities are also valid probability distributions.\nThe conditional probability density function of X1 given X2 is\nfX1,X2 (x1, x2)\nfX1|X2 (x1|x2) =\n.\nfX2 (x2)\nSimilar to the discrete case, the marginal and conditional probabilities are related by\nfX1,X2 (x1, x2) = fX1|X2 (x1|x2) · fX2 (x2) ,\nZ\nZ\nZZ\nZ\nZ\n\n\"\n# \"\n#\nor\nb2\nb2\nfX1 (x1) =\nfX1,X2 (x1, x2) dx2 =\nfX1|X2 (x1|x2) · fX2 (x2) dx2 .\na2\na2\nIn words, the marginal probability density function of X1 is equal to the integration of the condi\ntional probability density of fX1,X2 weighted by the probability density of X2.\nTwo continuous random variables are said to be independent if their joint probability density\nfunction satisfies\nfX1,X2 (x1, x2) = fX1 (x1) · fX2 (x2) .\nIn terms of conditional probability, the independence means that\nfX1,X2 (x1, x2)\nfX1 (x1) · fX2 (x2)\nfX1|X2 (x1, x2) =\n=\n= fX1 (x1) .\nfX2 (x2)\nfX2 (x2)\nIn words, knowing the outcome of X2 does not add any new knowledge about the probability\ndistribution of X1.\nThe covariance of X1 and X2 in the continuous case is defined as\nCov(X1, X2) = E[(X1 - μ1)(X2 - μ2)] ,\nand the correlation is given by\nCov(X1, X2)\nρX1X2 =\n.\nσX1 σX2\nRecall that the correlation takes on a value between -1 and 1 and indicates how strongly the\noutcome of two random events are related. In particular, if the random variables are independent,\nthen their correlation evaluates to zero. This is easily seen from\nb2\nb1\nCov(X1, X2) = E[(X1 - μ1)(X2 - μ2)] =\n(x1 - μ1)(x2 - μ2)fX1,X2 (x1, x2) dx1 dx2\na2\na1\nb2\nb1\n=\n(x1 - μ1)(x2 - μ2)fX1 (x1)fX2 (x2) dx1 dx2\na2\na1\nb2\nb1\n=\n(x2 - μ2)fX2 (x2) dx2 ·\n(x1 - μ1)fX1 (x1) dx1\na2\na1\n= 0 · 0 = 0 .\nNote the last step follows from the definition of the mean.\nExample 9.5.1 Bivariate uniform distribution\nA bivariate uniform distribution is defined by two sets of parameters [a1, b1] and [a2, b2] that specify\nthe range that X1 and X2 take on, respectively. The probability density function of (X1, X2) is\nfX1,X2 (x1, x2) =\n.\n(b1 - a1)(b2 - a2)\nNote here X1 and X2 are independent, so\nfX1,X2 (x1, x2) = fX1 (x1) · fX2 (x2) ,\nZ\nZ\nZ\nZ\nZ\nZ\n\"Z\n# \"Z\n#\n\n\"\n#\nwhere\nfX1 (x1) = b1 - a1\nand fX2 (x2) = b2 - a2\n.\nAs for the univariate case, we have\nAD\nP (X ∈ D) =\n,\nAR\nwhere AD is the area of some arbitrary region D and AR is the area of the rectangle. In words,\nthe probability that a uniform random vector -- a random \"dart\" lands in D -- is simply the ratio\nof AD to the total area of the dartboard (AR).1 This relationship -- together with our binomial\ndistribution -- will be the key ingredients for our Monte Carlo methods for area calculation.\nNote also that if AD is itself a rectangle aligned with the coordinate directions, AD ≡ c1 ≤\nx1 ≤ d1, c2 ≤ x2 ≤ d2, then P (X ∈ D) simplifies to the product of the length of D in x1, (d1 - c1),\ndivided by b1 - a1, and the length of D in x2, (d2 - c2), divided by b2 - a2. Independence is\nmanifested as a normalized product of lengths, or equivalently as the AND or intersection (not OR\nor union) of the two \"event\" rectangles c1 ≤ x1 ≤ d1, a2 ≤ x2 ≤ b2 and a1 ≤ x1 ≤ b1, c2 ≤ x2 ≤ d2.\nTo generate a realization of X = (X1, X2), we express the vector as a function of two independent\n(scalar) uniform distributions. Namely, let us consider U1 ∼U(0, 1) and U2 ∼U(0, 1). Then, we\ncan express the random vector as\nX1 = a1 + (b1 - a1)U1\nX2 = a2 + (b2 - a2)U2\nX = (X1, X2) .\nWe stress that U1 and U2 must be independent in order for X1 and X2 to be independent.\n·\nAdvanced Material\nExample 9.5.2 Bivariate normal distribution\nLet (X1, X2) be a bivariate normal random vector. The probability density function of (X1, X2) is\nof the form\n⎧\n⎨\n(x1, x2) = fbi-normal(x1, x2; μ1, μ2, σ1, σ2, ρ)\n(x1 - μ1)2\n(x2 - μ2)2\n2ρ(x1 - μ1)(x2 - μ2)\nfX1,X2\n⎫\n⎬\n≡\nexp\n-\n-\n+\n,\n2(1 - ρ2)\nσ2\nσ2\n⎩\n⎭\nσ1σ2\n2πσ1σ2\n1 - ρ2\nwhere (μ1, μ2) are the means, (σ1\n2, σ2\n2) are the variances, and ρ is the correlation. The pairs {μ1, σ1\n2}\nand {μ2, σ2\n2} describe the marginal distributions of X1 and X2, respectively. The correlation coef\nficient must satisfy\n-1 < ρ < 1\nand, if ρ = 0, then X1 and X2 are uncorrelated. For a joint normal distribution, uncorrelated\nimplies independence (this is not true for a general distribution).\n1 A bullseye (highest score) in darts is not difficult because it lies at the center, but rather because it occupies the\nleast area.\np\n\n\"\n#\n-10\n-5\n-5\n\nc=0.5\nc=1.0\nc=2.0\nrealizations\nFigure 9.15: A bivariate normal distribution with μ1 = μ2 = 0, σ1 = 3, σ2 = 2, and ρ = 1/2.\nThe probability density function for the bivariate normal distribution with μ1 = μ2 = 0,\nσ1 = 3, σ2 = 2, and ρ = 1/2 is shown in Figure 9.15. The lines shown are the lines of equal\ndensity. In particular, the solid line corresponds to the 1σ line, and the dashed lines are for σ/2\nand 2σ as indicated. 500 realizations of the distribution are also shown in red dots. For a bivariate\ndistribution, the chances are 11.8%, 39.4%, and 86.5% that (X1, X2) takes on the value within σ/2,\n1σ, and 2σ, respectively. The realizations shown confirm this trend, as only a small fraction of the\nred dots fall outside of the 2σ contour. This particular bivariate normal distribution has a weak\npositive correlation, i.e. given that X2 is greater than its mean μX2 , there is a higher probability\nthat X1 is also greater than its mean, μX1 .\nTo understand the behavior of bivariate normal distributions in more detail, let us consider\nthe marginal distributions of X1 and X2. The marginal distribution of X1 of a bivariate normal\ndistribution characterized by {μ1, μ2, σ1\n2, σ2\n2, ρ} is a univariate normal distribution with the mean\nμ1 and the variance σ1\n2, i.e.\ninf\n= fnormal(x1; μ1, σ1) .\nfX1 (x1) ≡\nfX1,X2 (x1, x2)dx2\nx2=-inf\nIn words, if we look at the samples of the binormal random variable (X1, X2) and focus on the\nbehavior of X1 only (i.e. disregard X2), then we will observe that X1 is normally distributed.\nSimilarly, the marginal density of X2 is\ninf\n= fnormal(x2; μ2, σ2) .\nfX2 (x2) ≡\nfX1,X2 (x1, x2)dx1\nx1=-inf\nThis rather surprising result is one of the properties of the binormal distribution, which in fact\nextends to higher-dimensional multivariate normal distributions.\nProof. For convenience, we will first rewrite the probability density function as\nfX1,X2 (x1, x2) =\nexp - q(x1, x2)\n2πσ1σ2\n1 - ρ2\nwhere the quadratic term is\n(x1 - μ1)2\n(x2 - μ2)2\n2ρ(x1 - μ1)(x2 - μ2)\nq(x1, x2) =\n+\n-\n.\n1 - ρ2\nσ2\nσ2\nσ1σ2\nZ\nZ\np\n\n\"\n#\n\n\"\n#\n\n\"\n\n#\n\nWe can manipulate the quadratic term to yield\n(x1 - μ1)2\nρ2(x1 - μ1)2\n(x2 - μ2)2\n2ρ(x1 - μ1)(x2 - μ2)\nq(x1, x2) =\n+\n+\n-\nσ2\n1 - ρ2\nσ2\nσ2\nσ1σ2\n(x1 - μ1)2\nρ(x1 - μ1)\nx2 - μ2\n=\n+\n-\nσ2\n1 - ρ2\nσ1\nσ2\n(x1 - μ1)2\nσ2\n=\n+\nx2 - μ2 + ρ\n(x1 - μ1)\n.\nσ2\nσ2(1 - ρ2)\nσ1\nSubstitution of the expression into the probability density function yields\nfX1,X2 (x1, x2) =\nexp - q(x1, x2)\n2πσ1σ2\n1 - ρ2\n1 (x1 - μ1)2\n= √\nexp -\nσ2\n2πσ1\n1 (x2 - (μ2 + ρ(σ2/σ1)(x1 - μ1)))2\n× √\nexp -\n2πσ2\n1 - ρ2\nσ2\n2(1 - ρ2)\n= fnormal(x1; μ1, σ1\n2) · fnormal\nσ2\nx2; μ2 + ρ\n(x1 - μ1), σ2\n2(1 - ρ2)\n.\nσ1\nNote that we have expressed the joint probability as the product of two univariate Gaussian func\ntions. We caution that this does not imply independence, because the mean of the second dis\ntribution is dependent on the value of x1. Applying the definition of marginal density of X1 and\nintegrating out the x2 term, we obtain\ninf\nfX1 (x1) =\nfX1,X2 (x1, x2)dx2\nx2=-inf\ninf\nfnormal(x1; μ1, σ1\n2) · fnormal\nσ2\n=\nx2; μ2 + ρ\n(x1 - μ1), σ2\n2(1 - ρ2) dx2\nx2=-inf\nσ1\ninf\n= fnormal(x1; μ1, σ2\nfnormal\nσ2\n1 ) ·\nx2; μ2 + ρ\n(x1 - μ1), σ2\n2(1 - ρ2) dx2\nx2=-inf\nσ1\n= fnormal(x1; μ1, σ2\n1 ) .\nThe integral of the second function evaluates to unity because it is a probability density function.\nThus, the marginal density of X1 is simply the univariate normal distribution with parameters μ1\nand σ1. The proof for the marginal density of X2 is identical due to the symmetry of the joint\nprobability density function.\nFigure 9.16 shows the marginal densities fX1 and fX2 along with the σ = 1- and σ = 2-contours\nof the joint probability density. The dots superimposed on the joint density are 500 realizations\nof (X1, X2). The histogram on the top summarizes the relative frequency of X1 taking on a value\nwithin the bins for the 500 realizations. Similarly, the histogram on the right summarizes relative\nfrequency of the values that X2 takes. The histograms closely matches the theoretical marginal\ndistributions for N (μ1, σ1\n2) and N (μ2, σ2\n2). In particular, we note that the marginal densities are\nindependent of the correlation coefficient ρ.\n\"\n#\n\n\"\n\n#\np\n\n!\n\n!\n\nZ\nZ\n\n0.05\n0.1\n0.15\nfX\n(x1)\n0.1\n0.2\nfX\n(x2)\n-10\n-5\n-10\n-5\nx1\nx2\n\n1σ\n2σ\nFigure 9.16: Illustration of marginal densities for a bivariate normal distribution (μ1 = μ2 = 0,\nσ1 = 3, σ2 = 2, ρ = 3/4).\nHaving studied the marginal densities of the bivariate normal distribution, let us now consider\nconditional probabilities. Combining the definition of conditional density and the expression for\nthe joint and marginal densities, we obtain\nfX1,X2 (x1, x2) = fnormal\nσ1\nfX1|X2 (x1|x2) =\nx1; μ1 + ρ\n(x2 - μ2), (1 - ρ2)σ1\nfX2 (x2)\nσ2\n1 (x1 - (μ1 + ρ(σ1/σ2)x2))2\n= √\nexp -\n.\nσ2\n2πσ1\n1 - ρ2\n1(1 - ρ2)\nSimilarly, the conditional density of X2 given X1 is\nfX1,X2 (x1, x2)\nσ2\n= fnormal\nfX2|X1 (x2, x1) =\nx2; μ2 + ρ\n(x1 - μ1), (1 - ρ2)σ2\n.\nfX1 (x1)\nσ1\nNote that unlike the marginal probabilities, the conditional probabilities are function of the cor\nrelation coefficient ρ. In particular, the standard deviation of the conditional distribution (i.e. its\nspread about its mean) decreases with |ρ| and vanishes as ρ →±1. In words, if the correlation is\nhigh, then we can deduce with a high probability the state of X1 given the value that X2 takes.\nWe also note that the positive correlation (ρ > 0) results in the mean of the conditional probability\nX1|X2 shifted in the direction of X2. That is, if X2 takes on a value higher than its mean, then it\nis more likely than not that X1 takes on a value higher than its mean.\nProof. Starting with the definition of conditional probability and substituting the joint and marginal\n\np\n\n!\n\n\"\n#\n\n\"\n#\n\"\n#\n\n\"\n\n#\n\n\"\n\n#\n\n⎫\n⎬\nprobability density functions,\nfX1,X2 (x1, x2)\nfX1|X2 (x1|x2) =\nfX2 (x2)\n⎧\n⎨\n(x1 - μ1)2\n(x2 - μ2)2\n2ρ(x1 - μ1)(x2 - μ2)\n-\n-\n+\n=\nexp\nσ2\nσ2\n2(1 - ρ2)\n⎩\nσ1σ2\n2πσ1σ2\n1 - ρ2\n√\n2πσ2\n1 (x2 - μ2)2\n×\nexp\nσ2\n= √\nexp - s(x1, x2)\n2πσ1\n1 - ρ2\nwhere\n(x1 - μ1)2\n(x2 - μ2)2\n2ρ(x1 - μ1)(x2 - μ2)\n(x2 - μ2)2\ns(x1, x2) =\n+\n-\n- (1 - ρ2)\n.\n1 - ρ2\nσ2\nσ2\nσ1σ2\nσ2\nRearrangement of the quadratic term s(x1, x2) yields\n(x1 - μ1)2\n2ρ(x1 - μ1)(x2 - μ2)\nρ2(x2 - μ2)2\ns(x1, x2) =\n-\n+\n1 - ρ2\nσ2\nσ2\nσ1σ2\nx1 - μ1\nρ(x2 - μ2)\n=\n-\n1 - ρ2\nσ1\nσ2\nσ1\n=\nx1 - μ1 + ρ\n(x2 - μ2)\n.\nσ2(1 - ρ2)\nσ2\nSubstitution of the quadratic term into the conditional probability density function yields\n⎧\n⎨\n⎫\n⎬\nσ1\nfX1|X2 (x1|x2) = √\n-\nx1 -\n(x2 - μ2)\nμ1 + ρ\nexp\n2 σ2(1 - ρ2)\n⎩\n⎭\nσ2\n2πσ1\n1 - ρ2\n= fnormal\nσ1\nx1; μ1 + ρσ2\n(x2 - μ2), (1 - ρ2)σ1\n,\nwhere the last equality follows from recognizing the univariate normal probability distribution\nfunction.\nFigure 9.17 shows the conditional densities fX1|X2 (x1|x2 = -2) and fX2|X1 (x2|x1 = 3) for a\nbivariate normal distribution (μ1 = μ2 = 0, σ1 = 3, σ2 = 2, ρ = 3/4). The histograms are\nconstructed by counting the relative frequency of occurrence for those realizations that falls near\nthe conditional value of x2 = -2 and x1 = 3, respectively. Clearly, the mean of the conditional\nprobability densities are shifted relative to the respective marginal densities. As ρ = 3/4 > 0 and\nx2 - μ2 = -2 < 0, the mean for X1|X2 is shifted in the negative direction. Conversely, ρ > 0\nand x1 - μ1 = 3 > 0 shifts the mean for X2|X1 in the positive direction. We also note that\nthe conditional probability densities are tighter than the respective marginal densities; due to the\nrelative strong correlation of ρ = 3/4, we have a better knowledge of the one state when we know\nthe value of the other state.\nFinally, to solidify the idea of correlation, let us consider the 1σ-contour for bivariate normal\ndistributions with several different values of ρ, shown in Figure 9.18. A stronger (positive) cor\nrelation implies that there is a high chance that a positive value of x2 implies a positive value of\n⎭\n\"\n#\n\n!\n\"\n#\n\"\n#\n\n\"\n\n#\np\n\"\n\n#\n\np\np\n\n0.1\n0.2\n0.3\n\nfX\n1|X\n2=-2\nfX\n0.2\n0.4\n\nfX\n2|X\n1=3\nfX\n-10\n-5\n-10\n-5\nx1\nx2\n\n1σ\n2σ\nFigure 9.17: Illustration of conditional densities fX1|X2 (x1|x2 = -2) and fX2|X1 (x2|x1 = 3) for a\nbivariate normal distribution (μ1 = μ2 = 0, σ1 = 3, σ2 = 2, ρ = 3/4).\nx1. Conversely, a strong negative correlation implies that there is a high chance a positive value\nof x2 implies a negative value of x1. Zero correlation -- which implies independence for normal\ndistributions -- means that we gain no additional information about the value that X1 takes on\nby knowing the value of X2; thus, the contour of equal probability density is not tilted.\n-4\n-3\n-2\n-1\n-3\n-2\n-1\n\nρ=0.0\nρ=0.5\nρ=0.98\nρ=-0.5\nFigure 9.18: Bivariate normal distributions with μ1 = μ2 = 0, σ1 = 3, σ2 = 2, and several values\nof ρ.\n·\n\nEnd Advanced Material\n\nChapter 10\nStatistical Estimation: Bernoulli\n(Coins)\n10.1\nIntroduction\nRecall that statistical estimation is a process through which we deduce parameters of the density\nthat characterize the behavior of a random experiment based on a sample -- a typically large but\nin any event finite number of observable outcomes of the random experiment. Specifically, a sample\nis a set of n independent and identically distributed (i.i.d.) random variables; we recall that a set\nof random variables\nX1, X2, . . . , Xn\nis i.i.d. if\nfX1,...,Xn (x1, . . . , xn) = fX (x1) · · · fX (xn),\nwhere fX is the common probability density for X1, . . . , Xn. We also define a statistic as a function\nof a sample which returns a random number that represents some attribute of the sample; a statistic\ncan also refer to the actual variable so calculated. Often a statistic serves to estimate a parameter.\nIn this chapter, we focus on statistical estimation of parameters associated with arguably the\nsimplest distribution: Bernoulli random variables.\n10.2\nThe Sample Mean: An Estimator / Estimate\nLet us illustrate the idea of sample mean in terms of a coin flip experiment, in which a coin is\nflipped n times. Unlike the previous cases, the coin may be unfair, i.e. the probability of heads,\nθ, may not be equal to 1/2. We assume that we do not know the value of θ, and we wish to\nestimate θ from data collected through n coin flips. In other words, this is a parameter estimation\nproblem, where the unknown parameter is θ. Although this chapter serves as a prerequisite for\nsubsequence chapters on Monte Carlo methods -- in which we apply probabilistic concepts to\ncalculates areas and more generally integrals -- in fact the current chapter focuses on how we\nDRAFT V1.2 (c) The Authors. License: Creative Commons BY-NC-SA 3.0.\n\nmight deduce physical parameters from noisy measurements. In short, statistics can be applied\neither to physical quantities treated as random variables or deterministic quantities which are re\ninterpreted as random (or pseudo-random).\nAs in the previous chapter, we associate the outcome of n flips with a random vector consisting\nof n i.i.d. Bernoulli random variables,\n(B1, B2, . . . , Bn) ,\nwhere each Bi takes on the value of 1 with probably of θ and 0 with probability of 1 - θ. The\nrandom variables are i.i.d. because the outcome of one flip is independent of another flip and we\nare using the same coin.\nWe define the sample mean of n coin flips as\nn\nJ\nBn ≡\nBi ,\nn i=1\nwhich is equal to the fraction of flips which are heads. Because Bn is a transformation (i.e. sum) of\nrandom variables, it is also a random variable. Intuitively, given a large number of flips, we \"expect\"\nthe fraction of flips which are heads -- the frequency of heads -- to approach the probability of a\nhead, θ, for n sufficiently large. For this reason, the sample mean is our estimator in the context of\nparameter estimation. Because the estimator estimates the parameter θ, we will denote it by Θe n,\nand it is given by\nn\nJ\neΘn = Bn =\nBi .\nn i=1\nNote that the sample mean is an example of a statistic -- a function of a sample returning a random\nvariable -- which, in this case, is intended to estimate the parameter θ.\nWe wish to estimate the parameter from a particular realization of coin flips (i.e. a realization\nof our random sample). For any particular realization, we calculate our estimate as\nn\nJ\nˆ\nˆ\nθn = bn ≡\nbi ,\nn i=1\nwhere bi is the particular outcome of the i-th flip. It is important to note that the bi, i = 1, . . . , n,\nare numbers, each taking the value of either 0 or 1. Thus, θˆn is a number and not a (random)\ndistribution. Let us summarize the distinctions:\nr.v.?\nDescription\nθ\nno\nParameter to be estimated that governs the behavior of underlying distribution\neΘn\nyes\nEstimator for the parameter θ\nˆθn\nno\nEstimate for the parameter θ obtained from a particular realization of our sample\nIn general, how the random variable e\nis distributed -- in particular about θ -- determines if\nΘn\nΘe n is a good estimator for the parameter θ. An example of convergence of θˆn to θ with n is shown\nin Figure 10.1. As n increases, θˆ converges to θ for essentially all realization of Bi's. This follows\nfrom the fact that Θe n is an unbiased estimator of θ -- an estimator whose expected value is equal\nto the true parameter. We shall prove this shortly.\nTo gain a better insight into the behavior of Θe n, we can construct the empirical distribution\nof Θe n by performing a large number of experiments for a given n. Let us denote the number of\n\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nn\nhat θn\n\nθ=0.5\nθ=0.75\nθ=0.02\nFigure 10.1: Convergence of estimate with n from a particular realization of coin flips.\n)exp 1 and\nexperiments by nexp. In the first experiment, we work with a realization (b1, b2, . . . , bn\nobtain the estimate by computing the mean, i.e.\nn\nJ\n)exp 1\nexp 1\n(bi)exp 1\nexp 1 : (b1, b2, . . . , bn\n⇒\nb\n=\n.\nn\nn i=1\nSimilarly, for the second experiment, we work with a new realization to obtain\nn\nJ\n)exp 2\nexp 2\n(bi)exp 2\nexp 2 : (b1, b2, . . . , bn\n⇒\nb\n=\n.\nn\nn i=1\nRepeating the procedure nexp times, we finally obtain\nn\nJ\nexp nexp\n)exp nexp\n(bi)exp nexp\nexp nexp : (b1, b2, . . . , bn\n⇒\nb\n=\n.\nn\nn i=1\nWe note that bn can take any value k/n, k = 0, . . . , n. We can compute the frequency of bn taking\non a certain value, i.e. the number of experiments that produces bn = k/n.\nThe numerical result of performing 10,000 experiments for n = 2, 10, 100, and 1000 flips are\nshown in Figure 10.2. The empirical distribution of Θe n shows that Θe n more frequently takes on the\nvalues close to the underlying parameter θ as the number of flips, n, increases. Thus, the numerical\nexperiment confirms that Θe n is indeed a good estimator of θ if n is sufficiently large.\nHaving seen that our estimate converges to the true parameter θ in practice, we will now\nanalyze the convergence behavior to the true parameter by relating the sample mean to a binomial\ndistribution. Recall, that the binomial distribution represents the number of heads obtained in\nflipping a coin n times, i.e. if Zn ∼B(n, θ), then\nn\nJ\nZn =\nBi ,\ni=1\nwhere Bi, i = 1, . . . , n, are the i.i.d. Bernoulli random variable representing the outcome of coin\nflips (each having the probability of head of θ). The binomial distribution and the sample mean\nare related by\nΘe n =\nZn .\nn\n\n-0.2\n0.2\n0.4\n0.6\n0.8\n1.2\nhat θ2\n0.2\n0.4\n0.6\n0.8\nhat θ10\n(a) n = 2\n(b) n = 10\n0.2\n0.4\n0.6\n0.8\nhat θ100\n0.2\n0.4\n0.6\n0.8\nhat θ1000\n(c) n = 100\n(d) n = 1000\nFigure 10.2: Empirical distribution of Θe n for n = 2, 10, 100, and 1000 and θ = 1/2 obtained from\n10,000 experiments.\n\n\"\n#\n\ns\ns\nThe mean (a deterministic parameter) of the sample mean (a random variable) is\nE[Θe n] = E\nZn =\nE[Zn] =\n(nθ) = θ .\nn\nn\nn\nIn other words, Θe n is an unbiased estimator of θ. The variance of the sample mean is\nVar[eΘn] = E[(eΘn - E[eΘn])2] = E\nn Zn - 1\nn E[Zn]\n= 1\nn2 E\n\n(Zn - E[Zn])2\n= 1\nn2 Var[Zn] = 1\nn2 nθ(1 - θ) = θ(1 - θ)\nn\n.\nThe standard deviation of eΘn is\nσˆΘn =\n\nVar[eΘn] =\nθ(1 - θ)\nn\n.\n√\ne\nThus, the standard deviation of Θn decreases with n, and in particular tends to zero as 1/\nn.\ne\ne\nThis implies that Θn → θ as n →inf because it is very unlikely that Θn will take on a value\nmany standard deviations away from the mean. In other words, the estimator converges to the true\nparameter with the number of flips.\n10.3\nConfidence Intervals\n10.3.1\nDefinition\nLet us now introduce the concept of confidence interval. The confidence interval is a probabilistic a\nposteriori error bound. A posteriori error bounds, as oppose to a priori error bounds, incorporate\nthe information gathered in the experiment in order to assess the error in the prediction.\nTo understand the behavior of the estimator Θe n, which is a random variable defined by\nn\nJ\nB1, . . . , Bn\n⇒\nΘe n = Bn =\nBi ,\nn i=1\nwe typically perform (in practice) a single experiment to generate a realization (b1, . . . , bn). Then,\nwe estimate the parameter by a number θˆn given by\nn\nJ\nˆ\nb1, . . . , bn\n⇒\nθn = bn =\nbi .\nn i=1\nA natural question: How good is the estimate θˆn? How can we quantify the small deviations of Θe n\nfrom θ as n increases?\nTo answer these questions, we may construct a confidence interval, [CI], defined by\n⎡\n⎤\ne\ne\n⎢\nΘn(1 - Θe n)\nΘn(1 - Θe n)⎥\ne\n[CI]n ≡ ⎣Θe n - zγ\n, Θn + zγ\n⎦\nn\nn\nsuch that\nP (θ ∈ [CI]n) = γ(zγ ) .\n\n\"\n]\n#\nr\n\ns\ns\nWe recall that θ is the true parameter; thus, γ is the confidence level that the true parameter\ne\nfalls within the confidence interval. Note that [CI]n is a random variable because Θn is a random\nvariable.\nFor a large enough n, a (oft-used) confidence level of γ = 0.95 results in zγ ≈ 1.96. In other\nwords, if we use zγ = 1.96 to construct our confidence interval, there is a 95% probability that the\ntrue parameter lies within the confidence interval. In general, as γ increases, zγ increases: if we\nwant to ensure that the parameter lies within a confidence interval at a higher level of confidence,\n√\nthen the width of the confidence interval must be increased for a given n. The appearance of 1/\nn\n√\nin the confidence interval is due to the appearance of the 1/\nn in the standard deviation of the\nestimator, σS : as n increases, there is less variation in the estimator.\nΘn\nStrictly speaking, the above result is only valid as n →inf (and θ /∈{0, 1}), which ensures that\nΘe n approaches the normal distribution by the central limit theorem. Then, under the normality\nassumption, we can calculate the value of the confidence-level-dependent multiplication factor zγ\naccording to\n\nzγ = z(1+γ)/2,\nwhere zα is the α quantile of the standard normal distribution, i.e. Φ( zα) = α where Φ is the\ncumulative distribution function of the standard normal distribution. For instance, as stated above,\nγ = 0.95 results in z0.95 = z 0.975 ≈ 1.96. A practical rule for determining the validity of the\nnormality assumption is to ensure that\nnθ > 5 and n(1 - θ) > 5.\nIn practice, the parameter θ appearing in the rule is replaced by its estimate, θˆ; i.e. we check\nˆ\nnθ > 5 and n(1 - θˆ) > 5.\n(10.1)\nIn particular, note that for θˆ = 0 or 1, we cannot construct our confidence interval. This is not\nsurprising, as, for θˆ = 0 or 1, our confidence interval would be of zero length, whereas clearly\nthere is some uncertainty in our prediction. In some sense, the criterion (10.1) ensures that our\nmeasurements contain some \"signal\" of the underlying parameter. We note that there are binomial\nconfidence intervals that do not require the normality assumption, but they are slightly more\ncomplicated and less intuitive.\n10.3.2\nFrequentist Interpretation\nTo get a better insight into the behavior of the confidence interval, let us provide an frequentist\ninterpretation of the interval. Let us perform nexp experiments and construct nexp realizations of\nconfidence intervals, i.e.\n⎡\n⎤\nj\nj\nj\nj\n⎢\nθˆn(1 - θˆn)\nθˆn(1 - θˆn)⎥\n[ci]j = ⎣θˆj - zγ\n, θˆj + zγ\n⎦ ,\nj = 1, . . . , nexp ,\nn\nn\nn\nn\nn\nwhere the realization of sample means is given by\nn\nJ\n)j\nθˆj\nj\n(b1, . . . , bn\n⇒\n=\nb .\ni\nn i=1\nThen, as nexp →inf, the fraction of experiments for which the true parameter θ lies inside [ci]n\nj\ntends to γ.\ns\ns\n\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\n0.55\n0.6\n0.65\n0.7\n0.75\nθ\nrealization\nout\nin\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n80% confidence\nfraction\n(a) 80% confidence\n(b) 80% confidence in/out\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\n0.55\n0.6\n0.65\n0.7\n0.75\nθ\nrealization\nout\nin\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n95% confidence\nfraction\n(c) 95% confidence\n(d) 95% confidence in/out\nFigure 10.3: An example of confidence intervals for estimating the mean of a Bernoulli random\nvariable (θ = 0.5) using 100 samples.\nAn example of confidence intervals for estimating the mean of Bernoulli random variable\n(θ = 0.5) using samples of size n = 100 is shown in Figure 10.3. In particular, we consider\nsets of 50 different realizations of our sample (i.e. 50 experiments, each with a sample of size 100)\nand construct 80% (zγ = 1.28) and 95% (zγ = 1.96) confidence intervals for each of the realizations.\nThe histograms shown in Figure 10.3(b) and 10.3(d) summarize the relative frequency of the true\nparameter falling in and out of the confidence intervals. We observe that 80% and 95% confidence\nintervals include the true parameter θ in 82% (9/51) and 94% (47/50) of the realizations, respec\ntively; the numbers are in good agreement with the frequentist interpretation of the confidence\nintervals. Note that, for the same number of samples n, the 95% confidence interval has a larger\nwidth, as it must ensure that the true parameter lies within the interval with a higher probability.\n\ns\ns\n10.3.3\nConvergence\nLet us now characterize the convergence of our prediction to the true parameter. First, we define\nthe half length of the confidence interval as\nθˆn(1 - θˆn)\nHalf Lengthθ;n ≡ zγ\n.\nn\nThen, we can define a relative error a relative error estimate in our prediction as\nRelErrθ;n = Half Lengthθ;n\nˆθ\n= zγ\n1 - ˆθn\nˆθnn\n.\n√\n√\nThe appearance of 1/\nn convergence of the relative error is due to the 1/\nn dependence in the\nstandard deviation σΘS n . Thus, the relative error converges in the sense that\nRelErrθ;n → 0 as n →inf .\nHowever, the convergence rate is slow\n-1/2\nRelErrθ;n ∼ n\n,\ni.e. the convergence rate if of order 1/2 as n →inf. Moreover, note that rare events (i.e. low θ) are\ndifficult to estimate accurately, as\nθ-1/2\nRelErrθ;n ∼ ˆ\n.\nn\nThis means that, if the number of experiments is fixed, the relative error in predicting an event\nthat occurs with 0.1% probability (θ = 0.001) is 10 times larger than that for an event that occurs\nwith 10% probability (θ = 0.1). Combined with the convergence rate of n-1/2, it takes 100 times\nas many experiments to achieve the similar level of relative error if the event is 100 times less likely.\nThus, predicting the probability of a rare event is costly.\n10.4\nCumulative Sample Means\nIn this subsection, we present a practical means of computing sample means. Let us denote the\ntotal number of coin flips by nmax, which defines the size of our sample. We assume nexp = 1, as is\nalmost always the case in practice. We create our sample of size nmax, and then for n = 1, . . . , nmax\nwe compute a sequence of cumulative sample means. That is, we start with a realization of nmax\ncoin tosses,\nb1, b2, . . . , bn, . . . , bnmax ,\ns\ns\n\ns\ns\ns\ns\ns\ns\ns\ns\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\nn\nθ\n\nestimate\n95% ci\ntrue\n-4\n-3\n-2\n-1\nn\nrelative error\n\n-0.50\nestimate\n95% ci\n(a) value\n(b) relative error\nFigure 10.4: Cumulative sample mean, confidence intervals, and their convergence for a Bernoulli\nrandom variable (θ = 0.5).\nand then compute the cumulative values,\n⎤\n⎡\n⎢ˆ\n⎣θ1 - zγ\nˆ\nˆ\nθ1(1 - θˆ1)\nˆ\nθ1(1 - θˆ1)\nθ1 + zγ\n⎥⎦\nˆθ1 = b1 =\n· b1\nand [ci]1 =\n,\n⎤\n⎡\nˆ\nˆ\nθ2(1 - θˆ2)\nˆ\nθ2(1 - θˆ2)\nθ2 + zγ\n⎢⎣ ˆθ2 - zγ\n⎥⎦\nˆθ2 = b2 =\n(b1 + b2) and [ci]2 =\n,\n. . .\n⎤\n⎡\nJ\nn\n= bn =\nbi\nand [ci]n\nˆ\nˆ\nθn(1 - θˆn)\nˆ\nθn(1 - θˆn)\nθn + zγ\n⎢⎣\nn\nn\nn\ni=1\n. . .\n⎥⎦\nˆθn\nˆθn - zγ\n=\n,\n⎤\n⎡\nJ\nnmax\n=\nand [ci]nmax\n= bnmax\nbi\nθˆnmax (1 - θˆnmax )\nˆ\nθˆnmax (1 - θˆnmax )\nθnmax\nˆθnmax\n⎣ˆθnmax - zγ\n+ zγ\n=\n,\n.\nn\nnmax\nnmax\ni=1\nNote that the random variables B1, . . . , Bnmax realized by b1, . . . , bnmax are not independent because\nthe sample means are computed from the same set of realizations; also, the random variable, [CI]n\nrealized by [ci]n are not joint with confidence γ. However in practice this is a computationally\nefficient way to estimate the parameter with typically only small loss in rigor. In particular, by\nplotting θˆn and [ci]n for n = 1, . . . , nmax, one can deduce the convergence behavior of the simulation.\nIn effect, we only perform one experiment, but we interpret it as nmax experiments.\nFigure 10.4 shows an example of computing the sample means and confidence intervals in a\ncumulative manner. The figure confirms that the estimate converges to the true parameter value\nof θ = 0.5. The confidence interval is a good indicator of the quality of the solution. The error\n(and the confidence interval) converges at the rate of n-1/2, which agrees with the theory.\n⎦\ns\ns\ns\ns\ns\ns\ns\ns\n\nChapter 11\nStatistical Estimation: the Normal\nDensity\nWe first review the \"statistical process.\" We typically begin with some population we wish to\ncharacterize; we then draw a sample from this population; we then inspect the data -- for example\nas a histogram -- and postulate an underlying probability density (here taking advantage of the\n\"frequency as probability\" perspective); we then estimate the parameters of the density from the\nsample; and finally we are prepared to make inferences about the population. It is critical to note\nthat in general we can \"draw\" from a population without knowing the underlying density; this in\nturn permits us to calibrate the postulated density.\nWe already observed one instance of this process with our coin flipping experiment. In this\ncase, the population is all possible \"behaviours\" or flips of our coin; our sample is a finite number,\nn, of coin flips; our underlying probability density is Bernoulli. We then estimate the Bernoulli\nparameter -- the probability of heads, θ -- through our sample mean and associated (normal\napproximation) confidence intervals. We are then prepared to make inferences: is the coin suitable\nto decide the opening moments of a football game? Note that in our experiments we effectively\nsample from a Bernoulli probability mass function with parameter θ but without knowing the value\nof θ.\nBernoulli estimation is very important, and occurs in everything from coin flips to area and\nintegral estimation (by Monte Carlo techniques as introduced in Chapter 12) to political and\nproduct preference polls. However, there are many other important probability mass functions\nand densities that arise often in the prediction or modeling of various natural and engineering\nphenomena. Perhaps premier among the densities is the normal, or Gaussian, density.\nWe have introduced the univariate normal density in Section 9.4. In this chapter, to avoid confu\nsion with typical variables in our next unit, regression, we shall denote our normal random variable\nas W = Wμ,σ ∼N (μ, σ2) corresponding to probability density function fW (w) = fnormal(w; μ, σ2).\nWe recall that the normal density is completely determined by the two parameters μ and σ which\nare in fact the mean and the standard deviation, respectively, of the normal density.\nThe normal density is ubiquitous for several reasons. First, more pragmatically, it has some\nrather intuitive characteristics: it is symmetric about the mean, it takes its maximum (the mode) at\nthe mean (which is also the median, by symmetry), and it is characterized by just two parameters\n-- a center (mean) and a spread (standard deviation). Second, and more profoundly, the normal\ndensity often arises \"due\" to the central limit theorem, described in Section 9.4.3. In short (in\nDRAFT V1.2 (c) The Authors. License: Creative Commons BY-NC-SA 3.0.\n\nfact, way too short), one form of the central limit theorem states that the average of many random\nperturbations -- perhaps described by different underlying probability densities -- approaches the\nnormal density. Since the behavior of many natural and engineered systems can be viewed as the\nconsequence of many random influences, the normal density is often encountered in practice.\nAs an intuitive example from biostatistics, we consider the height of US females (see L Winner\nnotes on Applied Statistics, University of Florida, http://www.stat.ufl.edu/~winner/statnotescomp/\nappstat.pdf Chapter 2, p 26). In this case our population is US females of ages 25-34. Our sam\nple might be the US Census data of 1992. The histogram appears quite normal-like, and we can\nthus postulate a normal density. We would next apply the estimation procedures described below\nto determine the mean and standard deviation (the two parameters associated with our \"chosen\"\ndensity). Finally, we can make inferences -- go beyond the sample to the population as whole --\nfor example related to US females in 2012.\nThe choice of population is important both in the sampling/estimation stage and of course\nalso in the inference stage. And the generation of appropriate samples can also be a very thorny\nissue. There is an immense literature on these topics which goes well beyond our scope and also,\nto a certain extent -- given our focus on engineered rather than social and biological systems --\nbeyond our immediate needs. As but one example, we would be remiss to apply the results from\na population of US females to different demographics such as \"females around the globe\" or \"US\nfemale jockeys\" or indeed \"all genders.\"\nWe should emphasize that the normal density is in almost all cases an approximation. For\nexample, very rarely can a quantity take on all values however small or large, and in particular\nquantities must often be positive. Nevertheless, the normal density can remain a good approxima\ntion; for example if μ - 3σ is positive, then negative values are effectively \"never seen.\" We should\nalso emphasize that there are many cases in which the normal density is not appropriate -- not\neven a good approximation. As always, the data must enter into the decision as to how to model\nthe phenomenon -- what probability density with what parameters will be most effective?\nAs an engineering example closer to home, we now turn to the Infra-Red Range Finder distance-\nvoltage data of Chapter 1 of Unit I. It can be motivated that in fact distance D and voltage V\nare inversely related, and hence it is plausible to assume that DV = C, where C is a constant\nassociated with our particular device. Of course, in actual practice, there will be measurement\nerror, and we might thus plausibly assume that\n(DV )meas = C + W\nwhere W is a normal random variable with density N (0, σ2). Note we assume that the noise is\ncentered about zero but of unknown variance. From the transformation property of Chapter 4,\nExample 9.4.5, we can further express our measurements as\n(DV )meas ∼N (C, σ2)\nsince if we add a constant to a zero-mean normal random variable we simply shift the mean. Note we\nnow have a classical statistical estimation problem: determine the mean C and standard deviation\nσ of a normal density. (Note we had largely ignored noise in Unit I, though in fact in interpolation\nand differentiation noise is often present and even dominant; in such cases we prefer to \"fit,\" as\ndescribed in more detail in Unit III.)\nIn terms of the statistical process, our population is all possible outputs of our IR Range Finder\ndevice, our sample will be a finite number of distance-voltage measurements, (DV )meas, 1 ≤ i ≤ n,\ni\nour estimation procedure is presented below, and finally our inference will be future predictions of\ndistance from voltage readings -- through our simple relation D = C/V . Of course, it will also be\nimportant to somehow justify or at least inspect our assumption that the noise is Gaussian.\n\nWe now present the standard and very simple estimation procedure for the normal density. We\npresent the method in terms of particular realization: the connection to probability (and random\nvariables) is through the frequentist interpretation. We presume that W is a normal random\nvariable with mean μ and standard deviation σ.\nfnormal(w; μ, σ2).\nWe first draw a sample of size n, wj , 1 ≤ j ≤ n, from fW (w) =\nWe then\ncalculate the sample mean as\nn\nwj ,\nn j=1\nJ\nwn =\nand the sample standard deviation as\n\nn\nn - 1 j=1\nJ\n(wj - wn)2\nsn =\n.\n(Of course, the wj , 1 ≤ j ≤ n, are realizations of random variables Wj , 1 ≤ j ≤ n, wn is a realization\nof a random variable W n, and sn is a realization of a random variable Sn.) Not surprisingly, wn,\nwhich is simply the average of the data, is an estimate for the mean, μ, and sn, which is simply the\nstandard deviation of the data, is an estimate for the standard deviation, σ. (The n - 1 rather than\nn in the denominator of sn is related to a particular choice of estimator and estimator properties;\nin any event, for n large, the difference is quite small.)\nFinally, we calculate the confidence interval for the mean\n[ci]μ;n = wn - tγ,n-1 √\nsn , wn + tγ,n-1 √\nsn\n,\nn\nn\nwhere γ is the confidence level and tγ,n-1 is related to the Student-t distribution.1 For the par\nticular case of γ = 0.95 you can find values for tγ=0.95,n for various n (sample sizes) in a table in\nUnit III. Note that for large n, tγ,n-1 approaches zγ discussed earlier in the context of (normal-\napproximation) binomial confidence intervals.\nWe recall the meaning of this confidence interval. If we perform nexp realizations (with nexp →\ninf) -- in which each realization corresponds to a (different) sample w1, . . . , wn, and hence different\nsample mean wn, different sample standard deviation sn, and different confidence interval [ci]μ;n --\nthen in a fraction γ of these realizations the true mean μ will reside within the confidence interval.\n(Or course this statement is only completely rigorous if the underlying density is precisely the\nnormal density.)\nWe can also translate our confidence interval into an \"error bound\" (with confidence level γ).\nIn particular, unfolding our confidence interval yields\nsn\n|μ - wn| ≤ tγ,n-1 √\n≡ Half Length\n.\nμ;n\nn\nWe observe the \"same\" square root of n, sample size, that we observed in our Bernoulli estimation\nprocedure, and in fact for the same reasons. Intuitively, say in our female height example, as we\nincrease our sample size there are many more ways to obtain a sample mean close to μ (with much\ncancellation about the mean) than to obtain a sample mean say σ above μ (e.g., with all heights\nwell above the mean). As you might expect, as γ increases, tγ,n-1 also increases: if we insist upon\ngreater certainty in our claims, then we will lose some accuracy as reflected in the Half Length of\nthe confidence interval.\n(γ + 1)/2 where F student-t(\n1 The multiplier tγ,n-1 satisfies F student-t(tγ,n-1; n - 1) =\n· ; n - 1) is the cfd of\nthe Student's-t distribution with n - 1 degrees of freedom; i.e. tγ,n-1 is the (γ + 1)/2 quantile of the Student's-t\ndistribution.\n\n(\n\nChapter 12\nMonte Carlo: Areas and Volumes\n12.1\nCalculating an Area\nWe have seen in Chapter 10 and 11 that parameters that describe probability distributions can be\nestimated using a finite number of realizations of the random variable and that furthermore we can\nconstruct an error bound (in the form of confidence interval) for such an estimate. In this chapter,\nwe introduce Monte Carlo methods to estimate the area (or volume) of implicitly-defined regions.\nSpecifically, we recast the area determination problem as a problem of estimating the mean of a\ncertain Bernoulli distribution and then apply the tools developed in Chapter 10 to estimate the\narea and also assess errors in our estimate.\n12.1.1\nObjective\nWe are given a two-dimensional domain D in a rectangle R = [a1, b1]×[a2, b2]. We would like to find,\nor estimate, the area of D, AD. Note that the area of the bounding rectangle, AR = (b1-a1)(b2-a2),\nis known.\n12.1.2\nA Continuous Uniform Random Variable\nLet X ≡ (X1, X2) be a uniform random variable over R. We know that, by the definition of uniform\ndistribution,\n1/AR, (x1, x2) ∈ R\nfX1,X2 (x1, x2) =\n,\n0,\n(x1, x2) ∈/ R\nand we know how to sample from fX1,X2 by using independence and univariate uniform densities.\nFinally, we can express the probability that X takes on a value in D as\nAD\nP (X ∈ D) =\nfX1,X2 (x1, x2) dx1 dx2 =\ndx1 dx2 =\n.\nD\nAR\nD\nAR\nIntuitively, this means that the probability of a random \"dart\" landing in D is equal to the fraction\nof the area that D occupies with respect to R.\nZZ\nD\nZZ\n(\nDRAFT V1.2 (c) The Authors. License: Creative Commons BY-NC-SA 3.0.\n\n(\ns\ns\n(\n(\n12.1.3\nA Bernoulli Random Variable\nLet us introduce a Bernoulli random variable,\n1 X ∈ D with probability θ\nB =\n.\n0 X /∈ D with probability 1 - θ\nBut,\nP (X ∈ D) = AD/AR ,\nSo, by our usual transformation rules,\nAD\nθ ≡\n.\nAR\nIn other words, if we can estimate θ we can estimate AD = ARθ. We know how to estimate θ --\nsame as coin flips. But, how do we sample B if we do not know θ?\n12.1.4\nEstimation: Monte Carlo\nWe draw a sample of random vectors,\n(x1, x2)1, (x1, x2)2, . . . , (x1, x2)n, . . . , (x1, x2)nmax\nand then map the sampled pairs to realization of Bernoulli random variables\n(x1, x2)i → bi,\ni = 1, . . . , nmax .\nGiven the realization of Bernoulli random variables,\nb1, . . . , bn, . . . , bnmax ,\nwe can apply the technique discussed in Section 10.4 to compute the sample means and confidence\nintervals: for n = 1, . . . , nmax,\n⎤\n⎡\nJ\nn\nn\nn\nn\ni=1\nThus, given the mapping from the sampled pairs to Bernoulli variables, we can estimate the pa\nrameter.\nThe only remaining question is how to construct the mapping (x1, x2)n → bn, n = 1, . . . , nmax.\nThe appropriate mapping is, given (x1, x2)n ∈ R,\nbn =\n1,\n(x1, x2)n ∈ D\n.\n0,\n(x1, x2)n /∈ D\nTo understand why this mapping works, we can look at the random variables: given (X1, X2)n,\nˆ\nˆ\nθn(1 - θˆn)\nˆ\nθn(1 - θˆn)\nθn + zγ\n⎢⎣\n⎥⎦\nˆ\n\nθn = bn\nˆθn\nbi\nand [ci]n\n- zγ\n=\n=\n,\n.\n1,\n(X1, X2)n ∈ D\nBn =\n.\n0,\n(X1, X2)n ∈/ D\n(\ns\ns\n(\n(\n\n0.2\n0.4\n0.6\n0.8\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\npiest = 3.0400, n = 200\n0.2\n0.4\n0.6\n0.8\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\npiest = 3.1750, n = 800\n(a) n = 200\n(b) n = 800\nFigure 12.1: Estimation of π by Monte Carlo method.\nBut,\nP ((X1, X2)n ∈ D) = θ ,\nso\nP (Bn = 1) = θ ,\nfor θ = AD/AR.\nThis procedure can be intuitively described as\n1. Throw n \"random darts\" at R\n2. Estimate θ = AD/AR by fraction of darts that land in D\nFinally, for AD, we can develop an estimate\n( e\nˆ\nAD)n = ARθn\nand confidence interval\n[ciAD ]n = AR[ci]n .\nExample 12.1.1 Estimating π by Monte Carlo method\nLet us consider an example of estimating the area using Monte Carlo method. In particular, we\nestimate the area of a circle with unit radius centered at the origin, which has the area of πr2 = π.\nNoting the symmetry of the problem, let us estimate the area of the quarter circle in the first\nquadrant and then multiply the area by four to obtain the estimate of π. In particular, we sample\nfrom the square\nR = [0, 1] × [0, 1]\nhaving the area of AR = 1 and aim to determine the area of the quarter circle D with the area of\nAD. Clearly, the analytical answer to this problem is AD = π/4. Thus, by estimating AD using\nthe Monte Carlo method and then multiplying AD by four, we can estimate the value π.\n\n(\n\n(\n\n2.5\n3.5\n4.5\nn\nπ estimate\n\nπ estimate\nπ\n95% ci\n-4\n-2\nn\nerror\n\nπ estimate\nn-1/2\n95% ci\n(a) value\n(b) error\nFigure 12.2: Convergence of the π estimate with the number of samples.\nThe sampling procedure is illustrated in Figure 12.1. To determine whether a given sample\n(x1, x2)n is in the quarter circle, we can compute its distance from the center and determine if the\ndistance is greater than unity, i.e. the Bernoulli variable is assigned according to\n1,\nx1 + x ≤ 1\nbn =\n.\n0,\notherwise\nThe samples that evaluates to bn = 1 and 0 are plotted in red and blue, respectively. Because the\nsamples are drawn uniformly from the square, the fraction of red dots is equal to the fraction of the\narea occupied by the quarter circle. We show in Figure 12.2 the convergence of the Monte Carlo\nestimation: we observe the anticipated square-root behavior. Note in the remainder of this section\nwe shall use the more conventional N rather than n for sample size.\n·\n12.1.5\nEstimation: Riemann Sum\nAs a comparison, let us also use the midpoint rule to find the area of a two-dimensional region D.\nWe first note that the area of D is equal to the integral of a characteristic function\n1,\n(x1, x2) ∈ D\nχ(x1, x2) =\n,\n0,\notherwise\nover the domain of integration R that encloses D. For simplicity, we consider rectangular domain\nR = [a1, b1] × [a2, b2]. We discretize the domain into N/2 little rectangles, each with the width\nof (b1 - a1)/ N/2 and the height of (b2 - a2)/ N/2. We further divide each rectangle into\ntwo right triangles to obtain a triangulation of R. The area of each little triangle K is AK =\n(b1 - a1)(b2 - a2)/N. Application of the midpoint rule to integrate the characteristic function\nyields\nJ\nJ (b1 - a1)(b2 - a2)\nARie\nAD ≈ ( e\n)N =\nAK χ(xc,K ) =\nχ(xc,K ) ,\nD\nN\nK\nK\n(\np\n(\n\n0.2\n0.4\n0.6\n0.8\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\npi ~ 3.1600, N = 200\n0.2\n0.4\n0.6\n0.8\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\npi ~ 3.1300, N = 800\n(a) N = 200\n(b) N = 800\nFigure 12.3: Estimation of π by deterministic Riemann sum.\nwhere xc,K is the centroid (i.e. the midpoint) of the triangle. Noting that AR = (b1 - a1)(b2 - a2)\nand rearranging the equation, we obtain\nJ\nARie\n( eD )N = AR\nχ(xc,K ) .\nN K\nBecause the characteristic function takes on either 0 or 1, the summation is simply equal to the\nnumber of times that xc,K is in the region D. Thus, we obtain our final expression\nARie\n( e\n)N\nnumber of points in D\nD\n=\n.\nAR\nN\nNote that the expression is very similar to that of the Monte Carlo integration. The main difference\nis that the sampling points are structured for the Riemann sum (i.e. the centroid of the triangles).\nWe can also estimate the error incurred in this process. First, we note that we cannot directly\napply the error convergence result for the midpoint rule developed previously because the derivation\nrelied on the smoothness of the integrand. The characteristic function is discontinuous along the\nboundary of D and thus is not smooth. To estimate the error, for simplicity, let us assume the\ndomain size is the same in each dimension, i.e. a = a1 = a2 and b = b1 = b2. Then, the area of\neach square is\nh2 = (b - a)2/N .\nThen,\nARie\n( e\n)N = (number of points in D) · h2 .\nD\nThere are no errors created by little squares fully inside or fully outside D. All the error is due to\nthe squares that intersect the perimeter. Thus, the error bound can be expressed as\nerror ≈ (number of squares that intersect D) · h2 ≈ (PerimeterD/h) · h2\n= O(h) = O( AR/N) .\np\n\n2.6\n2.8\n3.2\n3.4\n3.6\n3.8\nN\nπ estimate\n\nπ est. (MC)\nπ est. (RM)\nπ\n-4\n-2\nN\nerror\n\nπ est. (MC)\nπ est. (RM)\nN-1/2\n(a) value\n(b) error\nFigure 12.4: Convergence of the π estimate with the number of samples using Riemann sum.\nNote that this is an example of a priori error estimate. In particular, unlike the error estimate\nbased on the confidence interval of the sample mean for Monte Carlo, this estimate is not constant-\nfree. That is, while we know the asymptotic rate at which the method converges, it does not tell us\nthe actual magnitude of the error, which is problem-dependent. A constant-free estimate typically\nrequires an a posteriori error estimate, which incorporates the information gathered about the\nparticular problem of interest. We show in Figure 12.3 the Riemann sum grid, and in Figure 12.4\nthe convergence of the Riemann sum approach compared to the convergence of the Monte Carlo\napproach for our π example.\nExample 12.1.2 Integration of a rectangular area\nIn the case of finding the area of a quarter circle, the Riemann sum performed noticeably better\nthan the Monte Carlo method. However, this is not true in general. To demonstrate this, let us\nconsider integrating the area of a rectangle. In particular, we consider the region\nD = [0.2, 0.7] × [0.2, 0.8] .\nThe area of the rectangle is AD = (0.7 - 0.2) · (0.8 - 0.2) = 0.3.\nThe Monte Carlo integration procedure applied to the rectangular area is illustrated in Fig\nure 12.5(a). The convergence result in Figure 12.5(b) confirms that both Monte Carlo and Riemann\nsum converge at the rate of N-1/2 . Moreover, both methods produce the error of similar level for\nall ranges of the sample size N considered.\n·\nExample 12.1.3 Integration of a complex area\nLet us consider estimating the area of a more complex region, shown in Figure 12.6(a). The region\nD is implicitly defined in the polar coordinate as\nπ\nD =\n(r, θ) : r ≤\n+\ncos(4βθ), 0 ≤ θ ≤\n,\nwhere r =\nx2 + y2 and tan(θ) = y/x. The particular case shown in the figure is for β = 10. For\nany natural number β, the area of the region D is equal to\nπ/2\n2/3+1/3 cos(4βθ)\nπ\nAD =\nr dr dθ =\n,\nβ = 1, 2, . . . .\nθ=0\nr=0\n\np\nZ\nZ\n\n0.2\n0.4\n0.6\n0.8\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nArea ~ 0.2875, N = 800\n-4\n-2\nN\nerror\n\narea est. (MC)\narea est. (RM)\nN-1/2\n(a) Monte Carlo example\n(b) error\nFigure 12.5: The geometry and error convergence for the integration over a rectangular area.\n0.2\n0.4\n0.6\n0.8\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\npi ~ 3.1000, N = 800\n-4\n-2\nN\nerror\n\nπ est. (MC)\nπ est. (RM)\nN-1/2\n(a) Monte Carlo example\n(b) error\nFigure 12.6: The geometry and error convergence for the integration over a more complex area.\nThus, we can again estimate π by multiplying the estimated area of D by 8.\nThe result of estimating π by approximating the area of D is shown in Figure 12.6(b). The\nerror convergence plot confirms that both Monte Carlo and Riemann sum converge at the rate of\nN-1/2 . In fact, their performances are comparable for this slightly more complex domain.\n·\n12.2\nCalculation of Volumes in Higher Dimensions\n12.2.1\nThree Dimensions\nBoth the Monte Carlo method and Riemann sum used to estimate the area of region D in two\ndimensions trivially extends to higher dimensions. Let us consider their applications in three\ndimensions.\n\n(\n(\n\nMonte Carlo\nNow, we sample (X1, X2, X3) uniformly from a parallelepiped R = [a1, b1] × [a2, b2] × [a3, b3], where\nthe Xi's are mutually independent. Then, we assign a Bernoulli random variable according to\nwhether (X1, X2, X3) is inside or outside D as before, i.e.\n1,\n(X1, X2, X3) ∈ D\nB =\n.\n0,\notherwise\nRecall that the convergence of the sample mean to the true value -- in particular the convergence\nof the confidence interval -- is related to the Bernoulli random variable and not the Xi's. Thus,\neven in three dimensions, we still expect the error to converge as N-1/2, where N is the size of the\nsample.\nRiemann Sum\nFor simplicity, let us assume the parallelepiped is a cube, i.e. a = a1 = a2 = a3 and b = b1 = b2 = b3.\nWe consider a grid of N points centered in little cubes of size\nb - a\nh3 =\n,\nN\nsuch that Nh3 = VR. Extending the two-dimensional case, we estimate the volume of the region D\naccording to\nVe Rie\nD\nnumber of points in D\n=\n.\nVR\nN\nHowever, unlike the Monte Carlo method, the error calculation is dependent on the dimension.\nThe error is given by\nerror ≈ (number of cubes that intersect D) · h3\n≈ (surface area of D/h2) · h3\n≈ h ≈ N-1/3 .\nNote that the convergence rate has decreased from N-1/2 to N-1/3 in going from two to three\ndimensions.\nExample 12.2.1 Integration of a sphere\nLet us consider a problem of finding the volume of a unit 1/8th sphere lying in the first octant. We\nsample from a unit cube\nR = [0, 1] × [0, 1] × [0, 1]\nhaving a volume of VR = 1.0. As in the case of circle in two dimensions, we can perform simple\nin/out check by measuring the distance of the point from the origin; i.e the Bernoulli variable is\nassigned according to\n1,\nx1 + x2 + x ≤ 1\nbn =\n.\n0,\notherwise\nThe result of estimating the value of π based on the estimate of the volume of the 1/8th sphere is\nshown in Figure 12.7. (The raw estimated volume of the 1/8th sphere is scaled by 6.) As expected\n(\n(\np\n\n(\n\n2.5\n3.5\n4.5\n5.5\nN\nπ estimate\n\nπ est. (MC)\nπ est. (RM)\nπ\n-4\n-2\nN\nerror\n\nπ est. (MC)\nπ est. (RM)\nN-1/2\nN-1/3\n(a) value\n(b) error\nFigure 12.7: Convergence of the π estimate using the volume of a sphere.\nboth the Monte Carlo method and the Riemann sum converge to the correct value. In particular,\nthe Monte Carlo method converges at the expected rate of N-1/2 . The Riemann sum, on the other\nhand, converges at a faster rate than the expected rate of N-1/3 . This superconvergence is due\nto the symmetry in the tetrahedralization used in integration and the volume of interest. This\ndoes not contradict our a priori analysis, because the analysis tells us the asymptotic convergence\nrate for the worst case. The following example shows that the asymptotic convergence rate of the\nRiemann sum for a general geometry is indeed N-1/2 .\n·\nExample 12.2.2 Integration of a parallelpiped\nLet us consider a simpler example of finding the volume of a parallelpiped described by\nD = [0.1, 0.9] × [0.2, 0.7] × [0.1, 0.8] .\nThe volume of the parallelpiped is VD = 0.28.\nFigure 12.8 shows the result of the integration. The figure shows that the convergence rate of\nthe Riemann sum is N-1/3, which is consistent with the a priori analysis. On the other hand, the\nMonte Carlo method performs just as well as it did in two dimension, converging at the rate of\nN-1/2 . In particular, the Monte Carlo method performs noticeably better than the Riemann sum\nfor large values of N.\n·\nExample 12.2.3 Integration of a complex volume\nLet us consider a more general geometry, with the domain defined in the spherical coordinate as\n\nπ\nπ\nD =\n(r, θ, φ) : r ≤ sin(θ) 3 + 3 cos(40φ) , 0 ≤ θ ≤ 2 , 0 ≤ φ ≤ 2\n.\nThe volume of the region is given by\nπ/2\nπ/2\nsin(θ)(\ncos(40φ))\n+\n2 sin(θ) dr dθ dφ = 88\nVD\nπ .\n=\nr\nφ=0\nθ=0\nr=0\n(\n\nZ\nZ\n\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nN\nvolume estimate\n\nvol est. (MC)\nvol est. (RM)\nvol\n-4\n-2\nN\nerror\n\nvol est. (MC)\nvol est. (RM)\nN-1/2\nN-1/3\n(a) value\n(b) error\nFigure 12.8: Area of a parallelepiped.\nN\nπ estimate\n\nπ est. (MC)\nπ est. (RM)\nπ\n-4\n-2\nN\nerror\n\nπ est. (MC)\nπ est. (RM)\nN-1/2\nN-1/3\n(a) value\n(b) error\nFigure 12.9: Convergence of the π estimate using a complex three-dimensional integration.\n\nThus, we can estimate the value of π by first estimating the volume using Monte Carlo or Riemann\nsum, and then multiplying the result by 2835/88.\nFigure 12.9 shows the result of performing the integration. The figure shows that the conver\ngence rate of the Riemann sum is N-1/3, which is consistent with the a priori analysis. On the\nother hand, the Monte Carlo method performs just as well as it did for the simple sphere case.\n·\n12.2.2\nGeneral d-Dimensions\nLet us generalize our analysis to the case of integrating a general d-dimensional region. In this case,\nthe Monte Carlo method considers a random d-vector, (X1, . . . , Xd), and associate with the vector\na Bernoulli random variable. The convergence of the Monte Carlo integration is dependent on\nthe Bernoulli random variables and not directly affected by the random vector. In particular, the\nMonte Carlo method is oblivious to the length of the vector, d, i.e. the dimensionality of the space.\nBecause the standard deviation of the binomial distribution scales as N-1/2, we still expect the\nMonte Carlo method to converge at the rate of N-1/2 regardless of d. Thus, Monte Carlo methods\ndo not suffer from so-called curse of dimensionality, in which a method becomes intractable with\nincrease of the dimension of the problem.\nOn the other hand, the performance of the Riemann sum is a function of the dimension of the\nd-1\nspace. In a d-dimensional space, each little cube has the volume of N-1, and there are N d cube\nthat intersect the boundary of D. Thus, the error scales as\nd-1\n= N-1/d\nerror ≈ N d N-1\n.\nThe convergence rate worsens with the dimension, and this is an example of the curse of dimen\nsionality. While the integration of a physical volume is typically limited to three dimensions, there\nare many instances in science and engineering where a higher-dimensional integration is required.\nExample 12.2.4 integration over a hypersphere\nTo demonstrate that the convergence of Monte Carlo method is independent of the dimension, let\nus consider integration of a hypersphere in d-dimensional space. The volume of d-sphere is given\nby\nπd/2\nVD =\nr d ,\nΓ(n/2 + 1)\nwhere Γ is the gamma function. We can again use the integration of a d-sphere to estimate the\nvalue of π.\nThe result of estimating the d-dimensional volume is shown in Figure 12.10 for d = 2, 3, 5, 7.\nThe error convergence plot shows that the method converges at the rate of N -1/2 for all d. The\nresult confirms that Monte Carlo integration is a powerful method for integrating functions in\nhigher-dimensional spaces.\n·\n\n0.5\n1.5\n2.5\n3.5\n4.5\nN\nπ estimate\n\nd = 2\nd = 3\nd = 5\nd = 7\n-4\n-3\n-2\n-1\nN\nerror\n\nd = 2\nd = 3\nd = 5\nd = 7\nN-1/2\n(a) value\n(b) error\nFigure 12.10: Convergence of the π estimate using the Monte Carlo method on d-dimensional\nhyperspheres.\n\nChapter 13\nMonte Carlo: General Integration\nProcedures\nDRAFT V1.2 (c) The Authors. License: Creative Commons BY-NC-SA 3.0.\n\nChapter 14\nMonte Carlo: Failure Probabilities\nDRAFT V1.2 (c) The Authors. License: Creative Commons BY-NC-SA 3.0\n14.1\nCalculating a Failure Probability\n14.1.1\nObjective\nLet's say there is a set of \"environmental\" or \"load\" variables (x1, x2, . . . ) that affect the perfor\nmance of an engineering system. For simplicity, let us restrict ourselves to the parameter size of\ntwo, so that we only have (x1, x2). We also assume that there are two \"performance\" metrics,\ng1(x1, x2) and g2(x1, x2). Without loss of generality, let's assume smaller g1 and g2 means better\nperformance (we can always consider negative of the performance variable if larger values imply\nbetter performance). In fact, we assume that we wish to confirm that the performance metrics are\nbelow certain thresholds, i.e.\ng1(x1, x2) ≤ τ1\nand g2(x1, x2) ≤ τ2 .\n(14.1)\nEquivalently, we wish to avoid failure, which is defined as\ng1(x1, x2) > τ1\nor g2(x1, x2) > τ2 .\nNote that in this chapter failure is interpreted liberally as the condition (14.1) even if this condition\nis not equivalent in any given situation as actual failure.\nSuppose that (x1, x2) reside in some rectangle R. We now choose to interpret (x1, x2) as realiza\ntions of a random vector X = (X1, X2) with prescribed probability density function fX (x1, x2) =\nfX1,X2 (x1, x2). We then wish to quantify the failure probability θF , defined by\nθF = P (g1(X1, X2) > τ1 or g2(X1, X2) > τ2) .\nWe note that g1 and g2 are deterministic functions; however, because the argument to the functions\nare random variables, the output g1(X1, X2) and g2(X1, X2) are random variables. Thus, the failure\nis described probabilistically. If the bounds on the environmental variables (x1, x2) are known a\npriori one could design a system to handle the worst possible cases; however, the system design to\nhandle very rare events may be over designed. Thus, a probabilistic approach may be appropriate\nin many engineering scenarios.\nIn any probabilistic simulation, we must make sure that the probability density of the random\nvariable, fX , is meaningful and that the interpretation of the probabilistic statement is relevant.\n\n(\n\n(\n(\nFor example, in constructing the distribution, a good estimate may be obtained from statistical\ndata (i.e. by sampling a population). The failure probability θF can be interpreted as either\n(i) probability of failure for the next \"random\" set of environmental or operating conditions, or\n(ii) frequency of failure over a population (based on the frequentist perspective).\n14.1.2\nAn Integral\nWe now show that the computation of failure probability is similar to computation of an area. Let\nus define R to be the region from which X = (X1, X2) is sampled (not necessarily uniformly). In\nother words, R encompasses all possible values that the environmental variable X can take. Let us\nalso define D to be the region whose element (x1, x2) ∈ D would lead to failure, i.e.\nD ≡{(x1, x2) : g1(x1, x2) > τ1\nor g2(x1, x2) > τ2} .\nThen, the failure probability can be expressed as an integral\nθF =\nfX (x1, x2)dx1dx2 .\nD\nThis requires a integration over the region D, which can be complicated depending on the failure\ncriteria.\nHowever, we can simplify the integral using the technique previously used to compute the area.\nNamely, we introduce a failure indicator or characteristic function,\n1,\ng1(x1, x2) > τ1\nor g2(x1, x2) > τ2\n1F (x1, x2) =\n.\n0,\notherwise\nUsing the failure indicator, we can write the integral over D as an integral over the simpler domain\nR, i.e.\nθF =\n1(x1, x2)fX (x1, x2) dx1 dx2 .\nR\nNote that Monte Carlo methods can be used to evaluate any integral in any number of dimensions.\nThe two main approaches are \"hit or miss\" and \"sample mean,\" with the latter more efficient. Our\ncase here is a natural example of the sample mean approach, though it also has the flavor of \"hit\nor miss.\" In practice, variance reduction techniques are often applied to improve the convergence.\n14.1.3\nA Monte Carlo Approach\nWe can easily develop a Monte Carlo approach if we can reduce our problem to a Bernoulli random\nvariable with parameter θF such that\n1,\nwith probability θF\nB =\n.\n0,\nwith probability 1 - θF\nThen, the computation of the failure probability θF becomes the estimation of parameter θF through\nsampling (as in the coin flip example). This is easy: we draw a random vector (X1, X2) from fX\n-- for example, uniform or normal -- and then define\n1,\ng1(X) > τ1\nor g2(X) > τ2\nB =\n.\n(14.2)\n0,\notherwise\nZZ\n(\nZZ\n(\n(\n\ns\ns\nDetermination of B is easy assuming we can evaluate g1(x1, x2) and g2(x1, x2). But, by definition\nθF = P (g1(X) > τ1\nor g2(X) > τ2)\n=\n1F (x1, x2)fX (x1, x2) dx1 dx2 .\nR\nHence we have identified a Bernoulli random variable with the requisite parameter θF .\nThe Monte Carlo procedure is simple. First, we draw nmax random variables,\n(X1, X2)1, (X1, X2)2, . . . , (X1, X2)n, . . . , (X1, X2)nmax ,\nand map them to Bernoulli random variables\n(X1, X2)n → Bn\nn = 1, . . . , nmax ,\ne\naccording to (14.2). Using this mapping, we assign sample means, Θn, and confidence intervals,\n[CIF ]n, according to\nn\nJ\ne\n(ΘF )n =\nBi ,\n(14.3)\nn i=1\n⎡\n⎤\ne\ne\ne\ne\n⎢\n(ΘF )n(1 - (ΘF )n)\n(ΘF )n(1 - (ΘF )n)⎥\ne\ne\n[CIF ]n = ⎣(ΘF )n - zγ\n, (ΘF )n + zγ\n⎦ .\n(14.4)\nn\nn\nNote that in cases of failure, typically we would like θF to be very small. We recall from Sec\ntion 10.3.3 that it is precisely this case for which the relative error RelErr is quite large (and\nfurthermore for which the normal density confidence interval is only valid for quite large n). Hence,\nin practice, we must consider very large sample sizes in order to obtain relatively accurate results\nwith reasonable confidence. More sophisticated approaches partially address these issues, but even\nthese advanced approaches often rely on basic Monte Carlo ingredients.\nFinally, we note that although the above description is for the cumulative approach we can also\ndirectly apply equations 14.3 and 14.4 for any fixed n. In this case we obtain Pr(θF ∈ [CIf ]n) = γ.\nZZ\ns\ns\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n2.086 Numerical Computation for Mechanical Engineers\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Unit 3: Linear Algebra 1: Matrices and Least Squares; Regression from Math, Numerics, and Programming (for Mechanical Engineers). V1.2, September 2012.",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-086-numerical-computation-for-mechanical-engineers-fall-2012/016e58e13c5fca3e088ff3585eb4ca6b_MIT2_086F12_notes_unit3.pdf",
      "content": "DRAFT V1.2\nFrom\nMath, Numerics, & Programming\n(for Mechanical Engineers)\nMasayuki Yano\nJames Douglass Penn\nGeorge Konidaris\nAnthony T Patera\nSeptember 2012\n(c) The Authors. License: Creative Commons Attribution-Noncommercial-Share Alike 3.0\n(CC BY-NC-SA 3.0), which permits unrestricted use, distribution, and reproduction\nin any medium, provided the original authors and MIT OpenCourseWare source\nare credited; the use is non-commercial; and the CC BY-NC-SA license is\nretained. See also http://ocw.mit.edu/terms/.\n\nContents\nIII\nLinear Algebra 1: Matrices and Least Squares. Regression.\n15 Motivation\n16 Matrices and Vectors: Definitions and Operations\n16.1 Basic Vector and Matrix Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . 203\n16.1.1 Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203\nTranspose Operation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204\n16.1.2 Vector Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205\nInner Product . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207\nNorm (2-Norm) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207\nOrthogonality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211\nOrthonormality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212\n16.1.3 Linear Combinations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212\nLinear Independence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213\nVector Spaces and Bases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 214\n16.2 Matrix Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217\n16.2.1 Interpretation of Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217\n16.2.2 Matrix Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218\nMatrix-Matrix Product . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 219\n16.2.3 Interpretations of the Matrix-Vector Product . . . . . . . . . . . . . . . . . . 222\nRow Interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222\nColumn Interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 223\nLeft Vector-Matrix Product . . . . . . . . . . . . . . . . . . . . . . . . . . . . 223\n16.2.4 Interpretations of the Matrix-Matrix Product . . . . . . . . . . . . . . . . . . 224\nMatrix-Matrix Product as a Series of Matrix-Vector Products . . . . . . . . . 224\nMatrix-Matrix Product as a Series of Left Vector-Matrix Products . . . . . . 225\n16.2.5 Operation Count of Matrix-Matrix Product . . . . . . . . . . . . . . . . . . . 225\n16.2.6 The Inverse of a Matrix (Briefly) . . . . . . . . . . . . . . . . . . . . . . . . . 226\n16.3 Special Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227\n16.3.1 Diagonal Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228\n16.3.2 Symmetric Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228\n16.3.3 Symmetric Positive Definite Matrices . . . . . . . . . . . . . . . . . . . . . . . 228\n16.3.4 Triangular Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230\n16.3.5 Orthogonal Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230\n16.3.6 Orthonormal Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\n16.4 Further Concepts in Linear Algebra . . . . . . . . . . . . . . . . . . . . . . . . . . . 233\n16.4.1 Column Space and Null Space . . . . . . . . . . . . . . . . . . . . . . . . . . 233\n16.4.2 Projectors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234\n\n17 Least Squares\n17.1 Data Fitting in Absence of Noise and Bias\n. . . . . . . . . . . . . . . . . . . . . . . 237\n17.2 Overdetermined Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242\nRow Interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243\nColumn Interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244\n17.3 Least Squares . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245\n17.3.1 Measures of Closeness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245\n17.3.2 Least-Squares Formulation (£2 minimization) . . . . . . . . . . . . . . . . . . 246\n17.3.3 Computational Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . 250\nQR Factorization and the Gram-Schmidt Procedure . . . . . . . . . . . . . . 251\n17.3.4 Interpretation of Least Squares: Projection . . . . . . . . . . . . . . . . . . . 253\n17.3.5 Error Bounds for Least Squares . . . . . . . . . . . . . . . . . . . . . . . . . . 255\nError Bounds with Respect to Perturbation in Data, g (constant model) . . . 255\nError Bounds with Respect to Perturbation in Data, g (general) . . . . . . . 256\nError Bounds with Respect to Reduction in Space, B . . . . . . . . . . . . . 262\n18 Matlab Linear Algebra (Briefly)\n18.1 Matrix Multiplication (and Addition) . . . . . . . . . . . . . . . . . . . . . . . . . . 267\n18.2 The Matlab Inverse Function: inv . . . . . . . . . . . . . . . . . . . . . . . . . . . 268\n18.3 Solution of Linear Systems: Matlab Backslash . . . . . . . . . . . . . . . . . . . . . 269\n18.4 Solution of (Linear) Least-Squares Problems . . . . . . . . . . . . . . . . . . . . . . . 269\n19 Regression: Statistical Inference\n19.1 Simplest Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271\n19.1.1 Friction Coefficient Determination Problem Revisited . . . . . . . . . . . . . 271\n19.1.2 Response Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272\n19.1.3 Parameter Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275\n19.1.4 Confidence Intervals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277\nIndividual Confidence Intervals . . . . . . . . . . . . . . . . . . . . . . . . . . 278\nJoint Confidence Intervals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279\n19.1.5 Hypothesis Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284\n19.1.6 Inspection of Assumptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285\nChecking for Plausibility of the Noise Assumptions . . . . . . . . . . . . . . . 285\nChecking for Presence of Bias . . . . . . . . . . . . . . . . . . . . . . . . . . . 286\n19.2 General Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287\n19.2.1 Response Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287\n19.2.2 Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288\n19.2.3 Confidence Intervals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\n19.2.4 Overfitting (and Underfitting) . . . . . . . . . . . . . . . . . . . . . . . . . . 290\n\nUnit III\nLinear Algebra 1: Matrices and Least\nSquares. Regression.\n\nChapter 15\nMotivation\nDRAFT V1.2 (c) The Authors. License: Creative Commons BY-NC-SA 3.0 .\nIn odometry-based mobile robot navigation, the accuracy of the robot's dead reckoning pose\ntracking depends on minimizing slippage between the robot's wheels and the ground. Even a\nmomentary slip can lead to an error in heading that will cause the error in the robot's location\nestimate to grow linearly over its journey. It is thus important to determine the friction coefficient\nbetween the robot's wheels and the ground, which directly affects the robot's resistance to slippage.\nJust as importantly, this friction coefficient will significantly affect the performance of the robot:\nthe ability to push loads.\nWhen the mobile robot of Figure 15.1 is commanded to move forward, a number of forces come\ninto play. Internally, the drive motors exert a torque (not shown in the figure) on the wheels,\nwhich is resisted by the friction force Ff between the wheels and the ground. If the magnitude of Ff\ndictated by the sum of the drag force Fdrag (a combination of all forces resisting the robot's motion)\nand the product of the robot's mass and acceleration is less than the maximum static friction force\nF max\nbetween the wheels and the ground, the wheels will roll without slipping and the robot\nf, static\nwill move forward with velocity v = ωrwheel. If, however, the magnitude of Ff reaches F max , the\nf, static\nwheels will begin to slip and Ff will drop to a lower level Ff, kinetic, the kinetic friction force. The\nwheels will continue to slip (v < ωrwheel) until zero relative motion between the wheels and the\nground is restored (when v = ωrwheel).\nThe critical value defining the boundary between rolling and slipping, therefore, is the maximum\nFnormal, front\nFnormal, rear\nw\nFf\nv\nFdrag\nW\nFigure 15.1: A mobile robot in motion.\n\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n\ntime (seconds)\ntime (seconds)\nFfriction\nfriction vs.\nvs. Tim\nTime for\nfor 500\n500 Gr\nGram\nam Load\nLoad\nFf, ki\nkine\nnetic\nic = μk Fnor\nnorma\nmal + exp\nexperi\nerimen\nental\ntal error\nerror\nFfriction\nfriction (Newtons)\n(Newtons)\nFf, stat\nstatic\nic = Fta\ntangen\nngentia\nial, appl\napplied\nied ≤μs Fnor\nnorma\nmal\nmeas\neas\n\n= μs Fnor\nnorma\nmal + exp\nexperirimen\nental\ntal error\nerror\nFf, stat\nstatic\nic\nmax,\nax, meas\nmeas\nFigure 15.2: Experimental setup for friction\nmeasurement: Force transducer (A) is con- Figure 15.3:\nSample data for one friction\nnected to contact area (B) by a thin wire. measurement, yielding one data point for\nF max, meas\nNormal force is exerted on the contact area\n. Data courtesy of James Penn.\nf, static\nby load stack (C). Tangential force is ap\nplied using turntable (D) via the friction be\ntween the turntable surface and the contact\narea. Apparatus and photograph courtesy of\nJames Penn.\nstatic friction force. We expect that\nF max\nf, static = μs Fnormal, rear ,\n(15.1)\nwhere μs is the static coefficient of friction and Fnormal, rear is the normal force from the ground on\nthe rear, driving, wheels. In order to minimize the risk of slippage (and to be able to push large\nloads), robot wheels should be designed for a high value of μs between the wheels and the ground.\nThis value, although difficult to predict accurately by modeling, can be determined by experiment.\nWe first conduct experiments for the friction force F max\n(in Newtons) as a function of normal\nf, static\nload Fnormal, applied (in Newtons) and (nominal) surface area of contact Asurface (in cm2) with the\nfriction turntable apparatus depicted in Figure 15.2. Weights permit us to vary the normal load and\n\"washer\" inserts permit us to vary the nominal surface area of contact. A typical experiment (at a\nparticular prescribed value of Fnormal, applied and Asurface) yields the time trace of Figure 15.3 from\nwhich the F max, means (our measurement of F max ) is deduced as the maximum of the response.\nf, static\nf, static\nWe next postulate a dependence (or \"model\")\nF max\nf, static(Fnormal, applied, Asurface) = β0 + β1 Fnormal, applied + β2 Asurface ,\n(15.2)\nwhere we expect -- but do not a priori assume -- from Messieurs Amontons and Coulomb that\nβ0 = 0 and β2 = 0 (and of course β1 ≡ μs). In order to confirm that β0 = 0 and β2 = 0 -- or at\nleast confirm that β0 = 0 and β2 = 0 is not untrue -- and to find a good estimate for β1 ≡ μs, we\nmust appeal to our measurements.\nThe mathematical techniques by which to determine μs (and β0, β2) \"with some confidence\"\nfrom noisy experimental data is known as regression, which is the subject of Chapter 19. Regression,\nin turn, is best described in the language of linear algebra (Chapter 16), and is built upon the linear\nalgebra concept of least squares (Chapter 17).\n\nChapter 16\nMatrices and Vectors: Definitions and\nOperations\n16.1\nBasic Vector and Matrix Operations\n16.1.1\nDefinitions\nLet us first introduce the primitive objects in linear algebra: vectors and matrices. A m-vector\nv ∈ Rm×1 consists of m real numbers 1\n⎞\n⎛\nv =\n⎜\n⎜\n⎜\n⎜\n⎝\nv1\nv2\n. . .\nvm\n⎟\n⎟\n⎟\n⎟\n⎠\n.\nIt is also called a column vector, which is the default vector in linear algebra. Thus, by convention,\nv ∈ Rm implies that v is a column vector in Rm×1 . Note that we use subscript (·)i to address the\n∈ R1×n\ni-th component of a vector. The other kind of vector is a row vector v\nconsisting of n\nentries\n\nv =\nv1 v2 · · ·\nvn\n.\nLet us consider a few examples of column and row vectors.\nExample 16.1.1 vectors\nExamples of (column) vectors in R3 are\n⎛\n⎞\n⎛\n√\n⎞\n⎛\n⎞\n9.1\nv = ⎜\n⎝ 3 ⎟\n⎠ , u = ⎜\n⎝ -7 ⎟\n⎠ , and w = ⎜\n⎝ 7/3\n√\n⎟\n⎠ .\nπ\nπ\n1The concept of vectors readily extends to complex numbers, but we only consider real vectors in our presentation\nof this chapter.\nDRAFT V1.2 (c) The Authors. License: Creative Commons BY-NC-SA 3.0 .\n\n√\nTo address a specific component of the vectors, we write, for example, v1 = 1, u1 =\n3, and\nw3 = √ π. Examples of row vectors in R1×4 are\n√\n√\nv =\n2 -5\n2 e\nand u =\n- π 1\n.\nSome of the components of these row vectors are v2 = -5 and u4 = 0.\n·\nA matrix A ∈ Rm×n consists of m rows and n columns for the total of m · n entries,\n⎞\n⎛\nA =\n⎜\n⎜\n⎜\n⎜\n⎝\nA11\nA12\n· · ·\nA1n\nA21\nA22\n· · ·\nA2n\n. . .\n. . .\n. . .\n. . .\nAm1 Am2 · · ·\nAmn\n⎟\n⎟\n⎟\n⎟\n⎠\n.\nExtending the convention for addressing an entry of a vector, we use subscript (·)ij to address the\nentry on the i-th row and j-th column. Note that the order in which the row and column are\nreferred follows that for describing the size of the matrix. Thus, A ∈ Rm×n consists of entries\nAij ,\ni = 1, . . . , m,\nj = 1, . . . , n .\nSometimes it is convenient to think of a (column) vector as a special case of a matrix with only one\ncolumn, i.e., n = 1. Similarly, a (row) vector can be thought of as a special case of a matrix with\nm = 1. Conversely, an m × n matrix can be viewed as m row n-vectors or n column m-vectors, as\nwe discuss further below.\nExample 16.1.2 matrices\nExamples of matrices are\n⎛\n√\n⎞\n⎛\n⎞\n⎜\n⎝ -4\n9 ⎟\n⎠\nand B = ⎜\n⎝ -2 8\n1 ⎟\n⎠\nA =\n.\nπ\n-3\nThe matrix A is a 3 × 2 matrix (A ∈ R3×2) and matrix B is a 3 × 3 matrix (B ∈ R3×3). We can\n√\nalso address specific entries as, for example, A12 =\n3, A31 = -4, and B32 = 3.\n·\nWhile vectors and matrices may appear like arrays of numbers, linear algebra defines special\nset of rules to manipulate these objects. One such operation is the transpose operation considered\nnext.\nTranspose Operation\nThe first linear algebra operator we consider is the transpose operator, denoted by superscript (·)T .\nThe transpose operator swaps the rows and columns of the matrix. That is, if B = AT with\nA ∈ Rm×n, then\nBij = Aji,\n1 ≤ i ≤ n,\n1 ≤ j ≤ m .\nBecause the rows and columns of the matrix are swapped, the dimensions of the matrix are also\nswapped, i.e., if A ∈ Rm×n then B ∈ Rn×m .\nIf we swap the rows and columns twice, then we return to the original matrix. Thus, the\ntranspose of a transposed matrix is the original matrix, i.e.\n(AT)T = A .\n\n!\nExample 16.1.3 transpose\nLet us consider a few examples of transpose operation. A matrix A and its transpose B = AT are\nrelated by\n⎛\n√\n⎞\nA = ⎜\n⎝ -4\n9 ⎟\n⎠\nand B =\n-4\nπ\n√\n.\n-3\nπ\n-3\n√\nThe rows and columns are swapped in the sense that A31 = B13 = π and A12 = B21 =\n3. Also,\nbecause A ∈ R3×2 , B ∈ R2×3 . Interpreting a vector as a special case of a matrix with one column,\nwe can also apply the transpose operator to a column vector to create a row vector, i.e., given\n⎛\n⎞\n√\n⎜\n⎝\n⎟\n⎠\n-7\nv =\n,\nπ\nthe transpose operation yields\n√\nT\nu = v =\n3 -7 π\n.\nNote that the transpose of a column vector is a row vector, and the transpose of a row vector is a\ncolumn vector.\n·\n16.1.2\nVector Operations\nThe first vector operation we consider is multiplication of a vector v ∈ Rm by a scalar α ∈ R. The\noperation yields\nu = αv ,\nwhere each entry of u ∈ Rm is given by\nui = αvi,\ni = 1, . . . , m .\nIn other words, multiplication of a vector by a scalar results in each component of the vector being\nscaled by the scalar.\nThe second operation we consider is addition of two vectors v ∈ Rm and w ∈ Rm . The addition\nyields\nu = v + w ,\nwhere each entry of u ∈ Rm is given by\nui = vi + wi,\ni = 1, . . . , m .\nIn order for addition of two vectors to make sense, the vectors must have the same number of\ncomponents. Each entry of the resulting vector is simply the sum of the corresponding entries of\nthe two vectors.\nWe can summarize the action of the scaling and addition operations in a single operation. Let\nv ∈ Rm , w ∈ Rm and α ∈ R. Then, the operation\nu = v + αw\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n0.5\n1.5\n0.5\n1.5\nv\nu=α v\n0.5\n1.5\n0.5\n1.5\nv\nw\nu=v+w\n(a) scalar scaling\n(b) vector addition\nFigure 16.1: Illustration of vector scaling and vector addition.\nyields a vector u ∈ Rm whose entries are given by\nui = vi + αwi,\ni = 1, . . . , m .\nThe result is nothing more than a combination of the scalar multiplication and vector addition\nrules.\nExample 16.1.4 vector scaling and addition in R2\nLet us illustrate scaling of a vector by a scalar and addition of two vectors in R2 using\n1/2\nv =\n, w =\n,\nand α =\n.\n1/3\nFirst, let us consider scaling of the vector v by the scalar α. The operation yields\n3/2\nu = αv =\n=\n.\n1/3\n1/2\nThis operation is illustrated in Figure 16.1(a). The vector v is simply stretched by the factor of\n3/2 while preserving the direction.\nNow, let us consider addition of the vectors v and w. The vector addition yields\n1/2\n3/2\nu = v + w =\n+\n=\n.\n1/3\n4/3\nFigure 16.1(b) illustrates the vector addition process. We translate w so that it starts from the\ntip of v to form a parallelogram. The resultant vector is precisely the sum of the two vectors.\nNote that the geometric intuition for scaling and addition provided for R2 readily extends to higher\ndimensions.\n·\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\nv\nu\nu\nt\nExample 16.1.5 vector scaling and addition in R3\nT\nT\nLet v =\n, w =\n2 -1 0\n, and α = 3. Then,\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\nu = v + αw = ⎜\n⎝ 3 ⎟\n⎠ + 3 · ⎜\n⎝ -1 ⎟\n⎠ = ⎜\n⎝ 3 ⎟\n⎠ + ⎜\n⎝ -3 ⎟\n⎠ = ⎜\n⎝ 0 ⎟\n⎠ .\n·\nInner Product\nAnother important operation is the inner product. This operation takes two vectors of the same\ndimension, v ∈ Rm and w ∈ Rm, and yields a scalar β ∈ R:\nm\nm\nβ = v T w where β =\nviwi .\ni=1\nThe appearance of the transpose operator will become obvious once we introduce the matrix-matrix\nmultiplication rule. The inner product in a Euclidean vector space is also commonly called the dot\nproduct and is denoted by β = v · w. More generally, the inner product of two elements of a vector\nspace is denoted by (·, ·), i.e., β = (v, w).\nExample 16.1.6 inner product\nT\nT\nLet us consider two vectors in R3 , v =\nand w =\n2 -1 0\n. The inner product\nof these two vectors is\nm\nT\nβ = v w =\nviwi = 1 · 2 + 3 · (-1) + 6 · 0 = -1 .\ni=1\n·\nNorm (2-Norm)\nUsing the inner product, we can naturally define the 2-norm of a vector. Given v ∈ Rm, the 2-norm\nof v, denoted by IvI2, is defined by\nm\nm\ni=1\nNote that the norm of any vector is non-negative, because it is a sum m non-negative numbers\n√\nIvI2 =\nvTv =\nv i .\ng\n(squared values). The £2 norm is the usual Euclidean length; in particular, for m = 2, the expression\nsimplifies to the familiar Pythagorean theorem, IvI2 =\nv1 + v2. While there are other norms, we\nalmost exclusively use the 2-norm in this unit. Thus, for notational convenience, we will drop the\nsubscript 2 and write the 2-norm of v as IvI with the implicit understanding I · I ≡I · I2.\nBy definition, any norm must satisfy the triangle inequality,\nIv + wI ≤IvI + IwI ,\n\nv\nu\nu\nt\nv\nu\nu\nt\n\n!\n\n!\n\n!\n\n!\n\n!\nfor any v, w ∈ Rm . The theorem states that the sum of the lengths of two adjoining segments\nis longer than the distance between their non-joined end points, as is intuitively clear from Fig\nure 16.1(b). For norms defined by inner products, as our 2-norm above, the triangle inequality is\nautomatically satisfied.\nProof. For norms induced by an inner product, the proof of the triangle inequality follows directly\nfrom the definition of the norm and the Cauchy-Schwarz inequality. First, we expand the expression\nas\nT\nT\nT\nIv + wI2 = (v + w)T(v + w) = v v + 2v w + w w .\nThe middle terms can be bounded by the Cauchy-Schwarz inequality, which states that\nT\nT\nv w ≤|v w| ≤IvIIwI .\nThus, we can bound the norm as\nIv + wI2 ≤IvI2 + 2IvIIwI + IwI2 = (IvI + IwI)2 ,\nand taking the square root of both sides yields the desired result.\nExample 16.1.7 norm of a vector\nT\nT\nLet v =\nand w =\n2 -1 0\n. The £2 norms of these vectors are\nm\ng\n√\nIvI =\nvi =\n12 + 32 + 62 =\ni=1\nm\ng\n√\nand IwI =\nw =\n22 + (-1)2 + 02 =\n5 .\ni\ni=1\n·\nExample 16.1.8 triangle inequality\nLet us illustrate the triangle inequality using two vectors\n1/2\nv =\nand w =\n.\n1/3\nThe length (or the norm) of the vectors are\n\nIvI =\n≈ 1.054 and IwI =\n≈ 1.118 .\nOn the other hand, the sum of the two vectors is\n1/2\n3/2\nv + w =\n+\n=\n,\n1/3\n4/3\n\nv\nu\nu\nt\nv\nu\nu\nt\n\n!\n\n!\n0.5\n1.5\n0.5\n1.5\nv\nw\nv+w\n||v||\n||w||\nFigure 16.2: Illustration of the triangle inequality.\nand its length is\n√\nIv + wI =\n≈ 2.007 .\nThe norm of the sum is shorter than the sum of the norms, which is\nIvI + IwI ≈ 2.172 .\nThis inequality is illustrated in Figure 16.2. Clearly, the length of v +w is strictly less than the sum\nof the lengths of v and w (unless v and w align with each other, in which case we obtain equality).\n·\nIn two dimensions, the inner product can be interpreted as\nT\nv w = IvIIwI cos(θ) ,\n(16.1)\nwhere θ is the angle between v and w. In other words, the inner product is a measure of how well\nv and w align with each other. Note that we can show the Cauchy-Schwarz inequality from the\nabove equality. Namely, | cos(θ)| ≤ 1 implies that\nT\n|v w| = IvIIwI| cos(θ)| ≤IvIIwI .\nIn particular, we see that the inequality holds with equality if and only if θ = 0 or π, which\ncorresponds to the cases where v and w align. It is easy to demonstrate Eq. (16.1) in two dimensions.\nProof. Noting v, w ∈ R2, we express them in polar coordinates\ncos(θv)\ncos(θw)\nv = IvI\nand w = IwI\n.\nsin(θv)\nsin(θw)\n\nThe inner product of the two vectors yield\nm\nT\nβ = v w =\nviwi = IvI cos(θv)IwI cos(θw) + IvI sin(θv)IwI sin(θw)\ni=1\n\n= IvIIwI cos(θv) cos(θw) + sin(θv) sin(θw)\n\niθv\n-iθv )1\niθw\niθv\n-iθv ) 1\niθw\n-iθw )\n= IvIIwI\n(e\n+ e\n(e\n+ e -iθw ) +\n(e\n- e\n(e\n- e\n2i\n2i\ni(θv +θw)\n-i(θv +θw)\ni(θv -θw )\n-i(θv -θw )\n= IvIIwI\ne\n+ e\n+ e\n+ e\n\ni(θv +θw)\n-i(θv +θw ) - e i(θv -θw ) - e -i(θv -θw)\n-\ne\n+ e\n\ni(θv -θw)\n-i(θv -θw)\n= IvIIwI\ne\n+ e\n= IvIIwI cos(θv - θw) = IvIIwI cos(θ) ,\nwhere the last equality follows from the definition θ ≡ θv - θw.\nBegin Advanced Material\nFor completeness, let us introduce a more general class of norms.\nExample 16.1.9 p-norms\nThe 2-norm, which we will almost exclusively use, belong to a more general class of norms, called\nthe p-norms. The p-norm of a vector v ∈ Rm is\n⎛\n⎞1/p\nm\nm\n⎝\n⎠\nIvIp =\n|vi|p\n,\ni=1\nwhere p ≥ 1. Any p-norm satisfies the positivity requirement, the scalar scaling requirement, and\nthe triangle inequality. We see that 2-norm is a case of p-norm with p = 2.\nAnother case of p-norm that we frequently encounter is the 1-norm, which is simply the sum of\nthe absolute value of the entries, i.e.\nm\nm\nIvI1 =\n|vi| .\ni=1\nThe other one is the infinity norm given by\nIvIinf = lim IvIp = max |vi| .\np→inf\ni=1,...,m\nIn other words, the infinity norm of a vector is its largest entry in absolute value.\n·\nEnd Advanced Material\n\n!\n\n!\n\n!\n-5\n-4\n-3\n-2\n-1\nu\nv\nw\nFigure 16.3: Set of vectors considered to illustrate orthogonality.\nOrthogonality\nTwo vectors v ∈ Rm and w ∈ Rm are said to be orthogonal to each other if\nT\nv w = 0 .\nIn two dimensions, it is easy to see that\nT\nv w = IvIIwI cos(θ) = 0\n⇒\ncos(θ) = 0\n⇒\nθ = π/2 .\nThat is, the angle between v and w is π/2, which is the definition of orthogonality in the usual\ngeometric sense.\nExample 16.1.10 orthogonality\nLet us consider three vectors in R2 ,\n-4\nu =\n,\nv =\n,\nand w =\n,\nand compute three inner products formed by these vectors:\nT\nu v = -4 · 3 + 2 · 6 = 0\nT\nu w = -4 · 0 + 2 · 5 = 10\nT\nv w = 3 · 0 + 6 · 5 = 30 .\nT\nT\nBecause u v = 0, the vectors u and v are orthogonal to each other. On the other hand, u\n\nw = 0\nand the vectors u and w are not orthogonal to each other. Similarly, v and w are not orthogonal to\neach other. These vectors are plotted in Figure 16.3; the figure confirms that u and v are orthogonal\nin the usual geometric sense.\n·\n\n!\n\n!\n\n!\n\n!\n\n!\n!\n\n-1\n-0.5\n0.5\n0.5\nu\nv\nFigure 16.4: An orthonormal set of vectors.\nOrthonormality\nTwo vectors v ∈ Rm and w ∈ Rm are said to be orthonormal to each other if they are orthogonal\nto each other and each has unit length, i.e.\nT\nv w = 0 and IvI = IwI = 1 .\nExample 16.1.11 orthonormality\nTwo vectors\n-2\nu = √\nand v = √\nare orthonormal to each other. It is straightforward to verify that they are orthogonal to each other\nT\nT\n-2\n-2\nT\nu v = √\n√\n=\n= 0\nand that each of them have unit length\nIuI =\n((-2)2 + 12) = 1\nIvI =\n((1)2 + 22) = 1 .\nFigure 16.4 shows that the vectors are orthogonal and have unit length in the usual geometric\nsense.\n·\n16.1.3\nLinear Combinations\nLet us consider a set of n m-vectors\nv 1 ∈ Rm , v 2 ∈ Rm , . . . , v n ∈ Rm .\nA linear combination of the vectors is given by\nn\nm\nw =\nαj vj ,\nj=1\nwhere α1, α2, . . . , αn is a set of real numbers, and each vj is an m-vector.\n\nr\nr\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\nExample 16.1.12 linear combination of vectors\nT\nT\nT\nLet us consider three vectors in R2 , v\n=\n-4\n, v\n=\n3 6\n, and v\n=\n. A\nlinear combination of the vectors, with α1 = 1, α2 = -2, and α3 = 3, is\nm\n-4\nαj vj = 1 ·\n+ (-2) ·\n+ 3 ·\nw =\nj=1\n-4\n-6\n-10\n=\n+\n+\n=\n.\n-12\nAnother example of linear combination, with α1 = 1, α2 = 0, and α3 = 0, is\nj=1\nNote that a linear combination of a set of vectors is simply a weighted sum of the vectors.\n·\nLinear Independence\nA set of n m-vectors are linearly independent if\nm\n-4\n-4\nαj vj = 1 ·\n+ 0 ·\n+ 0 ·\n=\nw =\n.\nn\nαj vj = 0 only if α1 = α2 = · · · = αn = 0 .\nj=1\nOtherwise, the vectors are linearly dependent.\nm\nExample 16.1.13 linear independence\nLet us consider four vectors,\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n⎜\n⎝ 0 ⎟\n⎠ ,\nw = ⎜\n⎝ 0 ⎟\n⎠ ,\nw = ⎜\n⎝ 1 ⎟\n⎠ , and\nw = ⎜\n⎝ 0 ⎟\n⎠\nw =\n.\n⎞\n⎛\n⎞\n⎛\n4} is linearly dependent because\nThe set of vectors {w , w , w\n⎞\n⎛\n⎞\n⎛\n⎜\n⎝ 0 ⎟\n⎠ + · ⎜\n⎝ 0 ⎟\n⎠ - 1 · ⎜\n⎝ 0 ⎟\n⎠ = ⎜\n⎝ 0 ⎟\n⎠\n2 - 1 · w 4 = 1 ·\n1 · w +\n;\n· w\nthe linear combination with the weights {1, 5/3, -1} produces the zero vector. Note that the choice\nof the weights that achieves this is not unique; we just need to find one set of weights to show that\nthe vectors are not linearly independent (i.e., are linearly dependent).\nOn the other hand, the set of vectors {w , w , w3} is linearly independent. Considering a linear\ncombination,\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\nα1\n+ α2\n+ α3\n= α1\nw\nw\nw\n· ⎜\n⎝ 0 ⎟\n⎠ + α2 · ⎜\n⎝ 0 ⎟\n⎠ + α3 · ⎜\n⎝ 1 ⎟\n⎠ = ⎜\n⎝ 0 ⎟\n⎠ ,\n\nwe see that we must choose α1 = 0 to set the first component to 0, α2 = 0 to set the third\ncomponent to 0, and α3 = 0 to set the second component to 0. Thus, only way to satisfy the\nequation is to choose the trivial set of weights, {0, 0, 0}. Thus, the set of vectors {w , w , w3} is\nlinearly independent.\n·\nBegin Advanced Material\nVector Spaces and Bases\nGiven a set of n m-vectors, we can construct a vector space, V , given by\nV = span({v , v , . . . , v n}) ,\nwhere\n⎧\n⎨\n⎫\n⎬\nn\n, v , . . . , v\nv ∈ Rm : v =\nαk\nm\nv k, αk ∈ Rn\nn}) =\nspan({v\n⎩\n⎭\nk=1\nn\n= space of vectors which are linear combinations of v , v , . . . , v .\nIn general we do not require the vectors {v , . . . , vn} to be linearly independent. When they are\nlinearly independent, they are said to be a basis of the space. In other words, a basis of the vector\nspace V is a set of linearly independent vectors that spans the space. As we will see shortly in our\nexample, there are many bases for any space. However, the number of vectors in any bases for a\ngiven space is unique, and that number is called the dimension of the space. Let us demonstrate\nthe idea in a simple example.\nExample 16.1.14 Bases for a vector space in R3\nLet us consider a vector space V spanned by vectors\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\nv = ⎜\n⎝ 2 ⎟\n⎠\nv = ⎜\n⎝ 1 ⎟\n⎠\nand\nv = ⎜\n⎝ 1 ⎟\n⎠ .\nBy definition, any vector x ∈ V is of the form\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\nα1 + 2α2\nx = α1 v + α2 v + α3 v = α1 ⎜\n⎝ 2 ⎟\n⎠ + α2 ⎜\n⎝ 1 ⎟\n⎠ + α3 ⎜\n⎝ 1 ⎟\n⎠ = ⎜\n⎝ 2α1 + α2 + α3 ⎟\n⎠ .\nClearly, we can express any vector of the form x = (x1, x2, 0)T by choosing the coefficients α1 ,\nα2, and α3 judiciously. Thus, our vector space consists of vectors of the form (x1, x2, 0)T, i.e., all\nvectors in R3 with zero in the third entry.\nWe also note that the selection of coefficients that achieves (x1, x2, 0)T is not unique, as it\nrequires solution to a system of two linear equations with three unknowns. The non-uniqueness of\nthe coefficients is a direct consequence of {v , v , v3} not being linearly independent. We can easily\nverify the linear dependence by considering a non-trivial linear combination such as\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n2v 1 - v 2 - 3v 3 = 2 · ⎜\n⎝ 2 ⎟\n⎠ - 1 · ⎜\n⎝ 1 ⎟\n⎠ - 3 · ⎜\n⎝ 1 ⎟\n⎠ = ⎜\n⎝ 0 ⎟\n⎠ .\n\nBecause the vectors are not linearly independent, they do not form a basis of the space.\nTo choose a basis for the space, we first note that vectors in the space V are of the form\n(x1, x2, 0)T . We observe that, for example,\n⎞\n⎛\n⎞\n⎛\nw = ⎜\n⎝ 0 ⎟\n⎠\nand\nw = ⎜\n⎝ 1 ⎟\n⎠\nwould span the space because any vector in V -- a vector of the form (x1, x2, 0)T -- can be expressed\nas a linear combination,\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\nα1\nx1\n⎜\n⎝\n⎟\n⎠\n= α1 w + α2 w = α1 ⎜\n⎝ 0 ⎟\n⎠ + α2 ⎜\n⎝ 0 ⎟\n⎠ = ⎜\n⎝ α2 ⎟\n⎠ ,\nx2\nby choosing α1 = x1 and α2 = x . Moreover, w1 and w2 are linearly independent. Thus, {w , w2} is\na basis for the space V . Unlike the set {v , v , v3} which is not a basis, the coefficients for {w , w2}\nthat yields x ∈ V is unique. Because the basis consists of two vectors, the dimension of V is two.\nThis is succinctly written as\ndim(V ) = 2 .\nBecause a basis for a given space is not unique, we can pick a different set of vectors. For\nexample,\n⎞\n⎛\n⎞\n⎛\nz = ⎜\n⎝ 2 ⎟\n⎠\nand\nz = ⎜\n⎝ 1 ⎟\n⎠ ,\nis also a basis for V . Since z\nis not a constant multiple of z2, it is clear that they are linearly\nindependent. We need to verify that they span the space V . We can verify this by a direct\nargument,\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\nα1 + 2α2\nx1\n⎜\n⎝\n⎟\n⎠\n= α1 z + α2 z = α1 ⎜\n⎝ 2 ⎟\n⎠ + α2 ⎜\n⎝ 1 ⎟\n⎠ = ⎜\n⎝ 2α1 + α2 ⎟\n⎠ .\nx2\nWe see that, for any (x1, x2, 0)T, we can find the linear combination of z1 and z2 by choosing the\ncoefficients α1 = (-x1 + 2x2)/3 and α2 = (2x1 - x2)/3. Again, the coefficients that represents x\nusing {z , z2} are unique.\nFor the space V , and for any given basis, we can find a unique set of two coefficients to represent\nany vector x ∈ V . In other words, any vector in V is uniquely described by two coefficients, or\nparameters. Thus, a basis provides a parameterization of the vector space V . The dimension of the\nspace is two, because the basis has two vectors, i.e., the vectors in the space are uniquely described\nby two parameters.\n·\nWhile there are many bases for any space, there are certain bases that are more convenient to\nwork with than others. Orthonormal bases -- bases consisting of orthonormal sets of vectors --\nare such a class of bases. We recall that two set of vectors are orthogonal to each other if their\n\ninner product vanishes. In order for a set of vectors {v , . . . , vn} to be orthogonal, the vectors must\nsatisfy\nIn other words, the vectors are mutually orthogonal. An orthonormal set of vectors is an orthogonal\nset of vectors with each vector having norm unity. That is, the set of vectors {v , . . . , vn} is mutually\northonormal if\nWe note that an orthonormal set of vectors is linearly independent by construction, as we now\nprove.\nProof. Let {v , . . . , vn} be an orthogonal set of (non-zero) vectors. By definition, the set of vectors\nis linearly independent if the only linear combination that yields the zero vector corresponds to all\ncoefficients equal to zero, i.e.\nα1 1\n· + αn\nα1\nv + · ·\nv n = 0\n⇒\n= · · · = αn = 0 .\nTo verify this indeed is the case for any orthogonal set of vectors, we perform the inner product of\nthe linear combination with v1, . . . , vn to obtain\ni)T(α1 1\n· + αn\ni)T 1\ni)T i\ni)T n\n(v\nv + · ·\nv n) = α1(v\nv + · · · + αi(v\nv + · · · + αn(v\nv\n= αiIv iI2 ,\ni = 1, . . . , n .\nNote that (vi)Tvj = 0, i = j, due to orthogonality. Thus, setting the linear combination equal to\nzero requires\nαiIv iI2 = 0,\ni = 1, . . . , n .\nIn other words, αi = 0 or IviI2 = 0 for each i. If we restrict ourselves to a set of non-zero vectors,\nthen we must have αi = 0. Thus, a vanishing linear combination requires α1 = · · · = αn = 0, which\nis the definition of linear independence.\nBecause an orthogonal set of vectors is linearly independent by construction, an orthonormal\nbasis for a space V is an orthonormal set of vectors that spans V . One advantage of using an\northonormal basis is that finding the coefficients for any vector in V is straightforward. Suppose,\nwe have a basis {v , . . . , vn} and wish to find the coefficients α1, . . . , αn that results in x ∈ V . That\nis, we are looking for the coefficients such that\ni\nn\nx = α1 v + · · · + αi v + · · · + αn v\n.\nTo find the i-th coefficient αi, we simply consider the inner product with vi, i.e.\ni\ni)T\n(v\nx = (v i)T(α1 v + · · · + αi v + · · · + αn v n)\ni)T\ni)T\ni)T\ni\nn\n= α1(v\nv + · · · + αi(v\nv + · · · + αn(v\nv\ni\n= αi(v i)T v = αiIv iI2 = αi ,\ni = 1, . . . , n ,\nwhere the last equality follows from IviI2 = 1. That is, αi = (vi)Tx, i = 1, . . . , n. In particular, for\nan orthonormal basis, we simply need to perform n inner products to find the n coefficients. This\nis in contrast to an arbitrary basis, which requires a solution to an n × n linear system (which is\nsignificantly more costly, as we will see later).\n(vi)Tvj = 0,\ni = j .\n(vi)Tvj = 0,\ni = j\n∥vi∥= (vi)Tvi = 1,\ni = 1, . . . , n .\n\nExample 16.1.15 Orthonormal Basis\nLet us consider the space vector space V spanned by\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\nv = ⎜\n⎝ 2 ⎟\n⎠\nv = ⎜\n⎝ 1 ⎟\n⎠\nand\nv = ⎜\n⎝ 1 ⎟\n⎠ .\nRecalling every vector in V is of the form (x1, x2, 0)T, a set of vectors\n⎞\n⎛\n⎞\n⎛\nw = ⎜\n⎝ 0 ⎟\n⎠\nand\nw = ⎜\n⎝ 1 ⎟\n⎠\nforms an orthonormal basis of the space. It is trivial to verify they are orthonormal, as they are\northogonal, i.e., (w1)Tw2 = 0, and each vector is of unit length Iw1I = Iw2I = 1. We also see that\nwe can express any vector of the form (x1, x2, 0)T by choosing the coefficients α1 = x1 and α2 = x2.\nThus, {w , w2} spans the space. Because the set of vectors spans the space and is orthonormal\n(and hence linearly independent), it is an orthonormal basis of the space V .\nAnother orthonormal set of basis is formed by\n⎞\n⎛\n⎞\n⎛\nw = 1\n√ ⎜\n⎝\n2 ⎟\n⎠\nand\nw =\n⎜\n⎝ -1 ⎟\n⎠ .\n√\n⎞\n⎛\nWe can easily verify that they are orthogonal and each has a unit length. The coefficients for an\narbitrary vector x = (x1, x2, 0)T ∈ V represented in the basis {w\n2} are\n, w\nx1\n⎜\n⎝\n⎟\n⎠ =\n1)T\nα1 = (w\n√\n√ (x1 + 2x2)\nx =\nx2\n⎞\n⎛\nx1\n2 -1 0\n⎜\n⎝\n⎟\n⎠ =\n2)T\nα2 = (w\n√\n√ (2x1 - x2) .\nx =\nx2\n·\nEnd Advanced Material\n16.2\nMatrix Operations\n16.2.1\nInterpretation of Matrices\nRecall that a matrix A ∈ Rm×n consists of m rows and n columns for the total of m · n entries,\n⎞\n⎛\nA =\n⎜\n⎜\n⎜\n⎜\n⎝\nA11\nA12\n· · ·\nA1n\nA21\nA22\n· · ·\nA2n\n. . .\n. . .\n. . .\n. . .\nAm1 Am2 · · ·\nAmn\n⎟\n⎟\n⎟\n⎟\n⎠\n.\nThis matrix can be interpreted in a column-centric manner as a set of n column m-vectors. Alter\nnatively, the matrix can be interpreted in a row-centric manner as a set of m row n-vectors. Each\nof these interpretations is useful for understanding matrix operations, which is covered next.\n\n16.2.2\nMatrix Operations\nThe first matrix operation we consider is multiplication of a matrix A ∈ Rm1×n1 by a scalar α ∈ R.\nThe operation yields\nB = αA ,\nwhere each entry of B ∈ Rm1×n1 is given by\nBij = αAij ,\ni = 1, . . . , m1, j = 1, . . . , n1 .\nSimilar to the multiplication of a vector by a scalar, the multiplication of a matrix by a scalar scales\neach entry of the matrix.\nThe second operation we consider is addition of two matrices A ∈ Rm1×n1 and B ∈ Rm2×n2 .\nThe addition yields\nC = A + B ,\nwhere each entry of C ∈ Rm1×n1 is given by\nCij = Aij + Bij ,\ni = 1, . . . , m1, j = 1, . . . , n1 .\nIn order for addition of two matrices to make sense, the matrices must have the same dimensions,\nm1 and n1.\nWe can combine the scalar scaling and addition operation. Let A ∈ Rm1×n1 , B ∈ Rm1×n1 , and\nα ∈ R. Then, the operation\nC = A + αB\nyields a matrix C ∈ Rm1×n1 whose entries are given by\nCij = Aij + αBij ,\ni = 1, . . . , m1, j = 1, . . . , n1 .\nNote that the scalar-matrix multiplication and matrix-matrix addition operations treat the matrices\nas arrays of numbers, operating entry by entry. This is unlike the matrix-matrix prodcut, which is\nintroduced next after an example of matrix scaling and addition.\nExample 16.2.1 matrix scaling and addition\nConsider the following matrices and scalar,\n⎛\n√\n⎞\n⎛\n⎞\n⎜\n⎝ -4\n9 ⎟\n⎠ , B = ⎜\n⎝ 2 -3 ⎟\n⎠\nA =\n, and α = 2 .\nπ\n-3\nπ -4\nThen,\n⎛\n√\n⎛\n⎞\n⎛\n⎞\n⎞\n√\n3 + 4\n⎜\n⎝ -4\n9 ⎟\n⎠ + 2 · ⎜\n⎝ 2 -3 ⎟\n⎠ = ⎜\n⎝ 0\n⎟\n⎠\nC = A + αB =\n.\nπ\n-3\nπ -4\n3π\n-11\n·\n\n!\n\n!\n\n!\n\n!\nMatrix-Matrix Product\nLet us consider two matrices A ∈ Rm1×n1 and B ∈ Rm2×n2 with n1 = m2. The matrix-matrix\nproduct of the matrices results in\nC = AB\nwith\nn1\nCij =\nAikBkj ,\ni = 1, . . . , m1, j = 1, . . . , n2 .\nk=1\nBecause the summation applies to the second index of A and the first index of B, the number of\ncolumns of A must match the number of rows of B: n1 = m2 must be true. Let us consider a few\nexamples.\nExample 16.2.2 matrix-matrix product\nLet us consider matrices A ∈ R3×2 and B ∈ R2×3 with\nm\n⎞\n⎛\n3 ⎟\n⎠\n3 -5\nand B =\n.\n0 -1\nA = ⎜\n⎝ -4\n-3\nThe matrix-matrix product yields\n⎞\n⎛\n⎞\n⎛\n-8\n3 -5\n⎜\n⎝ -4\n9 ⎟\n⎠\n= ⎜\n⎝ 1\n-12 11 ⎟\n⎠\nC = AB =\n,\n0 -1\n-3\n-3\nwhere each entry is calculated as\nm\nC11 =\nA1kBk1 = A11B11 + A12B21 = 1 · 2 + 3 · 1 = 5\nk=1\nm\nC12 =\nA1kBk2 = A11B12 + A12B22 = 1 · 3 + 3 · 0 = 3\nk=1\nm\nC13 =\nA1kBk3 = A11B13 + A12B23 = 1 · -5 + 3 · (-1) = -8\nk=1\nm\nC21 =\nA2kBk1 = A21B11 + A22B21 = -4 · 2 + 9 · 1 = 1\nk=1\n. . .\nm\nC33 =\nA3kBk3 = A31B13 + A32B23 = 0 · -5 + (-3) · (-1) = 3 .\nk=1\nNote that because A ∈ R3×2 and B ∈ R2×3 , C ∈ R3×3 .\nThis is very different from\n⎞\n⎛\n3 -5\n⎜\n⎝\n⎟\n⎠\n-10 48\n=\n,\nD = BA =\n-4\n0 -1\n-3\n\nwhere each entry is calculated as\nD11 =\nA1kBk1 = B11A11 + B12A21 + B13A31 = 2 · 1 + 3 · (-4) + (-5) · 0 = -10\nk=1\n. . .\nm\nD22 =\nA2kBk2 = B21A12 + B22A22 + B23A32 = 1 · 3 + 0 · 9 + (-1) · (-3) = 6 .\nk=1\nNote that because B ∈ R2×3 and A ∈ R3×2 , D ∈ R2×2 . Clearly, C = AB = BA = D; C and D in\nfact have different dimensions. Thus, matrix-matrix product is not commutative in general, even\nif both AB and BA make sense.\n·\nExample 16.2.3 inner product as matrix-matrix product\nThe inner product of two vectors can be considered as a special case of matrix-matrix product. Let\nm\n⎞\n⎛\n⎞\n⎛\n-2\nv = ⎜\n⎝ 3 ⎟\n⎠\nand w = ⎜\n⎝ 0 ⎟\n⎠ .\nT ∈ R1×3\nWe have v, w ∈ R3(= R3×1). Taking the transpose, we have v\n. Noting that the second\ndimension of vT and the first dimension of w match, we can perform matrix-matrix product,\n⎞\n⎛\n-2\nβ\nT\n= v w =\n⎜\n⎝ 0 ⎟\n⎠ = 1 · (-2) + 3 · 0 + 6 · 4 = 22 .\n·\nExample 16.2.4 outer product\nThe outer product of two vectors is yet another special case of matrix-matrix product. The outer\nproduct B of two vectors v ∈ Rm and w ∈ Rm is defined as\nT\nB = vw .\nT\nBecause v ∈ Rm×1 and wT ∈ R1×m, the matrix-matrix product vw\nis well-defined and yields as\nm × m matrix.\nAs in the previous example, let\n⎞\n⎛\n⎞\n⎛\n-2\nv = ⎜\n⎝ 3 ⎟\n⎠\nand w = ⎜\n⎝ 0 ⎟\n⎠ .\nThe outer product of two vectors is given by\n⎞\n⎛\n⎞\n⎛\n-2\n-2 -6 -12\nT\nwv = ⎜\n⎝ 0 ⎟\n⎠\n= ⎜\n⎝ 0\n⎟\n⎠ .\nClearly, β = vTw = wvT = B, as they even have different dimensions.\n\n·\nIn the above example, we saw that AB = BA in general. In fact, AB might not even be allowed\neven if BA is allowed (consider A ∈ R2×1 and B ∈ R3×2). However, although the matrix-matrix\nproduct is not commutative in general, the matrix-matrix product is associative, i.e.\nABC = A(BC) = (AB)C .\nMoreover, the matrix-matrix product is also distributive, i.e.\n(A + B)C = AC + BC .\nProof. The associative and distributive properties of matrix-matrix product is readily proven from\nits definition. For associativity, we consider ij-entry of the m1 × n3 matrix A(BC), i.e.\n⎛\n⎞\nn1\nn1\nn2\nn1\nn2\nn2\nn1\nm\nm\nm\nm m\nm m\n⎝\n⎠ =\n(A(BC))ij =\nAik(BC)kj =\nAik\nBklClj\nAikBklClj =\nAikBklClj\nk=1\nk=1\nl=1\nk=1 l=1\nl=1 k=1\n⎛\n⎞\nn2\nn1\nn2\nm\nm\nm\n=\n⎝\nAikBkl ⎠ Clj =\n(AB)ilClj = ((AB)C)ij ,\n∀ i, j .\nl=1\nk=1\nl=1\nSince the equality (A(BC))ij = ((AB)C)ij holds for all entries, we have A(BC) = (AB)C.\nThe distributive property can also be proven directly. The ij-entry of (A+B)C can be expressed\nas\nn1\nn1\nn1\nm\nm\nm\n((A + B)C)ij =\n(A + B)ikCkj =\n(Aik + Bik)Ckj =\n(AikCkj + BikCkj )\nk=1\nk=1\nk=1\nn1\nn1\nm\nm\n=\nAikCkj +\nBikCkj = (AC)ij + (BC)ij ,\n∀ i, j .\nk=1\nk=1\nAgain, since the equality holds for all entries, we have (A + B)C = AC + BC.\nAnother useful rule concerning matrix-matrix product and transpose operation is\n(AB)T = BTAT .\nThis rule is used very often.\nProof. The proof follows by checking the components of each side. The left-hand side yields\nn1\nm\n((AB)T)ij = (AB)ji =\nAjkBki .\nk=1\nThe right-hand side yields\nn1\nn1\nn1\nm\nm\nm\n(BTAT)ij =\n(BT)ik(AT)kj =\nBkiAjk =\nAjkBki .\nk=1\nk=1\nk=1\n\nThus, we have\n((AB)T)ij = (BTAT)ij ,\ni = 1, . . . , n2, j = 1, . . . , m1 .\n16.2.3\nInterpretations of the Matrix-Vector Product\nLet us consider a special case of the matrix-matrix product: the matrix-vector product. The\nspecial case arises when the second matrix has only one column. Then, with A ∈ Rm×n and\nw = B ∈ Rn×1 = Rn, we have\nC = AB ,\nwhere\nn\nn\nCij =\nAikBkj =\nAikwk,\ni = 1, . . . , m1, j = 1 .\nk=1\nk=1\nSince C ∈ Rm×1 = Rm, we can introduce v ∈ Rm and concisely write the matrix-vector product as\nm\nv = Aw ,\nwhere\nm\nm\nn\nvi =\nAikwk,\ni = 1, . . . , m .\nk=1\nExpanding the summation, we can think of the matrix-vector product as\nv1 = A11w1 + A12w2 + · · · + A1nwn\nv2 = A21w1 + A22w2 + · · · + A2nwn\n. . .\nvm = Am1w1 + Am2w2 + · · · + Amnwn .\nNow, we consider two different interpretations of the matrix-vector product.\nRow Interpretation\nThe first interpretation is the \"row\" interpretation, where we consider the matrix-vector multipli\ncation as a series of inner products. In particular, we consider vi as the inner product of i-th row\nof A and w. In other words, the vector v is computed entry by entry in the sense that\n⎞\n⎛\nAi1 Ai2 · · ·\nAin\n⎜\n⎜\n⎜\n⎜\n⎝\nw1\nw2 ⎟\n⎟\n⎟\n⎟\n⎠\ni = 1, . . . , m .\nvi =\n. . .\nwn\n,\n\nExample 16.2.5 row interpretation of matrix-vector product\nAn example of the row interpretation of matrix-vector product is\n⎞\n⎛\nT\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n⎟\n⎠ =\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎝\nT\nT\nT\n·\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎠\n=\n⎜\n⎜\n⎜\n⎝\nv =\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎠\n⎜\n⎝\n⎟\n⎟\n⎟\n⎠ .\nColumn Interpretation\nThe second interpretation is the \"column\" interpretation, where we consider the matrix-vector\nmultiplication as a sum of n vectors corresponding to the n columns of the matrix, i.e.\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\nA11\nA12\nA1n\nv =\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\nw1 +\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\nw2 + · · · +\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\nwn .\nA21\n. . .\nA22\n. . .\nA2n\n. . .\nAm1\nAm2\nAmn\nIn this case, we consider v as a linear combination of columns of A with coefficients w. Hence\nv = Aw is simply another way to write a linear combination of vectors: the columns of A are the\nvectors, and w contains the coefficients.\nExample 16.2.6 column interpretation of matrix-vector product\nAn example of the column interpretation of matrix-vector product is\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\nv =\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎠\n= 3 ·\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎠ + 2 ·\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎠ + 1 ·\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎠ =\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎠ .\n⎜\n⎝\n⎟\n⎠\nClearly, the outcome of the matrix-vector product is identical to that computed using the row\ninterpretation.\n·\nLeft Vector-Matrix Product\nWe now consider another special case of the matrix-matrix product: the left vector-matrix product.\nThis special case arises when the first matrix only has one row. Then, we have A ∈ R1×m and\nT\nB ∈ Rm×n . Let us denote the matrix A, which is a row vector, by w . Clearly, w ∈ Rm, because\nT ∈ R1×m\nw\n. The left vector-matrix product yields\nv = w TB ,\nwhere\nm\nm\nvj =\nwkBkj ,\nj = 1, . . . , n .\nk=1\n\n!\n\n!\nThe resultant vector v is a row vector in R1×n . The left vector-matrix product can also be inter\npreted in two different manners. The first interpretation considers the product as a series of dot\nproducts, where each entry vj is computed as a dot product of w with the j-th column of B, i.e.\n⎞\n⎛\nvj =\nw1 w2 · · ·\nwm\n⎜\n⎜\n⎜\n⎜\n⎝\nB1j\nB2j\n. . .\nBmj\n⎟\n⎟\n⎟\n⎟\n⎠\n, j = 1, . . . , n .\nThe second interpretation considers the left vector-matrix product as a linear combination of rows\nof B, i.e.\nv = w1\nB11 B12 · · ·\nB1n\n+ w2\nB21 B22 · · ·\nB2n\n+ · · · + wm\nBm1 Bm2 · · ·\nBmn\n.\n16.2.4\nInterpretations of the Matrix-Matrix Product\nSimilar to the matrix-vector product, the matrix-matrix product can be interpreted in a few different\nways. Throughout the discussion, we assume A ∈ Rm1×n1 and B ∈ Rn1×n2 and hence C = AB ∈\nRm1×n2 .\nMatrix-Matrix Product as a Series of Matrix-Vector Products\nOne interpretation of the matrix-matrix product is to consider it as computing C one column at a\ntime, where the j-th column of C results from the matrix-vector product of the matrix A with the\nj-th column of B, i.e.\nC·j = AB·j ,\nj = 1, . . . , n2 ,\nwhere C·j refers to the j-th column of C. In other words,\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n⎜\n⎜\n⎜\n⎜\n⎝\nC1j\nC2j\n. . .\n⎟\n⎟\n⎟\n⎟\n⎠\n=\n⎜\n⎜\n⎜\n⎜\n⎝\nA11\nA12\n· · ·\nA1n1\nA21\nA22\n· · ·\nA2n1\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\nB1j\nB2j\n. . .\n⎟\n⎟\n⎟\n⎟\n⎠\n, j = 1, . . . , n2 .\nCm1j\nAm11 Am12 · · ·\nAm1n1\nBn1j\nExample 16.2.7 matrix-matrix product as a series of matrix-vector products\nLet us consider matrices A ∈ R3×2 and B ∈ R2×3 with\n⎞\n⎛\nA = ⎜\n⎝ -4\n9 ⎟\n⎠\n3 -5\nand B =\n.\n0 -1\n-3\nThe first column of C = AB ∈ R3×3 is given by\n⎞\n⎛\n⎞\n⎛\nC·1 = AB·1 = ⎜\n⎝ -4\n9 ⎟\n⎠\n= ⎜\n⎝ 1 ⎟\n⎠ .\n-3\n-3\n\n!\n\n!\n\nSimilarly, the second and third columns are given by\n⎞\n⎛\n⎞\n⎛\n⎜\n⎝ -4\n9 ⎟\n⎠\n=\n⎜\n⎝ -12 ⎟\n⎠\nC·2 = AB·2 =\n-3\nand\n⎞\n⎛\n⎞\n⎛\n-8\nC·3 = AB·3 = ⎜\n⎝ -4\n9 ⎟\n⎠\n-5\n= ⎜\n⎝ 11 ⎟\n⎠ .\n-1\n-3\nPutting the columns of C together\n⎞\n⎛\n-8\nC =\nC·1 C·2 C·3\n= ⎜\n⎝ 1\n-12 11 ⎟\n⎠ .\n-3\n·\nMatrix-Matrix Product as a Series of Left Vector-Matrix Products\nIn the previous interpretation, we performed the matrix-matrix product by constructing the re\nsultant matrix one column at a time. We can also use a series of left vector-matrix products to\nconstruct the resultant matrix one row at a time. Namely, in C = AB, the i-th row of C results\nfrom the left vector-matrix product of i-th row of A with the matrix B, i.e.\nCi· = Ai·B,\ni = 1, . . . , m1 ,\nwhere Ci· refers to the i-th row of C. In other words,\n⎞\n⎛\nCi1 · · ·\nCin1\n=\nAi1 · · ·\nAin1\n⎜\n⎜\n⎝\nB11\n· · ·\nB1n2\n.\n.\n.\n.\n.\n.\n.\n.\n.\nBm21 · · ·\nBm2n2\n⎟\n⎟\n⎠ , i = 1, . . . , m1 .\n16.2.5\nOperation Count of Matrix-Matrix Product\nMatrix-matrix product is ubiquitous in scientific computing, and significant effort has been put\ninto efficient performance of the operation on modern computers. Let us now count the number\nof additions and multiplications required to compute this product. Consider multiplication of\nA ∈ Rm1×n1 and B ∈ Rn1×n2 . To compute C = AB, we perform\nm\nn1\nCij =\nAikBkj ,\ni = 1, . . . , m1, j = 1, . . . , n2 .\nk=1\nComputing each Cij requires n1 multiplications and n1 additions, yielding the total of 2n1 opera\ntions. We must perform this for m1n2 entries in C. Thus, the total operation count for computing\nC is 2m1n1n2. Considering the matrix-vector product and the inner product as special cases of\nmatrix-matrix product, we can summarize how the operation count scales.\n\nOperation\nSizes\nOperation count\nMatrix-matrix\nm1 = n1 = m2 = n2 = n\n2n3\nMatrix-vector\nm1 = n1 = m2 = n, n2 = 1\n2n2\nInner product\nn1 = m1 = n, m1 = n2 = 1\n2n\nThe operation count is measured in FLoating Point Operations, or FLOPs. (Note FLOPS is\ndifferent from FLOPs: FLOPS refers to FLoating Point Operations per Second, which is a \"speed\"\nassociated with a particular computer/hardware and a particular implementation of an algorithm.)\n16.2.6\nThe Inverse of a Matrix (Briefly)\nWe have now studied the matrix vector product, in which, given a vector x ∈ Rn, we calculate a\nnew vector b = Ax, where A ∈ Rn×n and hence b ∈ Rn . We may think of this as a \"forward\"\nproblem, in which given x we calculate b = Ax. We can now also ask about the corresponding\n\"inverse\" problem: given b, can we find x such that Ax = b? Note in this section, and for reasons\nwhich shall become clear shortly, we shall exclusively consider square matrices, and hence we set\nm = n.\nTo begin, let us revert to the scalar case. If b is a scalar and a is a non-zero scalar, we know\nthat the (very simple linear) equation ax = b has the solution x = b/a. We may write this more\n-1\nsuggestively as x = a-1b since of course a\n= 1/a. It is important to note that the equation\nax = b has a solution only if a is non-zero; if a is zero, then of course there is no x such that ax = b.\n(This is not quite true: in fact, if b = 0 and a = 0 then ax = b has an infinity of solutions -- any\nvalue of x. We discuss this \"singular but solvable\" case in more detail in Unit V.)\nWe can now proceed to the matrix case \"by analogy.\" The matrix equation Ax = b can of course\nbe viewed as a system of linear equations in n unknowns. The first equation states that the inner\nproduct of the first row of A with x must equal b1; in general, the ith equation states that the inner\nproduct of the ith row of A with x must equal bi. Then if A is non-zero we could plausibly expect\nthat x = A-1b. This statement is clearly deficient in two related ways: what we do mean when we\nsay a matrix is non-zero? and what do we in fact mean by A-1 .\nAs regards the first question, Ax = b will have a solution when A is non-singular: non-singular is\nthe proper extension of the scalar concept of \"non-zero\" in this linear systems context. Conversely,\nif A is singular then (except for special b) Ax = b will have no solution: singular is the proper\nextension of the scalar concept of \"zero\" in this linear systems context. How can we determine if\na matrix A is singular? Unfortunately, it is not nearly as simple as verifying, say, that the matrix\nconsists of at least one non-zero entry, or contains all non-zero entries.\nThere are variety of ways to determine whether a matrix is non-singular, many of which may\nonly make good sense in later chapters (in particular, in Unit V): a non-singular n × n matrix A\nhas n independent columns (or, equivalently, n independent rows); a non-singular n × n matrix\nA has all non-zero eigenvalues; a non-singular matrix A has a non-zero determinant (perhaps this\ncondition is closest to the scalar case, but it is also perhaps the least useful); a non-singular matrix\nA has all non-zero pivots in a (partially pivoted) \"LU\" decomposition process (described in Unit\nV). For now, we shall simply assume that A is non-singular. (We should also emphasize that in\nthe numerical context we must be concerned not only with matrices which might be singular but\nalso with matrices which are \"almost\" singular in some appropriate sense.) As regards the second\nquestion, we must first introduce the identity matrix, I.\nLet us now define an identity matrix. The identity matrix is a m × m square matrix with ones\non the diagonal and zeros elsewhere, i.e.\n\n1,\ni = j\nIij =\n.\n0,\ni\nj\n=\n\n!\n\n!\n\n!\n\nIdentity matrices in R1 , R2, and R3 are\n⎞\n⎛\n⎜\n⎝ 0\n0 ⎟\n⎠\nI =\n1 , I =\n,\nand I =\n.\nThe identity matrix is conventionally denoted by I. If v ∈ Rm, the i-th entry of Iv is\nm\n(Iv)i =\nIikvk\nk=1\n\n= ((\n·\n· · +\nIi1v1 + · · +\nIi,i+1vi+1 + ·\nIi,i-1vi-1 + Iiivi +\nIimvm\n= vi,\ni = 1, . . . , m .\nTI\nT\nSo, we have Iv = v. Following the same argument, we also have v\n= v . In essence, I is the\nm-dimensional version of \"one.\"\nWe may then define A-1 as that (unique) matrix such that A-1A = I. (Of course in the scalar\n-1\n-1\n-1\ncase, this defines a\nas the unique scalar such that a\na = 1 and hence a\n= 1/a.) In fact,\nA-1A = I and also AA-1 = I and thus this is a case in which matrix multiplication does indeed\ncommute. We can now \"derive\" the result x = A-1b: we begin with Ax = b and multiply both sides\nby A-1 to obtain A-1Ax = A-1b or, since the matrix product is associative, x = A-1b. Of course\nthis definition of A-1 does not yet tell us how to find A-1: we shall shortly consider this question\nfrom a pragmatic Matlab perspective and then in Unit V from a more fundamental numerical\nlinear algebra perspective. We should note here, however, that the matrix inverse is very rarely\ncomputed or used in practice, for reasons we will understand in Unit V. Nevertheless, the inverse\ncan be quite useful for very small systems (n small) and of course more generally as an central\nm\nconcept in the consideration of linear systems of equations.\nExample 16.2.8 The inverse of a 2 × 2 matrix\nWe consider here the case of a 2 × 2 matrix A which we write as\nA =\na b\n.\nc d\nIf the columns are to be independent we must have a/b = c/d or (ad)/(bc) = 1 or ad - bc = 0 which\nin fact is the condition that the determinant of A is nonzero. The inverse of A is then given by\nd -b\nA-1 =\n.\nad - bc\n-c\na\nNote that this inverse is only defined if ad - bc = 0, and we thus see the necessity that A is non-\nsingular. It is a simple matter to show by explicit matrix multiplication that A-1A = AA-1 = I,\nas desired.\n·\n16.3\nSpecial Matrices\nLet us now introduce a few special matrices that we shall encounter frequently in numerical methods.\n\n!\n\n!\n\n16.3.1\nDiagonal Matrices\nA square matrix A is said to be diagonal if the off-diagonal entries are zero, i.e.\nAij = 0,\ni = j .\nExample 16.3.1 diagonal matrices\nExamples of diagonal matrix are\n⎞\n⎛\n= ⎜\n⎝ 0\n0 ⎟\n⎠ , and C =\n4 .\nA =\n,\nB\nThe identity matrix is a special case of a diagonal matrix with all the entries in the diagonal equal\nto 1. Any 1 × 1 matrix is trivially diagonal as it does not have any off-diagonal entries.\n·\n16.3.2\nSymmetric Matrices\nA square matrix A is said to be symmetric if the off-diagonal entries are symmetric about the\ndiagonal, i.e.\nAij = Aji,\ni = 1, . . . , m,\nj = 1, . . . , m .\nThe equivalent statement is that A is not changed by the transpose operation, i.e.\nAT = A .\nWe note that the identity matrix is a special case of symmetric matrix. Let us look at a few more\nexamples.\nExample 16.3.2 Symmetric matrices\nExamples of symmetric matrices are\n⎞\n⎛\nπ\n-2\n= ⎜\n⎝ π\n-1 ⎟\n⎠ , and C =\n4 .\nA =\n,\nB\n-2\n3 -1\nNote that any scalar, or a 1 × 1 matrix, is trivially symmetric and unchanged under transpose.\n·\n16.3.3\nSymmetric Positive Definite Matrices\nA m × m square matrix A is said to be symmetric positive definite (SPD) if it is symmetric and\nfurthermore satisfies\nv TAv > 0,\n∀ v ∈ Rm (v = 0) .\nBefore we discuss its properties, let us give an example of a SPD matrix.\n\n!\n\nExample 16.3.3 Symmetric positive definite matrices\nAn example of a symmetric positive definite matrix is\n-1\nA =\n.\n-1\nWe can confirm that A is symmetric by inspection. To check if A is positive definite, let us consider\nthe quadratic form\n⎛\n⎞\nm\nm\nm m\nq(v) ≡ v TAv =\nvi ⎝\nAij vj ⎠ =\nAij vivj\ni=1\nj=1\ni=1 j=1\n= A11v1\n2 + A12v1v2 + A21v2v1 + A22v2\n= A11v1\n2 + 2A12v1v2 + A22v 2 ,\nwhere the last equality follows from the symmetry condition A12 = A21. Substituting the entries\nof A,\n\nq(v) = v TAv = 2v1 - 2v1v2 + 2v2 = 2\nv1 - v2\n- v2 + v\n= 2\nv1 - v2\n+ v\n.\nBecause q(v) is a sum of two positive terms (each squared), it is non-negative. It is equal to zero\nonly if\n3 2\nv1 - v2 = 0 and\nv2 = 0 .\nThe second condition requires v2 = 0, and the first condition with v2 = 0 requires v1 = 0. Thus,\nwe have\nq(v) = v TAv > 0,\n∀ v ∈ R2 ,\nand vTAv = 0 if v = 0. Thus A is symmetric positive definite.\n·\nSymmetric positive definite matrices are encountered in many areas of engineering and science.\nThey arise naturally in the numerical solution of, for example, the heat equation, the wave equation,\nand the linear elasticity equations. One important property of symmetric positive definite matrices\nis that they are always invertible: A-1 always exists. Thus, if A is an SPD matrix, then, for any\nb, there is always a unique x such that\nAx = b .\nIn a later unit, we will discuss techniques for solution of linear systems, such as the one above. For\nnow, we just note that there are particularly efficient techniques for solving the system when the\nmatrix is symmetric positive definite.\n\n!\n\n!\n\n16.3.4\nTriangular Matrices\nTriangular matrices are square matrices whose entries are all zeros either below or above the\ndiagonal. A m × m square matrix is said to be upper triangular if all entries below the diagonal\nare zero, i.e.\nAij = 0,\ni > j .\nA square matrix is said to be lower triangular if all entries above the diagonal are zero, i.e.\nAij = 0,\nj > i .\nWe will see later that a linear system, Ax = b, in which A is a triangular matrix is particularly\neasy to solve. Furthermore, the linear system is guaranteed to have a unique solution as long as all\ndiagonal entries are nonzero.\nExample 16.3.4 triangular matrices\nExamples of upper triangular matrices are\n⎞\n⎛\n1 -2\nA =\nand B = ⎜\n⎝ 0\n1 ⎟\n⎠ .\n0 0 -3\nExamples of lower triangular matrices are\n⎛\n⎞\nC =\nand D = ⎜\n⎝ 7 -5 0 ⎟\n⎠ .\n-7\n·\nBegin Advanced Material\n16.3.5\nOrthogonal Matrices\nA m × m square matrix Q is said to be orthogonal if its columns form an orthonormal set. That\nis, if we denote the j-th column of Q by qj , we have\nQ =\nq1 q2 · · ·\nqm\n,\nwhere\nT\n1,\ni = j\nqi qj =\n.\n0,\ni = j\nOrthogonal matrices have a special property\nQTQ = I .\nThis relationship follows directly from the fact that columns of Q form an orthonormal set. Recall\nthat the ij entry of QTQ is the inner product of the i-th row of QT (which is the i-th column of\nQ) and the j-th column of Q. Thus,\nT\n1,\ni = j\n(QTQ)ij = qi qj =\n,\n0,\ni = j\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\nwhich is the definition of the identity matrix. Orthogonal matrices also satisfy\nQQT = I ,\nwhich in fact is a minor miracle.\nExample 16.3.5 Orthogonal matrices\nExamples of orthogonal matrices are\n√\n√\n2/ 5 -1/ 5\nQ =\n√\n√\nand I =\n.\n1/ 5\n2/ 5\nWe can easily verify that the columns the matrix Q are orthogonal to each other and each are of\nunit length. Thus, Q is an orthogonal matrix. We can also directly confirm that QTQ = QQT = I.\nSimilarly, the identity matrix is trivially orthogonal.\n·\nLet us discuss a few important properties of orthogonal matrices. First, the action by an\northogonal matrix preserves the 2-norm of a vector, i.e.\nIQxI2 = IxI2,\n∀ x ∈ Rm .\nThis follows directly from the definition of 2-norm and the fact that QTQ = I, i.e.\nT\nIQxI2\n2 = (Qx)T(Qx) = x TQTQx = x TIx = x x = IxI2\n2 .\nSecond, orthogonal matrices are always invertible. In fact, solving a linear system defined by an\northogonal matrix is trivial because\nQx = b\n⇒\nQTQx = QTb\n⇒\nx = QTb .\nIn considering linear spaces, we observed that a basis provides a unique description of vectors in\nV in terms of the coefficients. As columns of Q form an orthonormal set of m m-vectors, it can be\nthought of as an basis of Rm . In solving Qx = b, we are finding the representation of b in coefficients\nof {q1, . . . , qm}. Thus, the operation by QT (or Q) represent a simple coordinate transformation.\nLet us solidify this idea by showing that a rotation matrix in R2 is an orthogonal matrix.\nExample 16.3.6 Rotation matrix\nRotation of a vector is equivalent to representing the vector in a rotated coordinate system. A\nrotation matrix that rotates a vector in R2 by angle θ is\ncos(θ) - sin(θ)\nR(θ) =\n.\nsin(θ)\ncos(θ)\nLet us verify that the rotation matrix is orthogonal for any θ. The two columns are orthogonal\nbecause\n- sin(θ)\nT\nr1 r2 =\ncos(θ) sin(θ)\n= - cos(θ) sin(θ) + sin(θ) cos(θ) = 0,\n∀ θ .\ncos(θ)\nEach column is of unit length because\nIr1I2\n2 = (cos(θ))2 + (sin(θ))2 = 1\nIr2I2\n2 = (- sin(θ))2 + (cos(θ))2 = 1,\n∀ θ .\n\n!\n\n!\n\n!\nThus, the columns of the rotation matrix is orthonormal, and the matrix is orthogonal. This\nresult verifies that the action of the orthogonal matrix represents a coordinate transformation in\nR2 . The interpretation of an orthogonal matrix as a coordinate transformation readily extends to\nhigher-dimensional spaces.\n·\n16.3.6\nOrthonormal Matrices\nLet us define orthonormal matrices to be m × n matrices whose columns form an orthonormal set,\ni.e.\nQ =\nq1 q2 · · ·\nqn\n,\nwith\nT\n1,\ni = j\nqi qj =\n0,\ni = j .\nNote that, unlike an orthogonal matrix, we do not require the matrix to be square. Just like\northogonal matrices, we have\nQTQ = I ,\nwhere I is an n × n matrix. The proof is identical to that for the orthogonal matrix. However,\nQQT does not yield an identity matrix,\nQQT = I ,\nunless of course m = n.\nExample 16.3.7 orthonormal matrices\nAn example of an orthonormal matrix is\n⎛\n⎞\n√\n√\n1/ 6 -2/ 5\n√\n√\n⎜\n⎝\n⎟\n⎠\nQ =\n2/ 6\n1/ 5\n.\n√\n1/ 6\nWe can verify that QTQ = I because\n⎛\n⎞\n√\n√\n√\n√\n√\n1/ 6 -2/ 5\n√\n√\n1/ 6\n2/ 6\n1/ 6\n√\n=\n.\n⎜\n⎝\n⎟\n⎠\nQTQ =\n√\n2/ 6\n1/ 5\n√\n-2/ 5\n1/ 5\n1/ 6\nHowever, QQT = I because\n⎛\n⎞\n⎛\n⎞\n√\n√\n√\n√\n√\n1/ 6 -2/ 5\n√\n29/30\n-1/15 1/6\n-1/15\n13/15\n1/3\n√\n1/ 6\n2/ 6\n1/ 6\n√\n⎜\n⎝\n⎟\n⎠\n= ⎜\n⎝\n⎟\n⎠\nQQT =\n√\n2/ 6\n1/ 5\n.\n√\n-2/ 5\n1/ 5\n1/6\n1/3\n1/6\n1/ 6\n·\nEnd Advanced Material\n\n=\n\n(\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\nBegin Advanced Material\n16.4\nFurther Concepts in Linear Algebra\n16.4.1\nColumn Space and Null Space\nLet us introduce more concepts in linear algebra. First is the column space. The column space\nof matrix A is a space of vectors that can be expressed as Ax. From the column interpretation\nof matrix-vector product, we recall that Ax is a linear combination of the columns of A with the\nweights provided by x. We will denote the column space of A ∈ Rm×n by col(A), and the space is\ndefined as\ncol(A) = {v ∈ Rm : v = Ax for some x ∈ Rn} .\nThe column space of A is also called the image of A, img(A), or the range of A, range(A).\nThe second concept is the null space. The null space of A ∈ Rm×n is denoted by null(A) and is\ndefined as\nnull(A) = {x ∈ Rn : Ax = 0} ,\ni.e., the null space of A is a space of vectors that results in Ax = 0. Recalling the column\ninterpretation of matrix-vector product and the definition of linear independence, we note that the\ncolumns of A must be linearly dependent in order for A to have a non-trivial null space. The null\nspace defined above is more formally known as the right null space and also called the kernel of A,\nker(A).\nExample 16.4.1 column space and null space\nLet us consider a 3 × 2 matrix\n⎞\n⎛\nA = ⎜\n⎝ 1\n0 ⎟\n⎠ .\nThe column space of A is the set of vectors representable as Ax, which are\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n2x2\nAx = ⎜\n⎝ 1\n0 ⎟\n⎠\nx1\n= ⎜\n⎝ 1 ⎟\n⎠ · x1 + ⎜\n⎝ 0 ⎟\n⎠ · x2 = ⎜\n⎝\n⎟\n⎠ .\nx1\nx2\nSo, the column space of A is a set of vectors with arbitrary values in the first two entries and zero\nin the third entry. That is, col(A) is the 1-2 plane in R3 .\nBecause the columns of A are linearly independent, the only way to realize Ax = 0 is if x is the\nzero vector. Thus, the null space of A consists of the zero vector only.\nLet us now consider a 2 × 3 matrix\nB =\n-1\n.\nThe column space of B consists of vectors of the form\n⎞\n⎛\nx1\n⎜\n⎝\n⎟\n⎠\nx1 + 2x2\n=\n.\nBx =\nx2\n2 -1 3\n2x1 - x2 + 3x3\nx3\n\n!\n\nBy judiciously choosing x1, x2, and x3, we can express any vectors in R2 . Thus, the column space\nof B is entire R2, i.e., col(B) = R2 .\nBecause the columns of B are not linearly independent, we expect B to have a nontrivial null\nspace. Invoking the row interpretation of matrix-vector product, a vector x in the null space must\nsatisfy\nx1 + 2x2 = 0 and 2x1 - x2 + 3x3 = 0 .\nThe first equation requires x1 = -2x2. The combination of the first requirement and the second\nequation yields x3 = 3 x2. Thus, the null space of B is\n⎧\n⎪\n⎨\n⎫\n⎪\n⎬\n⎞\n⎛\n-2\n⎜\n⎝\n⎟\n⎠ : α ∈ R .\nnull(B) =\nα ·\n⎪\n⎩\n⎪\n⎭\n5/3\nThus, the null space is a one-dimensional space (i.e., a line) in R3 .\n·\n16.4.2\nProjectors\nAnother important concept -- in particular for least squares covered in Chapter 17 -- is the concept\nof projector. A projector is a square matrix P that is idempotent, i.e.\nP 2 = PP = P .\nLet v be an arbitrary vector in Rm . The projector P projects v, which is not necessary in col(P ),\nonto col(P ), i.e.\nw = P v ∈ col(P ),\n∀ v ∈ Rm .\nIn addition, the projector P does not modify a vector that is already in col(P ). This is easily\nverified because\nP w = P P v = P v = w,\n∀ w ∈ col(P ) .\nIntuitively, a projector projects a vector v ∈ Rm onto a smaller space col(P ). If the vector is already\nin col(P ), then it would be left unchanged.\nThe complementary projector of P is a projector I - P . It is easy to verify that I - P is a\nprojector itself because\n(I - P )2 = (I - P )(I - P ) = I - 2P + PP = I - P .\nIt can be shown that the complementary projector I - P projects onto the null space of P , null(P ).\nWhen the space along which the projector projects is orthogonal to the space onto which the\nprojector projects, the projector is said to be an orthogonal projector. Algebraically, orthogonal\nprojectors are symmetric.\nWhen an orthonormal basis for a space is available, it is particularly simple to construct an\northogonal projector onto the space. Say {q1, . . . , qn} is an orthonormal basis for a n-dimensional\nsubspace of Rm , n < m. Given any v ∈ Rm, we recall that\nT\nui = qi v\n\nis the component of v in the direction of qi represented in the basis {qi}. We then introduce the\nvector\nwi = qi(qi\nT v) ;\nthe sum of such vectors would produce the projection of v ∈ Rm onto V spanned by {qi}. More\ncompactly, if we form an m × n matrix\nQ =\nq1 · · ·\nqn\n,\nthen the projection of v onto the column space of Q is\nw = Q(QT v) = (QQT)v .\nWe recognize that the orthogonal projector onto the span of {qi} or col(Q) is\nP = QQT .\nOf course P is symmetric, (QQT)T = (QT)TQT = QQT , and idempotent, (QQT)(QQT) =\nQ(QTQ)QT = QQT .\nEnd Advanced Material\n\nChapter 17\nLeast Squares\n17.1\nData Fitting in Absence of Noise and Bias\nWe motivate our discussion by reconsidering the friction coefficient example of Chapter 15. We\nrecall that, according to Amontons, the static friction, Ff, static, and the applied normal force,\nFnormal, applied, are related by\nFf, static ≤ μs Fnormal, applied ;\nhere μs is the coefficient of friction, which is only dependent on the two materials in contact. In\nparticular, the maximum static friction is a linear function of the applied normal force, i.e.\nF max\nf, static = μs Fnormal, applied .\nWe wish to deduce μs by measuring the maximum static friction attainable for several different\nvalues of the applied normal force.\nOur approach to this problem is to first choose the form of a model based on physical principles\nand then deduce the parameters based on a set of measurements. In particular, let us consider a\nsimple affine model\ny = Ymodel(x; β) = β0 + β1x .\nThe variable y is the predicted quantity, or the output, which is the maximum static friction\nF max\nThe variable x is the independent variable, or the input, which is the maximum normal\nf, static.\nforce Fnormal, applied. The function Ymodel is our predictive model which is parameterized by a\nparameter β = (β0, β1). Note that Amontons' law is a particular case of our general affine model\nwith β0 = 0 and β1 = μs. If we take m noise-free measurements and Amontons' law is exact, then\nwe expect\nF max\nf, static i = μs Fnormal, applied i,\ni = 1, . . . , m .\nThe equation should be satisfied exactly for each one of the m measurements. Accordingly, there\nis also a unique solution to our model-parameter identification problem\nyi = β0 + β1xi,\ni = 1, . . . , m ,\nDRAFT V1.2 (c) The Authors. License: Creative Commons BY-NC-SA 3.0 .\n\n!\nwith the solution given by βtrue = 0 and βtrue = μs.\nBecause the dependency of the output y on the model parameters {β0, β1} is linear, we can\nwrite the system of equations as a m × 2 matrix equation\n⎞\n⎛\n⎞\n⎛\nx1 ⎟\n⎟\n⎟\n⎟\n⎠\nβ0\n=\nβ1\n⎜\n⎜\n⎜\n⎜\n⎝\ny1\ny2\n. . .\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\nx2\n.\n.\n.\n.\n.\n.\n,\n1 xm\nym\n'\nv\n'\n\"\nv\n'\n\"\nv \"\nX\nβ\nY\nor, more compactly,\nXβ = Y .\nUsing the row interpretation of matrix-vector multiplication, we immediately recover the original\nset of equations,\n⎞\n⎛\n⎞\n⎛\nβ0 + β1x1 ⎟\n⎟\n⎟\n⎟\n⎠\n=\n⎜\n⎜\n⎜\n⎜\n⎝\ny1\ny2\n. . .\n⎟\n⎟\n⎟\n⎟\n⎠\n= Y .\nXβ =\n⎜\n⎜\n⎜\n⎜\n⎝\nβ0 + β1x2\n. . .\nβ0 + β1xm\nym\nOr, using the column interpretation, we see that our parameter fitting problem corresponds to\nchoosing the two weights for the two m-vectors to match the right-hand side,\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\nx1 ⎟\n⎟\n⎟\n⎟\n⎠\n=\n⎜\n⎜\n⎜\n⎜\n⎝\ny1\ny2\n. . .\n⎟\n⎟\n⎟\n⎟\n⎠\n= Y .\nXβ = β0\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\n+ β1\n⎜\n⎜\n⎜\n⎜\n⎝\n. . .\nx2\n. . .\nxm\nym\nWe emphasize that the linear system Xβ = Y is overdetermined, i.e., more equations than\nunknowns (m > n). (We study this in more detail in the next section.) However, we can still find\na solution to the system because the following two conditions are satisfied:\nUnbiased: Our model includes the true functional dependence y = μsx, and thus the model\nis capable of representing this true underlying functional dependence. This would not be\nthe case if, for example, we consider a constant model y(x) = β0 because our model would\nbe incapable of representing the linear dependence of the friction force on the normal force.\nClearly the assumption of no bias is a very strong assumption given the complexity of the\nphysical world.\nNoise free: We have perfect measurements: each measurement yi corresponding to the\nindependent variable xi provides the \"exact\" value of the friction force. Obviously this is\nagain rather na ıve and will need to be relaxed.\nUnder these assumptions, there exists a parameter βtrue that completely describe the measurements,\ni.e.\nyi = Ymodel(x; βtrue),\ni = 1, . . . , m .\n\n(The βtrue will be unique if the columns of X are independent.) Consequently, our predictive model\nis perfect, and we can exactly predict the experimental output for any choice of x, i.e.\nY (x) = Ymodel(x; βtrue),\n∀ x ,\nwhere Y (x) is the experimental measurement corresponding to the condition described by x. How\never, in practice, the bias-free and noise-free assumptions are rarely satisfied, and our model is\nnever a perfect predictor of the reality.\nIn Chapter 19, we will develop a probabilistic tool for quantifying the effect of noise and bias; the\ncurrent chapter focuses on developing a least-squares technique for solving overdetermined linear\nsystem (in the deterministic context) which is essential to solving these data fitting problems. In\nparticular we will consider a strategy for solving overdetermined linear systems of the form\nBz = g ,\nwhere B ∈ Rm×n , z ∈ Rn, and g ∈ Rm with m > n.\nBefore we discuss the least-squares strategy, let us consider another example of overdetermined\nsystems in the context of polynomial fitting. Let us consider a particle experiencing constant\nacceleration, e.g. due to gravity. We know that the position y of the particle at time t is described\nby a quadratic function\ny(t) = 1 at2 + v0t + y0 ,\nwhere a is the acceleration, v0 is the initial velocity, and y0 is the initial position. Suppose that\nwe do not know the three parameters a, v0, and y0 that govern the motion of the particle and we\nare interested in determining the parameters. We could do this by first measuring the position of\nthe particle at several different times and recording the pairs {ti, y(ti)}. Then, we could fit our\nmeasurements to the quadratic model to deduce the parameters.\nThe problem of finding the parameters that govern the motion of the particle is a special case\nof a more general problem: polynomial fitting. Let us consider a quadratic polynomial, i.e.\ny(x) = βtrue + βtrue x + βtrue 2\nx ,\nwhere βtrue = {βtrue, βtrue, βtrue} is the set of true parameters characterizing the modeled phe\nnomenon. Suppose that we do not know βtrue but we do know that our output depends on the\ninput x in a quadratic manner. Thus, we consider a model of the form\nYmodel(x; β) = β0 + β1x + β2x 2 ,\nand we determine the coefficients by measuring the output y for several different values of x. We\nare free to choose the number of measurements m and the measurement points xi, i = 1, . . . , m.\nIn particular, upon choosing the measurement points and taking a measurement at each point, we\nobtain a system of linear equations,\nyi = Ymodel(xi; β) = β0 + β1xi + β2xi\n2 ,\ni = 1, . . . , m ,\nwhere yi is the measurement corresponding to the input xi.\nNote that the equation is linear in our unknowns {β0, β1, β2} (the appearance of x only affects\ni\nthe manner in which data enters the equation). Because the dependency on the parameters is\n\nlinear, we can write the system as matrix equation,\n⎞\n⎛\n⎞\n⎛\nx1\nx2\n⎞\n⎛\ny1\nβ0\nx2\nx2\ny2\n⎟\n⎠\nβ1\n=\n,\n.\n.\n.\n.\n.\n.\n.\n.\n⎜\n⎜\n⎜\n⎜\n⎝ .\n⎟\n⎟\n⎟\n⎟\n⎠\n⎜\n⎜\n⎜\n⎜\n⎝ .\n.\n.\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\nβ2\nym\n1 xm x2\nm\n\"\n'\n\"\n'\n\"\n' v\nY\nv\nX\nv\nβ\nor, more compactly,\nY = Xβ .\nNote that this particular matrix X has a rather special structure -- each row forms a geometric se\nj-1\nries and the ij-th entry is given by Bij = x\n. Matrices with this structure are called Vandermonde\ni\nmatrices.\nAs in the friction coefficient example considered earlier, the row interpretation of matrix-vector\nproduct recovers the original set of equation\n⎞\n⎛\n⎞\n⎛\nβ0 + β1x1 + β2x2\ny1\ny2\n. . .\nY =\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\n=\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\n= Xβ .\nβ0 + β1x2 + β2x2\n. . .\nβ0 + β1xm + β2x2\nym\nm\nWith the column interpretation, we immediately recognize that this is a problem of finding the\nthree coefficients, or parameters, of the linear combination that yields the desired m-vector Y , i.e.\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\nx1\nx2\ny1\ny2\n. . .\n⎟\n⎟\n⎟\n⎟\n⎠\n= β0\n⎜\n⎜\n⎜\n⎜\n⎝\nY =\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\n= Xβ .\n. . .\nx2\n. . .\nx 2\n+ β1\n+ β2\n. . .\nym\nxm\nxm\nWe know that if have three or more non-degenerate measurements (i.e., m ≥ 3), then we can find\nthe unique solution to the linear system. Moreover, the solution is the coefficients of the underlying\n, βtrue, βtrue\npolynomial, (βtrue\n).\nExample 17.1.1 A quadratic polynomial\nLet us consider a more specific case, where the underlying polynomial is of the form\ny(x) = - + x - cx .\nWe recognize that y(x) = Ymodel(x; βtrue) for Ymodel(x; β) = β0 +β1x+β2x2 and the true parameters\nβtrue\nβtrue\nβtrue\n= - ,\n= ,\nand\n= - c .\nThe parameter c controls the degree of quadratic dependency; in particular, c = 0 results in an\naffine function.\nFirst, we consider the case with c = 1, which results in a strong quadratic dependency, i.e.,\nβtrue = -1/8. The result of measuring y at three non-degenerate points (m = 3) is shown in\nFigure 17.1(a). Solving the 3 × 3 linear system with the coefficients as the unknown, we obtain\nβ0 = - 2,\nβ1 = 3,\nand β2 = - 8 .\n\n0.5\n1.5\n2.5\n-0.8\n-0.6\n-0.4\n-0.2\n0.2\n0.4\n0.6\nx\ny\n\nymeas\ny\n0.5\n1.5\n2.5\n-0.8\n-0.6\n-0.4\n-0.2\n0.2\n0.4\n0.6\nx\ny\n\nymeas\ny\n(a) m = 3\n(b) m = 7\nFigure 17.1: Deducing the coefficients of a polynomial with a strong quadratic dependence.\nNot surprisingly, we can find the true coefficients of the quadratic equation using three data points.\nSuppose we take more measurements. An example of taking seven measurements (m = 7) is\nshown in Figure 17.1(b). We now have seven data points and three unknowns, so we must solve\nthe 7 × 3 linear system, i.e., find the set β = {β0, β1, β2} that satisfies all seven equations. The\nsolution to the linear system, of course, is given by\nβ0 = - ,\nβ1 = ,\nand β2 = -\n.\nThe result is correct (β = βtrue) and, in particular, no different from the result for the m = 3 case.\nWe can modify the underlying polynomial slightly and repeat the same exercise. For example,\nlet us consider the case with c = 1/10, which results in a much weaker quadratic dependency of\ny on x, i.e., βtrue = -1/80. As shown in Figure 17.1.1, we can take either m = 3 or m = 7\nmeasurements. Similar to the c = 1 case, we identify the true coefficients,\nβ0 = - ,\nβ1 = ,\nand β2 = -\n,\nusing the either m = 3 or m = 7 (in fact using any three or more non-degenerate measurements).\n·\nIn the friction coefficient determination and the (particle motion) polynomial identification\nproblems, we have seen that we can find a solution to the m × n overdetermined system (m > n) if\n(a) our model includes the underlying input-output functional dependence -- no bias;\n(b) and the measurements are perfect -- no noise.\nAs already stated, in practice, these two assumptions are rarely satisfied; i.e., models are often\n(in fact, always) incomplete and measurements are often inaccurate. (For example, in our particle\nmotion model, we have neglected friction.) We can still construct a m × n linear system Bz = g\nusing our model and measurements, but the solution to the system in general does not exist.\nKnowing that we cannot find the \"solution\" to the overdetermined linear system, our objective is\n\n!\n\n0.5\n1.5\n2.5\n-1\n-0.5\n0.5\n1.5\nx\ny\n\nymeas\ny\n0.5\n1.5\n2.5\n-1\n-0.5\n0.5\n1.5\nx\ny\n\nymeas\ny\n(a) m = 3\n(b) m = 7\nFigure 17.2: Deducing the coefficients of a polynomial with a weak quadratic dependence.\nto find a solution that is \"close\" to satisfying the solution. In the following section, we will define\nthe notion of \"closeness\" suitable for our analysis and introduce a general procedure for finding the\n\"closest\" solution to a general overdetermined system of the form\nBz = g ,\nwhere B ∈ Rm×n with m > n. We will subsequently address the meaning and interpretation of\nthis (non-) solution.\n17.2\nOverdetermined Systems\nLet us consider an overdetermined linear system -- such as the one arising from the regression\nexample earlier -- of the form\nBz = g ,\nor, more explicitly,\n⎞\n⎛\n⎞\n⎛\nB11 B12\ng1\ng2\n⎜\n⎝\n⎟\n⎠\nz1\n= ⎜\n⎝\n⎟\n⎠ .\nB21 B22\nz2\nB31 B32\ng3\nOur objective is to find z that makes the three-component vector equation true, i.e., find the\nsolution to the linear system. In Chapter 16, we considered the \"forward problem\" of matrix-\nvector multiplication in which, given z, we calculate g = Bz. We also briefly discussed the \"inverse\"\nproblem in which given g we would like to find z. But for m = n, B-1 does not exist; as discussed\nin the previous section, there may be no z that satisfies Bz = g. Thus, we will need to look for a\nz that satisfies the equation \"closely\" in the sense we must specify and interpret. This is the focus\nof this section.1\n1Note later (in Unit V) we shall look at the ostensibly simpler case in which B is square and a solution z exists\nand is even unique. But, for many reasons, overdetermined systems are a nicer place to start.\n\n!\n\n!\n\n!\n\n!\nRow Interpretation\nLet us consider a row interpretation of the overdetermined system. Satisfying the linear system\nrequires\nBi1z1 + Bi2z2 = gi,\ni = 1, 2, 3 .\nNote that each of these equations define a line in R2 . Thus, satisfying the three equations is\nequivalent to finding a point that is shared by all three lines, which in general is not possible, as\nwe will demonstrate in an example.\nExample 17.2.1 row interpretation of overdetermined system\nLet us consider an overdetermined system\n⎞\n⎛\n⎞\n⎛\n⎜\n⎝\n⎟\n⎠\nz1\n= ⎜\n⎝\n5/2\n2 ⎟\n⎠ .\nz2\n2 -3\n-2\nUsing the row interpretation of the linear system, we see there are three linear equations to be\nsatisfied. The set of points x = (x1, x2) that satisfies the first equation,\n1 · x1 + 2 · x2 =\n,\nform a line\nL1 = {(x1, x2) : 1 · x2 + 2 · x2 = 5/2}\nin the two dimensional space. Similarly, the sets of points that satisfy the second and third equations\nform lines described by\nL2 = {(x1, x2) : 2 · x1 + 1 · x2 = 2}\nL3 = {(x1, x2) : 2 · x1 - 3 · x2 = -2} .\nThese set of points in L1, L2, and L3, or the lines, are shown in Figure 17.3(a).\nThe solution to the linear system must satisfy each of the three equations, i.e., belong to all\nthree lines. This means that there must be an intersection of all three lines and, if it exists, the\nsolution is the intersection. This linear system has the solution\n1/2\nz =\n.\nHowever, three lines intersecting in R2 is a rare occurrence; in fact the right-hand side of the system\nwas chosen carefully so that the system has a solution in this example. If we perturb either the\nmatrix or the right-hand side of the system, it is likely that the three lines will no longer intersect.\nA more typical overdetermined system is the following system,\n⎞\n⎛\n⎞\n⎛\n⎜\n⎝ 2\n1 ⎟\n⎠\nz1\n= ⎜\n⎝ 2 ⎟\n⎠ .\nz2\n2 -3\n-4\nAgain, interpreting the matrix equation as a system of three linear equations, we can illustrate the\nset of points that satisfy each equation as a line in R2 as shown in Figure 17.3(b). There is no\nsolution to this overdetermined system, because there is no point (z1, z2) that belongs to all three\nlines, i.e., the three lines do not intersect at a point.\n·\n\n!\n\n!\n\n!\n\n!\n-2\n-1\n-2\n-1\n\nL1\nL2\nL3\n-2\n-1\n-2\n-1\n\nL1\nL2\nL3\n(a) system with a solution\n(b) system without a solution\nFigure 17.3: Illustration of the row interpretation of the overdetermined systems. Each line is a set\nof points that satisfies Bix = gi, i = 1, 2, 3.\nColumn Interpretation\nLet us now consider a column interpretation of the overdetermined system. Satisfying the linear\nsystem requires\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\nB11\nB12 ⎟\n⎠ = ⎜\n⎝\ng1\ng2 ⎟\n⎠ .\nz1 · ⎜\n⎝\n⎟\n⎠ + z2 · ⎜\n⎝\nB21\nB22\nB31\nB32\ng3\nIn other words, we consider a linear combination of two vectors in R3 and try to match the right-\nhand side g ∈ R3 . The vectors span at most a plane in R3, so there is no weight (z1, z2) that makes\nthe equation hold unless the vector g happens to lie in the plane. To clarify the idea, let us consider\na specific example.\nExample 17.2.2 column interpretation of overdetermined system\nFor simplicity, let us consider the following special case:\n⎞\n⎛\n⎞\n⎛\n⎜\n⎝ 0\n1 ⎟\n⎠\nz1\n= ⎜\n⎝\n⎟\n⎠ .\n3/2\nz2\nThe column interpretation results in\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n⎜\n⎝ 0 ⎟\n⎠ z1 + ⎜\n⎝ 1 ⎟\n⎠ z2 = ⎜\n⎝ 3/2 ⎟\n⎠ .\nBy changing z1 and z2, we can move in the plane\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\nz1\n⎜\n⎝ 0 ⎟\n⎠ z1 + ⎜\n⎝ 1 ⎟\n⎠ z2 = ⎜\n⎝\n⎟\n⎠ .\nz2\n\n!\n\n-2\n-1\n-2\n-1\n-1\n\ncol(B)\nspan(col(B))\ng\nBz*\nFigure 17.4: Illustration of the column interpretation of the overdetermined system.\nClearly, if g3 = 0, it is not possible to find z1 and z2 that satisfy the linear equation, Bz = g. In\nother words, g must lie in the plane spanned by the columns of B, which is the 1 - 2 plane in this\ncase.\nFigure 17.4 illustrates the column interpretation of the overdetermined system. The vector\ng ∈ R3 does not lie in the space spanned by the columns of B, thus there is no solution to the\n∗\nsystem. However, if g3 is \"small\", then we can find a z such that Bz∗ is \"close\" to g, i.e., a good\napproximation to g. Such an approximation is shown in the figure, and the next section discusses\nhow to find such an approximation.\n·\n17.3\nLeast Squares\n17.3.1\nMeasures of Closeness\nIn the previous section, we observed that it is in general not possible to find a solution to an\noverdetermined system. Our aim is thus to find z such that Bz is \"close\" to g, i.e., z such that\nBz ≈ g ,\nfor B ∈ Rm×n , m > n. For convenience, let us introduce the residual function, which is defined as\nr(z) ≡ g - Bz .\nNote that\nn\nm\nri = gi - (Bz)i = gi -\nBij zj ,\ni = 1, . . . , m .\nj=1\nThus, ri is the \"extent\" to which i-th equation (Bz)i = gi is not satisfied. In particular, if ri(z) = 0,\ni = 1, . . . , m, then Bz = g and z is the solution to the linear system. We note that the residual is\na measure of closeness described by m values. It is more convenient to have a single scalar value\nfor assessing the extent to which the equation is satisfied. A simple way to achieve this is to take\na norm of the residual vector. Different norms result in different measures of closeness, which in\nturn produce different best-fit solutions.\n\nBegin Advanced Material\nLet us consider first two examples, neither of which we will pursue in this chapter.\nExample 17.3.1 £1 minimization\nThe first method is based on measuring the residual in the 1-norm. The scalar representing the\nextent of mismatch is\nm\nm\nm\nm\nJ1(z) ≡Ir(z)I1 =\n|ri(z)| =\n|(g - Bz)i| .\ni=1\ni=1\nThe best z, denoted by z ∗, is the z that minimizes the extent of mismatch measured in J1(z), i.e.\n∗\nz = arg min J1(z) .\nz∈Rm\nThe arg minz∈Rn J1(z) returns the argument z that minimizes the function J1(z). In other words,\n∗\nz satisfies\nJ1(z ∗ ) ≤ J1(z),\n∀ z ∈ Rm .\nThis minimization problem can be formulated as a linear programming problem. The minimizer\nis not necessarily unique and the solution procedure is not as simple as that resulting from the\n2-norm. Thus, we will not pursue this option here.\n·\nExample 17.3.2 £inf minimization\nThe second method is based on measuring the residual in the inf-norm. The scalar representing the\nextent of mismatch is\nJinf(z) ≡Ir(z)Iinf = max |ri(z)| = max |(g - Bz)i| .\ni=1,...,m\ni=1,...,m\nThe best z that minimizes Jinf(z) is\n∗\nz = arg min Jinf(z) .\nz∈Rn\nThis so-called min-max problem can also be cast as a linear programming problem. Again, this\nprocedure is rather complicated, and the solution is not necessarily unique.\n·\nEnd Advanced Material\n17.3.2\nLeast-Squares Formulation (.2 minimization)\nMinimizing the residual measured in (say) the 1-norm or inf-norm results in a linear programming\nproblem that is not so easy to solve. Here we will show that measuring the residual in the 2-norm\nresults in a particularly simple minimization problem. Moreover, the solution to the minimization\nproblem is unique assuming that the matrix B is full rank -- has n independent columns. We shall\nassume that B does indeed have independent columns.\n\nThe scalar function representing the extent of mismatch for £2 minimization is\nJ2(z) ≡Ir(z)I2 = r T(z)r(z) = (g - Bz)T(g - Bz) .\nNote that we consider the square of the 2-norm for convenience, rather than the 2-norm itself. Our\n∗\nobjective is to find z such that\nz ∗ = arg min\nz∈Rn J2(z) ,\n∗\nwhich is equivalent to find z with\n∗\nIg - Bz ∗ I2 = J2(z ∗ ) < J2(z) = Ig - BzI2\n2,\n∀ z = z\n.\n(Note \"arg min\" refers to the argument which minimizes: so \"min\" is the minimum and \"arg min\"\nis the minimizer.) Note that we can write our objective function J2(z) as\nm\nm\nJ2(z) = Ir(z)I2 = r T(z)r(z) =\n(ri(z))2 .\ni=1\nIn other words, our objective is to minimize the sum of the square of the residuals, i.e., least squares.\n∗\n∗\nThus, we say that z is the least-squares solution to the overdetermined system Bz = g: z is that\nz which makes J2(z) -- the sum of the squares of the residuals -- as small as possible.\nNote that if Bz = g does have a solution, the least-squares solution is the solution to the\noverdetermined system. If z is the solution, then r = Bz - g = 0 and in particular J2(z) = 0, which\n∗\nis the minimum value that J2 can take. Thus, the solution z is the minimizer of J2: z = z . Let us\nnow derive a procedure for solving the least-squares problem for a more general case where Bz = g\ndoes not have a solution.\nFor convenience, we drop the subscript 2 of the objective function J2, and simply denote it by\n∗\nJ. Again, our objective is to find z such that\n∗\nJ(z ∗ ) < J(z),\n∀ z = z\n.\nExpanding out the expression for J(z), we have\nJ(z) = (g - Bz)T(g - Bz) = (g T - (Bz)T)(g - Bz)\n= g T(g - Bz) - (Bz)T(g - Bz)\nT\n= g g - g TBz - (Bz)T g + (Bz)T(Bz)\nT\nTBT\n= g g - g TBz - z\ng + z TBTBz ,\nwhere we have used the transpose rule which tells us that (Bz)T = zTBT . We note that gTBz is\na scalar, so it does not change under the transpose operation. Thus, gTBz can be expressed as\nTBT\ng TBz = (g TBz)T = z\ng ,\nagain by the transpose rule. The function J thus simplifies to\nT\nTBT\nJ(z) = g g - 2z\ng + z TBTBz .\nFor convenience, let us define N ≡ BTB ∈ Rn×n, so that\nT\nTBT\nJ(z) = g g - 2z\ng + z TNz .\n\nIt is simple to confirm that each term in the above expression is indeed a scalar.\nThe solution to the minimization problem is given by\nNz ∗ = d ,\nwhere d = BTg. The equation is called the \"normal\" equation, which can be written out as\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n∗\nN11\nN12\n· · ·\nN1n\nd1\nz1\n∗\nz2 . . .\n⎜\n⎜\n⎜\n⎜\n⎝\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\n⎟\n⎟\n⎟\n⎟\n⎠\n=\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\n.\nN21\nN22\n· · ·\nN2n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\nd2\n. . .\n\"\n∗\nNn1 Nn2 · · ·\nNnn\nzn\ndn\n'\n∗\nThe existence and uniqueness of z is guaranteed assuming that the columns of B are independent.\n∗\nWe provide below the proof that z is the unique minimizer of J(z) in the case in which B has\nindependent columns.\nProof. We first show that the normal matrix N is symmetric positive definite, i.e.\nx TNx > 0,\n∀ x ∈ Rn (x = 0) ,\nassuming the columns of B are linearly independent. The normal matrix N = BTB is symmetric\nbecause\n\"\nN T = (BTB)T = BT(BT)T = BTB = N .\nTo show N is positive definite, we first observe that\nx TNx = x TBTBx = (Bx)T(Bx) = IBxI2 .\nThat is, xTNx is the 2-norm of Bx. Recall that the norm of a vector is zero if and only if the\nvector is the zero vector. In our case,\nx TNx = 0 if and only if Bx = 0 .\n'\nBecause the columns of B are linearly independent, Bx = 0 if and only if x = 0. Thus, we have\nx TNx = IBxI2 > 0,\nx = 0 .\nThus, N is symmetric positive definite.\nNow recall that the function to be minimized is\nT\nTBT\nJ(z) = g g - 2z\ng + z TNz .\n∗\nIf z minimizes the function, then for any δz = 0, we must have\n∗\nJ(z ∗ ) < J(z + δz) ;\n∗\nLet us expand J(z + δz):\n∗\nT\n∗\n∗\n∗\nJ(z + δz) = g g - 2(z + δz)TBT g + (z + δz)TN(z + δz) ,\nT\n∗ BT\n= g g - 2z\ng + (z ∗ )TNz ∗ -2δzTBT g + δzTNz ∗ +\n(z ∗ )TNδz\n+δzTNδz ,\nv\nv\nJ(z ∗)\nδzTNTz ∗ =δzTNz∗\n= J(z ∗ ) + 2δzT(Nz ∗ - BT g) + δzTNδz .\n=\n=\n=\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n∗\nNote that NT = N because NT = (BTB)T = BTB = N. If z satisfies the normal equation,\nNz∗ = BTg, then\nNz ∗ - BT g = 0 ,\nand thus\n∗\nJ(z + δz) = J(z ∗ ) + δzTNδz .\nThe second term is always positive because N is positive definite. Thus, we have\n∗\nJ(z + δz) > J(z ∗ ),\n∀ δz = 0 ,\n∗\nor, setting δz = z - z ,\n∗\nJ(z ∗ ) < J(z),\n∀ z = z\n.\n∗\nThus, z satisfying the normal equation Nz∗ = BTg is the minimizer of J, i.e., the least-squares\nsolution to the overdetermined system Bz = g.\nExample 17.3.3 2 × 1 least-squares and its geometric interpretation\nConsider a simple case of a overdetermined system,\nB =\nz\n=\n.\nBecause the system is 2 × 1, there is a single scalar parameter, z, to be chosen. To obtain the\nnormal equation, we first construct the matrix N and the vector d (both of which are simply scalar\nfor this problem):\nN = BTB =\n= 5\nd = BT g =\n= 4 .\nSolving the normal equation, we obtain the least-squares solution\n∗\n∗\nNz ∗ = d\n⇒\n5z = 4\n⇒\nz = 4/5 .\nThis choice of z yields\n8/5\nBz ∗ =\n·\n=\n,\n4/5\nwhich of course is different from g.\nThe process is illustrated in Figure 17.5. The span of the column of B is the line parameterized\nT\nby\nz, z ∈ R. Recall that the solution Bz∗ is the point on the line that is closest to g in\nthe least-squares sense, i.e.\n∗\nIBz ∗ - gI2 < IBz - gI,\n∀ z = z\n.\n\n=\n=\n\n!\n\n!\n\n!\n-0.5\n0.5\n1.5\n2.5\n-0.5\n0.5\n1.5\n2.5\n\ncol(B)\nspan(col(B))\ng\nBz*\nFigure 17.5: Illustration of least-squares in R2 .\nRecalling that the £2 distance is the usual Euclidean distance, we expect the closest point to be the\northogonal projection of g onto the line span(col(B)). The figure confirms that this indeed is the\ncase. We can verify this algebraically,\n⎛\n⎞\n3/5\nBT(Bz ∗ - g) =\n⎝\n·\n-\n⎠ =\n= 0 .\n-6/5\nThus, the residual vector Bz∗ - g and the column space of B are orthogonal to each other. While\nthe geometric illustration of orthogonality may be difficult for a higher-dimensional least squares,\nthe orthogonality condition can be checked systematically using the algebraic method.\n·\n17.3.3\nComputational Considerations\nLet us analyze the computational cost of solving the least-squares system. The first step is the\nformulation of the normal matrix,\nN = BTB ,\nwhich requires a matrix-matrix multiplication of BT ∈ Rn×m and B ∈ Rm×n . Because N is sym\nmetric, we only need to compute the upper triangular part of N, which corresponds to performing\nn(n + 1)/2 m-vector inner products. Thus, the computational cost is mn(n + 1). Forming the\nright-hand side,\nd = BT g ,\nrequires a matrix-vector multiplication of BT ∈ Rn×m and g ∈ Rm . This requires n m-vector inner\nproducts, so the computational cost is 2mn. This cost is negligible compared to the mn(n + 1)\noperations required to form the normal matrix. Finally, we must solve the n-dimensional linear\nsystem\nNz = d .\n\nAs we will see in the linear algebra unit, solving the n × n symmetric positive definite linear system\nrequires approximately 3 n\noperations using the Cholesky factorization (as we discuss further in\nUnit V). Thus, the total operation count is\nCnormal ≈ mn(n + 1) + 1 3\nn .\nFor a system arising from regression, m » n, so we can further simplify the expression to\nCnormal ≈ mn(n + 1) ≈ mn 2 ,\nwhich is quite modest for n not too large.\nWhile the method based on the normal equation works well for small systems, this process turns\nout to be numerically \"unstable\" for larger problems. We will visit the notion of stability later;\nfor now, we can think of stability as an ability of an algorithm to control the perturbation in the\nsolution under a small perturbation in data (or input). In general, we would like our algorithm to\nbe stable. We discuss below the method of choice.\nBegin Advanced Material\nQR Factorization and the Gram-Schmidt Procedure\nA more stable procedure for solving the overdetermined system is that based on QR factorization.\nQR factorization is a procedure to factorize, or decompose, a matrix B ∈ Rm×n into an orthonormal\nmatrix Q ∈ Rm×n and an upper triangular matrix R ∈ Rn×n such that B = QR. Once we have\nsuch a factorization, we can greatly simplify the normal equation BTBz∗ = BTg. Substitution of\nthe factorization into the normal equation yields\nBTBz ∗ = BT g\n⇒\nRT QTQ Rz ∗ = RTQT g\n⇒\nRTRz ∗ = RTQT g .\n' v \"\nI\nHere, we use the fact that QTQ = I if Q is an orthonormal matrix. The upper triangular matrix\nis invertible as long as its diagonal entries are all nonzero (which is the case for B with linearly\nindependent columns), so we can further simplify the expression to yield\nRz ∗ = QT g .\nThus, once the factorization is available, we need to form the right-hand side QTg, which requires\n2mn operations, and solve the n × n upper triangular linear system, which requires n2 operations.\nBoth of these operations are inexpensive. The majority of the cost is in factorizing the matrix B\ninto matrices Q and R.\nThere are two classes of methods for producing a QR factorization: the Gram-Schmidt proce\ndure and the Householder transform. Here, we will briefly discuss the Gram-Schmidt procedure.\nThe idea behind the Gram-Schmidt procedure is to successively turn the columns of B into or\nthonormal vectors to form the orthonormal matrix Q. For convenience, we denote the j-th column\nof B by bj , i.e.\nB =\nb1 b2 · · ·\nbn\n,\nwhere bj is an m-vector. Similarly, we express our orthonormal matrix as\nQ =\nq1 q2 · · ·\nqn\n.\n\n!\n\n!\nT\nRecall q\nqj = δi j (Kronecker-delta), 1 ≤ i, j ≤ n.\ni\nThe Gram-Schmidt procedure starts with a set which consists of a single vector, b1. We construct\nan orthonormal set consisting of single vector q1 that spans the same space as {b1}. Trivially, we\ncan take\nq1 =\nb1 .\nIb1I\nOr, we can express b1 as\nb1 = q1Ib1I ,\nwhich is the product of a unit vector and an amplitude.\nNow we consider a set which consists of the first two columns of B, {b1, b2}. Our objective is\nto construct an orthonormal set {q1, q2} that spans the same space as {b1, b2}. In particular, we\nwill keep the q1 we have constructed in the first step unchanged, and choose q2 such that (i) it is\northogonal to q1, and (ii) {q1, q2} spans the same space as {b1, b2}. To do this, we can start with\nb2 and first remove the component in the direction of q1, i.e.\nT\nq 2 = b2 - (q1 b2)q1 .\nT\nHere, we recall the fact that the inner product q1 b2 is the component of b2 in the direction of q1.\nWe can easily confirm that q2 is orthogonal to q1, i.e.\nT\nT\nT\nT\nT\nT\nT\nT\nq1 q 2 = q1 (b2 - (q1 b2)q1) = q1 b2 - (q1 b2)q1 q1 = q1 b2 - (q1 b2) · 1 = 0 .\nFinally, we normalize q2 to yield the unit length vector\nq2 = q 2/Iq 2I .\nWith some rearrangement, we see that b2 can be expressed as\nb2 = (q1\nTb2)q1 + q2 = (q1\nTb2)q1 + Iq 2Iq2 .\nUsing a matrix-vector product, we can express this as\nT\nq1 b2\nb2 =\nq1 q2\n.\nIq 2I\nCombining with the expression for b1, we have\nT\nIb1I q1 b2\nb1 b2\n=\nq1 q2\n.\nIq 2I\nIn two steps, we have factorized the first two columns of B into an m × 2 orthogonal matrix\n(q1, q2) and a 2 × 2 upper triangular matrix. The Gram-Schmidt procedure consists of repeating\nthe procedure n times; let us show one more step for clarity.\nIn the third step, we consider a set which consists of the first three columns of B, {b1, b2, b3}.\nOur objective it to construct an orthonormal set {q1, q2, q3}. Following the same recipe as the\nsecond step, we keep q1 and q2 unchanged, and choose q3 such that (i) it is orthogonal to q1 and q2,\nand (ii) {q1, q2, q3} spans the same space as {b1, b2, b3}. This time, we start from b3, and remove\nthe components of b3 in the direction of q1 and q2, i.e.\nT\nT\nq 3 = b3 - (q1 b3)q1 - (q2 b3)q2 .\n\nT\nT\nAgain, we recall that q1 b3 and q2 b3 are the components of b3 in the direction of q1 and q2, respec\ntively. We can again confirm that q3 is orthogonal to q1\nT\nT\nT\nT\nT\nT\nT\nT\nT\nq1 q 3 = q1 (b3 - (q1 b3)q1 - (q2 b3)q2) = q1 b3 - (q1 b3)q1 q1 - (q2 b3)q1 q2 = 0\nand to q2\nT\nT\nT\nT\nT\nT\nT\nT\nT\nq2 q 3 = q2 (b3 - (q1 b3)q1 - (q2 b3)q2) = q2 b3 - (q1 b3)q2 q1 - (q2 b3)q2 q2 = 0 .\nWe can express b3 as\nT\nT\nb3 = (q1 b3)q1 + (q2 b3)q2 + Iq 3Iq3 .\nOr, putting the first three columns together\n⎞\n⎛\nb1 b2 b3\n=\nq1 q2 q3\n⎜\n⎝\nT\nT\nIb1I q1 b2 q1 b3\nT\nIq 2I q2 b3 ⎟\n⎠ .\nIq 3I\nWe can see that repeating the procedure n times would result in the complete orthogonalization of\nthe columns of B.\nLet us count the number of operations of the Gram-Schmidt procedure. At j-th step, there are\nj - 1 components to be removed, each requiring of 4m operations. Thus, the total operation count\nis\nm\nn\nCGram-Schmidt ≈\n(j - 1)4m ≈ 2mn .\nj=1\nThus, for solution of the least-squares problem, the method based on Gram-Schmidt is approx\nimately twice as expensive as the method based on normal equation for m » n. However, the\nsuperior numerical stability often warrants the additional cost.\nWe note that there is a modified version of Gram-Schmidt, called the modified Gram-Schmidt\nprocedure, which is more stable than the algorithm presented above. The modified Gram-Schmidt\nprocedure requires the same computational cost. There is also another fundamentally different QR\nfactorization algorithm, called the Householder transformation, which is even more stable than the\nmodified Gram-Schmidt procedure. The Householder algorithm requires approximately the same\ncost as the Gram-Schmidt procedure.\nEnd Advanced Material\nBegin Advanced Material\n17.3.4\nInterpretation of Least Squares: Projection\nSo far, we have discussed a procedure for solving an overdetermined system,\nBz = g ,\nin the least-squares sense. Using the column interpretation of matrix-vector product, we are looking\nfor the linear combination of the columns of B that minimizes the 2-norm of the residual -- the\n\n*\n\n*\n\n*\n\n*\n\nmismatch between a representation Bz and the data g. The least-squares solution to the problem\nis\n∗\nBTBz ∗ = BT g\n⇒\nz = (BTB)-1BT g .\nThat is, the closest approximation of the data g using the columns of B is\nLS\ng = P LS\ng\n= Bz ∗ = B(BTB)-1BT\ng .\nOur best representation of g, gLS, is the projection of g by the projector P LS . We can verify that\nthe operator P LS = B(BTB)-1BT is indeed a projector:\n(P LS)2 = (B(BTB)-1BT)2 = B(BTB)-1BTB(BTB)-1BT = B ((BTB)-1BTB)(BTB)-1BT\n'\nv\n\"\nI\n= P LS\n= B(BTB)-1BT\n.\nIn fact, P LS is an orthogonal projector because P LS is symmetric. This agrees with our intuition;\nthe closest representation of g using the columns of B results from projecting g onto col(B) along\na space orthogonal to col(B). This is clearly demonstrated for R2 in Figure 17.5 considered earlier.\nUsing the orthogonal projector onto col(B), P LS , we can think of another interpretation of\nleast-squares solution. We first project the data g orthogonally to the column space to form\nLS = P LS\ng\ng .\nThen, we find the coefficients for the linear combination of the columns of B that results in P LSg,\ni.e.\n= P LS\nBz ∗\ng .\nThis problem has a solution because P LSg ∈ col(B).\nThis interpretation is useful especially when the QR factorization of B is available. If B = QR,\nthen col(B) = col(Q). So, the orthogonal projector onto col(B) is the same as the orthogonal\nprojector onto col(Q) and is given by\nP LS = QQT .\nWe can verify that P LS is indeed an orthogonal projector by checking that it is (i) idempotent\n(P LSP LS = P LS), and (ii) symmetric ((P LS)T = P LS), i.e.\nQT\n= P LS\nP LSP LS = (QQT)(QQT) = Q QTQ\n= QQT\n,\n' v \"\nI\n= P LS\n(P LS)T = (QQT)T = (QT)TQT = QQT\n.\nUsing the QR factorization of B, we can rewrite the least-squares solution as\n= P LS\nBz ∗\ng\n⇒\nQRz ∗ = QQT g .\nApplying QT on both sides and using the fact that QTQ = I, we obtain\nRz ∗ = QT g .\nGeometrically, we are orthogonally projecting the data g onto col(Q) but representing the projected\nsolution in the basis {qi}n\nof the n-dimensional space (instead of in the standard basis of Rm).\ni=1\n∗\nThen, we find the coefficients z that yield the projected data.\nEnd Advanced Material\n\nBegin Advanced Material\n17.3.5\nError Bounds for Least Squares\nPerhaps the most obvious way to measure the goodness of our solution is in terms of the residual\nIg - Bz∗I which indicates the extent to which the equations Bz∗ = g are satisfied -- how well Bz∗\n∗\npredicts g. Since we choose z to minimize Ig - Bz∗I we can hope that Ig - Bz∗I is small. But\nit is important to recognize that in most cases g only reflects data from a particular experiment\n∗\nwhereas we would like to then use our prediction for z in other, different, experiments or even\ncontexts. For example, the friction coefficient we measure in the laboratory will subsequently be\nused \"in the field\" as part of a larger system prediction for, say, robot performance. In this sense,\nnot only might the residual not be a good measure of the \"error in z,\" a smaller residual might\nnot even imply a \"better prediction\" for z. In this section, we look at how noise and incomplete\nmodels (bias) can be related directly to our prediction for z.\nNote that, for notational simplicity, we use subscript 0 to represent superscript \"true\" in this\nsection.\nError Bounds with Respect to Perturbation in Data, g (constant model)\nLet us consider a parameter fitting for a simple constant model. First, let us assume that there is\na solution z0 to the overdetermined system\n⎞\n⎛\n⎞\n⎛\n⎜\n⎜\n⎜\n⎜\n⎝\n. . .\n⎟\n⎟\n⎟\n⎟\n⎠\nz0 =\n⎜\n⎜\n⎜\n⎜\n⎝\ng0,1\ng0,2\n. . .\n⎟\n⎟\n⎟\n⎟\n⎠\n.\ng0,m\n\"\n'\n\"\n' v\nv\nB\ng0\nBecause z0 is the solution to the system, g0 must be a constant multiple of B. That is, the entries\nof g0 must all be the same. Now, suppose that the data is perturbed such that g = g0. With\nthe perturbed data, the overdetermined system is unlikely to have a solution, so we consider the\n∗\nleast-squares solution z to the problem\nBz = g .\nWe would like to know how much perturbation in the data g - g0 changes the solution z ∗ - z0.\nTo quantify the effect of the perturbation, we first note that both the original solution and the\nsolution to the perturbed system satisfy the normal equation, i.e.\nBTBz0 = BT g0\nand BTBz ∗ = BT g .\nTaking the difference of the two expressions, we obtain\nBTB(z ∗ - z0) = BT(g - g0) .\nFor B with the constant model, we have BTB = m, simplifying the expression to\nz ∗ - z0 = 1 BT(g - g0)\nm\n1 m\nm\n=\n(g - g0)i .\nm i=1\n\n∗\nThus if the \"noise\" is close to zero-mean, z is close to Z0. More generally, we can show that\n|z ∗ - z0| ≤ √\nIg - g0I .\nm\nWe see that the deviation in the solution is bounded by the perturbation data. Thus, our least\n∗\nsquares solution z is a good approximation as long as the perturbation Ig - g0I is small.\nTo prove this result, we apply the Cauchy-Schwarz inequality, i.e.\n1 √\n|z ∗ - z0| =\n|BT(g - g0)| ≤\nIBI Ig - g0I =\nmIg - g0I = √\nIg - g0I .\nm\nm\nm\nm\nRecall that the Cauchy-Schwarz inequality gives a rather pessimistic bound when the two vectors\nare not very well aligned.\nLet us now study more formally how the alignment of the two vectors B and g - g0 affects the\nerror in the solution. To quantify the effect let us recall that the least-squares solution satisfies\n= P LS\nBz ∗\ng ,\nwhere P LS is the orthogonal projector onto the column space of B, col(B). If g - g0 is exactly zero\nmean, i.e.\nm\nm\n(g0,i - gi) = 0 ,\nm i=1\nthen g - g0 is orthogonal to col(B). Because any perturbation orthogonal to col(B) lies in the\ndirection along which the projection is performed, it does not affect P LSg (and hence Bz∗), and in\n∗\n∗\nparticular z . That is, the least-squares solution, z , to\nBz = g = g0 + (g - g0)\nis z0 if g - g0 has zero mean. We can also show that the zero-mean perturbation has no influence\nin the solution algebraically using the normal equation, i.e.\ng0 +�\nBTBz ∗ = BT(g0 + (g - g0)) = BT\nBT(g - g0) = BT g0 .\n∗\nThe perturbed data g does not enter the calculation of z if g - g0 has zero mean. Thus, any error\nin the solution z - z0 must be due to the non-zero-mean perturbation in the data. Consequently,\nthe bound based on the Cauchy-Schwarz inequality is rather pessimistic when the perturbation is\nclose to zero mean.\nError Bounds with Respect to Perturbation in Data, g (general)\nLet us now generalize the perturbation analysis to a general overdetermined system,\nBz0 = g0 ,\nwhere B ∈ Rm×n with m > n. We assume that g0 is chosen such that the solution to the linear\nsystem exists. Now let us say measurement error has corrupted g0 to g = g0 + E. In particular, we\nassume that the linear system\nBz = g\n\n∗\ndoes not have a solution. Thus, we instead find the least-squares solution z of the system.\nTo establish the error bounds, we will first introduce the concept of maximum and minimum\nsingular values, which help us characterize the behavior of B. The maximum and minimum singular\nvalues of B are defined by\nIBvI\nIBvI\nνmax(B) = max\nand νmin(B) = min\n.\nv∈Rn IvI\nv∈Rn IvI\nNote that, because the norm scales linearly under scalar multiplication, equivalent definitions of\nthe singular values are\nνmax(B) = max IBvI and νmin(B) = min IBvI .\nv∈Rn\nv∈Rn\nIvI=1\nIvI=1\nIn other words, the maximum singular value is the maximum stretching that B can induce to a\nunit vector. Similarly, the minimum singular value is the maximum contraction B can induce.\nIn particular, recall that if the columns of B are not linearly independent, then we can find a\nnon-trivial v for which Bv = 0. Thus, if the columns of B are linearly dependent, νmin(B) = 0.\nWe also note that the singular values are related to the eigenvalues of BTB. Recall that 2-norm\nis related to the inner product by\nIBvI2 = (Bv)T(Bv) = v TBTBv ,\nthus, from the Rayleigh quotient, the square root of the maximum and minimum eigenvalues of\nBTB are the maximum and minimum singular values of B.\nLet us quantify the sensitivity of the solution error to the right-hand side in two different\nmanners. First is the absolute conditioning, which relates Iz ∗ - z0I to Ig - g0I. The bound is given\nby\nIz ∗ - z0I ≤\nIg - g0I .\nνmin(B)\nSecond is the relative conditioning, which relates the relative perturbation in the solution Iz ∗ -\nz0I/Iz0I and the relative perturbation in the right-hand side Ig - g0I/Ig0I. This bound is give by\nIz ∗ - z0I\nνmax(B) Ig - g0I\n=\n.\nIz0I\nνmin(B)\nIg0I\nWe derive these results shortly.\nIf the perturbation Ig - g0I is small, we expect the error Iz ∗ - z0I to be small as long as B\nis well-conditioned in the sense that νmax(B)/νmin(B) is not too large. Note that if B has linearly\ndependent columns, then νmin = 0 and νmax/νmin is infinite; thus, νmax/νmin is a measure of the\nindependence of the columns of B and hence the extent to which we can independently determine\nthe different elements of z. More generally, νmax/νmin is a measure of the sensitivity or stability of\nour least-squares solutions to perturbations (e.g. in g). As we have already seen in this chapter,\nand will see again in Chapter 19 within the regression context, we can to a certain extent \"control\"\nB through the choice of variables, functional dependencies, and measurement points; we can thus\nstrive to control νmax/νmin through good \"independent\" choices and thus ensure good prediction\nof z.\nExample 17.3.4 Measurement Noise in Polynomial Fitting\nLet us demonstrate the effect of perturbation in g -- or the measurement error -- in the context\n\n0.5\n1.5\n2.5\n-0.8\n-0.6\n-0.4\n-0.2\n0.2\n0.4\n0.6\nx\ny\n\n||g-g0||=0.223\n||z-z0||=0.072\nymeas\ny(z0(g0))\ny(z*(g))\n0.5\n1.5\n2.5\n-0.8\n-0.6\n-0.4\n-0.2\n0.2\n0.4\n0.6\nx\ny\n\n||g-g0||=0.022\n||z-z0||=0.007\nymeas\ny(z0(g0))\ny(z*(g))\n(a) large perturbation\n(b) small perturbation\nFigure 17.6: The effect of data perturbation on the solution.\nof polynomial fitting we considered earlier. As before, we assume that the output depends on the\ninput quadratically according to\ny(x) = - + x - cx ,\nwith c = 1. We construct clean data g0 ∈ Rm , m = 7, by evaluating y at\nxi = (i - 1)/2,\ni = 1, . . . , m ,\nand setting\ng0,i = y(xi),\ni = 1, . . . , m .\nBecause g0 precisely follows the quadratic function, z0 = (-1/2, 2/3, -1/8) satisfies the overdeter\nmined system Bz0 = g0. Recall that B is the m × n Vandermonde matrix with the evaluation\npoints {xi}.\nWe then construct perturbed data g by adding random noise to g0, i.e.\ngi = g0,i + Ei,\ni = 1, . . . , m .\n∗\nThen, we solve for the least-squares solution z of Bz∗ = g.\nThe result of solving the polynomial fitting problem for two different perturbation levels is\nshown in Figure 17.6. For the large perturbation case, the perturbation in data and the error in\nthe solution -- both measured in 2-norm -- are\nIg - g0I = 0.223 and Iz - z0I = 0.072 .\nIn contrast, the small perturbation case produces\nIg - g0I = 0.022 and Iz - z0I = 0.007 .\nThe results confirm that a smaller perturbation in data results in a smaller error in the solution.\n\nWe can also verify the error bounds. The minimum singular value of the Vandermonde matrix\nis\nνmin(B) = 0.627 .\nApplication of the (absolute) error bound to the large perturbation case yields\n0.072 = Iz - z0I ≤\nIg - g0I = 0.356 .\nνmin(B)\nThe error bound is clearly satisfied. The error bound for the small perturbation case is similarly\nsatisfied.\n·\nWe now prove the error bounds.\nProof. To establish the absolute error bound, we first note that the solution to the clean problem,\nz0, and the solution to the perturbed problem, z ∗, satisfy the normal equation, i.e.\nBTBz0 = BT g0\nand BTBz ∗ = BT g .\nTaking the difference of the two equations\nBTB(z ∗ - z0) = BT(g - g0) .\nNow, we multiply both sides by (z ∗ - z0)T to obtain\n(LHS) = (z ∗ - z0)TBTB(z ∗ - z0) = (B(z ∗ - z0))T(B(z ∗ - z0)) = IB(z ∗ - z0)I2\n(RHS) = (z ∗ - z0)TBT(g - g0) = (B(z ∗ - z0))T(g - g0) ≤IB(z ∗ - z0)IIg - g0I ,\nwhere we have invoked the Cauchy-Schwarz inequality on the right-hand side. Thus, we have\nIB(z ∗ - z0)I2 ≤IB(z ∗ - z0)IIg - g0I\n⇒\nIB(z ∗ - z0)I ≤Ig - g0I .\nWe can bound the left-hand side from below using the definition of the minimum singular value\nνmin(B)Iz ∗ - z0I ≤IB(z ∗ - z0)I .\nThus, we have\nνminIz ∗ - z0I ≤IB(z ∗ - z0)I ≤Ig - g0I\n⇒\nIz ∗ - z0I ≤\nIg - g0I ,\nνmin(B)\nwhich is the desired absolute error bound.\nTo obtain the relative error bound, we first divide the absolute error bound by Iz0I to obtain\nIz ∗ - z0I\nIg - g0I\nIg - g0I Ig0I\n≤\n=\n.\nIz0I\nνmin(B)\nIz0I\nνmin(B)\nIg0I\nIz0I\nTo bound the quotient Ig0I/Iz0I, we take the norm of both sides of Bz0 = g0 and invoke the\ndefinition of the maximum singular value, i.e.\nIg0I\nIg0I = IBz0I ≤ νmaxIz0I\n⇒\n≤ νmax .\nIz0I\n\n!\n\nSubstituting the expression to the previous bound\nIz ∗ - z0I\nIg - g0I Ig0I\nνmax(B) Ig - g0I\n≤\n≤\n,\nIz0I\nνmin(B)\nIg0I\nIz0I\nνmin(B)\nIg0I\nwhich is the desired relative error bound.\nProof (using singular value decomposition). We start with the singular value decomposition of ma\ntrix B,\nB = UΣV T ,\nwhere U is an m × m unitary matrix, V is an n × n unitary matrix, and Σ is an m × n diagonal\nmatrix. In particular, Σ consists of singular values of B and is of the form\n⎞\n⎛\nΣ =\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎝\nν1\nν2\n. . .\nνn\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎠\nΣ\n=\n.\nThe singular value decomposition exists for any matrix. The solution to the original problem is\ngiven by\nBz = g\n⇒\nUΣV T z = g\n⇒\nΣV T z = UT g .\nThe solution to the least-squares problem is\n∗\nz = arg min IBz - gI = arg min IUΣV T z - gI = arg min IΣV T z - UT gI\nz\nz\nz\n= V\narg min IΣ z - g I\n,\nz\nwhere the third equality follows from the fact that the action by an unitary matrix does not alter\nthe 2-norm, and we have made the substitutions z = V Tz and g = U Tg. We note that because Σ\nis diagonal, the 2-norm to be minimized is particularly simple,\n⎞\n⎛\n⎞\n⎛\n-\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎝\ng 1\n. . .\ng n\ng n+1\n. . .\ng m\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎠\n.\nν1\nΣ z - g = Σ =\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎝\n⎛\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎠\n⎞\n. .\nz 1\n.\n⎜\n⎜\n⎝\n⎟\n⎟\n⎠\nνn\n. . .\nz n\n\n!\n\n!\n\n!\n\n!\n\n!\nNote that choosing z1, . . . , z n only affects the first n component of the residual vector. Thus, we\nshould pick z1, . . . , z n such that\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\nν1\nz 1\ng 1\n⎜\n⎜\n⎝\n. . .\n⎜\n⎜\n⎝\n⎟\n⎟\n⎠\n. . .\n⎟\n⎟\n⎠ =\n⎜\n⎜\n⎝\n. . .\n⎟\n⎟\n⎠\n⇒\nz i = g i , i = 1, . . . , n .\nνi\nνn\nz n\ng n\nBy introducing a n × m restriction matrix that extracts the first n entries of g, we can concisely\nwrite the above as\nΣ z = Rg\n⇒\nz = Σ-1R g ,\nand the solution to the least-squares problem as\n∗\n∗\nz = V z = V Σ-1Rg = V Σ-1RUT g .\nThe absolute condition number bound is obtained by\nIV Σ-1RUT(g - g0)I\nIz ∗ - z0I = IV Σ-1RUT(g - g0)I =\nIg - g0I\nIg - g0I\nIV Σ-1RUTδgI\n≤\nsup\nIg - g0I .\nδg\nIδgI\nThe term in the parenthesis is bounded by noting that orthogonal transformations preserve the\n2-norm and that the restriction operator does not increase the 2-norm, i.e.\nIV Σ-1RUTδgI\nIV Σ-1Rδg I\nIΣ-1Rδg I\nsup\n= sup\n= sup\n≤\n.\nδg\nIδgI\nδg\nIUδg I\nδg\nIδg I\nνmin(B)\nThus, we have the desired absolute error bound\nIz ∗ - z0I ≤\nIg - g0I .\nνmin(B)\nNow let us consider the relative error bound. We first note that\nIz ∗ - z0I\nIg - g0I Ig0I\n=\nIg - g0I\n=\n.\nIz0I\nνmin(B)\nIz0I\nνmin(B)\nIg0I\nIz0I\nThe term Ig0I/Iz0I can be bounded by expressing z0 in terms of g using the explicit expression\nfor the least-squares solution, i.e.\nIg0I\nIBz0I\nIUΣV Tz0I\nIUΣV TzI\nIUΣ zI\nIΣ zI\n=\n=\n≤ sup\n= sup\n= sup\n= νmax(B) .\nIz0I\nIz0I\nIz0I\nz\nIzI\nz\nIV z I\nz\nIz I\nThus, we have the relative error bound\nIz ∗ - z0I\nνmax(B) Ig - g0I\n≤\n.\nIz0I\nνmin(B)\nIg0I\nThis concludes the proof.\nb\nb\nb\nb\nb\nb\n\nb\n!\n\nb\n!\n\nb\n!\nb\n!\n\n!\nError Bounds with Respect to Reduction in Space, B\nLet us now consider a scenario that illustrates the effect of bias. Again, we start with an overde\ntermined linear system,\nB0z0 = g ,\nwhere B0 ∈ Rm×n with m > n. We assume that z0 satisfies all m equations. We recall that, in the\ncontext of polynomial fitting, B0 is of the form,\n⎞\n⎛\nB0 =\n⎜\n⎜\n⎜\n⎜\n⎝\nx1\nx2\n· · ·\nxn\nn\nx2\nx2\n· · ·\nx2\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n1 xm x2\n· · ·\nxn\nm\nm\n⎟\n⎟\n⎟\n⎟\n⎠\n,\nwhere m is the number of data points and n is the degree of polynomial. Now, suppose that we\ndecide to use a p-th degree polynomial rather than the n-th degree polynomial, where p < n. In\nother words, we can partition B0 into\n⎞\n⎛\nB0 =\nBI BII\n=\n⎜\n⎜\n⎜\n⎜\n⎝\np\nx\n· · ·\nx\np\nx\n· · ·\nx\n.\n.\n.\n.\n.\n.\n.\n.\n.\np\n1 x1\n· · ·\nxm\nm\np+1\nn\nx\n· · ·\nx\np+1\nn\nx\n· · ·\nx\nm\n,\n.\n.\n.\n.\n.\n.\np+1\nn\nm\nx\n· · ·\nxm\n⎟\n⎟\n⎟\n⎟\n⎠\nwhere BI ∈ Rm×(p+1) and BII ∈ Rm×(n-p). Then we can solve the least-squares problem resulting\nfrom the first partition, i.e.\n∗\nBIz = g .\nFor convenience, let us also partition the solution to the original system z0 into two parts corre\nsponding to BI and BII, i.e.\nzI\nz0 =\n,\nzII\n∗\nwhere zI ∈ Rp+1 and zII ∈ Rn-p. The question is, how close are the coefficients z = (z1, . . . , zp-1)\nof the reduced system compared to the coefficients of the first partition of the original system, zI?\nWe can in fact bound the error in the solution Iz ∗ - zII in terms of the \"missing space\" BII.\nIn particular, the absolute error bound is given by\nIz ∗ - zII ≤\nIBIIzIII\nνmin(BI)\nand the relative error bound is given by\nIz ∗ - zII\nνmax(BI)\nIBIIzIII\n≤\n,\nIzII\nνmin(BI) Ig - BIIzIII\nwhere νmin(BI) and νmax(BI) are the minimum and maximum singular values of BI.\n\n!\n\n.\n\nExample 17.3.5 Bias Effect in Polynomial Fitting\nLet us demonstrate the effect of reduced solution space -- or the bias effect -- in the context of\npolynomial fitting. As before, the output depends on the input quadratically according to\ny(x) = - + x - cx .\nRecall that c controls the strength of quadratic dependence. The data g is generated by evaluating y\nat xi = (i-1)/2 and setting gi = y(xi) for i = 1, . . . , m, with m = 7. We partition our Vandermonde\nmatrix for the quadratic model B0 into that for the affine model BI and the quadratic only part\nBII, i.e.\n⎞\n⎛\n⎞\n⎛\nx1\nx2\nx1\nx\nB0 =\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\n=\nBI BII\n.\n1 x2\nx\nx\nx2\n=\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n1 xm x2\n1 xm x\nm\nm\nAs before, because the underlying data is quadratic, we can exactly match the function using the\nfull space B0, i.e., B0z0 = g.\n∗\n∗\nNow, we restrict ourselves to affine functions, and find the least-squares solution z to BIz = g.\nWe would like to quantify the difference in the first two coefficients of the full model zI and the\n∗\ncoefficients of the reduced model z .\nFigure 17.7 shows the result of fitting an affine function to the quadratic function for c = 1\nand c = 1/10. For the c = 1 case, with the strong quadratic dependence, the effect of the missing\nquadratic function is\nIBIIzIII = 1.491 .\nThis results in a relative large solution error of\nIz ∗ - zII = 0.406 .\nWe also note that, with the minimum singular value of νmin(BI) = 1.323, the (absolute) error bound\nis satisfied as\n0.406 = Iz ∗ - zII ≤\nIBIIzII I = 1.1267 .\nνmin(BI)\nIn fact, the bound in this particular case is reasonable sharp.\n∗\nRecall that the least-squares solution z minimizes the £2 residual\n0.286 = IBIz ∗ - gI ≤IBIz - gI,\n∀ z ∈ R2 ,\nand the residual is in particular smaller than that for the truncated solution\nIBIzI - gI = 1.491 .\nHowever, the error for the least-squares solution -- in terms of predicting the first two coefficients\nof the underlying polynomial -- is larger than that of the truncated solution (which of course is\nzero). This case demonstrates that minimizing the residual does not necessarily minimize the error.\nFor the c = 1/10 with a weaker quadratic dependence, the effect of missing the quadratic\nfunction is\nIBIIzIII = 0.149\n\n0.5\n1.5\n2.5\n-0.8\n-0.6\n-0.4\n-0.2\n0.2\n0.4\n0.6\n0.8\nx\ny\n\n||BIIzII||=1.491\n||z*-zI||=0.406\nymeas\ny(z0(B0))\ny(z*(BI))\n0.5\n1.5\n2.5\n-1\n-0.5\n0.5\n1.5\nx\ny\n\n||BIIzII||=0.149\n||z*-zI||=0.041\nymeas\ny(z0(B0))\ny(z*(BI))\n(a) c = 1\n(b) c = 1/10\nFigure 17.7: The effect of reduction in space on the solution.\nand the error in the solution is accordingly smaller as\nIz ∗ - zII = 0.041 .\nThis agrees with our intuition. If the underlying data exhibits a weak quadratic dependence, then\nwe can represent the data well using an affine function, i.e., IBIIzIII is small. Then, the (absolute)\nerror bound suggests that the small residual results in a small error.\n·\nWe now prove the error bound.\nProof. We rearrange the original system as\nB0z0 = BIzI + BIIzII = g\n⇒\nBIzI = g - BIIzII .\nBy our assumption, there is a solution zI that satisfies the m × (p + 1) overdetermined system\nBIzI = g - BIIzII .\nThe reduced system,\n∗\nBIz = g ,\ndoes not have a solution in general, so is solved in the least-squares sense. These two cases are\nidentical to the unperturbed and perturbed right-hand side cases considered the previous subsection.\nIn particular, the perturbation in the right-hand side is\nIg - (g - BIIzII)I = IBIIzIII ,\nand the perturbation in the solution is Iz ∗ -zII. Substitution of the perturbations into the absolute\nand relative error bounds established in the previous subsection yields the desired results.\n\nEnd Advanced Material\n\nChapter 18\nMatlab Linear Algebra (Briefly)\n18.1\nMatrix Multiplication (and Addition)\nWe can think of a hypothetical computer (or scripting) language in which we must declare a\n\"tableau\" of m by n numbers to be either a double-index array or a matrix; we also introduce\na hypothetical \"multiplication\" operator #. (Note that # is not an actual Matlab multiplication\ncharacter/operator -- it is introduced here solely for temporary pedagogical purposes.) In the case\nin which we (say) declare A and B to be arrays then the product C = A # B would be automatically\ninterpreted as element-by-element multiplication: both A and B must be of the same size m × n\nfor the operation to make sense, and the result C would of course also be of size m × n. In the\ncase in which we declare A and B to be matrices then the product A # B would be automatically\ninterpreted as matrix-matrix multiplication: if A is m1 by n1 and B is m2 by n2 then n1 must\nequal m2 for the operation to make sense and the product C = A # B would be of dimensions\nm1 × n2. This is a very simple example of object-oriented programming in which an operation, say\nmultiplication, is defined -- in potentially different ways -- for different classes of objects (in our\ncase here, arrays and matrices) -- but we could also envision an extension to functions and other\nentities as well. This model for programming languages and abstraction can be very powerful for\na variety of reasons.\nHowever, in some cases such abstraction can arguably be more of a burden than a blessing.\nFor example, in Matlab we often wish to re-interpret arrays as matrices or matrices as arrays on\nmany different occasions even with a single code or application. To avoid conversion issues between\nthese two classes, Matlab prefers to treat arrays and matrices as (effectively) a single class and\nthen to distinguish the two options for multiplication through special operators. In particular, as\nwe already know, element-by-element multiplication of two arrays is effected by the .* operator --\nC = A.*B forms C as the element-by-element product of A and B; matrix-matrix multiplication (in\nthe sense of linear algebra) is then effected simply by * -- C = A*B forms C as the matrix product\nof A and B. In fact, the emphasis in Matlab at least historically is on linear algebra, and thus\nmatrix multiplication is in some sense the default; element-by-element operations are the \"special\ncase\" and require the \"dotted operators.\"\nIn principle, we should also need to distinguish element-by-element addition and subtraction as\n.+ and .- from matrix-matrix addition and subtraction as + and -. However, element-by-element\naddition and subtraction and matrix-matrix addition and subtraction are identical -- both in terms\nDRAFT V1.2 (c) The Authors. License: Creative Commons BY-NC-SA 3.0 .\n\nof the requirements on the operands and on the result of the operation -- and hence it suffices to\nintroduce only a single addition and subtraction operator, + and -, respectively. (In particular,\nnote that there are no operators .+ and .- in Matlab.) In a similar fashion, we need only a single\ntranspose operator, ', which is directly applicable to both arrays and matrices.2\nIt thus follows that the matrix-matrix addition, subtraction, multiplication, and transpose are\neffected in Matlab in essentially the same way as we would write such operations in the linear\nalgebra context: in the addition or subtraction of two vectors x and y, the x + y and x - y of linear\nalgebra becomes x + y and x - y in Matlab; in the multiplication of two matrices A and B, the\nAB of linear algebra becomes A*B in Matlab; and in the transpose of a matrix (or vector) M, the\nM T of linear algebra becomes M' in Matlab.\nOf course, you could also always implement these matrix operations in Matlab \"explicitly\"\nwith for loops and appropriate indexing: for example, z = x + y could be implemented as\nz = 0.*x; % initialize z to be same size as x\nfor i = 1:length(x)\nz(i) = x(i) + y(i);\nend\nhowever this leads to code which is both much less efficient and also much longer and indeed much\nless readable (and hence de-buggable). (Note also that the above does not yet contain any check\non dimensions or error flags.) We have already discussed the power of function abstraction. In the\ncase of these very ubiquitous functions -- standard array and matrix manipulations -- Matlab\nprovides the further convenience of special characters and hence very simple syntax. (Note that\nas these special characters are, as always, just an easy way to invoke the underlying Matlab\noperator or function: for example, the element-by-element multiplication operation A.*B can also\nbe written (but less conveniently) as times(A,B), and the matrix-matrix multiplication A*B can\nalso be written as mtimes(A,B).)\nWe close with a simple example to again illustrate the differences between array and matrix\noperations. We introduce two column vectors x = (1 1)T and y = (2 2)T which in Matlab\nwe express as x = [1; 1] and y = [2; 2]. (Note the distinction: parentheses for vectors and\nmatrices in the linear algebra context, brackets for vectors and matrices in Matlab; parentheses in\nMatlab are used for indexing and function calls, not to define a vector or matrix.) We may then\nperform the linear algebra operation of inner product, α = xTy, in two fashions: with element-by\nelement multiplication (and hence times) as alpha = sum(x.*y); with matrix multiplication (and\nhence mtimes) as alpha_too = x'*y.\n18.2\nThe Matlab Inverse Function: inv\nThis section is short. Given a non-singular square matrix A, A in Matlab, we can find A-1 in\nMatlab as inv(A) (which of course may also be assigned to a new matrix, as in Ainv = inv(A)).\nTo within round-off error we can anticipate that inv(A)*A and A*inv(A) should both evaluate to\nthe identity matrix. (In finite-precision arithmetic, of course we will not obtain exactly an identity\n2 In fact, the array transpose and the matrix transpose are different: the array transpose is given by .' and\nswitches rows and columns; the matrix transpose is given by ' and effects the conjugate, or Hermitian transpose,\nin which AH =\nand\nrefers to the complex conjugate. The Hermitian transpose (superscript H) is the correct\nij\nAij\ngeneralization from real matrices to complex matrices in order to ensure that all our linear algebra concepts (e.g.,\nnorm) extend correctly to the complex case. We will encounter complex variables in Unit IV related to eigenvalues.\nNote that for real matrices we can use either ' (array) or .' (matrix) to effect the (Hermitian) matrix transpose since\nthe complex conjugate of a real number is simply the real number.\n\nmatrix; however, for \"well-conditioned\" matrices we should obtain a matrix which differs from the\nidentity by roughly machine precision.)\nAs we have already discussed, and as will be demonstrated in Unit V, the inv operation is quite\nexpensive, and in most cases there are better ways to achieve any desired end than through a call\nto inv. Nevertheless for small systems, and in cases in which we do explicitly require the inverse\nfor some reason, the inv function is very convenient.\n18.3\nSolution of Linear Systems: Matlab Backslash\nWe now consider a system of n linear equations in n unknowns: Ax = b. We presume that the\nmatrix A is non-singular such that there is indeed a solution, and in fact a unique solution, to this\nsystem of equations. We know that we may write this solution if we wish as x = A-1b. There are\ntwo ways in which we find x in Matlab. Actually, more than two ways: we restrict attention to\nthe most obvious (and worst) and then the best.\nAs our first option we can simply write x = inv(A)*b. However, except for small systems, this\nwill be unnecessarily expensive. This \"inverse\" approach is in particular very wasteful in the case\nin which the matrix A is quite sparse -- with many zeros -- a situation that arises very (very)\noften in the context of mechanical engineering and physical modeling more generally. We discuss\nthe root cause of this inefficiency in Unit V.\nAs our second option we can invoke the Matlab \"backslash\" operator \\ (corresponding to the\nfunction mldivide) as follows: x = A \\ b. This backslash operator is essentially a collection of\nrelated (direct) solution options from which Matlab will choose the most appropriate based on\nthe form of A; these options are all related to the \"LU\" decomposition of the matrix A (followed\nby forward and back substitution), as we will discuss in greater detail in Unit V. Note that these\nLU approaches do not form the inverse of A but rather directly attack the problem of solution of\nthe linear system. The Matlab backslash operator is very efficient not only due to the algorithm\nchosen but also due to the careful and highly optimized implementation.\n18.4\nSolution of (Linear) Least-Squares Problems\nIn Chapter 17 we considered the solution of least squares problems: given B ∈ Rm×n and g ∈ Rm\n∗\n∗\nfind z ∈ Rn which minimizes IBz - gI2 over all z ∈ Rn . We showed that z satisfies the normal\nequations, Nz∗ = BTg, where N ≡ BTB. There are (at least) three ways we can implement this\nleast-squares solution in Matlab.\nThe first, and worst, is to write zstar = inv(B'*B)*(B'*g). The second, and slightly better,\nis to take advantage of our backslash operator to write zstar_too = (B'*B)\\(B'*g). However,\nboth of the approaches are less than numerically stable (and more generally we should avoid taking\npowers of matrices since this just exacerbates any intrinsic conditioning or \"sensitivity\" issues).\nThe third option, and by far the best, is to write zstar_best = B\\g. Here the backslash operator\n\"recognizes\" that B is not a square matrix and automatically pursues a least-squares solution based\non the stable and efficient QR decomposition discussed in Chapter 17.\nFinally, we shall see in Chapter 19 on statistical regression that some elements of the matrix\n(BTB)-1 will be required to construct confidence intervals. Although it is possible to efficiently cal\nculate certain select elements of this inverse matrix without construction of the full inverse matrix,\nin fact our systems shall be relatively small and hence inv(B'*B) is quite inexpensive. (Neverthe\nless, the solution of the least-squares problem is still best implemented as zstar_best = B \\ g,\neven if we subsequently form the inverse inv(B'*B) for purposes of confidence intervals.)\n\nChapter 19\nRegression: Statistical Inference\n19.1\nSimplest Case\nLet us first consider a \"simple\" case of regression, where we restrict ourselves to one independent\nvariable and linear basis functions.\n19.1.1\nFriction Coefficient Determination Problem Revisited\nRecall the friction coefficient determination problem we considered in Section 17.1. We have seen\nthat in presence of m perfect measurements, we can find a μs that satisfies m equations\nF max, meas = μs Fnormal, applied i,\ni = 1, . . . , m .\nf, static i\nIn other words, we can use any one of the m-measurements and solve for μs according to\nF max, meas\nf, static i\nμs,i =\n,\nFnormal, applied i\nand all μs,i, i = 1, . . . , m, will be identical and agree with the true value μs.\nUnfortunately, real measurements are corrupted by noise. In particular, it is unlikely that we\ncan find a single coefficient that satisfies all m measurement pairs. In other words, μs computed\nusing the m different pairs are likely not to be identical. A more suitable model for static friction\nthat incorporates the notion of measurement noise is\nF max, meas\nf, static\n= μs Fnormal, applied + E .\nThe noise associated with each measurement is obviously unknown (otherwise we could correct the\nmeasurements), so the equation in the current form is not very useful. However, if we make some\nweak assumptions on the behavior of the noise, we can in fact:\n(a) infer the value of μs with associated confidence,\n(b) estimate the noise level,\n(c) confirm that our model is correct (more precisely, not incorrect),\n(d) and detect significant unmodeled effects.\nDRAFT V1.2 (c) The Authors. License: Creative Commons BY-NC-SA 3.0 .\n\nThis is the idea behind regression -- a framework for deducing the relationship between a set\nF max, meas\nof inputs (e.g. Fnormal,applied) and the outputs (e.g.\n) in the presence of noise. The\nf, static\nregression framework consists of two steps: (i) construction of an appropriate response model, and\n(ii) identification of the model parameters based on data. We will now develop procedures for\ncarrying out these tasks.\n19.1.2\nResponse Model\nLet us describe the relationship between the input x and output Y by\nY (x) = Ymodel(x; β) + E(x) ,\n(19.1)\nwhere\n(a) x is the independent variable, which is deterministic.\n(b) Y is the measured quantity (i.e., data), which in general is noisy. Because the noise is assumed\nto be random, Y is a random variable.\n(c) Ymodel is the predictive model with no noise. In linear regression, Ymodel is a linear function\nof the model parameter β by definition. In addition, we assume here that the model is an\naffine function of x, i.e.\nYmodel(x; β) = β0 + β1x ,\nwhere β0 and β1 are the components of the model parameter β. We will relax this affine-in-x\nassumption in the next section and consider more general functional dependencies as well as\nadditional independent variables.\n(d) E is the noise, which is a random variable.\nOur objective is to infer the model parameter β that best describes the behavior of the measured\nquantity and to build a model Ymodel(·; β) that can be used to predict the output for a new x.\n(Note that in some cases, the estimation of the parameter itself may be of interest, e.g. deducing\nthe friction coefficient. In other cases, the primary interest may be to predict the output using\nthe model, e.g. predicting the frictional force for a given normal force. In the second case, the\nparameter estimation itself is simply a means to the end.)\nAs considered in Section 17.1, we assume that our model is unbiased. That is, in the absence\nof noise (E = 0), our underlying input-output relationship can be perfectly described by\ny(x) = Ymodel(x; βtrue)\nfor some \"true\" parameter βtrue . In other words, our model includes the true functional dependency\n(but may include more generality than is actually needed). We observed in Section 17.1 that if\nthe model is unbiased and measurements are noise-free, then we can deduce the true parameter,\nβtrue, using a number of data points equal to or greater than the degrees of freedom of the model\n(m ≥ n).\nIn this chapter, while we still assume that the model is unbiased1 , we relax the noise-free\nassumption. Our measurement (i.e., data) is now of the form\nY (x) = Ymodel(x; βtrue) + E(x) ,\nwhere E is the noise. In order to estimate the true parameter, βtrue, with confidence, we make\nthree important assumptions about the behavior of the noise. These assumptions allow us to make\nquantitative (statistical) claims about the quality of our regression.\n1In Section 19.2.4, we will consider effects of bias (or undermodelling) in one of the examples.\n\n0.5\n1.5\n2.5\n-1\n-0.5\n0.5\n1.5\n\nY\nYmodel\nfY\nFigure 19.1: Illustration of the regression process.\n(i) Normality (N1): We assume the noise is a normally distributed with zero-mean, i.e., E(x) ∼\nN (0, σ2(x)). Thus, the noise E(x) is described by a single parameter σ2(x).\n(ii) Homoscedasticity (N2): We assume that E is not a function of x in the sense that the\ndistribution of E, in particular σ2, does not depend on x.\n(iii) Independence (N3): We assume that E(x1) and E(x2) are independent and hence uncorre\nlated.\nWe will refer to these three assumptions as (N1), (N2), and (N3) throughout the rest of the chapter.\nThese assumptions imply that E(x) = E = N (0, σ2), where σ2 is the single parameter for all instances\nof x.\nNote that because\nY (x) = Ymodel(x; β) + E = β0 + β1x + E\nand E ∼N (0, σ2), the deterministic model Ymodel(x; β) simply shifts the mean of the normal\ndistribution. Thus, the measurement is a random variable with the distribution\nY (x) ∼N (Ymodel(x; β), σ2) = N (β0 + β1x, σ2) .\nIn other words, when we perform a measurement at some point xi, we are in theory drawing\na random variable from the distribution N (β0 + β1xi, σ2). We may think of Y (x) as a random\nvariable (with mean) parameterized by x, or we may think of Y (x) as a random function (often\ndenoted a random process).\nA typical regression process is illustrated in Figure 19.1. The model Ymodel is a linear function\nof the form β0 + β1x. The probability density functions of Y , fY , shows that the error is normally\ndistributed (N1) and that the variance does not change with x (N2). The realizations of Y sampled\nfor x = 0.0, 0.5, 1.0, . . . , 3.0 confirms that it is unlikely for realizations to fall outside of the 3σ bounds\nplotted. (Recall that 99.7% of the samples falls within the 3σ bounds for a normal distribution.)\nFigure 19.1 suggests that the likely outcome of Y depends on our independent variable x in a\nlinear manner. This does not mean that Y is a function of x only. In particular, the outcome of\nan experiment is in general a function of many independent variables,\nx =\n· · ·\n.\nx(1) x(2)\nx(k)\n\nBut, in constructing our model, we assume that the outcome only strongly depends on the behavior\nof x = x(1), and the net effect of the other variables\nx(2) · · ·\nx(k)\ncan be modeled as random\nthrough E. In other words, the underlying process that governs the input-output relationship may\nbe completely deterministic if we are given k variables that provides the full description of the\nsystem, i.e.\ny(x(1), x(2), . . . , x(k)) = f(x(1), x(2), . . . , x(k)) .\nHowever, it is unlikely that we have the full knowledge of functional dependencies as well as the\nstate of the system.\nKnowing that the deterministic prediction of the output is intractable, we resort to under\nstanding the functional dependency of the most significant variable, say x(1). If we know that the\ndependency of y on x(1) is most dominantly affine (say based on a physical law), then we can split\nour (intractable) functional dependency into\ny(x(1), x(2), . . . , x(k)) = β0 + β1x(1) + g(x(1), x(2), . . . , x(k)) .\nHere g(x(1), x(2), . . . , x(k)) includes both the unmodeled system behavior and the unmodeled process\nthat leads to measurement errors. At this point, we assume the effect of (x(2), . . . , x(k)) on y and\nthe weak effect of x(1) on y through g can be lumped into a zero-mean random variable E, i.e.\nY (x(1); β) = β0 + β1x(1) + E .\nAt some level this equation is almost guaranteed to be wrong.\nFirst, there will be some bias: here bias refers to a deviation of the mean of Y (x) from β0 +β1x(1)\n-- which of course can not be represented by E which is assumed zero mean. Second, our model for\nthe noise (e.g., (N1), (N2), (N3)) -- indeed, any model for noise -- is certainly not perfect. However,\nif the bias is small, and the deviations of the noise from our assumptions (N1), (N2), and (N3)\nare small, our procedures typically provide good answers. Hence we must always question whether\nthe response model Ymodel is correct, in the sense that it includes the correct model. Furthermore,\nthe assumptions (N1), (N2), and (N3) do not apply to all physical processes and should be treated\nwith skepticism.\nWe also note that the appropriate number of independent variables that are explicitly modeled,\nwithout being lumped into the random variable, depends on the system. (In the next section,\nwe will treat the case in which we must consider the functional dependencies on more than one\nindependent variable.) Let us solidify the idea using a very simple example of multiple coin flips in\nwhich in fact we need not consider any independent variables.\nExample 19.1.1 Functional dependencies in coin flips\nLet us say the system is 100 fair coin flips and Y is the total number of heads. The outcome of\neach coin flip, which affects the output Y , is a function of many variables: the mass of the coin,\nthe moment of inertia of the coin, initial launch velocity, initial angular momentum, elasticity of\nthe surface, density of the air, etc. If we had a complete description of the environment, then the\noutcome of each coin flip is deterministic, governed by Euler's equations (for rigid body dynamics),\nthe Navier-Stokes equations (for air dynamics), etc. We see this deterministic approach renders our\nsimulation intractable -- both in terms of the number of states and the functional dependencies --\neven for something as simple as coin flips.\nThus, we take an alternative approach and lump some of the functional dependencies into a\nrandom variable. From Chapter 9, we know that Y will have a binomial distribution B(n = 100, θ =\n1/2). The mean and the variance of Y are\nE[Y ] = nθ = 50 and E[(Y - μY )2] = nθ(1 - θ) = 25 .\n\nIn fact, by the central limit theorem, we know that Y can be approximated by\nY ∼N (50, 25) .\nThe fact that Y can be modeled as N (50, 25) without any explicit dependence on any of the many\nindependent variables we cited earlier does not mean that Y does not depend on the variables. It\nonly means that the cumulative effect of the all independent variables on Y can be modeled as a\nzero-mean normal random variable. This can perhaps be motivated more generally by the central\nlimit theorem, which heuristically justifies the treatment of many small random effects as normal\nnoise.\n·\n19.1.3\nParameter Estimation\nWe now perform m experiments, each of which is characterized by the independent variable xi. Each\nexperiment described by xi results in a measurement Yi, and we collect m variable-measurement\npairs,\n(xi, Yi),\ni = 1, . . . , m .\nIn general, the value of the independent variables xi can be repeated. We assume that our mea\nsurements satisfy\nYi = Ymodel(xi; β) + Ei = β0 + β1xi + Ei .\n(βtrue, βtrue\nFrom the experiments, we wish to estimate the true parameter βtrue =\n) without the\nprecise knowledge of E (which is described by σ). In fact we will estimate βtrue and σ by βˆ and ˆσ,\nrespectively.\nIt turns out, from our assumptions (N1), (N2), and (N3), that the maximum likelihood estimator\n(MLE) for β -- the most likely value for the parameter given the measurements (xi, Yi), i = 1, . . . , m\n-- is precisely our least squares fit, i.e., βˆ = β∗ . In other words, if we form\n⎞\n⎛\n⎞\n⎛\nY1\nx1\nX =\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\nand Y =\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\nY2\n. . .\nx2\n,\n.\n.\n.\n.\n.\n.\n1 xm\nYm\nthen the MLE, βˆ, satisfies\nˆ\nIXβˆ - Y I2 < IXβ - Y I2,\n∀ β = β .\nEquivalently, βˆ satisfies the normal equation\n(XTX)βˆ = XTY .\nWe provide the proof.\n\nProof. We show that the least squares solution is the maximum likelihood estimator (MLE) for β.\nRecall that we consider each measurement as Yi = N (β0 + β1xi, σ2) = N (Xi·β, σ2). Noting the\nnoise is independent, the m measurement collectively defines a joint distribution,\nY = N (Xβ, Σ) ,\nwhere Σ is the diagonal covariance matrix Σ = diag(σ2, . . . , σ2). To find the MLE, we first form\nthe conditional probability density of Y assuming β is given, i.e.\nfY |B(y|β) =\nexp - (y - Xβ)TΣ-1(y - Xβ) ,\n(2π)m/1|Σ|1/2\nwhich can be viewed as a likelihood function if we now fix y and let β vary -- β|y rather than y|β.\nThe MLE -- the β that maximizes the likelihood of measurements {yi}m -- is then\n⎛\ni=1\n⎞\nˆβ = arg max\nβ∈R2 fY |B(y|β) = arg max\nβ∈R2\n(2π)m/1|Σ|1/2 exp\n⎜\n⎜\n⎝ -\n'\n2(y - Xβ)TΣ-1(y - Xβ)\n⎟\n⎟\n⎠ .\n\"\nv\nJ\nThe maximum is obtained when J is minimized. Thus,\nβˆ = arg min J(β) = arg min 1(y - Xβ)TΣ-1(y - Xβ) .\nβ∈R2\nβ∈R2 2\nRecalling the form of Σ, we can simplify the expression to\nβˆ = arg min 1 (y - Xβ)T(y - Xβ) = arg min (y - Xβ)T(y - Xβ)\nβ∈R2 2σ2\nβ∈R2\n= arg min Iy - XβI2 .\nβ∈R2\nThis is precisely the least squares problem. Thus, the solution to the least squares problem Xβ = y\nis the MLE.\nHaving estimated the unknown parameter βtrue by βˆ, let us now estimate the noise E charac\nterized by the unknown σtrue . Our estimator for σtrue, ˆσ, is\n1/2\nσˆ =\nIY - XβˆI2\n.\nm - 2\nNote that IY - XβˆI is just the root mean square of the residual as motivated by the least squares\napproach earlier. The normalization factor, 1/(m - 2), comes from the fact that there are m\nmeasurement points and two parameters to be fit. If m = 2, then all the data goes to fitting the\nparameters {β0, β1} -- two points determine a line -- and none is left over to estimate the error;\nthus, in this case, we cannot estimate the error. Note that\n(Xβˆ)i = Ymodel(xi; β)|\nˆ ≡ Yi\nβ=β\nˆ\nis our response model evaluated at the parameter β = β; we may thus write\nˆσ =\nIY - Y I2\n1/2\n.\nm - 2\n\nb\nb\n\nˆ\nIn some sense, β minimizes the misfit and what is left is attributed to noise ˆσ (per our model).\nNote that we use the data at all points, x1, . . . , xm, to obtain an estimate of our single parameter,\nσ; this is due to our homoscedasticity assumption (N2), which assumes that E (and hence σ) is\nindependent of x.\nWe also note that the least squares estimate preserves the mean of the measurements in the\nsense that\nm\nm\nm\nm\nY ≡\nYi =\nYi ≡ Y .\nm\nm\ni=1\ni=1\nProof. The preservation of the mean is a direct consequence of the estimator βˆ satisfying the normal\nequation. Recall, βˆ satisfies\nXTXβˆ = XTY .\nBecause Y = Xβˆ, we can write this as\nXTY = XTY .\nRecalling the \"row\" interpretation of matrix-vector product and noting that the column of X is all\nones, the first component of the left-hand side is\n⎞\n⎛\nY1\nm\nm\nYm\ni=1\nSimilarly, the first component of the right-hand side is\n⎜\n⎜\n⎝\n⎟\n⎟\n⎠\n(XTY )1\n.\n1 · · ·\nYi\n=\n=\n.\n.\n.\n⎞\n⎛\nY1\nm\nm\nYm\ni=1\nThus, we have\n⎜\n⎜\n⎝\n⎟\n⎟\n⎠\n(XTY )1\n.\n1 · · ·\nYi\n=\n=\n.\n.\n.\nm\nm\nm\nm\n(XTY )1 = (XTY )1\n⇒\nYi =\nYi ,\ni=1\ni=1\nwhich proves that the model preserves the mean.\n19.1.4\nConfidence Intervals\nWe consider two sets of confidence intervals. The first set of confidence intervals, which we refer to\nas individual confidence intervals, are the intervals associated with each individual parameter. The\nsecond set of confidence intervals, which we refer to as joint confidence intervals, are the intervals\nassociated with the joint behavior of the parameters.\nb\nb\nb\nb\nb\nb\nb\nb\n\nIndividual Confidence Intervals\nLet us introduce an estimate for the covariance of βˆ,\nΣ ≡ σˆ2(XTX)-1 .\nFor our case with two parameters, the covariance matrix is 2 × 2. From our estimate of the\ncovariance, we can construct the confidence interval for β0 as\n\nI0 ≡\nβˆ0 - tγ,m-2\nΣ11, βˆ0 + tγ,m-2\nΣ11\n,\nand the confidence interval for β1 as\n\nI1 ≡\nβˆ1 - tγ,m-2\nΣ22, βˆ1 + tγ,m-2\nΣ22\n.\nThe coefficient tγ,m-2 depends on the confidence level, γ, and the degrees of freedom, m - 2.\n\nNote that the Half Length of the confidence intervals for β0 and β1 are equal to tγ,m-2\nΣ11 and\n\ntγ,m-2\nΣ22 , respectively.\nThe confidence interval I0 is an interval such that the probability of the parameter βtrue taking\non a value within the interval is equal to the confidence level γ, i.e.\nP (βtrue ∈ I0) = γ .\nSeparately, the confidence interval I1 satisfies\nP (βtrue ∈ I1) = γ .\nThe parameter tγ,q is the value that satisfies\ntγ,q\nfT,q(s) ds = γ ,\n-tγ,q\nwhere fT,q is the probability density function for the Student's t-distribution with q degrees of\nfreedom. We recall the frequentistic interpretation of confidence intervals from our earlier estmation\ndiscussion of Unit II.\nNote that we can relate tγ,q to the cumulative distribution function of the t-distribution, FT,q,\nas follows. First, we note that fT,q is symmetric about zero. Thus, we have\ntγ,q\nγ\nfT,q(s) ds = 2\nand\n\nx\nx\nFT,q(x) ≡\nfT,q(s) ds =\n+\nfT,q(s) ds .\n-inf\nEvaluating the cumulative distribution function at tγ,q and substituting the desired integral rela\ntionship,\ntγ,q\nγ\nFT,q(tγ,q) =\n+\nfT,q(tγ,q) ds =\n+\n.\nIn particular, given an inverse cumulative distribution function for the Student's t-distribution, we\ncan readily compute tγ,q as\nγ\ntγ,q = F -1\n+\n.\nT,q\nFor convenience, we have tabulated the coefficients for 95% confidence level for select values of\ndegrees of freedom in Table 19.1(a).\n\nb\nb\nb\nb\nb\nb\n\n(a) t-distribution\n(b) F -distribution\nq\ntγ,q|γ=0.95\nq\nk = 1\nsγ,k,q|γ=0.95\n2.571\n2.571\n3.402\n4.028\n4.557\n5.025\n6.881\n8.324\n9.548\n2.228\n2.228\n2.865\n3.335\n3.730\n4.078\n5.457\n6.533\n7.449\n2.131\n2.131\n2.714\n3.140\n3.496\n3.809\n5.044\n6.004\n6.823\n2.086\n2.086\n2.643\n3.049\n3.386\n3.682\n4.845\n5.749\n6.518\n2.060\n2.060\n2.602\n2.996\n3.322\n3.608\n4.729\n5.598\n6.336\n2.042\n2.042\n2.575\n2.961\n3.280\n3.559\n4.653\n5.497\n6.216\n2.021\n2.021\n2.542\n2.918\n3.229\n3.500\n4.558\n5.373\n6.064\n2.009\n2.009\n2.523\n2.893\n3.198\n3.464\n4.501\n5.298\n5.973\n2.000\n2.000\n2.510\n2.876\n3.178\n3.441\n4.464\n5.248\n5.913\ninf\n1.960\ninf\n1.960\n2.448\n2.796\n3.080\n3.327\n4.279\n5.000\n5.605\nTable 19.1: The coefficient for computing the 95% confidence interval from Student's t-distribution\nand F -distribution.\nJoint Confidence Intervals\nSometimes we are more interested in constructing joint confidence intervals -- confidence intervals\nwithin which the true values of all the parameters lie in a fraction γ of all realizations. These\nconfidence intervals are constructed in essentially the same manner as the individual confidence\nintervals and take on a similar form. Joint confidence intervals for β0 and β1 are of the form\njoint\nˆ\nˆ\nI\n≡ β0 - sγ,2,m-2\nΣ11 , β0 + sγ,2,m-2\nΣ11\nand\njoint\nI1\n≡ βˆ1 - sγ,2,m-2\nΣ22 , βˆ1 + sγ,2,m-2\nΣ22\n.\nNote that the parameter tγ,m-2 has been replaced by a parameter sγ,2,m-2. More generally, the\nparameter takes the form sγ,n,m-n, where γ is the confidence level, n is the number of parameters in\nthe model (here n = 2), and m is the number of measurements. With the joint confidence interval,\nwe have\nβtrue\njoint and βtrue\njoint\nP\n∈ I\n∈ I\n≥ γ .\nNote the inequality -- ≥ γ -- is because our intervals are a \"bounding box\" for the actual sharp\nconfidence ellipse.\nThe parameter sγ,k,q is related to γ-quantile for the F -distribution, gγ,k,q, by\ng\nsγ,k,q =\nkgγ,k,q .\nNote gγ,k,q satisfies\ngγ,k,q\nfF,k,q(s) ds = γ ,\nwhere fF,k,q is the probability density function of the F -distribution; we may also express gγ,k,q in\nterms of the cumulative distribution function of the F -distribution as\ngγ,k,q\nFF,k,q(gγ,k,q) =\nfF,k,q(s) ds = γ .\nq\nq\nq\nq\n\nZ\nZ\nb\nb\nb\nb\n\nIn particular, we can explicitly write sγ,k,q using the inverse cumulative distribution for the F\ndistribution, i.e.\nsγ,k,q =\n=\nkF -1 (γ) .\nkgγ,k,q\nF,k,q\nFor convenience, we have tabulated the values of sγ,k,q for several different combinations of k and\nq in Table 19.1(b).\nWe note that\nsγ,k,q = tγ,q,\nk = 1 ,\nas expected, because the joint distribution is same as the individual distribution for the case with\none parameter. Furthermore,\nsγ,k,q > tγ,q,\nk > 1 ,\nindicating that the joint confidence intervals are larger than the individual confidence intervals. In\nother words, the individual confidence intervals are too small to yield jointly the desired γ.\nWe can understand these confidence intervals with some simple examples.\nExample 19.1.2 least-squares estimate for a constant model\nLet us consider a simple response model of the form\ng\nYmodel(x; β) = β0 ,\nwhere β0 is the single parameter to be determined. The overdetermined system is given by\n⎞\n⎛\n⎞\n⎛\nY1\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\n=\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\nβ0 = Xβ0 ,\nY2\n. . .\n. . .\nYm\nand we recognize X =\n1 1 · · ·\nT\n. Note that we have\nXTX = m .\nm\nFor this simple system, we can develop an explicit expression for the parameter β0 by solving the\nnormal equation, i.e.\nm\nm\nm\nXTXβ0 = XTY\n⇒\nmβ0 =\nYi\n⇒\nβ0\n=\nYi .\nm\ni=1\ni=1\nOur parameter estimator β0 is (not surprisingly) identical to the sample mean of Chapter 11 since\nour model here Y = N (β0, σ2) is identical to the model of Chapter 11.\nThe covariance matrix (which is a scalar for this case),\nΣ = σˆ2(XTX)-1 = σˆ2/m .\nThus, the confidence interval, I0, has the Half Length\nHalf Length(I0) = tγ,m-1\ng\n√\nσ/ m .\nΣ = tγ,m-1 ˆ\nq\nb\n\n0.5\n1.5\n2.5\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n\nYmeasured\nYmodel\nyclean\n0.5\n1.5\n2.5\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n\nYmeasured\nYmodel\nyclean\n(a) m = 14\n(b) m = 140\nFigure 19.2: Least square fitting of a constant function using a constant model.\nOur confidence in the estimator βˆ0 converges as 1/ √ m = m-1/2 . Again, the convergence rate is\nidentical to that in Chapter 11.\nAs an example, consider a random function of the form\nY ∼ 1 + N (0, σ2) ,\nwith the variance σ2 = 0.01, and a constant (polynomial) response model, i.e.\nYmodel(x; β) = β0 .\nNote that the true parameter is given by βtrue = 1/2. Our objective is to compute the least-squares\nestimate of βtrue , βˆ0, and the associated confidence interval estimate, I0. We take measurements\nat seven points, x = 0, 0.5, 1.0, . . . , 3.0; at each point we take nsample measurements for the total of\nm = 7 · nsample measurements. Several measurements (or replication) at the same x can be advan\ntageous, as we will see shortly; however it is also possible in particular thanks to our homoscedastic\nassumption to take only a single measurement at each value of x.\nThe results of the least squares fitting for m = 14 and m = 140 are shown in Figure 19.2.\nHere yclean corresponds to the noise-free data, yclean = 1/2. The convergence of the 95% confidence\ninterval with number of samples is depicted in Figure 19.3(a). We emphasize that for the purpose\nof these figures and later similar figures we plot the confidence intervals shifted by βtrue . We would\nnot know βtrue in practice, however these figures are intended to demonstrate the performance\nof the confidence intervals in a case in which the true values are indeed known. Each of the\nrealizations of the confidence intervals includes the true parameter value. In fact, for the m = 140\ncase, Figure 19.3(b) shows that 96 out of 100 realizations of the confidence interval include the true\nparameter value, which is consistent with the 95% confidence level for the interval. (Of course in\npractice we would compute only a single confidence interval.)\n·\n\n-0.08\n-0.06\n-0.04\n-0.02\n0.02\n0.04\nindex\nIi - βi\ntrue\n\nm=14\nm=140\nm=1400\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nfraction in\nindex\n95% confidence\n(a) 95% shifted confidence intervals\n(b) 95% ci in/out (100 realizations, m = 140)\nFigure 19.3: (a) The variation in the 95% confidence interval with the sampling size m for the\nconstant model fitting. (b) The frequency of the confidence interval I0 including the true parameter\nβtrue\n.\nExample 19.1.3 constant regression model and its relation to deterministic analysis\nEarlier, we studied how a data perturbation g - g0 affects the least squares solution z ∗ - z0. In the\nanalysis we assumed that there is a unique solution z0 to the clean problem, Bz0 = g0, and then\n∗\ncompared the solution to the least squares solution z to the perturbed problem, Bz∗ = g. As in\nthe previous analysis, we use subscript 0 to represent superscript \"true\" to declutter the notation.\nNow let us consider a statistical context, where the perturbation in the right-hand side is induced\nby the zero-mean normal distribution with variance σ2 . In this case,\nm\nm\n(g0,i - gi)\nm i=1\nis the sample mean of the normal distribution, which we expect to incur fluctuations on the order\n√\nof σ/ m. In other words, the deviation in the solution is\nm\nm\n∗\n-1\nz0 - z = (BTB)-1BT(g0 - g) = m\n(g0,i - gi) = O\n√ σ\n.\nm\ni=1\nNote that this convergence is faster than that obtained directly from the earlier perturbation\nbounds,\n1 √\n|z0 - z ∗ | ≤ √ Ig0 - gI = √\nmσ = σ ,\nm\nm\nwhich suggests that the error would not converge. The difference suggests that the perturbation\nresulting from the normal noise is different from any arbitrary perturbation. In particular, recall\nthat the deterministic bound based on the Cauchy-Schwarz inequality is pessimistic when the\nperturbation is not well aligned with col(B), which is a constant. In the statistical context, the\nnoise g0 - g is relatively orthogonal to the column space col(B), resulting in a faster convergence\nthan for an arbitrary perturbation.\n\n0.5\n1.5\n2.5\n-1\n-0.5\n0.5\n1.5\n\nYmeasured\nYmodel\nyclean\n0.5\n1.5\n2.5\n-1\n-0.5\n0.5\n1.5\n\nYmeasured\nYmodel\nyclean\n(a) m = 14\n(b) m = 140\nFigure 19.4: Least square fitting of a linear function using a linear model.\n·\nExample 19.1.4 least-squares estimate for a linear model\nAs the second example, consider a random function of the form\nY (x) ∼- 1 + 2 x + N (0, σ2) ,\nwith the variance σ2 = 0.01. The objective is to model the function using a linear model\nYmodel(x; β) = β0 + β1x ,\nwhere the parameters (β0, β1) are found through least squares fitting. Note that the true parameters\nare given by βtrue = -1/2 and βtrue = 2/3. As in the constant model case, we take measurements\nat seven points, x = 0, 0.5, 1.0, . . . , 3.0; at each point we take nsample measurements for the total\nof m = 7 · nsample measurements. Here, it is important that we take measurements at at least two\ndifferent x locations; otherwise, the matrix B will be singular. This makes sense because if we\nchoose only a single x location we are effectively trying to fit a line through a single point, which\nis an ill-posed problem.\nThe results of the least squares fitting for m = 14 and m = 140 are shown in Figure 19.4. We\nsee that the fit gets tighter as the number of samples, m, increases.\nWe can also quantify the quality of the parameter estimation in terms of the confidence intervals.\nThe convergence of the individual 95% confidence interval with number of samples is depicted in\nFigure 19.5(a). Recall that the individual confidence intervals, Ii, i = 0, 1, are constructed to satisfy\nP (βtrue\nP (βtrue\n∈ I0) = γ\nand\n∈ I1) = γ\nwith the confidence level γ (95% for this case) using the Student's t-distribution. Clearly each of\nthe individual confidence intervals gets tighter as we take more measurements and our confidence\nin our parameter estimate improves. Note that the realization of confidence intervals include the\ntrue parameter value for each of the sample sizes considered.\n\n-0.14\n-0.12\n-0.1\n-0.08\n-0.06\n-0.04\n-0.02\n0.02\n0.04\n0.06\nindex\nIi - βi\ntrue\n\nm=14\nm=140\nm=1400\nall\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nfraction in\nindex\n95% confidence\n(a) 95% shifted confidence intervals\n(b) 95% ci in/out (1000 realizations, m = 140)\nFigure 19.5: a) The variation in the 95% confidence interval with the sampling size m for the linear\nmodel fitting. b) The frequency of the individual confidence intervals I0 and I1 including the true\nand βtrue\njoint\njoint\n, βtrue\nparameters βtrue\n(0 and 1, respectively), and I\n× I\njointly including (βtrue\n)\n(all).\nWe can verify the validity of the individual confidence intervals by measuring the frequency that\neach of the true parameters lies in the corresponding interval for a large number of realizations.\nThe result for 1000 realizations is shown in Figure 19.5(b). The column indexed \"0\" corresponds to\nthe frequency of βtrue ∈ I0, and the column indexed \"1\" corresponds to the frequency of βtrue ∈ I1.\nAs designed, each of the individual confidence intervals includes the true parameter γ = 95% of\nthe times.\nWe can also check the validity of the joint confidence interval by measuring the frequency that\njoint\njoint\nthe parameters (β1, β2) jointly takes on values within I0\n×I1\n. Recall that the our joint intervals\nare designed to satisfy\nP(βtrue\njoint and βtrue\njoint\n∈ I\n∈ I\n)≥ γ\nand it uses the F -distribution. The column indexed \"all\" in Figure 19.5(b). corresponds to the\n, βtrue\njoint\njoint\nfrequency that (βtrue\n) ∈ I\n× I\n. Note that the joint success rate is a slightly higher\n(≈ 97%) than γ since the confidence intervals we provide are a simple but conservative bound\nfor the actual elliptical confidence region. On the other hand, if we mistakenly use the individual\nconfidence intervals instead of the joint confidence interval, the individual confidence intervals are\ntoo small and jointly include the true parameters only ≈ 92% of the time. Thus, we emphasize that\nit is important to construct confidence intervals that are appropriate for the question of interest.\n·\n19.1.5\nHypothesis Testing\nWe can also, in place of our CI's (or in fact, based on our CI's), consider a hypotheses on the\nparameters -- and then test these hypotheses. For example, in this last example, we might wish\n\nto test the hypothesis (known as the null hypothesis) that β0 = 0. We consider the case in which\nm = 1400. Clearly, our CI does not include β0 = 0. Thus most likely β = 0, and we reject the\nhypothesis. In general, we reject the hypothesis when the CI does not include zero.\nWe can easily analyze the Type I error, which is defined as the probability that we reject the\nhypothesis when the hypothesis is in fact true. We assume the hypothesis is true. Then, the\nprobability that the CI does not include zero -- and hence that we reject the hypothesis -- is 0.05,\nsince we know that 95% of the time our CI will include zero -- the true value under our hypothesis.\n(This can be rephrased in terms of a test statistic and a critical region for rejection.) We denote\nby 0.05 the \"size\" of the test, which is also known as the \"p value\" of the test -- the probability\nthat we incorrectly reject the hypothesis due to an unlucky (rare) \"fluctuation.\" We say that a\ntest with a small size or small p-value is statistically significant in that our conclusion most likely\nis not influenced by random effects (e.g., due to finite sample size).\nWe can also introduce the notion of a Type II error, which is defined as the probability that\nwe accept the hypothesis when the hypothesis is in fact false. And the \"power\" of the test is\nthe probability that we reject the hypothesis when the hypothesis in fact false: the power is\n1 - the Type II error. Typically it is more difficult to calculate Type II errors (and power) than\nType I errors.\n19.1.6\nInspection of Assumptions\nIn estimating the parameters for the response model and constructing the corresponding confidence\nintervals, we relied on the noise assumptions (N1), (N2), and (N3). In this section, we consider\nexamples that illustrate how the assumptions may be broken. Then, we propose methods for\nverifying the plausibility of the assumptions. Note we give here some rather simple tests without\nany underlying statistical structure; in fact, it is possible to be more rigorous about when to accept\nor reject our noise and bias hypotheses by introducing appropriate statistics such that \"small\" and\n\"large\" can be quantified. (It is also possible to directly pursue our parameter estimation under\nmore general noise assumptions.)\nChecking for Plausibility of the Noise Assumptions\nLet us consider a system governed by a random affine function, but assume that the noise E(x) is\nperfectly correlated in x. That is,\nY (xi) = βtrue + βtrue xi + E(xi) ,\nwhere\nE(x1) = E(x2) = · · · = E(xm) ∼N (0, σ2) .\nEven though the assumptions (N1) and (N2) are satisfied, the assumption on independence, (N3),\nis violated in this case. Because the systematic error shifts the output by a constant, the coefficient\nof the least-squares solution corresponding to the constant function β0 would be shifted by the\nerror. Here, the (perfectly correlated) noise E is incorrectly interpreted as signal.\nLet us now present a test to verify the plausibility of the assumptions, which would detect the\npresence of the above scenario (amongst others). The verification can be accomplished by sampling\nthe system in a controlled manner. Say we gather N samples evaluated at xL,\nL1, L2, . . . , LN\nwhere Li = Y (xL),\ni = 1, . . . , N .\n\nSimilarly, we gather another set of N samples evaluated at xR = xL,\nR1, R2, . . . , RN\nwhere Ri = Y (xR),\ni = 1, . . . , N .\nUsing the samples, we first compute the estimate for the mean and variance for L,\nN\nm\nN\nμˆL =\nLi\nand\nm\nσˆ2 =\nL\n(Li - μˆL)2 ,\nN\nN - 1\ni=1\ni=1\nand those for R,\nN\nm\nN\nμˆR =\nRi\nand\nm\nσˆ2 =\nR\n(Ri - μˆR)2 .\nN\nN - 1\ni=1\ni=1\nTo check for the normality assumption (N1), we can plot the histogram for L and R (using an\nappropriate number of bins) and for N (ˆμL, σˆ2 ) and N (ˆμR, σˆ2 ). If the error is normally distributed,\nL\nR\nthese histograms should be similar, and resemble the normal distribution.\nTo check for the homoscedasticity assumption (N2), we can compare the variance estimate for\nsamples L and R, i.e., is ˆσ2 ≈ σˆ2 ? If ˆσ2\nσˆ2 , then assumption (N2) is not likely plausible because\nL\nR\nL\nR\nthe noise at xL and xR have different distributions.\nFinally, to check for the uncorrelatedness assumption (N3), we can check the correlation coeffi\ncient ρL,R between L and R. The correlation coefficient is estimated as\nm\nN\nρˆL,R =\n(Li - μˆL)(Ri - μˆR) .\nσˆLσˆR N - 1 i=1\nIf the correlation coefficient is not close to 0, then the assumption (N3) is not likely plausible. In\nthe example considered with the correlated noise, our system would fail this last test.\nChecking for Presence of Bias\nLet us again consider a system governed by an affine function. This time, we assume that the\nsystem is noise free, i.e.\nY (x) = βtrue + βtrue x .\nWe will model the system using a constant function,\nYmodel = β0 .\nBecause our constant model would match the mean of the underlying distribution, we would inter\npret Y - mean(Y ) as the error. In this case, the signal is interpreted as a noise.\nWe can check for the presence of bias by checking if\n|μˆL - Ymodel(xL)| ∼O(ˆσ) .\nIf the relationship does not hold, then it indicates a lack of fit, i.e., the presence of bias. Note\nthat replication -- as well as data exploration more generally -- is crucial in understanding the\nassumptions.\n=\n≈\nb\n\n19.2\nGeneral Case\nWe consider a more general case of regression, in which we do not restrict ourselves to a linear\nresponse model. However, we still assume that the noise assumptions (N1), (N2), and (N3) hold.\n19.2.1\nResponse Model\nConsider a general relationship between the measurement Y , response model Ymodel, and the noise\nE of the form\nY (x) = Ymodel(x; β) + E ,\nwhere the independent variable x is vector valued with p components, i.e.\nT\nx =\nx(1), x(2), · · · , x(p)\n∈ D ⊂ Rp .\nThe response model is of the form\nn-1\nm\nYmodel(x; β) = β0 +\nβj hj (x) ,\nj=1\nwhere hj, j = 0, . . . , n - 1, are the basis functions and βj , j = 0, . . . , n - 1, are the regression\ncoefficients. Note that we have chosen h0(x) = 1. Similar to the affine case, we assume that Ymodel\nis sufficiently rich (with respect to the underlying random function Y ), such that there exists a pa\nrameter βtrue with which Ymodel(·; βtrue) perfectly describes the behavior of the noise-free underlying\nfunction, i.e., unbiased. (Equivalently, there exists a βtrue such that Y (x) ∼N (Ymodel(x; βtrue), σ2).\nIt is important to note that this is still a linear regression. It is linear in the sense that the\nregression coefficients βj , j = 0, . . . , n - 1, appear linearly in Ymodel. The basis functions hj ,\nj = 0, . . . , n - 1, do not need to be linear in x; for example, h1(x(1), x(2), x(3)) = x(1) exp(x(2)x(3))\nis perfectly acceptable for a basis function. The simple case considered in the previous section\ncorresponds to p = 1, n = 2, with h0(x) = 1 and h1(x) = x.\nThere are two main approaches to choose the basis functions.\n(i) Functions derived from anticipated behavior based on physical models. For example, to\ndeduce the friction coefficient, we can relate the static friction and the normal force following\nthe Amontons' and Coulomb's laws of friction,\nFf, static = μs Fnormal, applied ,\nwhere Ff, static is the friction force, μs is the friction coefficient, and Fnormal, applied is the normal\nforce. Noting that Ff, static is a linear function of Fnormal, applied, we can choose a linear basis\nfunction h1(x) = x.\n(ii) Functions derived from general mathematical approximations, which provide good accuracy\nin some neighborhood D. Low-order polynomials are typically used to construct the model,\nfor example\nYmodel(x(1), x(2); β) = β0 + β1x(1) + β2x(2) + β3x(1)x(2) + β4x(1) + β5x\n.\n(2)\nAlthough we can choose n large and let least-squares find the good β -- the good model within\nour general expansion -- this is typically not a good idea: to avoid overfitting, we must ensure the\nnumber of experiments is much greater than the order of the model, i.e., m » n. We return to\noverfitting later in the chapter.\n\n19.2.2\nEstimation\nWe take m measurements to collect m independent variable-measurement pairs\n(xi, Yi),\ni = 1, . . . , m ,\nwhere xi = (x(1), x(2), . . . , x(p))i. We claim\nYi = Ymodel(xi; β) + Ei\nn-1\n= β0 +\nβj hj (xi) + Ei,\ni = 1, . . . , m ,\nj=1\nwhich yields\nm\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\n⎞\n⎛\nY1 ⎟\n⎟\n⎟\n⎟\n⎠\n=\n⎜\n⎜\n⎜\n⎜\n⎝\nh1(x1)\nh2(x1)\n. . .\nhn-1(x1)\nh1(x2)\nh2(x2)\n. . .\nhn-1(x2)\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎠\nβ0\nβ1\n. . .\n⎟\n⎟\n⎟\n⎟\n⎠\n+\n⎜\n⎜\n⎜\n⎜\n⎝\nE(x1)\nE(x2)\n. . .\n⎟\n⎟\n⎟\n⎟\n⎠\n⎜\n⎜\n⎜\n⎜\n⎝\nY2\n. . .\n.\nYm\n1 h1(xm) h2(xm) . . .\nhn-1(xm)\nβn-1\nE(xm)\n\"\n'\n\"\n'\n\"\n'\n\"\n'\nv\nY\nv\nX\nv\nβ\nv\nE\nThe least-squares estimator ˆβ is given by\n(XTX) ˆβ = XTY ,\nand the goodness of fit is measured by ˆσ,\nˆσ =\nm - n IY - Y I2\n1/2\n,\nwhere\n⎞\n⎛\n⎞\n⎛\nn-1\nˆβ0 +\nβˆj hj (x1)\nYmodel(x1)\nYmodel(x2)\n. . .\nj=1\nn-1\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎠\n=\n⎜\n⎜\n⎜\n⎜\n⎜\n⎜\n⎝\n⎟\n⎟\n⎟\n⎟\n⎟\n⎟\n⎠\n\nˆβ0 +\nβˆj hj (x2)\n= X ˆβ .\nj=1 . . .\nY =\nn-1\nˆβ0 +\nβˆj hj (xm)\nYmodel(xm)\nj=1\nAs before, the mean of the mean of the model is equal to the mean of the measurements, i.e.\nY = Y ,\nwhere\nm\nm\nm\nm\nY =\nYi\nand Y =\nYi .\nm\nm\ni=1\ni=1\nThe preservation of the mean is ensured by the presence of the constant term β0 · 1 in our model.\n\nb\n\nb\nb\nb\n\n19.2.3\nConfidence Intervals\nThe construction of the confidence intervals follows the procedure developed in the previous section.\nLet us define the covariance matrix\nΣ = σˆ2(XTX)-1 .\nThen, the individual confidence intervals are given by\nIj = βˆj - tγ,m-n\nΣj+1,j+1, βˆj + tγ,m-n\nΣj+1,j+1 ,\nj = 0, . . . , n - 1 ,\nwhere tγ,m-n comes from the Student's t-distribution as before, i.e.\nγ\n= F -1\ntγ,m-n\nT,m-n\n+\n,\nwhere F -1 is the inverse cumulative distribution function of the t-distribution. The shifting of the\nT,q\ncovariance matrix indices is due to the index for the parameters starting from 0 and the index for\nthe matrix starting from 1. Each of the individual confidence intervals satisfies\nP (βtrue ∈ Ij ) = γ,\nj = 0, . . . , n - 1 ,\nj\nwhere γ is the confidence level.\nWe can also develop joint confidence intervals,\njoint\nI\n= βˆj - sγ,n,m-n\nΣj+1,j+1, βˆj + sγ,n,m-n\nΣj+1,j+1 ,\nj = 0, . . . , n - 1 ,\nj\nwhere the parameter sγ,n,m-n is calculated from the inverse cumulative distribution function for\nthe F -distribution according to\n=\nnF -1\n(γ) .\nThe joint confidence intervals satisfy\nsγ,n,m-n\nF,n,m-n\nβtrue\njoint , βtrue\njoint\njoint and βtrue\njoint\nP\n∈ I\n∈ I\n, . . . , βtrue\n≥ γ .\nn-2 ∈ In-2 ,\nn-1 ∈ In-1\nExample 19.2.1 least-squares estimate for a quadratic function\nConsider a random function of the form\n1 2\nY (x) ∼- + x - x + N (0, σ2) ,\nwith the variance σ2 = 0.01. We would like to model the behavior of the function. Suppose we\nknow (though a physical law or experience) that the output of the underlying process depends\nquadratically on input x. Thus, we choose the basis functions\nh1(x) = 1,\nh2(x) = x,\nand h3(x) = x 2 .\nThe resulting model is of the form\nYmodel(x; β) = β0 + β1x + β2x 2 ,\nq\nq\nq\nq\nq\nb\nb\n\n0.5\n1.5\n2.5\n-0.8\n-0.6\n-0.4\n-0.2\n0.2\n0.4\n0.6\n\nYmeasured\nYmodel\nyclean\n0.5\n1.5\n2.5\n-0.8\n-0.6\n-0.4\n-0.2\n0.2\n0.4\n0.6\n\nYmeasured\nYmodel\nyclean\n(a) m = 14\n(b) m = 140\nFigure 19.6: Least squares fitting of a quadratic function using a quadratic model.\nwhere (β0, β1, β2) are the parameters to be determined through least squares fitting. Note that the\n= -1/2, βtrue\ntrue parameters are given by βtrue\n= 2/3, and βtrue = -1/8.\nThe result of the calculation is shown in Figure 19.6. Our model qualitatively matches well with\nthe underlying \"true\" model. Figure 19.7(a) shows that the 95% individual confidence interval for\neach of the parameters converges as the number of samples increase.\nFigure 19.7(b) verifies that the individual confidence intervals include the true parameter ap\nproximately 95% of the times (shown in the columns indexed 0, 1, and 2). Our joint confidence\ninterval also jointly include the true parameter about 98% of the times, which is greater than the\nprescribed confidence level of 95%. (Note that individual confidence intervals jointly include the\ntrue parameters only about 91% of the times.) These results confirm that both the individual and\njoint confidence intervals are reliable indicators of the quality of the respective estimates.\n·\n19.2.4\nOverfitting (and Underfitting)\nWe have discussed the importance of choosing a model with a sufficiently large n -- such that\nthe true underlying distribution is representable and there would be no bias -- but also hinted\nthat n much larger than necessary can result in an overfitting of the data. Overfitting significantly\ndegrades the quality of our parameter estimate and predictive model, especially when the data is\nnoisy or the number of data points is small. Let us illustrate the effect of overfitting using a few\nexamples.\nExample 19.2.2 overfitting of a linear function\nLet us consider a noisy linear function\nY (x) ∼ 1 + 2x + N (0, σ2) .\nHowever, unlike in the previous examples, we assume that we do not know the form of the input-\noutput dependency. In this and the next two examples, we will consider a general n - 1 degree\npolynomial fit of the form\nn-1\nYmodel,n(x; β) = β0 + β1x + · · · + βn-1x\n.\n\n-0.25\n-0.2\n-0.15\n-0.1\n-0.05\n0.05\n0.1\n0.15\n0.2\nindex\nIi - βi\ntrue\n\nn=3, m=14\nn=3, m=140\nn=3, m=1400\nall\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nfraction in\nindex\n95% confidence\n(a) 95% shifted confidence intervals\n(b) 95% ci in/out (1000 realizations, m = 140)\nFigure 19.7: (a) The variation in the 95% confidence interval with the sampling size m for the linear\nmodel fitting. (b) The frequency of the individual confidence intervals I0, I1, and I2 including the\n, βtrue\njoint\njoint\njoint\ntrue parameters βtrue\n, and βtrue (0, 1, and 2, respectively), and I\n× I\n× I\njointly\n, βtrue, βtrue\nincluding (βtrue\n) (all).\nNote that the true parameters for the noisy function are\nβtrue\nβtrue\nβtrue\n· = βtrue\n= ,\n= 2,\nand\n= · ·\n= 0 ,\nn\nfor any n ≥ 2.\nThe results of fitting the noisy linear function using m = 7 measurements for the n = 2, n = 3,\nand n = 5 response models are shown in Figure 19.8(a), (b), and (c), respectively. The n = 2 is\nthe nominal case, which matches the true underlying functional dependency, and the n = 3 and\nn = 5 cases correspond to overfitting cases. For each fit, we also state the least-squares estimate\nof the parameters. Qualitatively, we see that the prediction error, yclean(x) - Ymodel(x), is larger\nfor the quartic model (n = 5) than the affine model (n = 2). In particular, because the quartic\nmodel is fitting five parameters using just seven data points, the model is close to interpolating\nthe noise, resulting in an oscillatory behavior that follows the noise. This oscillation becomes more\npronounced as the noise level, σ, increases.\nand βtrue\nIn terms of estimating the parameters βtrue\n, the affine model again performs better\nthan the overfit cases. In particular, the error in βˆ1 is over an order of magnitude larger for the n = 5\nmodel than for the n = 2 model. Fortunately, this inaccuracy in the parameter estimate is reflected\nin large confidence intervals, as shown in Figure 19.9. The confidence intervals are valid because\nour models with n ≥ 2 are capable of representing the underlying functional dependency with\ntrue\nn\n= 2, and the unbiasedness assumption used to construct the confidence intervals still holds.\nThus, while the estimate may be poor, we are informed that we should not have much confidence in\nour estimate of the parameters. The large confidence intervals result from the fact that overfitting\neffectively leaves no degrees of freedom (or information) to estimate the noise because relatively\ntoo many degrees of freedom are used to determine the parameters. Indeed, when m = n, the\nconfidence intervals are infinite.\nBecause the model is unbiased, more data ultimately resolves the poor fit, as shown in Fig\n-1/2\nure 19.8(d). However, recalling that the confidence intervals converge only as m\n, a large\n\n0.5\n1.5\n2.5\n-2\n-1\n\nσ = 0.5, m = 7, n = 2\nβ0 = 0.44, β1 = 1.88\nYmeasured\nYmodel\nyclean\n0.5\n1.5\n2.5\n-2\n-1\n\nσ = 0.5, m = 7, n = 3\nβ0 = 0.54, β1 = 1.65, β2 = 0.08\nYmeasured\nYmodel\nyclean\n(a) m = 7, n = 2\n(b) m = 7, n = 3\n0.5\n1.5\n2.5\n-2\n-1\n\nσ = 0.5, m = 7, n = 5\nβ0 = 0.22, β1 = 5.82, β2 = -6.32, β3 = 3.15, β4 = -0.49\nYmeasured\nYmodel\nyclean\n0.5\n1.5\n2.5\n-2\n-1\n\nσ = 0.5, m = 70, n = 5\nβ0 = 0.27, β1 = 2.24, β2 = 0.44, β3 = -0.47, β4 = 0.10\nYmeasured\nYmodel\nyclean\n(c) m = 7, n = 5\n(d) m = 70, n = 5\nFigure 19.8: Least squares fitting of a linear function using polynomial models of various orders.\n-20\n-15\n-10\n-5\nindex\nIi - βi\ntrue\n\nn=2, m=7\nn=3, m=7\nn=5, m=7\nFigure 19.9: The 95% shifted confidence intervals for fitting a linear function using polynomial\nmodels of various orders.\n\nnumber of samples are required to tighten the confidence intervals -- and improve our parameter\nestimates -- for the overfitting cases. Thus, deducing an appropriate response model based on, for\nexample, physical principles can significantly improve the quality of the parameter estimates and\nthe performance of the predictive model.\n·\nBegin Advanced Material\nExample 19.2.3 overfitting of a quadratic function\nIn this example, we study the effect of overfitting in more detail. We consider data governed by a\nrandom quadratic function of the form\nY (x) ∼- + x - cx + N (0, σ2) ,\nwith c = 1. We again consider for our model the polynomial form Ymodel,n(x; β).\nFigure 19.10(a) shows a typical result of fitting the data using m = 14 sampling points and\nn = 4. Our cubic model includes the underlying quadratic distribution. Thus there is no bias and\nour noise assumptions are satisfied. However, compared to the quadratic model (n = 3), the cubic\nmodel is affected by the noise in the measurement and produces spurious variations. This spurious\nvariation tend to disappear with the number of sampling points, and Figure 19.10(b) with m = 140\nsampling points exhibits a more stable fit.\nFigure 19.10(c) shows a realization of confidence intervals for the cubic model (n = 4) using\nm = 14 and m = 140 sampling points. A realization of confidence intervals for the quadratic model\n(n = 3) is also shown for comparison. Using the same set of data, the confidence intervals for the\ncubic model are larger than those of the quadratic model. However, the confidence intervals of the\ncubic model include the true parameter value for most cases. Figure 19.10(d) confirms that the\n95% of the realization of the confidence intervals include the true parameter. Thus, the confidence\nintervals are reliable indicators of the quality of the parameter estimates, and in general the intervals\nget tighter with m, as expected. Modest overfitting, n = 4 vs. n = 3, with m sufficiently large,\nposes little threat.\nLet us check how overfitting affects the quality of the fit using two different measures. The first\nis a measure of how well we can predict, or reproduce, the clean underlying function; the second is\na measure for how well we approximate the underlying parameters.\nFirst, we quantify the quality of prediction using the maximum difference in the model and the\nclean underlying data,\nemax ≡\nmax\n|Ymodel,n(x; βˆ) - Yclean(x)| .\nx∈[-1/4,3+1/4]\nFigure 19.11(a) shows the variation in the maximum prediction error with n for a few different\nvalues of m. We see that we get the closest fit (in the sense of the maximum error), when n = 3\n-- when there are no \"extra\" terms in our model. When only m = 7 data points are used, the\nquality of the regression degrades significantly as we overfit the data (n > 3). As the dimension of\nthe model n approaches the number of measurements, m, we are effectively interpolating the noise.\nThe interpolation induces a large error in the parameter estimates, and we can not estimate the\nnoise since we are fitting the noise. We observe in general that the quality of the estimate improves\nas the number of samples is increased.\nSecond, we quantify the quality of the parameter estimates by measuring the error in the\nquadratic coefficient, i.e., |β2 - βˆ2|. Figure 19.11(b) shows that, not surprisingly, the error in the\n\n0.5\n1.5\n2.5\n-0.8\n-0.6\n-0.4\n-0.2\n0.2\n0.4\n0.6\n\nYmeasured\nYmodel\nyclean\n0.5\n1.5\n2.5\n-0.8\n-0.6\n-0.4\n-0.2\n0.2\n0.4\n0.6\n\nYmeasured\nYmodel\nyclean\n(a) m = 14\n(b) m = 140\n-0.8\n-0.6\n-0.4\n-0.2\n0.2\n0.4\n0.6\nindex\nIi - βi\ntrue\n\nn=4, m=14\nn=4, m=140\nn=3, m=14\nn=3, m=140\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nfraction in\nindex\n95% confidence\n(c) 95% shifted confidence intervals\n(d) 95% ci in/out (100 realizations, m = 140)\nFigure 19.10: Least squares fitting of a quadratic function (c = 1) using a cubic model.\n\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nn\nmaximum error\n\nm=7\nm=14\nm=140\n-3\n-2\n-1\nn\nβ2 error\n\nm=7\nm=14\nm=140\n(a) maximum prediction error\n(b) error in parameter β2\n-3\n-2\n-1\nn\n||Y- X β ||/m1/2\n\nm=7\nm=14\nm=140\n^\nn\nνmax/νmin\n\nm=7\nm=14\nm=140\n(c) (normalized) residual\n(d) condition number\nFigure 19.11: Variation in the quality of regression with overfitting.\n\nparameter increases under overfitting. In particular, for the small sample size of m = 7, the error\nin the estimate for β3 increases from O(10-2) for n = 3 to O(1) for n ≥ 5. Since β3 is an O(1)\nquantity, this renders the parameter estimates for n ≥ 5 essentially meaningless.\nIt is important to recognize that the degradation in the quality of estimate -- either in terms\nof predictability or parameter error -- is not due to the poor fit at the data points. In particular,\nthe (normalized) residual,\nm\n1/2 IY - XβˆI ,\nwhich measures the fit at the data points, decreases as n increases, as shown in Figure 19.11(c). The\ndecrease in the residual is not surprising. We have new coefficients which were previously implicitly\nzero and hence the least squares must provide a residual which is non-increasing as we increase\nn and let these coefficients realize their optimal values (with respect to residual minimization).\nHowever, as we see in Figure 19.11(a) and 19.11(b), better fit at data points does not imply better\nrepresentation of the underlying function or parameters.\nThe worse prediction of the parameter is due to the increase in the conditioning of the problem\n(νmax/νmin), as shown in Figure 19.11(d). Recall that the error in the parameter is a function of\nboth residual (goodness of fit at data points) and conditioning of the problem, i.e.\nIβˆ - βI\nνmax IXβˆ - Y I\n≤\n.\nIβI\nνmin\nIY I\nAs we increase n for a fixed m, we do reduce the residual. However, clearly the error is larger both\nin terms of output prediction and parameter estimate. Once again we see that the residual -- and\nsimilar commonly used goodness of fit statistics such as R2 -- is not the \"final answer\" in terms of\nthe success of any particular regression exercise.\nFortunately, similar to the previous example, this poor estimate of the parameters is reflected\nin large confidence intervals, as shown in Figure 19.12. Thus, while the estimates may be poor, we\nare informed that we should not have much confidence in our estimate of the parameters and that\nwe need more data points to improve the fit.\nFinally, we note that the conditioning of the problem reflects where we choose to make our\nmeasurements, our choice of response model, and how we choose to represent this response model.\nFor example, as regards the latter, a Legendre (polynomial) expansion of order n would certainly\ndecrease νmax/νmin, albeit at some complication in how we extract various parameters of interest.\n·\nExample 19.2.4 underfitting of a quadratic function\nWe consider data governed by a noisy quadratic function (ntrue ≡ 3) of the form\nY (x) ∼- + x - cx + N (0, σ2) .\nWe again assume that the input-output dependency is unknown. The focus of this example is\nunderfitting; i.e., the case in which the degree of freedom of the model n is less than that of data\ntrue\nn\n. In particular, we will consider an affine model (n = 2),\nYmodel,2(x; β) = β0 + β1x ,\nwhich is clearly biased (unless c = 0).\nFor the first case, we consider the true underlying distribution with c = 1, which results in a\nstrong quadratic dependency of Y on x. The result of fitting the function is shown in Figure 19.13.\n\n-4\n-3\n-2\n-1\nindex\nIi - βi\ntrue\n\nn=3, m=14\nn=4, m=14\nn=5, m=14\nn=6, m=14\n-2.5\n-2\n-1.5\n-1\n-0.5\n0.5\n1.5\nindex\nIi - βi\ntrue\n\nn=3, m=140\nn=4, m=140\nn=5, m=140\nn=6, m=140\n(a) m = 14\n(b) m = 140\nFigure 19.12: The variation in the confidence intervals for fitting a quadratic function using\nquadratic (n = 3), cubic (n = 4), quartic (n = 5), and quintic (n = 6) polynomials. Note the\ndifference in the scales for the m = 14 and m = 140 cases.\nNote that the affine model is incapable of representing the quadratic dependency even in the absence\nof noise. Thus, comparing Figure 19.13(a) and 19.13(b), the fit does not improve with the number\nof sampling points.\nFigure 19.13(c) shows typical individual confidence intervals for the affine model (n = 2) using\nm = 14 and m = 140 sampling points. Typical confidence intervals for the quadratic model (n = 3)\nare also provided for comparison. Let us first focus on analyzing the fit of the affine model (n = 2)\nusing m = 14 sampling points. We observe that this realization of confidence intervals I0 and I1\nand βtrue\ndoes not include the true parameters βtrue\n, respectively. In fact, Figure 19.13(d) shows\nthat only 37 of the 100 realizations of the confidence interval I0 include βtrue and that none of the\nrealizations of I1 include β1\ntrue . Thus the frequency that the true value lies in the confidence interval\nis significantly lower than 95%. This is due to the presence of the bias error, which violates our\nassumptions about the behavior of the noise -- the assumptions on which our confidence interval\nestimate rely. In fact, as we increase the number of sampling point from m = 14 to m = 140 we\nsee that the confidence intervals for both β0 and β1 tighten; however, they converge toward wrong\nvalues. Thus, in the presence of bias, the confidence intervals are unreliable, and their convergence\nimplies little about the quality of the estimates.\nLet us now consider the second case with c = 1/10. This case results in a much weaker\nquadratic dependency of Y on x. Typical fits obtained using the affine model are shown in Fig\nure 19.14(a) and 19.14(b) for m = 14 and m = 140 sampling points, respectively. Note that the fit\nis better than the c = 1 case because the c = 1/10 data can be better represented using the affine\nmodel.\nTypical confidence intervals, shown in Figure 19.14(c), confirm that the confidence intervals are\nmore reliable than in the c = 1 case. Of the 100 realizations for the m = 14 case, 87% and 67%\nand βtrue\nof the confidence intervals include the true values β0\ntrue\n, respectively. The frequencies\nare lower than the 95%, i.e., the confidence intervals are not as reliable as their pretension, due\nto the presence of bias. However, they are more reliable than the case with a stronger quadratic\ndependence, i.e. a stronger bias. Recall that a smaller bias leading to a smaller error is consistent\nwith the deterministic error bounds we developed in the presence of bias.\nSimilar to the c = 1 case, the confidence interval tightens with the number of samples m, but\n\n0.5\n1.5\n2.5\n-0.8\n-0.6\n-0.4\n-0.2\n0.2\n0.4\n0.6\n\nYmeasured\nYmodel\nyclean\n0.5\n1.5\n2.5\n-0.8\n-0.6\n-0.4\n-0.2\n0.2\n0.4\n0.6\n\nYmeasured\nYmodel\nyclean\n(a) m = 14\n(b) m = 140\n-0.5\n-0.4\n-0.3\n-0.2\n-0.1\n0.1\n0.2\n0.3\nindex\nIi - βi\ntrue\n\nn=2, m=14\nn=2, m=140\nn=3, m=14\nn=3, m=140\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nfraction in\nindex\n95% confidence\n(c) 95% shifted confidence intervals\n(d) 95% ci in/out (100 realizations, m = 14)\nFigure 19.13: Least squares fitting of a quadratic function (c = 1) using an affine model.\n\n0.5\n1.5\n2.5\n-1\n-0.5\n0.5\n1.5\n\nYmeasured\nYmodel\nyclean\n0.5\n1.5\n2.5\n-1\n-0.5\n0.5\n1.5\n\nYmeasured\nYmodel\nyclean\n(a) m = 14\n(b) m = 140\n-0.25\n-0.2\n-0.15\n-0.1\n-0.05\n0.05\n0.1\n0.15\n0.2\nindex\nIi - βi\ntrue\n\nn=2, m=14\nn=2, m=140\nn=3, m=14\nn=3, m=140\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nfraction in\nindex\n95% confidence\n(c) 95% shifted confidence intervals\n(d) 95% ci in/out (100 realizations, m = 14)\nFigure 19.14: Least squares fitting of a quadratic function (c = 1/10) using an affine model.\n\nthey converge to a wrong value. Accordingly, the reliability of the confidence intervals decreases\nwith m.\n·\nEnd Advanced Material\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n2.086 Numerical Computation for Mechanical Engineers\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Unit 4: (Numerical) Differential Equations from Math, Numerics, and Programming (for Mechanical Engineers). V1.2, September 2012.",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-086-numerical-computation-for-mechanical-engineers-fall-2012/53ab25108f65316a6889a3053e1f4864_MIT2_086F12_notes_unit4.pdf",
      "content": "DRAFT V1.2\nFrom\nMath, Numerics, & Programming\n(for Mechanical Engineers)\nMasayuki Yano\nJames Douglass Penn\nGeorge Konidaris\nAnthony T Patera\nSeptember 2012\n(c) The Authors. License: Creative Commons Attribution-Noncommercial-Share Alike 3.0\n(CC BY-NC-SA 3.0), which permits unrestricted use, distribution, and reproduction\nin any medium, provided the original authors and MIT OpenCourseWare source\nare credited; the use is non-commercial; and the CC BY-NC-SA license is\nretained. See also http://ocw.mit.edu/terms/.\n\nContents\nIV\n(Numerical) Differential Equations\n20 Motivation\n21 Initial Value Problems\n21.1 Scalar First-Order Linear ODEs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307\n21.1.1 Model Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307\n21.1.2 Analytical Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 308\nHomogeneous Equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 308\nConstant Forcing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 308\nSinusoidal Forcing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309\n21.1.3 A First Numerical Method: Euler Backward (Implicit) . . . . . . . . . . . . . 310\nDiscretization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 311\nConsistency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312\nStability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314\nConvergence: Dahlquist Equivalence Theorem . . . . . . . . . . . . . . . . . . 315\nOrder of Accuracy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 317\n21.1.4 An Explicit Scheme: Euler Forward . . . . . . . . . . . . . . . . . . . . . . . 317\n21.1.5 Stiff Equations: Implicit vs. Explicit . . . . . . . . . . . . . . . . . . . . . . . 320\n21.1.6 Unstable Equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322\n21.1.7 Absolute Stability and Stability Diagrams . . . . . . . . . . . . . . . . . . . . 322\nEuler Backward . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322\nEuler Forward . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325\n21.1.8 Multistep Schemes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325\nAdams-Bashforth Schemes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 328\nAdams-Moulton Schemes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 329\nConvergence of Multistep Schemes: Consistency and Stability . . . . . . . . . 331\nBackward Differentiation Formulas . . . . . . . . . . . . . . . . . . . . . . . . 335\n21.1.9 Multistage Schemes: Runge-Kutta . . . . . . . . . . . . . . . . . . . . . . . . 337\n21.2 Scalar Second-Order Linear ODEs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 341\n21.2.1 Model Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 341\n21.2.2 Analytical Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342\nHomogeneous Equation: Undamped . . . . . . . . . . . . . . . . . . . . . . . 342\nHomogeneous Equation: Underdamped . . . . . . . . . . . . . . . . . . . . . 344\nHomogeneous Equation: Overdamped . . . . . . . . . . . . . . . . . . . . . . 345\nSinusoidal Forcing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 346\n21.3 System of Two First-Order Linear ODEs . . . . . . . . . . . . . . . . . . . . . . . . . 347\n21.3.1 State Space Representation of Scalar Second-Order ODEs . . . . . . . . . . . 348\nSolution by Modal Expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . 349\n\n21.3.2 Numerical Approximation of a System of Two ODEs . . . . . . . . . . . . . . 351\nCrank-Nicolson . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 351\nGeneral Recipe . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352\n21.4 IVPs: System of n Linear ODEs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 356\n22 Boundary Value Problems\n23 Partial Differential Equations\n\nUnit IV\n(Numerical) Differential Equations\n\nChapter 20\nMotivation\nAlthough mobile robots operating in flat, indoor environments can often perform quite well\nwithout any suspension, in uneven terrain, a well-designed suspension can be critical.\nAn actual robot suspension and its simplified model are shown in Figure 20.1. The rear and front\nsprings with spring constants k1 and k2 serve to decouple the rest of the robot chassis from the\nwheels, allowing the chassis and any attached instrumentation to \"float\" relatively unperturbed\nwhile the wheels remain free to follow the terrain and maintain traction. The rear and front\ndampers with damping coefficients c1 and c2 (shown here inside the springs) dissipate energy to\nprevent excessive chassis displacements (e.g., from excitation of a resonant mode) and oscillations.\nNote that in our \"half-robot\" model, k1 accounts for the combined stiffness of both rear wheels,\nand k2 accounts for the combined stiffness of both front wheels. Similarly, c1 and c2 account for\nthe combined damping coefficients of both rear wheels and both front wheels, respectively.\nWe are particularly concerned with the possibility of either the front or rear wheels losing contact\nwith the ground, the consequences of which -- loss of control and a potentially harsh landing --\nwe wish to avoid.\nTo aid in our understanding of robot suspensions and, in particular, to understand the condi\ntions resulting in loss of contact, we wish to develop a simulation based on the simple model of\nFigure 20.1(b). Specifically, we wish to simulate the transient (time) response of the robot with\nsuspension traveling at some constant velocity v over a surface with profile H(x), the height of the\nground as a function of x, and to check if loss of contact occurs. To do so, we must integrate the\ndifferential equations of motion for the system.\nFirst, we determine the motion at the rear (subscript 1) and front (subscript 2) wheels in order\nto calculate the normal forces N1 and N2. Because we assume constant velocity v, we can determine\nthe position in x of the center of mass at any time t (we assume X(t = 0) = 0) as\nX = vt .\n(20.1)\nGiven the current state Y , Y , θ (the inclination of the chassis), and θ , we can then calculate the\nDRAFT V1.2 (c) The Authors. License: Creative Commons BY-NC-SA 3.0.\n\nH(x)\nθ\nmg\nN1\nN2\nY\nv\nx\ny\nh2\nm,Izz\nL2\nL1\nk ,c\nk ,c\n(a) Actual robot suspension.\n(b) Robot suspension model.\nFigure 20.1: Mobile robot suspension\npositions and velocities in both x and y at the rear and front wheels (assuming θ is small) as\nX1 = X - L1,\n(X 1 = v) ,\nX2 = X + L2,\n(X 2 = v) ,\nY1 = Y - L1θ ,\n(20.2)\n\nY1 = Y - L1θ ,\nY2 = Y + L2θ ,\n\nY2 = Y + L2θ ,\nwhere L1 and L2 are the distances to the system's center of mass from the rear and front wheels.\n(Recall refers to time derivative.) Note that we define Y = 0 as the height of the robot's center\nof mass with both wheels in contact with flat ground and both springs at their unstretched and\nuncompressed lengths, i.e., when N1 = N2 = 0. Next, we determine the heights of the ground at\nthe rear and front contact points as\nh1 = H(X1) ,\n(20.3)\nh2 = H(X2) .\nSimilarly, the rates of change of the ground height at the rear and front are given by\ndh1\nd\n\n= h1 = v\nH(X1) ,\ndt\ndx\n(20.4)\ndh2\nd\n\n= h2 = v\nH(X2) .\ndt\ndx\ndX\nNote that we must multiply the spatial derivatives dH\ndx by v = dt to find the temporal derivatives.\nWhile the wheels are in contact with the ground we can determine the normal forces at the rear\nand front from the constitutive equations for the springs and dampers as\nN1 = k1(h1 - Y1) + c1(h 1 - Y 1) ,\n(20.5)\nN2 = k2(h2 - Y2) + c2(h 2 - Y 2) .\nCourtesy of James Penn. Used with permission.\n\nIf either N1 or N2 is calculated from Equations (20.5) to be less than or equal to zero, we can\ndetermine that the respective wheel has lost contact with the ground and stop the simulation,\nconcluding loss of contact, i.e., failure.\nFinally, we can determine the rates of change of the state from the linearized (cos θ ≈ 1,\nsin θ ≈ θ) equations of motion for the robot, given by Newton-Euler as\n\nX = 0,\nX = v,\nX(0) = 0 ,\nN1 + N2\nY = -g +\n,\nY (0) = Y 0,\nY (0) = Y0 ,\n(20.6)\nm\nN2L2 - N1L1\n\nθ =\n,\nθ (0) = θ 0,\nθ(0) = θ0 ,\nIzz\nwhere m is the mass of the robot, and Izz is the moment of inertia of the robot about an axis\nparallel to the Z axis passing through the robot's center of mass.\nIn this unit we shall discuss the numerical procedures by which to integrate systems of ordinary\ndifferential equations such as (20.6). This integration can then permit us to determine loss of\ncontact and hence failure.\n\nChapter 21\nInitial Value Problems\n21.1\nScalar First-Order Linear ODEs\n21.1.1\nModel Problem\nLet us consider a canonical initial value problem (IVP),\ndu = λu + f(t),\n0 < t < tf ,\ndt\nu(0) = u0 .\nThe objective is to find u over all time t ∈ ]0, tf ] that satisfies the ordinary differential equation\n(ODE) and the initial condition. This problem belongs to the class of initial value problems (IVP)\nsince we supplement the equation with condition(s) only at the initial time. The ODE is first order\nbecause the highest derivative that appears in the equation is the first-order derivative; because it\nis first order, only one initial condition is required to define a unique solution. The ODE is linear\nbecause the expression is linear with respect to u and its derivative du/dt; note that f does not have\nto be a linear function of t for the ODE to be linear. Finally, the equation is scalar since we have\nonly a single unknown, u(t) ∈ R. The coefficient λ ∈ R controls the behavior of the ODE; λ < 0\nresults in a stable (i.e. decaying) behavior, whereas λ > 0 results in an unstable (i.e. growing)\nbehavior.\nWe can motivate this model problem (with λ < 0) physically with a simple heat transfer\nsituation. We consider a body at initial temperature u0 > 0 which is then \"dunked\" or \"immersed\"\ninto a fluid flow -- forced or natural convection -- of ambient temperature (away from the body)\nzero. (More physically, we may view u0 as the temperature elevation above some non-zero ambient\ntemperature.) We model the heat transfer from the body to the fluid by a heat transfer coefficient,\nh. We also permit heat generation within the body, q (t), due (say) to Joule heating or radiation.\nIf we now assume that the Biot number -- the product of h and the body \"diameter\" in the\nnumerator, thermal conductivity of the body in the denominator -- is small, the temperature of\nthe body will be roughly uniform in space. In this case, the temperature of the body as a function\nof time, u(t), will be governed by our ordinary differential equation (ODE) initial value problem\n(IVP), with λ = -h Area/ρc Vol and f(t) = q (t)/ρc Vol, where ρ and c are the body density and\nspecific heat, respectively, and Area and Vol are the body surface area and volume, respectively.\nDRAFT V1.2 (c) The Authors. License: Creative Commons BY-NC-SA 3.0.\n\nIn fact, it is possible to express the solution to our model problem in closed form (as a con\nvolution). Our interest in the model problem is thus not because we require a numerical solution\nprocedure for this particular simple problem. Rather, as we shall see, our model problem will\nprovide a foundation on which to construct and understand numerical procedures for much more\ndifficult problems -- which do not admit closed-form solution.\n21.1.2\nAnalytical Solution\nBefore we pursue numerical methods for solving the IVP, let us study the analytical solution for\na few cases which provide insight into the solution and also suggest test cases for our numerical\napproaches.\nHomogeneous Equation\nThe first case considered is the homogeneous case, i.e., f(t) = 0. Without loss of generality, let us\nset u0 = 1. Thus, we consider\ndu = λu,\n0 < t < tf ,\ndt\nu(0) = 1 .\nWe find the analytical solution by following the standard procedure for obtaining the homogeneous\nsolution, i.e., substitute u = αeβt to obtain\n(LHS) = du = d (αeβt) = αβet ,\ndt\ndt\n(RHS) = λαeβt .\nEquating the LHS and RHS, we obtain β = λ. The solution is of the form u(t) = αeλt . The\ncoefficient α is specified by the initial condition, i.e.\nu(t = 0) = α = 1 ;\nthus, the coefficient is α = 1. The solution to the homogeneous ODE is\nu(t) = e λt .\nNote that solution starts from 1 (per the initial condition) and decays to zero for λ < 0. The decay\nrate is controlled by the time constant 1/|λ| -- the larger the λ, the faster the decay. The solution\nfor a few different values of λ are shown in Figure 21.1.\nWe note that for λ > 0 the solution grows exponentially in time: the system is unstable. (In\nactual fact, in most physical situations, at some point additional terms -- for example, nonlinear\neffects not included in our simple model -- would become important and ensure saturation in\nsome steady state.) In the remainder of this chapter unless specifically indicated otherwise we shall\nassume that λ < 0.\nConstant Forcing\nNext, we consider a constant forcing case with u0 = 0 and f(t) = 1, i.e.\ndu = λu + 1 ,\ndt\nu0 = 0 .\n\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nt\nu(t)\n\nλ = -1\nλ = -0.5\nλ = -4.0\nFigure 21.1: Solutions to the homogeneous equation.\nWe have already found the homogeneous solution to the ODE. We now find the particular solution.\nBecause the forcing term is constant, we consider a particular solution of the form up(t) = γ.\nSubstitution of up yields\n0 = λγ + 1\n⇒\nγ = -\n.\nλ\nThus, our solution is of the form\nu(t) = - 1 + αeλt .\nλ\nEnforcing the initial condition,\nu(t = 0) = - + α = 0\n⇒\nα =\n.\nλ\nλ\nThus, our solution is given by\n\nλt - 1\nu(t) =\ne\n.\nλ\nThe solutions for a few different values of λ are shown in Figure 21.2. For λ < 0, after the transient\nwhich decays on the time scale 1/|λ|, the solution settles to the steady state value of -1/λ.\nSinusoidal Forcing\nLet us consider a final case with u0 = 0 and a sinusoidal forcing, f(t) = cos(ωt), i.e.\ndu = λu + cos(ωt) ,\ndt\nu0 = 0 .\nBecause the forcing term is sinusoidal with the frequency ω, the particular solution is of the form\nup(t) = γ sin(ωt) + δ cos(ωt). Substitution of the particular solution to the ODE yields\ndup\n(LHS) =\n= ω(γ cos(ωt) - δ sin(ωt)) ,\ndt\n(RHS) = λ(γ sin(ωt) + δ cos(ωt)) + cos(ωt) .\n\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n1.6\n1.8\nt\nu(t)\n\nλ = -1\nλ = -0.5\nλ = -4.0\nFigure 21.2: Solutions to the ODE with unit constant forcing.\nEquating the LHS and RHS and collecting like coefficients we obtain\nωγ = λδ + 1 ,\n-ωδ = λγ .\nThe solution to this linear system is given by γ = ω/(ω2 + λ2) and δ = -λ/(ω2 + λ2). Thus, the\nsolution is of the form\nu(t) =\nω\nsin(ωt) -\nλ\ncos(ωt) + αeλt .\nω2 + λ2\nω2 + λ2\nImposing the boundary condition, we obtain\nλ\nλ\nu(t = 0) = -\n+ α = 0\n⇒\nα =\n.\nω2 + λ2\nω2 + λ2\nThus, the solution to the IVP with the sinusoidal forcing is\nω\nλ\nλt\nu(t) =\nsin(ωt) -\ncos(ωt) - e\n.\nω2 + λ2\nω2 + λ2\nWe note that for low frequency there is no phase shift; however, for high frequency there is a π/2\nphase shift.\nThe solutions for λ = -1, ω = 1 and λ = -20, ω = 1 are shown in Figure 21.3. The steady\nstate behavior is controlled by the sinusoidal forcing function and has the time scale of 1/ω. On\nthe other hand, the initial transient is controlled by λ and has the time scale of 1/|λ|. In particular,\nnote that for |λ| » ω, the solution exhibits very different time scales in the transient and in the\nsteady (periodic) state. This is an example of a stiff equation (we shall see another example at the\nconclusion of this unit). Solving a stiff equation introduces additional computational challenges for\nnumerical schemes, as we will see shortly.\n21.1.3\nA First Numerical Method: Euler Backward (Implicit)\nIn this section, we consider the Euler Backward integrator for solving initial value problems. We\nfirst introduce the time stepping scheme and then discuss a number of properties that characterize\nthe scheme.\n\n-1\nt\nu(t)\n\n5-0.05\n0.05\nλ = -1, ω = -1\nλ = -20, ω = -1\nFigure 21.3: Solutions to the ODE with sinusoidal forcing.\nDiscretization\nIn order to solve an IVP numerically, we first discretize the time domain ]0, tf ] into J segments.\nThe discrete time points are given by\njt = jΔt,\nj = 0, 1, . . . , J = tf /Δt ,\nwhere Δt is the time step. For simplicity, we assume in this chapter that the time step is constant\nthroughout the time integration.\nThe Euler Backward method is obtained by applying the first-order Backward Difference For\nmula (see Unit I) to the time derivative. Namely, we approximate the time derivative by\nj-1\ndu\nu j - u\n≈\n,\ndt\nΔt\nwhere uj = u (tj ) is the approximation to u(tj ) and Δt = tj - tj-1 is the time step. Substituting\nthe approximation into the differential equation, we obtain a difference equation\nj-1\nu j - u\n= λu j + f(tj ),\nj = 1, . . . , J ,\nΔt\nu 0 = u0 ,\nj\nfor u , j = 0, . . . , J. Note the scheme is called \"implicit\" because time level j appears on the\nright-hand side. We can think of Euler Backward as a kind of rectangle, right integration rule --\nbut now the integrand is not known a priori.\nWe anticipate that the solution uj , j = 1, . . . , J, approaches the true solution u(tj ), j = 1, . . . , J,\nas the time step gets smaller and the finite difference approximation approaches the continuous sys\ntem. In order for this convergence to the true solution to take place, the discretization must possess\ntwo important properties: consistency and stability. Note our analysis here is more subtle than\nthe analysis in Unit I. In Unit I we looked at the error in the finite difference approximation; here,\nwe are interested in the error induced by the finite difference approximation on the approximate\nsolution of the ODE IVP.\n\n|\n{z\n}\nConsistency\nConsistency is a property of a discretization that ensures that the discrete equation approximates\nthe same process as the underlying ODE as the time step goes to zero. This is an important\nproperty, because if the scheme is not consistent with the ODE, then the scheme is modeling a\ndifferent process and the solution would not converge to the true solution.\nLet us define the notion of consistency more formally. We first define the truncation error by\nsubstituting the true solution u(t) into the Euler Backward discretization, i.e.\nj\nu(tj ) - u(tj-1)\nτ\n≡\n- λu(tj ) - f(tj ),\nj = 1, . . . , J .\ntrunc\nΔt\nj\nNote that the truncation error, τ\n, measures the extent to which the exact solution to the ODE\ntrunc\ndoes not satisfy the difference equation. In general, the exact solution does not satisfy the difference\nj\nj\nj\nequation, so τ\n\n= 0, j = 1, . . . , J, then = u(tj ),\n= 0. In fact, as we will see shortly, if τ\nu\ntrunc\ntrunc\ni.e., uj is the exact solution to the ODE at the time points.\nWe are particularly interested in the largest of the truncation errors, which is in a sense the\nlargest discrepancy between the differential equation and the difference equation. We denote this\nusing the infinity norm,\nj\nIτtruncIinf = max |τ\n| .\ntrunc\nj=1,...,J\nA scheme is consistent with the ODE if\nIτtruncIinf → 0 as Δt → 0 .\nThe difference equation for a consistent scheme approaches the differential equation as Δt →\n0. However, this does not necessary imply that the solution to the difference equation, u (tj ),\napproaches the solution to the differential equation, u(tj ).\nThe Euler Backward scheme is consistent. In particular\n\nd2u\ndt2 (t)\n→ 0 as Δt → 0 .\nIτtruncIinf ≤ Δt max\n2 t∈[0,tf ]\nWe demonstrate this result below.\nBegin Advanced Material\nLet us now analyze the consistency of the Euler Backward integration scheme. We first apply\nTaylor expansion to u(tj-1) about tj , i.e.\nu(t j-1) = u(tj ) - Δt du\ndt (t j ) -\ntj τ\nd2u\n\n(γ)dγ\ndτ .\ndt2\ntj-1\ntj-1\nsj (u)\nThis result is simple to derive. By the fundamental theorem of calculus,\nτ\ndu2\ndu\ndu\n(γ)dγ =\n(τ ) -\n(tj-1) .\ntj-1 dt2\ndt\ndt\n\n|\n{z\n}\n\nIntegrating both sides over ]tj-1, tj [,\n\ntj\nτ\ntj\ntj\ndu2\ndu\ndu\nj-1)\n(γ)dγ dτ =\n(τ)\ndτ -\n(t\ndτ\ntj-1\ntj-1 dt2\ntj-1\ndt\ntj-1\ndt\n= u(tj ) - u(tj-1) - (tj - tj-1) du (tj-1)\ndt\nj-1) - Δtdu\nj-1) .\n= u(tj ) - u(t\n(t\ndt\nSubstitution of the expression to the right-hand side of the Taylor series expansion yields\ndu\ndu\ndu\nu(tj ) - Δt\n(tj ) - sj (u) = u(tj ) - Δt\n(tj) - u(tj ) + u(tj-1) + Δt\n(tj-1) = u(tj-1) ,\ndt\ndt\ndt\nwhich proves the desired result.\nSubstituting the Taylor expansion into the expression for the truncation error,\nu(tj ) - u(tj-1)\nj\nj )\nτ\n=\n- λu(tj ) - f(t\ntrunc\nΔt\n\n= 1\nu(tj ) -\nu(tj ) - Δtdu (tj ) - sj (u)\n- λu(tj ) - f(tj )\nΔt\ndt\ndu\nsj (u)\n=\n(tj ) - λu(tj ) - f(tj ) +\ndt\nΔt\n=0 : by ODE\nsj (u)\n=\n.\nΔt\nWe now bound the remainder term sj (u) as a function of Δt. Note that\ntj\nτ\ntj\nτ\nd2\nd2\nu\nu\nsj (u) =\n(γ)dγ dτ ≤\n(γ) dγ dτ\ntj-1\ntj-1 dt2\ntj-1\ntj-1 dt2\ntj\nτ\nd2u\n≤\nmax\n(t)\ndγdτ\nt∈[tj-1,tj ] dt2\ntj-1\ntj-1\nd2\nΔt2\nu\n=\nmax\n(t)\n,\nj = 1, . . . , J .\nt∈[tj-1,tj ] dt2\nSo, the maximum truncation error is\nj\nd2u\nΔt2\nΔt\nd2u\nIτtruncIinf = max |τ\n| ≤ max\nmax\n(t)\n≤\nmax\n(t) .\ntrunc\nj=1,...,J\nj=1,...,J\nΔt t∈[tj-1,tj ] dt2\n2 t∈[0,tf ] dt2\nWe see that\nΔt\nd2u\nIτtruncIinf ≤\nmax\n(t) → 0 as Δt → 0 .\n2 t∈[0,tf ] dt2\nThus, the Euler Backward scheme is consistent.\nEnd Advanced Material\nZ\nZ\n!\nZ\n\nZ\n\n!\nZ\nZ\n!\nZ\nZ\n\n!\n\nZ\nZ\n\n!\n\n|\n{z\n}\n\nStability\nStability is a property of a discretization that ensures that the error in the numerical approximation\ndoes not grow with time. This is an important property, because it ensures that a small truncation\nerror introduced at each time step does not cause a catastrophic divergence in the solution over\ntime.\nTo study stability, let us consider a homogeneous IVP,\ndu = λu ,\ndt\nu(0) = 1 .\nRecall that the true solution is of the form u(t) = eλt and decays for λ < 0. Applying the Euler\nBackward scheme, we obtain\nj-1\nu j - u\nj\n= λu ,\nj = 1, . . . , J ,\nΔt\nu 0 = 1 .\nA scheme is said to be absolutely stable if\n|u j | ≤|u j-1|,\nj = 1, . . . , J .\nAlternatively, we can define the amplification factor, γ, as\n|u j |\nγ ≡\n.\n|u j-1|\nAbsolute stability requires that γ ≤ 1 for all j = 1, . . . , J.\nLet us now show that the Euler Backward scheme is stable for all Δt (for λ < 0). Rearranging\nthe difference equation,\nj-1\nj\nu j - u\n= λΔt u\nu j (1 - λΔt) = u j-1\n|u j | |1 - λΔt| = |u j-1| .\nSo, we have\n|u j |\nγ =\n=\n.\n|u j-1|\n|1 - λΔt|\nRecalling that λ < 0 (and Δt > 0), we have\nγ =\n< 1 .\n1 - λΔt\nThus, the Euler Backward scheme is stable for all Δt for the model problem considered. The\nscheme is said to be unconditionally stable because it is stable for all Δt. Some schemes are only\nconditionally stable, which means the scheme is stable for Δt ≤ Δtcr, where Δtcr is some critical\ntime step.\n\nConvergence: Dahlquist Equivalence Theorem\nNow we define the notion of convergence. A scheme is convergent if the numerical approximation\napproaches the analytical solution as the time step is reduced. Formally, this means that\nu j ≡ u (tj ) → u(tj ) for fixed tj as Δt → 0 .\nNote that fixed time tj means that the time index must go to infinity (i.e., an infinite number of\ntime steps are required) as Δt → 0 because tj = jΔt. Thus, convergence requires that not too\nmuch error is accumulated at each time step. Furthermore, the error generated at a given step\nshould not grow over time.\nThe relationship between consistency, stability, and convergence is summarized in the Dahlquist\nequivalence theorem. The theorem states that consistency and stability are the necessary and\nsufficient condition for a convergent scheme, i.e.\nconsistency + stability ⇔ convergence .\nThus, we only need to show that a scheme is consistent and (absolutely) stable to show that\nthe scheme is convergent. In particular, the Euler Backward scheme is convergent because it is\nconsistent and (absolutely) stable.\nBegin Advanced Material\nExample 21.1.1 Consistency, stability, and convergence for Euler Backward\nIn this example, we will study in detail the relationship among consistency, stability, and conver\nj\ngence for the Euler Backward scheme. Let us denote the error in the solution by e ,\nej ≡ u(tj ) - u (tj ) .\nWe first relate the evolution of the error to the truncation error. To begin, we recall that\nu(tj ) - u(tj-1) - λΔtu(tj ) - Δtf(tj ) = Δtτ j\n,\ntrunc\nu (tj ) - u (tj-1) - λΔtu (tj ) - Δtf(tj ) = 0 ;\nsubtracting these two equations and using the definition of the error we obtain\nej - ej-1 - λΔtej = Δtτ j\n,\ntrunc\nor, rearranging the equation,\n(1 - λΔt)ej - ej-1 = Δtτ j\n.\ntrunc\nWe see that the error itself satisfies the Euler Backward difference equation with the truncation\nj\nerror as the source term. Clearly, if the truncation error τ\nis zero for all time steps (and initial\ntrunc\nerror is zero), then the error remains zero. In other words, if the truncation error is zero then the\nscheme produces the exact solution at each time step.\nHowever, in general, the truncation error is nonzero, and we would like to analyze its influence\non the error. Let us multiply the equation by (1 - λΔt)j-1 to get\n(1 - λΔt)j ej - (1 - λΔt)j-1 ej-1 = (1 - λΔt)j-1Δtτ j\n,\ntrunc\n\nNow, let us compute the sum for j = 1, . . . , n, for some n ≤ J,\nn\n\nn\n\nn\nn\n(1 - λΔt)j ej - (1 - λΔt)j-1 ej-1 =\n(1 - λΔt)j-1Δtτ j\n.\ntrunc\nj=1\nj=1\nThis is a telescopic series and all the middle terms on the left-hand side cancel. More explicitly,\n(1 - λΔt)n e n - (1 - λΔt)n-1 e n-1 = (1 - λΔt)n-1Δtτ n\ntrunc\n(1 - λΔt)n-1 e n-1 - (1 - λΔt)n-2 e n-2 = (1 - λΔt)n-2Δtτ n-1\ntrunc\n. . .\n(1 - λΔt)2 e 2 - (1 - λΔt)1 e 1 = (1 - λΔt)1Δtτ 2\ntrunc\n(1 - λΔt)1 e 1 - (1 - λΔt)0 e 0 = (1 - λΔt)0Δtτ 1\ntrunc\nsimplifies to\nn\nn\n(1 - λΔt)n e n - e 0 =\n(1 - λΔt)j-1Δtτ j\n.\ntrunc\nj=1\nRecall that we set u = u (t0) = u(t0), so the initial error is zero (e0 = 0). Thus, we are left with\nn\nn\n(1 - λΔt)n e n =\n(1 - λΔt)j-1Δtτ j\ntrunc\nj=1\nor, equivalently,\nn\nn\ne n =\n(1 - λΔt)j-n-1Δtτ j\n.\ntrunc\nj=1\nj\nRecalling that IτtruncIinf = maxj=1,...,J |τ\n|, we can bound the error by\ntrunc\nn\nn\n|e n| ≤ ΔtIτtruncIinf\n(1 - λΔt)j-n-1 .\nj=1\nRecalling the amplification factor for the Euler Backward scheme, γ = 1/(1 - λΔt), the summation\ncan be rewritten as\nn\nn\n(1 - λΔt)j-n-1 =\n+\n+ · · · +\n(1 - λΔt)n\n(1 - λΔt)n-1\n(1 - λΔt)\nj=1\n+ γn-1\n= γn\n+ · · · + γ .\nBecause the scheme is stable, the amplification factor satisfies γ ≤ 1. Thus, the sum is bounded by\nn\nn\n(1 - λΔt)j-n-1 = γn + γn-1 + · · · + γ ≤ nγ ≤ n .\nj=1\n\nThus, we have\n|e n| ≤ (nΔt)IτtruncIinf = tnIτtruncIinf .\nFurthermore, because the scheme is consistent, IτtruncIinf → 0 as Δt → 0. Thus,\nIe nI ≤ tnIτtruncIinf → 0 as Δt → 0\nfor fixed tn = nΔt. Note that the proof of convergence relies on stability (γ ≤ 1) and consistency\n(IτtruncIinf → 0 as Δt → 0).\n·\nEnd Advanced Material\nOrder of Accuracy\nThe Dahlquist equivalence theorem shows that if a scheme is consistent and stable, then it is\nconvergent. However, the theorem does not state how quickly the scheme converges to the true\nsolution as the time step is reduced. Formally, a scheme is said to be pth-order accurate if\nj\n|ej | < CΔtp\nfor a fixed t = jΔt as Δt → 0 .\nThe Euler Backward scheme is first-order accurate (p = 1), because\nj Δt\nd2u\nIej I ≤ tj IτtruncIinf ≤ t\nmax\n(t) ≤ CΔt\n2 t∈[0,tf ] dt2\nwith\ntf\nd2u\nC =\nmax\n(t) .\n2 t∈[0,tf ] dt2\n(We use here tj ≤ tf .)\nIn general, for a stable scheme, if the truncation error is pth-order accurate, then the scheme is\npth-order accurate, i.e.\np\np\nj\nIτtruncIinf ≤ CΔt\n⇒\n|ej | ≤ CΔt\nfor a fixed t = jΔt .\nIn other words, once we prove the stability of a scheme, then we just need to analyze its truncation\nerror to understand its convergence rate. This requires little more work than checking for consis\ntency. It is significantly simpler than deriving the expression for the evolution of the error and\nanalyzing the error behavior directly.\nFigure 21.4 shows the error convergence behavior of the Euler Backward scheme applied to the\nhomogeneous ODE with λ = -4. The error is measured at t = 1. Consistent with the theory, the\nscheme converges at the rate of p = 1.\n21.1.4\nAn Explicit Scheme: Euler Forward\nLet us now introduce a new scheme, the Euler Forward scheme. The Euler Forward scheme is\nobtained by applying the first-order forward difference formula to the time derivative, i.e.\nj+1 - j\ndu\nu\nu\n≈\n.\ndt\nΔt\n\n|\n{z\n}\n0.2\n0.4\n0.6\n0.8\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nt\nu\n\n∆t = 0.5\n∆t = 0.125\n∆t = 0.03125\nexact\n-2\n-1\n-3\n-2\n-1\n1.00\n∆t\ne(t=1)\n(a) solution\n(b) error\nFigure 21.4: The error convergence behavior for the Euler Backward scheme applied to the homo\ngeneous ODE (λ = -4). Note e(t = 1) = |u(tj ) - u j | at tj = jΔt = 1.\nSubstitution of the expression to the linear ODE yields a difference equation,\nj+1 - j\nu\nu = λuj + f(tj ),\nj = 0, . . . , J - 1 ,\nΔt\nu 0 = u0 .\nTo maintain the same time index as the Euler Backward scheme (i.e., the difference equation\ninvolves the unknowns uj and uj-1), let us shift the indices to obtain\nj-1\nu j - u\n= λuj-1 + f(tj-1),\nj = 1, . . . , J ,\nΔt\nu 0 = u0 .\nThe key difference from the Euler Backward scheme is that the terms on the right-hand side are\nevaluated at tj-1 instead of at tj . Schemes for which the right-hand side does not involve time\nlevel j are known as \"explicit\" schemes. While the change may appear minor, this significantly\nmodifies the stability. (It also changes the computational complexity, as we will discuss later.) We\nmay view Euler Forward as a kind of \"rectangle, left\" integration rule.\nLet us now analyze the consistency and stability of the scheme. The proof of consistency is\nsimilar to that for the Euler Backward scheme. The truncation error for the scheme is\nj\nu(tj ) - u(tj-1)\nτ\n=\n- λu(tj-1) - f(tj-1) .\ntrunc\nΔt\nTo analyze the convergence of the truncation error, we apply Taylor expansion to u(tj ) about tj-1\nto obtain,\ntj\nτ\ndu\ndu2\nu(tj ) = u(tj-1) + Δt\n(tj-1) +\n(γ)dγ dτ .\ndt\ntj-1\ntj-1 dt2\nsj (u)\nZ\nZ\n!\n|\n{z\n}\n\n|\n{z\n}\n\nThus, the truncation error simplifies to\nj\nj-1)\nj-1)\nτ\n= 1\nu(tj-1) + Δtdu (tj-1) + sj (u) - u(t\n- λu(tj-1) - f(t\ntrunc\nΔt\ndt\ndu\nsj (u)\nj-1)\n=\n(tj-1) - λu(tj-1) - f(t\n+\ndt\nΔt\n=0 : by ODE\nsj (u)\n=\n.\nΔt\nIn proving the consistency of the Euler Backward scheme, we have shown that sj (u) is bounded by\nd2\nΔt2\nu\nsj(u) ≤\nmax\n(t)\n,\nj = 1, . . . , J .\nt∈[tj-1,tj ] dt2\nThus, the maximum truncation error is bounded by\nd2u\nΔt\nIτtruncIinf ≤ max\n(t)\n.\nt∈[0,tf ] dt2\nAgain, the truncation error converges linearly with Δt and the scheme is consistent because\nIτtruncIinf → 0 as Δt → 0. Because the scheme is consistent, we only need to show that it is\nstable to ensure convergence.\nTo analyze the stability of the scheme, let us compute the amplification factor. Rearranging\nthe difference equation for the homogeneous case,\nj-1\nj-1\nu j - u\n= λΔtu\nor\n|u j | = |1 + λΔt||u j-1|\nwhich gives\nγ = |1 + λΔt| .\nThus, absolute stability (i.e., γ ≤ 1) requires\n-1 ≤ 1 + λΔt ≤ 1\n-2 ≤ λΔt ≤ 0 .\nNoting λΔt ≤ 0 is a trivial condition for λ < 0, the condition for stability is\nΔt ≤-\n≡ Δtcr .\nλ\nNote that the Euler Forward scheme is stable only for Δt ≤ 2/|λ|. Thus, the scheme is conditionally\nstable. Recalling the stability is a necessary condition for convergence, we conclude that the scheme\nconverges for Δt ≤ Δtcr, but diverges (i.e., blows up) with j if Δt > Δtcr.\nFigure 21.5 shows the error convergence behavior of the Euler Forward scheme applied to the\nhomogeneous ODE with λ = -4. The error is measured at t = 1. The critical time step for stability\nis Δtcr = -2/λ = 1/2. The error convergence plot shows that the error grows exponentially for\n\n{z\n}\n\n|\n\n0.2\n0.4\n0.6\n0.8\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nt\nu\n\n∆t = 0.125\n∆t = 0.0625\n∆t = 0.03125\nexact\n-2\n-1\n-3\n-2\n-1\n1.00\n∆t\ne(t=1)\n(a) solution\n(b) error\nFigure 21.5: The error convergence behavior for the Euler Forward scheme applied to du/dt = -4u.\nNote e(t = 1) = |u(tj ) - u j | at tj = jΔt = 1.\nΔt > 1/2. As Δt tends to zero, the numerical approximation converges to the exact solution, and\nthe convergence rate (order) is p = 1 -- consistent with the theory.\nWe should emphasize that the instability of the Euler Forward scheme for Δt > Δtcr is not due to\nround-off errors and floating point representation (which involves \"truncation,\" but not truncation\nof the variety discussed in this chapter). In particular, all of our arguments for instability hold in\ninfinite-precision arithmetic as well as finite-precision arithmetic. The instability derives from the\ndifference equation; the instability amplifies truncation error, which is a property of the difference\nequation and differential equation. Of course, an unstable difference equation will also amplify\nround-off errors, but that is an additional consideration and not the main reason for the explosion\nin Figure 21.5.\n21.1.5\nStiff Equations: Implicit vs. Explicit\nStiff equations are the class of equations that exhibit a wide range of time scales. For example,\nrecall the linear ODE with a sinusoidal forcing,\ndu = λt + cos(ωt) ,\ndt\nwith |λ| » ω. The transient response of the solution is dictated by the time constant 1/|λ|.\nHowever, this initial transient decays exponentially with time. The long time response is governed\nby the time constant 1/ω » 1/|λ|.\nLet us consider the case with λ = -100 and ω = 4; the time scales differ by a factor of 25.\nThe result of applying the Euler Backward and Euler Forward schemes with several different time\nsteps is shown in Figure 21.6. Recall that the Euler Backward scheme is stable for any time step\nfor λ < 0. The numerical result confirms that the solution is bounded for all time steps considered.\nWhile a large time step (in particular Δt > 1/|λ|) results in an approximation which does not\ncapture the initial transient, the long term behavior of the solution is still well represented. Thus,\nif the initial transient is not of interest, we can use a Δt optimized to resolve only the long term\nbehavior associated with the characteristic time scale of 1/ω -- in other words, Δt ∼ O(1/10),\n\n0.2\n0.4\n0.6\n0.8\n-0.01\n-0.008\n-0.006\n-0.004\n-0.002\n0.002\n0.004\n0.006\n0.008\n0.01\nt\nu\n\n∆t = 0.25\n∆t = 0.0625\n∆t = 0.015625\nexact\n-3\n-2\n-1\n-6\n-5\n-4\n-3\n1.00\n∆t\ne(t=1)\n(a) Euler Backward (solution)\n(b) Euler Backward (convergence)\n0.2\n0.4\n0.6\n0.8\n-0.01\n-0.008\n-0.006\n-0.004\n-0.002\n0.002\n0.004\n0.006\n0.008\n0.01\nt\nu\n\n∆t = 0.25\n∆t = 0.0625\n∆t = 0.015625\nexact\n-3\n-2\n-1\n-10\n-5\n1.00\n∆t\ne(t=1)\n(c) Euler Forward (solution)\n(d) Euler Forward (convergence)\nFigure 21.6: Application of the Euler Backward and Euler Forward schemes to a stiff equation.\nNote e(t = 1) = |u(tj ) - u j | at tj = jΔt = 1.\nrather than Δt ∼ O(1/|λ|). If |λ| » ω, then we significantly reduce the number of time steps (and\nthus the computational cost).\nUnlike its implicit counterpart, the Euler Forward method is only conditionally stable. In\nparticular, the critical time step for this problem is Δtcr = 2/|λ| = 0.02. Thus, even if we are not\ninterested in the initial transient, we cannot use a large time step because the scheme would be\nunstable. Only one of the three numerical solution (Δt = 1/64 < Δtcr) is shown in Figure 21.6(c)\nbecause the other two time steps (Δt = 1/16, Δt = 1/4) result in an unstable discretization and\na useless approximation. The exponential growth of the error for Δt > Δtcr is clearly reflected in\nFigure 21.6(d).\nStiff equations are ubiquitous in the science and engineering context; in fact, it is not uncommon\nto see scales that differ by over ten orders of magnitude. For example, the time scale associated\nwith the dynamics of a passenger jet is several orders of magnitude larger than the time scale\nassociated with turbulent eddies. If the dynamics of the smallest time scale is not of interest,\nthen an unconditionally stable scheme that allows us to take arbitrarily large time steps may be\n\ncomputationally advantageous. In particular, we can select the time step that is necessary to achieve\nsufficient accuracy without any time step restriction arising from the stability consideration. Put\nanother way, integration of a stiff system using a conditionally stable method may place a stringent\nrequirement on the time step, rendering the integration prohibitively expensive. As none of the\nexplicit schemes are unconditionally stable, implicit schemes are often preferred for stiff equations.\nWe might conclude from the above that explicit schemes serve very little purpose. In fact, this\nis not the case, because the story is a bit more complicated. In particular, we note that for Euler\nBackward, at every time step, we must effect a division operation, 1/(1 - (λΔt)), whereas for Euler\nForward we must effect a multiplication, 1 + (λΔt). When we consider real problems of interest --\nsystems, often large systems, of many and often nonlinear ODEs -- these scalar algebraic operations\nof division for implicit schemes and multiplication for explicit schemes will translate into matrix\ninversion (more precisely, solution of matrix equations) and matrix multiplication, respectively.\nIn general, and as we shall see in Unit V, matrix inversion is much more costly than matrix\nmultiplication.\nHence the total cost equation is more nuanced. An implicit scheme will typically enjoy a larger\ntime step and hence fewer time steps -- but require more work for each time step (matrix solution).\nIn contrast, an explicit scheme may require a much smaller time step and hence many more time\nsteps -- but will entail much less work for each time step. For stiff equations in which the Δt for\naccuracy is much, much larger than the Δtcr required for stability (of explicit schemes), typically\nimplicit wins. On the other hand, for non-stiff equations, in which the Δt for accuracy might be on\nthe same order as Δtcr required for stability (of explicit schemes), explicit can often win: in such\ncases we would in any event (for reasons of accuracy) choose a Δt ≈ Δtcr; hence, since an explicit\nscheme will be stable for this Δt, we might as well choose an explicit scheme to minimize the work\nper time step.\nBegin Advanced Material\n21.1.6\nUnstable Equations\nEnd Advanced Material\n21.1.7\nAbsolute Stability and Stability Diagrams\nWe have learned that different integration schemes exhibit different stability characteristics. In\nparticular, implicit methods tend to be more stable than explicit methods. To characterize the\nstability of different numerical integrators, let us introduce absolute stability diagrams. These\ndiagrams allow us to quickly analyze whether an integration scheme will be stable for a given\nsystem.\nEuler Backward\nLet us construct the stability diagram for the Euler Backward scheme. We start with the homoge\nneous equation\ndz = λz .\ndt\nSo far, we have only considered a real λ; now we allow λ to be a general complex number. (Later\nλ will represent an eigenvalue of a system, which in general will be a complex number.) The Euler\n\nRe(λ∆t)\nIm(λ∆t)\n-3\n-2\n-1\n-3\n-2\n-1\nFigure 21.7: The absolute stability diagram for the Euler Backward scheme.\nBackward discretization of the equation is\nj-1\nz j - z\nj\nj-1\n= λz\n⇒\nz j = (1 - (λΔt))-1 z\n.\nΔt\nRecall that we defined the absolute stability as the region in which the amplification factor γ ≡\n|z j |/|z j-1| is less than or equal to unity. This requires\n|z j |\nγ =\n=\n≤ 1 .\n|z j-1|\n1 - (λΔt)\nWe wish to find the values of (λΔt) for which the numerical solution exhibits a stable behavior\n(i.e., γ ≤ 1). A simple approach to achieve this is to solve for the stability boundary by setting the\namplification factor to 1 = |eiθ|, i.e.\niθ\ne =\n.\n1 - (λΔt)\nSolving for (λΔt), we obtain\n(λΔt) = 1 - e -iθ .\nThus, the stability boundary for the Euler Backward scheme is a circle of unit radius (the \"one\"\nmultiplying eiθ) centered at 1 (the one directly after the = sign).\nTo deduce on which side of the boundary the scheme is stable, we can check the amplification\nfactor evaluated at a point not on the circle. For example, if we pick λΔt = -1, we observe that\nγ = 1/2 ≤ 1. Thus, the scheme is stable outside of the unit circle. Figure 21.7 shows the stability\ndiagram for the Euler Backward scheme. The scheme is unstable in the shaded region; it is stable\nin the unshaded region; it is neutrally stable, |z j | = |z j-1|, on the unit circle. The unshaded region\n(γ < 1) and the boundary of the shaded and unshaded regions (γ = 1) represent the absolute\nstability region; the entire picture is denoted the absolute stability diagram.\nTo gain understanding of the stability diagram, let us consider the behavior of the Euler Back\nward scheme for a few select values of λΔt. First, we consider a stable homogeneous equation, with\nλ = -1 < 0. We consider three different values of λΔt, -0.5, -1.7, and -2.2. Figure 21.8(a) shows\n\nRe(λ∆t)\nIm(λ∆t)\n\n-3\n-2\n-1\n-3\n-2\n-1\nλ∆t = -0.5\nλ∆t = -1.7\nλ∆t = -2.2\n0.2\n0.4\n0.6\n0.8\nt\nu\n\nλ∆t = -0.5\nλ∆t = -1.7\nλ∆t = -2.2\nexact\n(a) λΔt for λ = -1\n(b) solution (λ = -1)\nRe(λ∆t)\nIm(λ∆t)\n\n-3\n-2\n-1\n-3\n-2\n-1\nλ∆t = 0.5\nλ∆t = 1.7\nλ∆t = 2.2\n-2\nt\nu\n\nλ∆t = 0.5\nλ∆t = 1.7\nλ∆t = 2.2\nexact\n(c) λΔt for λ = 1\n(d) solution (λ = 1)\nFigure 21.8: The behavior of the Euler Backward scheme for selected values of (λΔt).\nthe three points on the stability diagram that correspond to these choices of λΔt. All three points\nlie in the unshaded region, which is a stable region. Figure 21.8(b) shows that all three numerical\nsolutions decay with time as expected. While the smaller Δt results in a smaller error, all schemes\nare stable and converge to the same steady state solution.\nBegin Advanced Material\nNext, we consider an unstable homogeneous equation, with λ = 1 > 0. We again consider\nthree different values of λΔt, 0.5, 1.7, and 2.2. Figure 21.8(c) shows that two of these points lie\nin the unstable region, while λΔt = 2.2 lies in the stable region. Figure 21.8(d) confirms that the\nsolutions for λΔt = 0.5 and 1.7 grow with time, while λΔt = 2.2 results in a decaying solution.\nThe true solution, of course, grows exponentially with time. Thus, if the time step is too large\n(specifically λΔt > 2), then the Euler Backward scheme can produce a decaying solution even if\nthe true solution grows with time -- which is undesirable; nevertheless, as Δt → 0, we obtain\nthe correct behavior. In general, the interior of the absolute stability region should not include\nλΔt = 0. (In fact λΔt = 0 should be on the stability boundary.)\n\nRe(λ∆t)\nIm(λ∆t)\n-3\n-2\n-1\n-3\n-2\n-1\nFigure 21.9: The absolute stability diagram for the Euler Forward scheme. The white area corre\nsponds to stability (the absolute stability region) and the gray area to instability.\nEnd Advanced Material\nEuler Forward\nLet us now analyze the absolute stability characteristics of the Euler Forward scheme. Similar\nto the Euler Backward scheme, we start with the homogeneous equation. The Euler Forward\ndiscretization of the equation yields\nj-1\nz j - z\nj-1\nj-1\n= λz\n⇒\nz j = (1 + (λΔt)) z\n.\nΔt\nThe stability boundary, on which the amplification factor is unity, is given by\n-iθ - 1 .\nγ = |1 + (λΔt)| = 1\n⇒\n(λΔt) = e\nThe stability boundary is a circle of unit radius centered at -1. Substitution of, for example,\nλΔt = -1/2, yields γ(λΔt = -1/2) = 1/2, so the amplification is less than unity inside the circle.\nThe stability diagram for the Euler Forward scheme is shown in Figure 21.9.\nAs in the Euler Backward case, let us pick a few select values of λΔt and study the behavior of the\nEuler Forward scheme. The stability diagram and solution behavior for a stable ODE (λ = -1 < 0)\nare shown in Figure 21.10(a) and 21.10(b), respectively. The cases with λΔt = -0.5 and -1.7 lie\nin the stable region of the stability diagram, while λΔt = -2.2 lies in the unstable region. Due to\ninstability, the numerical solution for λΔt = -2.2 diverges exponentially with time, even though\nthe true solution decays with time. The solution for λΔt = -1.7 shows some oscillation, but the\nmagnitude of the oscillation decays with time, agreeing with the stability diagram. (For an unstable\nODE (λ = 1 > 0), Figure 21.10(c) shows that all time steps considered lie in the unstable region\nof the stability diagram. Figure 21.10(d) confirms that all these choices of Δt produce a growing\nsolution.)\n21.1.8\nMultistep Schemes\nWe have so far considered two schemes: the Euler Backward scheme and the Euler Forward scheme.\nj\nj-1\nThese two schemes compute the state u\nfrom the previous state u\nand the source function\n\nRe(λ∆t)\nIm(λ∆t)\n\n-3\n-2\n-1\n-3\n-2\n-1\nλ∆t = -0.5\nλ∆t = -1.7\nλ∆t = -2.2\n-2\n-1.5\n-1\n-0.5\n0.5\n1.5\n2.5\nt\nu\n\nλ∆t = -0.5\nλ∆t = -1.7\nλ∆t = -2.2\nexact\n(a) λΔt for λ = -1\n(b) solution (λ = -1)\nRe(λ∆t)\nIm(λ∆t)\n\n-3\n-2\n-1\n-3\n-2\n-1\nλ∆t = 0.5\nλ∆t = 1.7\nλ∆t = 2.2\nt\nu\n\nλ∆t = 0.5\nλ∆t = 1.7\nλ∆t = 2.2\nexact\n(c) λΔt for λ = 1\n(d) solution (λ = 1)\nFigure 21.10: The behavior of the Euler Forward scheme for selected values of λΔt.\n\nevaluated at tj or tj-1 . The two schemes are special cases of multistep schemes, where the solution\nat the current time uj is approximated from the previous solutions. In general, for an ODE of the\nform\ndu = g(u, t) ,\ndt\na K-step multistep scheme takes the form\nK\nK\nn\nn\nαku j-k = Δt\nβkgj-k ,\nj = 1, . . . , J ,\nk=0\nk=0\nj\nu = u0 ,\nj-k\nj-k\nwhere g\n= g( u\n, tj-k). Note that the linear ODE we have been considering results from the\nchoice g(u, t) = λu + f(t). A K-step multistep scheme requires solutions (and derivatives) at K\nprevious time steps. Without loss of generality, we choose α0 = 1. A scheme is uniquely defined\nby choosing 2K + 1 coefficients, αk, k = 1, . . . , K, and βk, k = 0, . . . , K.\nMultistep schemes can be categorized into implicit and explicit schemes. If we choose β0 = 0,\nthen uj does not appear on the right-hand side, resulting in an explicit scheme. As discussed before,\nexplicit schemes are only conditionally stable, but are computationally less expensive per step. If\nwe choose β0 = 0, then uj appears on the right-hand side, resulting in an implicit scheme. Implicit\nschemes tend to be more stable, but are more computationally expensive per step, especially for a\nsystem of nonlinear ODEs.\nLet us recast the Euler Backward and Euler Forward schemes in the multistep method frame\nwork.\nExample 21.1.2 Euler Backward as a multistep scheme\nThe Euler Backward scheme is a 1-step method with the choices\nα1 = -1,\nβ0 = 1,\nand β1 = 0 .\nThis results in\nu j - u j-1 = Δtgj ,\nj = 1, . . . , J .\n·\nExample 21.1.3 Euler Forward as a multistep scheme\nThe Euler Forward scheme is a 1-step method with the choices\nα1 = -1,\nβ0 = 0,\nand β1 = 1 .\nThis results in\nu j - u j-1 = Δtgj-1 ,\nj = 1, . . . , J .\n·\nNow we consider three families of multistep schemes: Adams-Bashforth, Adams-Moulton, and\nBackward Differentiation Formulas.\n\nAdams-Bashforth Schemes\nAdams-Bashforth schemes are explicit multistep time integration schemes (β0 = 0). Furthermore,\nwe restrict ourselves to\nα1 = -1 and αk = 0,\nk = 2, . . . , K .\nThe resulting family of the schemes takes the form\nK\nj\nj-1\nj-k\nu = u\n+\nβkg\n.\nk=1\nNow we must choose βk, k = 1, . . . K, to define a scheme. To choose the appropriate values of βk,\nwe first note that the true solution u(tj ) and u(tj-1) are related by\ntj\ntj\nu(tj) = u(tj-1) +\ndu (τ)dτ = u(tj-1) +\ng(u(τ), τ)dτ .\n(21.1)\ntj-1 dt\ntj-1\nThen, we approximate the integrand g(u(τ), τ), τ ∈ (tj-1, tj ), using the values gj-k , k = 1, . . . , K.\nn\nth\n-\nSpecifically, we construct a (K\n1) -degree polynomial (τ ) using the K data points, i.e.\np\nK\nn\nj-k\np(τ) =\nφk(τ)g\n,\nk=1\nwhere φk(τ ), k = 1, . . . , K, are the Lagrange interpolation polynomials defined by the points\ntj-k , k = 1, . . . , K. Recalling the polynomial interpolation theory from Unit I, we note that the\n(K - 1)th-degree polynomial interpolant is Kth-order accurate for g(u(τ), τ) sufficiently smooth,\ni.e.\np(τ) = g(u(τ), τ) + O(ΔtK ) .\n(Note in fact here we consider \"extrapolation\" of our interpolant.) Thus, we expect the order of\napproximation to improve as we incorporate more points given sufficient smoothness. Substitution\nof the polynomial approximation of the derivative to Eq. (21.1) yields\nn\nn\nK\nK\nu(tj ) ≈ u(tj-1) +\nφk(τ)gj-kdτ = u(tj-1) +\nφk(τ )dτ gj-k .\ntj-1\ntj-1\nk=1\nk=1\nTo simplify the integral, let us consider the change of variable τ = tj - (tj - tj-1)ˆτ = tj - Δtτˆ.\nThe change of variable yields\ntj\ntj\nn\nK\nu(tj ) ≈ u(tj-1) + Δt\nˆ\nτ)dˆ\n,\nφk(ˆ\nτ gj-k\nk=1\nwhere the φˆk are the Lagrange polynomials associated with the interpolation points ˆτ = 1, 2, . . . , K.\nWe recognize that the approximation fits the Adams-Bashforth form if we choose\nˆ\nβk =\nφk(ˆτ)dτˆ .\nLet us develop a few examples of Adams-Bashforth schemes.\nZ\nZ\nZ\nZ\nZ\nZ\n\nExample 21.1.4 1-step Adams-Bashforth (Euler Forward)\nThe 1-step Adams-Bashforth scheme requires evaluation of β1. The Lagrange polynomial for this\ncase is a constant polynomial, φˆ1(ˆτ) = 1. Thus, we obtain\nˆ\nβ1 =\nφ1(ˆτ)dτˆ =\n1dτˆ = 1 .\nThus, the scheme is\nj\nj-1\nu = u j-1 + Δtg\n,\nwhich is the Euler Forward scheme, first-order accurate.\n·\nExample 21.1.5 2-step Adams-Bashforth\nThe 2-step Adams-Bashforth scheme requires specification of β1 and β2. The Lagrange interpolation\npolynomials for this case are linear polynomials\nˆ\nˆ\nφ1(ˆτ ) = -τˆ + 2 and φ2(ˆτ ) = τˆ - 1 .\nˆ\nˆ\nIt is easy to verify that these are the Lagrange polynomials because φ1(1) = φ2(2) = 1 and\nφˆ1(2) = φˆ2(1) = 0. Integrating the polynomials\nβ1 =\nφ1(ˆτ)dτˆ =\n(-τˆ + 2)dτˆ =\n,\nβ2 =\nφ2(ˆτ)dτˆ =\n(ˆτ - 1)dτˆ = -\n.\nThe resulting scheme is\nj\nj-1 -\nj-2\nu = u j-1 + Δt 3 g\n1 g\n.\nThis scheme is second-order accurate.\n·\nAdams-Moulton Schemes\nAdams-Moulton schemes are implicit multistep time integration schemes (β0\n0). Similar to\nAdams-Bashforth schemes, we restrict ourselves to\nα1 = -1 and αk = 0,\nk = 2, . . . , K .\nThe Adams-Moulton family of the schemes takes the form\nK\nn\nj\nj-1\nj-k\nu = u\n+\nβkg\n.\nk=0\nWe must choose βk, k = 1, . . . , K to define a scheme. The choice of βk follows exactly the same\nprocedure as that for Adams-Bashforth. Namely, we consider the expansion of the form Eq. (21.1)\nZ\nZ\nZ\nZ\nZ\nZ\n\n=\n\nand approximate g(u(τ), τ) by a polynomial. This time, we have K + 1 points, thus we construct\na Kth-degree polynomial\nK\nn\nj-k\np(τ) =\nφk(τ)g\n,\nk=0\nwhere φk(τ), k = 0, . . . , K, are the Lagrange interpolation polynomials defined by the points tj-k ,\nk = 0, . . . , K. Note that these polynomials are different from those for the Adams-Bashforth\nschemes due to the inclusion of tj as one of the interpolation points. (Hence here we consider true\ninterpolation, not extrapolation.) Moreover, the interpolation is now (K + 1)th-order accurate.\nUsing the same change of variable as for Adams-Bashforth schemes, τ = tj - Δtτˆ, we arrive at\na similar expression,\nK\nn\nu(tj ) ≈ u(tj-1) + Δt\nˆ\nτ)dˆ\n,\nφk(ˆ\nτgj-k\nk=0\nfor the Adams-Moulton schemes; here the φˆk are the Kth-degree Lagrange polynomials defined by\nthe points ˆτ = 0, 1, . . . , K. Thus, the βk are given by\nˆ\nβk =\nφk(ˆτ)dτˆ .\nLet us develop a few examples of Adams-Moulton schemes.\nExample 21.1.6 0-step Adams-Moulton (Euler Backward)\nThe 0-step Adams-Moulton scheme requires just one coefficient, β0. The \"Lagrange\" polynomial\nis 0th degree, i.e. a constant function φˆ0(ˆτ) = 1, and the integration of the constant function over\nthe unit interval yields\nˆ\nβ0 =\nφ0(ˆτ)dτˆ =\n1dτˆ = 1.\nThus, the 0-step Adams-Moulton scheme is given by\nu j = u j-1 + Δtgj ,\nwhich in fact is the Euler Backward scheme. Recall that the Euler Backward scheme is first-order\naccurate.\n·\nExample 21.1.7 1-step Adams-Moulton (Crank-Nicolson)\nThe 1-step Adams-Moulton scheme requires determination of two coefficients, β0 and β1. The\nLagrange polynomials for this case are linear polynomials\nˆ\nˆ\nφ0(ˆτ) = -τ + 1 and φ1(ˆτ) = τ .\nIntegrating the polynomials,\nˆ\nβ0 =\nφ0(ˆτ)dτˆ =\n(-τ + 1)dτˆ =\n,\nˆ\nβ1 =\nτ)dˆ =\nτdˆ =\n.\nφ1(ˆ\nτ\nˆ τ\nZ\nZ\nZ\nZ\nZ\nZ\nZ\nZ\n\nThe choice of βk yields the Crank-Nicolson scheme\nj\nj\nj-1\nu = u j-1 + Δt 1 g + 1 g\n.\nThe Crank-Nicolson scheme is second-order accurate. We can view Crank-Nicolson as a kind of\n\"trapezoidal\" rule.\n·\nExample 21.1.8 2-step Adams-Moulton\nThe 2-step Adams-Moulton scheme requires three coefficients, β0, β1, and β2. The Lagrange\npolynomials for this case are the quadratic polynomials\nφˆ0(ˆτ) = 1(ˆτ - 1)(ˆτ - 2) = 1(ˆτ 2 - 3ˆτ + 2) ,\nˆφ1(ˆτ) = -τˆ(ˆτ - 2) = -τˆ2 + 2ˆτ ,\nφˆ2(ˆτ) = 1 τˆ(ˆτ - 1) = 1 τˆ2 - τˆ .\nIntegrating the polynomials,\nˆ\nβ0 =\nφ0(ˆτ)dτˆ =\n1(ˆτ 2 - 3ˆτ + 2)ˆτ = 5\nβ1 =\nφˆ1(ˆτ)dτˆ =\n(-τˆ2 + 2ˆτ )dτˆ = 2 ,\nβ2 =\nφˆ2(ˆτ)dτˆ =\n1 τˆ2 - τˆ dτˆ = - 1 .\nThus, the 2-step Adams-Moulton scheme is given by\nj\nj\nj-1 -\nj-2\nu = u j-1 + Δt\ng + g\ng\n.\nThis AM2 scheme is third-order accurate.\n·\nConvergence of Multistep Schemes: Consistency and Stability\nLet us now introduce techniques for analyzing the convergence of a multistep scheme. Due to the\nDahlquist equivalence theorem, we only need to show that the scheme is consistent and stable.\nTo show that the scheme is consistent, we need to compute the truncation error. Recalling that\nthe local truncation error is obtained by substituting the exact solution to the difference equation\n(normalized such that uj has the coefficient of 1) and dividing by Δt, we have for any multistep\nschemes\n⎡\n⎤\nK\nK\nn\nn\nj\nj-k)⎦ -\nj-k\nτ\n= 1 ⎣u(tj) +\nαk u(t\nβk g(t\n, u(tj-k)) .\ntrunc\nΔt\nk=1\nk=0\n\nZ\nZ\nZ\nZ\nZ\nZ\n\n\"\n#\nFor simplicity we specialize our analysis to the Adams-Bashforth family, such that\nK\nn\nj\nj-1)\n= 1\nu(tj ) - u(t\ntrunc\n-\nβk g(tj-k , u(tj-k)) .\nτ\nΔt\nk=1\nWe recall that the coefficients βk were selected to match the extrapolation from polynomial fitting.\nBacktracking the derivation, we simplify the sum as follows\nK\nK\nj-k\nˆ\nj-k\nβk g(t\n, u(tj-k)) =\nτ )dˆ\n, u(tj-k))\nφk(ˆ\nτ g(t\nk=1\nk=1\nn\nn\nK\n=\nΔt tj-1\nk=1\nn\ntj\nj-k\nφk(τ)dτ g(t\n, u(tj-k))\ntj\n= Δt tj-1\n⎤\nK\nn\n⎡\n⎣\nφk(τ) g(tj-k , u(tj-k))⎦ dτ\nk=1\ntj\n=\np(τ)dτ .\nn\nΔt\ntj-1\nWe recall that p(τ) is a (K - 1)th\nth-order accurate interpolation with the error O(ΔtK ). Thus,\nK\nj\nj-1)\n= 1\nu(tj ) - u(t\ntrunc\nτ\n-\nβk g(tj-k , u(tj-k))\nΔt\nk=1\ntj\ntj\n=\nu(tj ) - u(tj-1) -\ng(τ, u(τ ))dτ +\nO(ΔtK )dτ\nΔt\nΔt tj-1\nΔt jj-1\ntj\n= 1\nu(tj ) - u(tj-1) -\ng(τ, u(τ ))dτ + O(ΔtK )\nΔt\ntj-1\n= O(ΔtK ) .\nNote that the term in the bracket vanishes from g = du/dt and the fundamental theorem of calculus.\nThe truncation error of the scheme is O(ΔtK ). In particular, since K > 0, τtrunc → 0 as Δt → 0\nand the Adams-Bashforth schemes are consistent. Thus, if the schemes are stable, they would\nconverge at ΔtK .\nThe analysis of stability relies on a solution technique for difference equations. We first restrict\nourselves to linear equation of the form g(t, u) = λu. By rearranging the form of difference equation\nfor the multistep methods, we obtain\nn\nK\n(αk - (λΔt) βk) uj-k = 0,\nj = 1, . . . , J .\nk=0\n\nZ\nZ\nZ\n\nZ\nZ\nZ\nZ\n\nThe solution to the difference equation is governed by the initial condition and the K roots of the\npolynomial\nK\nn\nq(x) =\n(αk - (λΔt) βk)x K-k .\nk=0\nIn particular, for any initial condition, the solution will exhibit a stable behavior if all roots rk,\nk = 1, . . . , K, have magnitude less than or equal to unity. Thus, the absolute stability condition\nfor multistep schemes is\n(λΔt) such that |rK | ≤ 1,\nk = 1, . . . , K ,\nwhere rk, k = 1, . . . , K are the roots of q.\nExample 21.1.9 Stability of the 2-step Adams-Bashforth scheme\nRecall that the 2-step Adams-Bashforth results from the choice\nα0 = 1,\nα1 = -1,\nα2 = 0,\nβ0 = 0,\nβ1 = ,\nand β2 = -\n.\nThe stability of the scheme is governed by the roots of the polynomial\nn\n2-k\nq(x) =\n(αk - (λΔt) βk)x\n= x + -1 - (λΔt) x +\n(λΔt) = 0 .\nk=0\nThe roots of the polynomial are given by\n⎡\n\n⎤\nr1,2 =\n⎣1 + (λΔt) ±\n1 + (λΔt)\n- 2(λΔt) ⎦ .\nWe now look for (λΔt) such that |r1| ≤ 1 and |r2| ≤ 1.\nIt is a simple matter to determine if a particular λΔt is inside, on the boundary of, or outside\nthe absolute stability region. For example, for λΔt = -1 we obtain r1 = -1, r2 = 1/2 and hence --\nsince |r1| = 1 -- λΔt = -1 is in fact on the boundary of the absolute stability diagram. Similarly,\nit is simple to confirm that λΔt = -1/2 yields both r1 and r2 of modulus strictly less than 1,\nand hence λΔt = -1/2 is inside the absolute stability region. We can thus in principle check each\npoint λΔt (or enlist more sophisticated solution procedures) in order to construct the full absolute\nstability diagram.\nWe shall primarily be concerned with the use of the stability diagram rather than the construc\ntion of the stability diagram -- which for most schemes of interest are already derived and well\ndocumented. We present in Figure 21.11(b) the absolute stability diagram for the 2-step Adams-\nBashforth scheme. For comparison we show in Figure 21.11(a) the absolute stability diagram for\nEuler Forward, which is the 1-step Adams-Bashforth scheme. Note that the stability region of the\nAdams-Bashforth schemes are quite small; in fact the stability region decreases further for higher\norder Adams-Bashforth schemes. Thus, the method is only well suited for non-stiff equations.\n·\nExample 21.1.10 Stability of the Crank-Nicolson scheme\nLet us analyze the absolute stability of the Crank-Nicolson scheme. Recall that the stability of a\nmultistep scheme is governed by the roots of the polynomial\nK\nn\nq(x) =\n(αk - λΔt βk) x K-k .\nk=0\n\nRe(λ∆t)\nIm(λ∆t)\n-3\n-2\n-1\n-3\n-2\n-1\nRe(λ∆t)\nIm(λ∆t)\n-3\n-2\n-1\n-3\n-2\n-1\n(a) Euler Forward (AB1)\n(b) 2-step Adams-Bashforth (AB2)\nFigure 21.11: The stability diagrams for Adams-Bashforth methods.\nFor the Crank-Nicolson scheme, we have α0 = 1, α1 = -1, β0 = 1/2, and β1 = 1/2. Thus, the\npolynomial is\nq(x) = 1 - 2(λΔt) x + -1 - 2(λΔt) .\nThe root of the polynomial is\n2 + (λΔt)\nr =\n.\n2 - (λΔt)\nTo solve for the stability boundary, let us set |r| = 1 = |eiθ| and solve for (λΔt), i.e.\n2 + (λΔt)\niθ\n2(eiθ - 1)\ni2 sin(θ)\n= e\n⇒\n(λΔt) =\n=\n.\n2 - (λΔt)\neiθ + 1\n1 + cos(θ)\nThus, as θ varies from 0 to π/2, λΔt varies from 0 to iinf along the imaginary axis. Similarly, as\nθ varies from 0 to -π/2, λΔt varies from 0 to -iinf along the imaginary axis. Thus, the stability\nboundary is the imaginary axis. The absolute stability region is the entire left-hand (complex)\nplane.\nThe stability diagrams for the 1- and 2-step Adams-Moulton methods are shown in Figure 21.11.\nThe Crank-Nicolson scheme shows the ideal stability diagram; it is stable for all stable ODEs (λ ≤ 0)\nand unstable for all unstable ODEs (λ > 0) regardless of the time step selection. (Furthermore,\nfor neutrally stable ODEs, λ = 0, Crank-Nicolson is neutrally stable -- γ, the amplification factor,\nis unity.) The selection of time step is dictated by the accuracy requirement rather than stability\nconcerns.1 Despite being an implicit scheme, AM2 is not stable for all λΔt in the left-hand plane;\nfor example, along the real axis, the time step is limited to -λΔt ≤ 6. While the stability\nregion is larger than, for example, the Euler Forward scheme, the stability region of AM2 is rather\ndisappointing considering the additional computational cost associated with each step of an implicit\nscheme.\n·\n1However, the Crank-Nicolson method does exhibit undesirable oscillations for λΔt →- (real) inf, and the lack\nof any dissipation on the imaginary axis can also sometimes cause difficulties. Nobody's perfect.\n\nRe(λ∆t)\nIm(λ∆t)\n-3\n-2\n-1\n-3\n-2\n-1\nRe(λ∆t)\nIm(λ∆t)\n-8\n-6\n-4\n-2\n-5\n-4\n-3\n-2\n-1\n(a) Crank-Nicolson (AM1)\n(b) 2-step Adams-Moulton (AM2)\nFigure 21.12: The stability diagrams for 2-step Adams-Moulton methods.\nBackward Differentiation Formulas\nThe Backward Differentiation Formulas are implicit multistep schemes that are well suited for stiff\nproblems. Unlike the Adams-Bashforth and Adams-Moulton schemes, we restrict ourselves to\nβk = 0,\nk = 1, . . . , K .\nThus, the Backward Differential Formulas are of the form\nn\nK\nu j +\nαku j-k = Δt β0gj .\nk=1\nOur task is to find the coefficients αk, k = 1, . . . , K, and β0. We first construct a Kth-degree\nj-k\ninterpolating polynomial using u\n, k = 0, . . . , K, to approximate u(t), i.e.\nn\nK\nj-k\nu(t) ≈\nφk(t) u\n,\nk=0\nwhere φk(t), k = 0, . . . , K, are the Lagrange interpolation polynomials defined at the points tj-k ,\nk = 0, . . . , K; i.e., the same polynomials used to develop the Adams-Moulton schemes. Differenti\nating the function and evaluating it at t = tj , we obtain\nn\nK\ndt\ndt\ntj\ntj\nk=0\nAgain, we apply the change of variable of the form t = tj - Δtτˆ, so that\ndu\ndφk\nj-k\nu\n≈\n.\nn\n⎛\nn\nK\nK\ntj\ntj\ndt\ndτˆ\ndt\nΔt\ndτˆ\nk=0\nk=0\nj = g(u(tj ), tj ) = du/dt|tj , we set\nd ˆφk\nd ˆφk\ndu\ndτˆ\nj-k\nj-k\n≈\n= -\nu\nu\n.\nRecalling g\n⎞\nn\nn\nn\nK\nK\nK\nk=1\nk=0\nk=0\ndφˆk\ndφˆk\nu j +\nj-k ≈ Δtβ0\nj-k\nu j-k .\n⎝-\n⎠ = -β0\nαku\nu\nΔt\ndτˆ\ndτˆ\n\nj-k\nMatching the coefficients for u\n, k = 0, . . . , K, we obtain\ndφˆk\n1 = -β0 dτˆ\nd ˆφk\nαk = -β0\n,\nk = 1, . . . , K .\ndτˆ\nLet us develop a few Backward Differentiation Formulas.\nExample 21.1.11 1-step Backward Differentiation Formula (Euler Backward)\nThe 1-step Backward Differentiation Formula requires specification of β0 and α1. As in the 1-step\nAdams-Moulton scheme, the Lagrange polynomials for this case are\nˆ\nˆ\nφ0(ˆτ) = -τ + 1 and φ1(ˆτ) = τ .\nDifferentiating and evaluating at ˆτ = 0\n⎛\n⎞-1\nβ0 = - ⎝ dφˆ0 ⎠\n= -(-1)-1 = 1 ,\ndτˆ\ndφˆ1\nα1 = -β0\n= -1 .\ndτˆ\nThe resulting scheme is\nu j - u j-1 = Δtgj ,\nwhich is the Euler Backward scheme. Again.\n·\nExample 21.1.12 2-step Backward Differentiation Formula\nThe 2-step Backward Differentiation Formula requires specification of β0, α1, and α2. The Lagrange\npolynomials for this case are\nφˆ0(ˆτ) = 1(ˆτ 2 - 3ˆτ + 2) ,\nφˆ1(ˆτ) = -τˆ2 + 2ˆτ ,\nφˆ2(ˆτ) = 1 τˆ2 - τˆ .\nDifferentiation yields\n⎛\n⎞-1\n⎝ dφˆ0 ⎠\nβ0 = -\n=\n,\ndτˆ\ndφˆ1\nα1 = -β0\n= -\n· 2 = -\n,\ndτˆ\ndφˆ2\nα2 = -β0\n= - · - =\n.\ndτˆ\n\nRe(λ∆t)\nIm(λ∆t)\n-2\n-5\n-4\n-3\n-2\n-1\nRe(λ∆t)\nIm(λ∆t)\n-2\n-5\n-4\n-3\n-2\n-1\nRe(λ∆t)\nIm(λ∆t)\n-2\n-5\n-4\n-3\n-2\n-1\n(a) BDF1 (Euler Backward)\n(b) BDF2\n(c) BDF3\nFigure 21.13: The absolute stability diagrams for Backward Differentiation Formulas.\nThe resulting scheme is\nj-1\nj-2\nj\nu j - u\n+ u\n=\nΔtg .\nThe 2-step Backward Differentiation Formula (BDF2) is unconditionally stable and is second-order\naccurate.\n·\nExample 21.1.13 3-step Backward Differentiation Formula\nFollowing the same procedure, we can develop the 3-step Backward Differentiation Formula (BDF3).\nThe scheme is given by\nj-1\nj-2 -\nj-3\nj\nu j -\nu\n+\nu\nu\n=\nΔtg .\nThe scheme is unconditionally stable and is third-order accurate.\n·\nThe stability diagrams for the 1-, 2-, and 3-step Backward Differentiation Formulas are shown\nin Figure 21.13. The BDF1 and BDF2 schemes are A-stable (i.e., the stable region includes the\nentire left-hand plane). Unfortunately, BDF3 is not A-stable; in fact the region of instability in the\nleft-hand plane increases for the higher-order BDFs. However, for stiff engineering systems whose\neigenvalues are clustered along the real axis, the BDF methods are attractive choices.\n21.1.9\nMultistage Schemes: Runge-Kutta\nAnother family of important and powerful integration schemes are multistage schemes, the most\nfamous of which are the Runge-Kutta schemes. While a detailed analysis of the Runge-Kutta\nschemes is quite involved, we briefly introduce the methods due to their prevalence in the scientific\nand engineering context.\nUnlike multistep schemes, multistage schemes only require the solution at the previous time\nj-1\nj\nstep u\nto approximate the new state u\nat time tj . To develop an update formula, we first\nobserve that\ntj\ntj\nu(tj) = u (tj-1) +\ndu (τ)dτ = u (tj-1) +\ng(u(τ), τ)dτ .\ntj-1 dt\ntj-1\nZ\nZ\n\nClearly, we cannot use the formula directly to approximate u(tj ) because we do not know g(u(τ ), τ),\nτ ∈ ]tj-1, tj [ . To derive the Adams schemes, we replaced the unknown function g with its polynomial\napproximation based on g evaluated at K previous time steps. In the case of Runge-Kutta, we\ndirectly apply numerical quadrature to the integral to obtain\nK\nn\nj-1\nj-1\nu(tj ) ≈ u(tj-1) + Δt\nbk g u(t\n+ ckΔt), t\n+ ckΔt\n,\nk=1\nwhere the bk are the quadrature weights and the tj + ckΔt are the quadrature points. We need to\nmake further approximations to define a scheme, because we do not know the values of u at the K\nstages, u(tj + ckΔt), k = 1, . . . , K. Our approach is to replace the K stage values u(tj-1 + ckΔt)\nby approximations vk and then to form the K stage derivatives as\nj-1\nGk = g vk, t\n+ ckΔt\n.\nIt remains to specify the approximation scheme.\nFor an explicit Runge-Kutta scheme, we construct the kth-stage approximation as a linear\ncombination of the previous stage derivatives and uj-1, i.e.\nvk = u j-1 + Δt\n\nAk1G1 + Ak2G2 + · · · + Ak,k-1Gk-1\n\n.\nBecause this kth-stage estimate only depends on the previous stage derivatives, we can compute\nthe stage values in sequence,\nj-1\nv1 = u\n(⇒ G1) ,\nv2 = u j-1 + ΔtA21G1\n(⇒ G2) ,\nv3 = u j-1 + ΔtA31G1 + ΔtA32G2\n(⇒ G3) ,\n. . .\nK-1\nvK = u j-1 + Δt\nk=1 AKkGk\n(⇒ GK ) .\nOnce the stage values are available, we estimate the integral by\nK\nn\nu j = u j-1 + Δt\nbk Gk ,\nk=1\nand proceed to the next time step.\nNote that a Runge-Kutta scheme is uniquely defined by the choice of the vector b for quadrature\nweight, the vector c for quadrature points, and the matrix A for the stage reconstruction. The\ncoefficients are often tabulated in a Butcher table, which is a collection of the coefficients of the\nform\nc\nA\n.\nbT\nFor explicit Runge-Kutta methods, we require Aij = 0, i ≤ j. Let us now introduce two popular\nexplicit Runge-Kutta schemes.\n\nExample 21.1.14 Two-stage Runge-Kutta\nA popular two-stage Runge-Kutta method (RK2) has the Butcher table\n.\n0 1\nThis results in the following update formula\nj-1\nj-1) ,\nv1 = u\n,\nG1 = g(v1, t\nj-1\nj-1\nv2 = u\n+ 2 ΔtG1,\nG2 = g\nv2, t\n+\nΔt\n,\nu j = u j + ΔtG2 .\nThe two-stage Runge-Kutta scheme is conditionally stable and is second-order accurate. We might\nview this scheme as a kind of midpoint rule.\n·\nExample 21.1.15 Four-stage Runge-Kutta\nA popular four-stage Runge-Kutta method (RK4) -- and perhaps the most popular of all Runge-\nKutta methods -- has the Butcher table of the form\n.\n0 0 1\nThis results in the following update formula\nj-1\nj-1) ,\nv1 = u\n,\nG1 = g(v1, t\nj-1\nj-1\nv2 = u\n+ 2 ΔtG1,\nG2 = g\nv2, t\n+\nΔt\n,\nj-1\nj-1\nv3 = u\n+ 2 ΔtG2,\nG3 = g\nv3, t\n+\nΔt\n,\nv4 = u j-1 + ΔtG3,\nG4 = g\nv4, tj-1 + Δt ,\nu j = u j-1 + Δt\nG1 + G2 + G3 + G4 .\nThe four-stage Runge-Kutta scheme is conditionally stable and is fourth-order accurate.\n·\n\nThe accuracy analysis of the Runge-Kutta schemes is quite involved and is omitted here. There\nare various choices of coefficients that achieve pth-order accuracy using p stages for p ≤ 4. It\nis also worth noting that even though we can achieve fourth-order accuracy using a four-stage\nRunge-Kutta method, six stages are necessary to achieve fifth-order accuracy.\nExplicit Runge-Kutta methods required that a stage value is a linear combination of the previous\nstage derivatives. In other words, the A matrix is lower triangular with zeros on the diagonal. This\nmade the calculation of the state values straightforward, as we could compute the stage values in\nsequence. If we remove this restriction, we arrive at family of implicit Runge-Kutta methods (IRK).\nThe stage value updates for implicit Runge-Kutta schemes are fully coupled, i.e.\nK\nn\nvk = u j-1 + Δt\nAkiGi,\nk = 1, . . . , K .\ni=1\nIn other words, the matrix A is full in general. Like other implicit methods, implicit Runge-Kutta\nschemes tend to be more stable than their explicit counterparts (although also more expensive per\ntime step). Moreover, for all K, there is a unique IRK method that achieves 2K order of accuracy.\nLet us introduce one such scheme.\nExample 21.1.16 Two-stage Gauss-Legendre Implicit Runge-Kutta\nThe two-stage Gauss-Legendre Runge-Kutta method2 (GL-IRK2) is described by the Butcher table\n√\n-\n√\n+\n√\n-\n√\n+\n.\nTo compute the update we must first solve a system of equations to obtain the stage values v1 and\nv2\nj-1\nv1 = u\n+ A11ΔtG1 + A12ΔG2 ,\nj-1\nv2 = u\n+ A21ΔtG1 + A12ΔG2 ,\nor\nj-1\nj-1\nj-1\nv1 = u\n+ A11Δtg(v1, t\n+ c1Δt) + A12Δtg(v2, t\n+ c2Δt) ,\nj-1\nj-1\nj-1\nv2 = u\n+ A21Δtg(v1, t\n+ c1Δt) + A22Δtg(v2, t\n+ c2Δt) ,\nwhere the coefficients A and c are provided by the Butcher table. Once the stage values are\ncomputed, we compute uj according to\nj\nj-1\nj-1\nu = u j-1 + Δt b1 g(v1, t\n+ c1Δt) + b2 g(v2, t\n+ c2Δt) ,\nwhere the coefficients b are given by the Butcher table.\nThe two-stage Gauss-Legendre Runge-Kutta scheme is A-stable and is fourth-order accurate.\nWhile the method is computationally expensive and difficult to implement, the A-stability and\nfourth-order accuracy are attractive features for certain applications.\n2The naming is due to the use of the Gauss quadrature points, which are the roots of Legendre polynomials on\nthe unit interval.\n\nRe(λ∆t)\nIm(λ∆t)\n-3\n-2\n-1\n-3\n-2\n-1\nRe(λ∆t)\nIm(λ∆t)\n-3\n-2\n-1\n-3\n-2\n-1\nRe(λ∆t)\nIm(λ∆t)\n-3\n-2\n-1\n-3\n-2\n-1\n(a) RK2\n(b) RK4\n(c) Gauss-Legendre IRK2\nFigure 21.14: The absolute stability diagrams for the Runge-Kutta family of schemes.\n·\nThere is a family of implicit Runge-Kutta methods called diagonally implicit Runge-Kutta\n(DIRK). These methods have an A matrix that is lower triangular with the same coefficients\nin each diagonal element. This family of methods inherits the stability advantage of IRK schemes\nwhile being computationally more efficient than other IRK schemes for nonlinear systems, as we\ncan incrementally update the stages.\nThe stability diagrams for the three Runge-Kutta schemes presented are shown in Figure 21.14.\nThe two explicit Runge-Kutta methods, RK2 and RK4, are not A-stable. The time step along the\nreal axis is limited to -λΔt ≤ 2 for RK2 and -λΔt . 2.8 for RK4. However, the stability region\nfor the explicit Runge-Kutta schemes are considerably larger than the Adams-Bashforth family of\nexplicit schemes. While the explicit Runge-Kutta methods are not suited for very stiff systems,\nthey can be used for moderately stiff systems. The implicit method, GL-IRK2, is A-stable; it also\ncorrectly exhibits growing behavior for unstable systems.\nFigure 21.15 shows the error behavior of the Runge-Kutta schemes applied to du/dt = -4u.\nThe higher accuracy of the Runge-Kutta schemes compared to the Euler Forward scheme is evident\nfrom the solution. The error convergence plot confirms the theoretical convergence rates for these\nmethods.\n21.2\nScalar Second-Order Linear ODEs\n21.2.1\nModel Problem\nLet us consider a canonical second-order ODE,\nd2u\ndu\nm\n+ c\n+ ku = f(t),\n0 < t < tf ,\ndt2\ndt\nu(0) = u0 ,\ndu (0) = v0 .\ndt\nThe ODE is second order, because the highest derivative that appears in the equation is the second\nderivative. Because the equation is second order, we now require two initial conditions: one for\n\n0.2\n0.4\n0.6\n0.8\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nt\nu\n\nEF\nRK2\nRK4\nGL-IRK2\nexact\n-2\n-1\n-10\n-8\n-6\n-4\n-2\n1.00\n2.00\n4.00\n∆t\ne(t=1)\n\nEF\nRK2\nRK4\nGL-IRK2\n(a) solution (Δt = 1/8)\n(b) error\nFigure 21.15: The error convergence behavior for the Runge-Kutta family of schemes applied to\ndu/dt = -4u. Here e(t = 1) = |u(tj ) - u j | for tj = jΔt = 1.\ndisplacement, and one for velocity. It is a linear ODE because the equation is linear with respect\nto u and its derivatives.\nA typical spring-mass-damper system is governed by this second-order ODE, where u is the\ndisplacement, m is the mass, c is the damping constant, k is the spring constant, and f is the\nexternal forcing. This system is of course a damped oscillator, as we now illustrate through the\nclassical solutions.\n21.2.2\nAnalytical Solution\nHomogeneous Equation: Undamped\nLet us consider the undamped homogeneous case, with c = 0 and f = 0,\nd2u\nm\n+ ku = 0,\n0 < t < tf ,\ndt2\nu(0) = u0 ,\ndu (0) = v0 .\ndt\nTo solve the ODE, we assume solutions of the form eλt, which yields\n(mλ2 + k) e λt = 0 .\nThis implies that mλ2 + k = 0, or that λ must be a root of the characteristic polynomial\n\np(λ) = mλ2 + k = 0\n⇒\nλ1,2 = ±i\nk .\nm\n\nLet us define the natural frequency, ωn ≡\nk/m. The roots of the characteristic polynomials are\nthen λ1,2 = ±iωn. The solution to the ODE is thus of the form\nu(t) = αeiωnt + βe-iωnt .\n\n-1\n-0.5\n0.5\nt\nu\n\nωn=1.00, ζ=0.00\nωn=2.00, ζ=0.00\nFigure 21.16: Response of undamped spring-mass systems.\nRearranging the equation,\nα + β\niωnt\nα - β\niωnt - e -iωnt)\nu(t) = αeiωnt + βe-iωnt =\n(e\n+ e -iωnt) +\n(e\n= (α + β) cos(ωnt) + i(α - β) sin(ωnt) .\nWithout loss of generality, let us redefine the coefficients by c1 = α + β and c2 = i(α - β). The\ngeneral form of the solution is thus\nu(t) = c1 cos(ωnt) + c2 sin(ωnt) .\nThe coefficients c1 and c2 are specified by the initial condition. In particular,\nu(t = 0) = c1 = u0\n⇒\nc1 = u0 ,\ndu\nv0\n(t = 0) = c2ωn = v0\n⇒\nc2 =\n.\ndt\nωn\nThus, the solution to the undamped homogeneous equation is\nv0\nu(t) = u0 cos(ωnt) +\nsin(ωnt) ,\nωn\nwhich represents a (non-decaying) sinusoid.\nExample 21.2.1 Undamped spring-mass system\nLet us consider two spring-mass systems with the natural frequencies ωn = 1.0 and 2.0. The\nresponses of the systems to initial displacement of u(t = 0) = 1.0 are shown in Figure 21.16. As\nthe systems are undamped, the amplitudes of the oscillations do not decay with time.\n·\n\nHomogeneous Equation: Underdamped\nLet us now consider the homogeneous case (f = 0) but with finite (but weak) damping\nd2u\ndu\nm\n+ c\n+ ku = 0,\n0 < t < tf ,\ndt2\ndt\nu(0) = u0 ,\ndu (0) = v0 .\ndt\nTo solve the ODE, we again assume behavior of the form u = eλt . Now the roots of the characteristic\npolynomial are given by\nc\nc\nk\np(λ) = mλ2 + cλ + k = 0\n⇒\nλ1,2 = -\n±\n-\n.\n2m\n2m\nm\nLet us rewrite the roots as\nc\nc\nk\nk\nc\nk\nc\nλ1,2 = -\n±\n-\n= -\n√\n±\n- 1 .\n2m\n2m\nm\nm 2 mk\nm\n4mk\nFor convenience, let us define the damping ratio as\nc\nc\nζ = √\n=\n.\n2 mk\n2mωn\nTogether with the definition of natural frequency, ωn =\nk/m, we can simplify the roots to\nλ1,2 = -ζωn ± ωn\nζ2 - 1 .\nThe underdamped case is characterized by the condition\nζ2 - 1 < 0 ,\ni.e., ζ < 1.\nIn this case, the roots can be conveniently expressed as\nλ1,2 = -ζωn ± iωn\n1 - ζ2 = -ζωn ± iωd ,\nwhere ωd ≡ ωn\n1 - ζ2 is the damped frequency. The solution to the underdamped homogeneous\nsystem is\n+ βe-ζωnt-iωdt\nu(t) = αe-ζωnt+iωdt\n.\nUsing a similar technique as that used for the undamped case, we can simplify the expression to\n-ζωnt\nu(t) = e\nc1 cos(ωdt) + c2 sin(ωdt) .\nSubstitution of the initial condition yields\nv0 + ζωnu0\n-ζωnt\nu(t) = e\nu0 cos(ωdt) +\nsin(ωdt) .\nωd\nThus, the solution is sinusoidal with exponentially decaying amplitude. The decay rate is set by\nthe damping ratio, ζ. If ζ « 1, then the oscillation decays slowly -- over many periods.\ns\n\ns\n\nr\nr\nr\np\np\np\np\n\n-1\n-0.5\n0.5\nt\nu\n\nωn=1.00, ζ=0.10\nωn=1.00, ζ=0.50\nFigure 21.17: Response of underdamped spring-mass-damper systems.\nExample 21.2.2 Underdamped spring-mass-damper system\nLet us consider two underdamped spring-mass-damper systems with\nSystem 1:\nωn = 1.0 and ζ = 0.1\nSystem 2:\nωn = 1.0 and ζ = 0.5 .\nThe responses of the systems to initial displacement of u(t = 0) = 1.0 are shown in Figure 21.17.\nUnlike the undamped systems considered in Example 21.2.1, the amplitude of the oscillations decays\nwith time; the oscillation of System 2 with a higher damping coefficient decays quicker than that\nof System 1.\n·\nHomogeneous Equation: Overdamped\nIn the underdamped case, we assumed ζ < 1. If ζ > 1, then we have an overdamped system. In\nthis case, we write the roots as\nλ1,2 = -ωn ζ ±\nζ2 - 1\n,\nboth of which are real. The solution is then given by\nλ1t\nλ2t\nu(t) = c1e\n+ c2e\n.\nThe substitution of the initial conditions yields\nλ2u0 - v0\n-λ2u0 + v0\nc1 =\nand c2 =\n.\nλ2 - λ1\nλ2 - λ1\nThe solution is a linear combination of two exponentials that decay with time constants of 1/|λ1|\nand 1/|λ2|, respectively. Because |λ1| > |λ2|, |λ2| dictates the long time decay behavior of the\nsystem. For ζ →inf, λ2 behaves as -ωn/(2ζ) = -k/c.\nExample 21.2.3 Overdamped spring-mass-damper system\nLet us consider two overdamped spring-mass-damper systems with\nSystem 1:\nωn = 1.0 and ζ = 1.0\nSystem 2:\nωn = 1.0 and ζ = 5.0 .\n\np\n\n-1\n-0.5\n0.5\nt\nu\n\nωn=1.00, ζ=1.00\nωn=1.00, ζ=5.00\nFigure 21.18: Response of overdamped spring-mass-damper systems.\nThe responses of the systems to initial displacement of u(t = 0) = 1.0 are shown in Figure 21.17.\nAs the systems are overdamped, they exhibit non-oscillatory behaviors. Note that the oscillation\nof System 2 with a higher damping coefficient decays more slowly than that of System 1. This is\nin contrast to the underdamped cases considered in Example 21.2.2, in which the oscillation of the\nsystem with a higher damping coefficient decays more quickly.\n·\nSinusoidal Forcing\nLet us consider a sinusoidal forcing of the second-order system. In particular, we consider a system\nof the form\nd2u\ndu\nm\n+ c\n+ ku = A cos(ωt) .\ndt2\ndt\nIn terms of the natural frequency and the damping ratio previously defined, we can rewrite the\nsystem as\nd2u\ndu\nA\n+ 2ζωn\n+ ω2 u =\ncos(ωt) .\nn\ndt2\ndt\nm\nA particular solution is of the form\nup(t) = α cos(ωt) + β sin(ωt) .\nSubstituting the assumed form of particular solution into the governing equation, we obtain\nd2up\ndup\nA\n0 =\n+ 2ζωn\n+ ωn\n2 up -\ncos(ωt)\ndt2\ndt\nm\n= - αω2 cos(ωt) - βω2 sin(ωt) + 2ζωn(-αω sin(ωt) + βω cos(ωt))\n+ ω2 (α cos(ωt) + β sin(ωt)) - A cos(ωt) .\nn\n\n0.5\n1.5\n2.5\n0.5\n1.5\n2.5\n3.5\n4.5\nr\nApk/A\n\nζ=0.01\nζ=0.1\nζ=0.2\nζ=0.3\nζ=0.5\nζ=1\nFigure 21.19: The variation in the amplification factor for the sinusoidally forced system.\nWe next match terms in sin and cos to obtain\nα(ω2\nA\n- ω2) + β(2ζωωn) =\n,\nn\nm\nβ(ω2 - ω2) - α(2ζωωn) = 0 ,\nn\nand solve for the coefficients,\n(ω2 - ω2)\nA\n1 - r\nA\n1 - r\nA\nn\nα =\n=\n=\n,\n(ω2 - ω2)2 + (2ζωωn)2 m\n(1 - r2)2 + (2ζr)2 mω2\n(1 - r2)2 + (2ζr)2 k\nn\nn\n(2ζωωn)\nA\n2ζr\nA\n2ζr\nA\nβ =\n=\n=\n,\n(ω2 - ω2)2 + (2ζωωn)2 m\n(1 - r2)2 + (2ζr)2 mω2\n(1 - r2)2 + (2ζr)2 k\nn\nn\nwhere r ≡ ω/ωn is the ratio of the forced to natural frequency.\nUsing a trigonometric identity, we may compute the amplitude of the particular solution as\n(1 - r2)2 + (2ζr)2 A\nA\nAp =\nα2 + β2 =\n=\n.\n(1 - r2)2 + (2ζr)2 k\n(1 - r2)2 + (2ζr)2 k\nNote that the magnitude of the amplification varies with the frequency ratio, r, and the damping\nratio, ζ. This variation in the amplification factor is plotted in Figure 21.19. For a given ζ, the\namplification factor is maximized at r = 1 (i.e., ωn = ω), and the peak amplification factor is\n1/(2ζ). This increase in the magnitude of oscillation near the natural frequency of the system is\nknown as resonance. The natural frequency is clearly crucial in understanding the forced response\nof the system, in particular for lightly damped systems.3\n21.3\nSystem of Two First-Order Linear ODEs\nIt is possible to directly numerically tackle the second-order system of Section 21.2 for example\nusing Newmark integration schemes. However, we shall focus on a state-space approach which is\nmuch more general and in fact is the basis for numerical solution of systems of ODEs of virtually\nany kind.\n3 Note that for ζ = 0 (which in fact is not realizable physically in any event), the amplitude is only infinite as\nt →inf; in particular, in resonant conditions, the amplitude will grow linearly in time.\np\np\np\n\n|\n{z\n}\n\n21.3.1\nState Space Representation of Scalar Second-Order ODEs\nIn this section, we develop a state space representation of the canonical second-order ODE. Recall\nthat the ODE of interest is of the form\nd2u\ndu\n+ 2ζωn\n+ ω2 u =\nf(t),\n0 < t < tf ,\nn\ndt2\ndt\nm\nu(0) = u0 ,\ndu (0) = v0 .\ndt\nBecause this is a second-order equation, we need two variables to fully describe the state of the\nsystem. Let us choose these state variables to be\ndu\nw1(t) = u(t) and w2(t) =\n(t) ,\ndt\ncorresponding to the displacement and velocity, respectively. We have the trivial relationship\nbetween w1 and w2\ndw1\ndu\n=\n= w2 .\ndt\ndt\nFurthermore, the governing second-order ODE can be rewritten in terms of w1 and w2 as\ndw2\nd du\nd2u\ndu\n=\n=\n- 2ζωn\n= -ω2 u +\nf = -2ζωnw2 - ω2 w1 +\nf .\nn\nn\ndt\ndt dt\ndt2\ndt\nm\nm\nTogether, we can rewrite the original second-order ODE as a system of two first-order ODEs,\nd\nw1\nw2\n=\n.\ndt\nw2\n-ω2 w1 - 2ζωnw2 +\nf\nn\nm\nThis equation can be written in the matrix form\nd\nw1\nw1\n=\n+\n(21.2)\ndt\nw2\n-ω2\n-2ζωn\nf\nn\nw2\nm\nA\nwith the initial condition\nw1(0) = u0\nand w2(0) = v0 .\nIf we define w = (w1 w2)T and F = (0\nf)T, then\nm\ndw\nu0\n= Aw + F,\nw(t = 0) = w0 =\n,\n(21.3)\ndt\nv0\nsuccinctly summarizes the \"state-space\" representation of our ODE.\n\n!\n\n!\n\n!\n\n-\n!\n|\n}\n\n!\n\n!\n\n!\n-\n{z\n\nSolution by Modal Expansion\nTo solve this equation, we first find the eigenvalues of A. We recall that the eigenvalues are the\nroots of the characteristic equation p(λ; A) = det(λI - A), where det refers to the determinant. (In\nactual practice for large systems the eigenvalues are not computed from the characteristic equation.\nIn our 2 × 2 case we obtain\nλ\n-1\np(λ; A) = det(λI - A) = det\n= λ2 + 2ζωnλ + ω2 .\nn\nω2\nλ + 2ζωn\nn\nThe eigenvalues, the roots of characteristic equation, are thus\nλ1,2 = -ζωn ± ωn\nζ2 - 1 .\nWe shall henceforth assume that the system is underdamped (i.e., ζ < 1), in which case it is more\nconvenient to express the eigenvalues as\nλ1,2 = -ζωn ± iωn\n1 - ζ2 .\nNote since the eigenvalue has non-zero imaginary part the solution will be oscillatory and since the\nreal part is negative (left-hand of the complex plane) the solution is stable. We now consider the\neigenvectors.\nTowards that end, we first generalize our earlier discussion of vectors of real-valued components\nto the case of vectors of complex-valued components. To wit, if we are given two vectors v ∈ Cm×1 ,\nw ∈ Cm×1 -- v and w are each column vectors with m complex entries -- the inner product is now\ngiven by\nm\nn\nH\n∗\nβ = v w =\nvj wj ,\n(21.4)\nj=1\nwhere β is in general complex, H stands for Hermitian (complex transpose) and replaces T for\n∗\ntranspose, and ∗ denotes complex conjugate -- so vj = Real(vj ) + i Imag(vj ) and vj = Real(vj ) -\n√\ni Imag(vj ), for i =\n-1.\nThe various concepts built on the inner product change in a similar fashion. For example,\ntwo complex-valued vectors v and w are orthogonal if vHw = 0. Most importantly, the norm of\ncomplex-valued vector is now given by\n⎛\n⎞\n⎛\n⎞\n1/2\n1/2\nm\nm\n√\nn\nn\n∗\nH\n⎝\n⎠\n⎝\n⎠\nIvI =\nv v =\nvj vj\n=\n|vj |2\n,\n(21.5)\nj=1\nj=1\n∗\nwhere | · | denotes the complex modulus; |vj |2 = v vj = (Real(vj ))2 + (Imag(vj ))2 . Note the\nj\ndefinition (21.5) of the norm ensures that IvI is a non-negative real number, as we would expect\nof a length.\nTo obtain the eigenvectors, we must find a solution to the equation\n(λI - A)χ = 0\n(21.6)\nfor λ = λ1 (⇒ eigenvector χ1 ∈ C2) and λ = λ2 (⇒ eigenvector χ2 ∈ C2). The equations (21.6)\nwill have a solution since λ has been chosen to make (λI - A) singular: the columns of λI - A are\nnot linearly independent, and hence there exists a (in fact, many) nontrivial linear combination,\nχ\n0, of the columns of λI - A which yields the zero vector.\n=\n\n!\np\np\n\nProceeding with the first eigenvector, we write (λ1I - A)χ1 = 0 as\n⎛\n⎞\n⎛\n⎞\n-ζωn + iωn\n1 - ζ2\n-1\nχ1\n⎝\n⎠\n⎝\n⎠\n=\nχ1\nω2\nζωn + iωn\n1 - ζ2\nn\nto obtain (say, setting χ1 = c),\n⎛\n⎞\n⎜\n⎟\nχ1\n⎜\n⎟\n= c\n.\n⎝\n-ωn\n⎠\nζωn + iωn\n1 - ζ2\nWe now choose c to achieve Iχ1I = 1, yielding\n⎛\n⎞\nχ1\n⎝\n⎠\n=\n.\n1 + ω2\nn\n-ζωn + iωn\n1 - ζ2\nIn a similar fashion we obtain from (λ2I - A)χ2 = 0 the second eigenvector\n⎛\n⎞\nχ2\n⎝\n⎠\n=\n,\n1 + ω2\nn\n-ζωn - iωn\n1 - ζ2\nwhich satisfies Iχ2I = 1.\nWe now introduce two additional vectors, ψ1 and ψ2 . The vector ψ1 is chosen to satisfy\n(ψ1)Hχ2 = 0 and (ψ1)Hχ1 = 1, while the vector ψ2 is chosen to satisfy (ψ2)Hχ1 = 0 and (ψ2)Hχ2 =\n1. We find, after a little algebra,\n⎛\n⎞\n⎛\n⎞\n-ζωn + iωn\n1 - ζ2\n-ζωn - iωn\n1 - ζ2\n1 + ω2\n1 + ω2\nn\nn\nψ1\n⎝\n⎠\nψ2\n⎝\n⎠\n=\n,\n=\n.\n2iωn\n1 - ζ2\n-2iωn\n1 - ζ2\n-1\n-1\nThese choices may appear mysterious, but in a moment we will see the utility of this \"bi-orthogonal\"\nsystem of vectors. (The steps here in fact correspond to the \"diagonalization\" of A.)\nWe now write w as a linear combination of the two eigenvectors, or \"modes,\"\nw(t)\n= z1(t) χ1 + z2(t) χ2\n= S z(t)\n(21.7)\nwhere\nS = (χ1 χ2)\nis the 2 × 2 matrix whose jth-column is given by the jth-eigenvector, χj . We next insert (21.7) into\n(21.3) to obtain\nχ1 dz1 + χ2 dz2\n= A(χ1 z1 + χ2 z2) + F ,\n(21.8)\ndt\ndt\n(χ1 z1 + χ2 z2)(t = 0) = w0 .\n(21.9)\nWe now take advantage of the ψ vectors.\np\np\np\np\np\np\np\np\np\np\np\np\np\n\n!\n\nFirst we multiply (21.8) by (ψ1)H and take advantage of (ψ1)H χ2 = 0, (ψ1)H χ1 = 1, and\nAχj = λj χj to obtain\ndz1 = λ1 z1 + (ψ1)H F ;\n(21.10)\ndt\nif we similarly multiply (21.9) we obtain\nz1(t = 0) = (ψ1)H w0 .\n(21.11)\nThe same procedure but now with (ψ2)H rather than (ψ1)H gives\ndz2\n= λ2 z2 + (ψ2)H F ;\n(21.12)\ndt\nz2(t = 0) = (ψ2)H w0 .\n(21.13)\nWe thus observe that our modal expansion reduces our coupled 2×2 ODE system into two decoupled\nODEs.\nThe fact that λ1 and λ2 are complex means that z1 and z2 are also complex, which might appear\ninconsistent with our original real equation (21.3) and real solution w(t). However, we note that\n∗\nλ2 = λ∗ and ψ2 = (ψ1)∗ and thus z2 = z1 . It thus follows from (21.7) that, since χ2 = (χ1)∗ as\nwell,\n∗\nw = z1χ1 + z1 (χ1) ∗ ,\nand thus\nw = 2 Real(z1χ1) .\nUpon superposition, our solution is indeed real, as desired.\nIt is possible to use this modal decomposition to construct numerical procedures. However, our\ninterest here in the modal decomposition is as a way to understand how to choose an ODE scheme\nfor a system of two (later n) ODEs, and, for the chosen scheme, how to choose Δt for stability.\n21.3.2\nNumerical Approximation of a System of Two ODEs\nCrank-Nicolson\nThe application of the Crank-Nicolson scheme to our system (21.3) is identical to the application of\nthe Crank-Nicolson scheme to a scalar ODE. In particular, we directly take the scheme of example\n21.1.8 and replace uj ∈ R with wj ∈ R2 and g with Aw j + F j to obtain\nj\nj-1\nΔt\nj\nΔt (F j + F j-1) .\nw = w\n+\n(Aw + Aw j-1) +\n(21.14)\n(Note if our force f is constant in time then F j = F .) In general if follows from consistency\narguments that we will obtain the same order of convergence as for the scalar problem -- if (21.14)\nis stable. The difficult issue for systems is stability: Will a particular scheme have good stability\nproperties for a particular equation (e.g., our particular A of (21.2))? And for what Δt will the\nscheme be stable? (The latter is particularly important for explicit schemes.)\nTo address these questions we again apply modal analysis but now to our discrete equations\n(21.14). In particular, we write\nj\nj\nj χ2\nw = z χ1 + z\n,\n(21.15)\n\nwhere χ1 and χ2 are the eigenvectors of A as derived in the previous section. We now insert (21.15)\ninto (21.14) and multiply by (ψ1)H and (ψ2)H -- just as in the previous section -- to obtain\nj\nj-1\nλ1Δt\nj\nj-1\nz\n= z\n+\n( z + z\n) + (ψ1)H Δt (F j + F j-1) ,\n(21.16)\nj\nj-1\nλ2Δt\nj\nj-1\n(F j + F j-1) ,\nz 2 = z 2\n+\n( z2 + z2\n) + (ψ2)H Δt\n(21.17)\nwith corresponding initial conditions (which are not relevant to our current discussion).\nWe now recall that for the model problem\ndu = λu + f ,\n(21.18)\ndt\nanalogous to (21.10), we arrive at the Crank-Nicolson scheme\nλΔt\nΔt\nj\nj-1\nu = u\n+\n( uj + uj-1) +\n(fj + fj-1) ,\n(21.19)\nanalogous to (21.16). Working backwards, for (21.19) and hence (21.16) to be a stable approx\nimation to (21.18) and hence (21.10), we must require λΔt, and hence λ1Δt, to reside in the\nCrank-Nicolson absolute stability region depicted in Figure 21.12(a). Put more bluntly, we know\nthat the difference equation (21.16) will blow up -- and hence also (21.14) by virture of (21.15)\n-- if λ1Δt is not in the unshaded region of Figure 21.12(a). By similar arguments, λ2Δt must also\nlie in the unshaded region of Figure 21.12(a). In this case, we know that both λ1 and λ2 -- for\nour particular equation, that is, for our particular matrix A (which determines the eigenvalues λ1,\nλ2) -- are in the left-hand plane, and hence in the Crank-Nicolson absolute stability region; thus\nCrank-Nicolson is unconditionally stable -- stable for all Δt -- for our particular equation and will\nconverge as O(Δt2) as Δt → 0.\nWe emphasize that the numerical procedure is given by (21.14) , and not by (21.16), (21.17).\nThe modal decomposition is just for the purposes of understanding and analysis -- to determine if a\nscheme is stable and if so for what values of Δt. (For a 2×2 matrix A the full modal decomposition is\nsimple. But for larger systems, as we will consider in the next section, the full modal decomposition\nis very expensive. Hence we prefer to directly discretize the original equation, as in (21.14). This\ndirect approach is also more general, for example for treatment of nonlinear problems.) It follows\nthat Δt in (21.16) and (21.17) are the same -- both originate in the equation (21.14). We discuss\nthis further below in the context of stiff equations.\nGeneral Recipe\nWe now consider a general system of n = 2 ODEs given by\ndw = Aw + F ,\ndt\n(21.20)\nw(0) = w0 ,\nwhere w ∈ R2 , A ∈ R2×2 (a 2 × 2 matrix), F ∈ R2, and w0 ∈ R2 . We next discretize (21.20) by any\nof the schemes developed earlier for the scalar equation\ndu = g(u, t)\ndt\n\nsimply by substituting w for u and Aw + F for g(u, t). We shall denote the scheme by S and the\nassociated absolute stability region by RS. Recall that RS is the subset of the complex plane which\ncontains all λΔt for which the scheme S applied to g(u, t) = λu is absolutely stable.\nFor example, if we apply the Euler Forward scheme S we obtain\nj\nj-1\nw = w j-1 + Δt(Aw\n+ F j-1) ,\n(21.21)\nwhereas Euler Backward as S yields\nw j = w j-1 + Δt(Aw j + F j ) ,\n(21.22)\nand Crank-Nicolson as S gives\nΔt\nΔt\nj\nj-1\nj\nw = w\n+\n(Aw + Aw j-1) +\n(F j + F j-1) .\n(21.23)\nA multistep scheme such as AB2 as S gives\nj\nj-1 -\nj-2\nF j-1 -\nF j-2\nw = w j-1 + Δt\nAw\nAw\n+ Δt\n.\n(21.24)\nThe stability diagrams for these four schemes, RS, are given by Figure 21.9, Figure 21.7, Fig\nure 21.12(a), and Figure 21.11(b), respectively.\nWe next assume that we can calculate the two eigenvalues of A, λ1, and λ2. A particular Δt\nwill lead to a stable scheme if and only if the two points λ1Δt and λ2Δt both lie inside RS. If either\nor both of the two points λ1Δt or λ2Δt lie outside RS, then we must decrease Δt until both λ1Δt\nand λ2Δt lie inside RS. The critical time step, Δtcr, is defined to be the largest Δt for which the\ntwo rays [0, λ1Δt], [0, λ2Δt], both lie within RS; Δtcr will depend on the shape and size of RS and\nthe \"orientation\" of the two rays [0, λ1Δt], [0, λ2Δt].\nWe can derive Δtcr in a slightly different fashion. We first define M\nΔt1 to be the largest Δt such\nthat the ray [0, λ1Δt] is in RS; we next define M\nΔt2 to be the largest Δt such that the ray [0, λ2Δt]\nis in RS. We can then deduce that Δtcr\nΔt1, M\n= min(M\nΔt2). In particular, we note that if Δt > Δtcr\nthen one of the two modes -- and hence the entire solution -- will explode. We can also see here\nagain the difficulty with stiff equations in which λ1 and λ2\nΔt1\nare very different: M\nmay be (say)\nmuch larger than M\nΔt2 will dictate Δt and thus force us to take many time steps\nmany\nΔt2, but M\n--\nmore than required to resolve the slower mode (smaller |λ1| associated with slower decay or slower\noscillation) which is often the behavior of interest.\nIn the above we assumed, as is almost always the case, that the λ are in the left-hand plane.\nFor any λ which are in the right-hand plane, our condition is flipped: we now must make sure that\nthe λΔt are not in the absolute stability region in order to obtain the desired growing (unstable)\nsolutions.\nLet us close this section with two examples.\nExample 21.3.1 Undamped spring-mass system\nIn this example, we revisit the undamped spring-mass system considered in the previous section.\nThe two eigenvalues of A are λ1 = iωn and λ2 = iωn; without loss of generality, we set ωn = 1.0.\nWe will consider application of several different numerical integration schemes to the problem; for\neach integrator, we assess its applicability based on theory (by appealing to the absolute stability\ndiagram) and verify our assessment through numerical experiments.\n(i) Euler Forward is a poor choice since both λ1Δt and λ2Δt are outside RS=EF for all Δt. The\nresult of numerical experiment, shown in Figure 21.20(a), confirms that the amplitude of the\noscillation grows for both Δt = 0.5 and Δt = 0.025; the smaller time step results in a smaller\n(artificial) amplification.\n\n-1.5\n-1\n-0.5\n0.5\n1.5\nt\nu\n\n∆t=0.500\n∆t=0.025\nexact\n-1.5\n-1\n-0.5\n0.5\n1.5\nt\nu\n\n∆t=0.500\n∆t=0.025\nexact\n(a) Euler Forward\n(b) Euler Backward\n-1.5\n-1\n-0.5\n0.5\n1.5\nt\nu\n\n∆t=0.500\n∆t=0.025\nexact\n-1.5\n-1\n-0.5\n0.5\n1.5\nt\nu\n\n∆t=0.500\n∆t=0.025\nexact\n(c) Crank-Nicolson\n(d) Four-stage Runge-Kutta\nFigure 21.20: Comparison of numerical integration schemes for an undamped spring-mass system\nwith ωn = 1.0.\n\n.\n\n.\n(ii) Euler Backward is also a poor choice since λ1Δt and λ2Δt are in the interior of RS=EB for all\nΔt and hence the discrete solution will decay even though the exact solution is a non-decaying\noscillation. Figure 21.20(b) confirms the assessment.\n(iii) Crank-Nicolson is a very good choice since λ1Δt ∈RS=CN, λ2Δt ∈RS=CN for all Δt, and\nfurthermore λ1Δt, λ2Δt lie on the boundary of RS=CN and hence the discrete solution, just\nas the exact solution, will not decay. Figure 21.20(c) confirms that Crank-Nicolson preserves\nthe amplitude of the response regardless of the choice of Δt; however, the Δt = 0.5 case\nresults in a noticeable phase error.\n(iv) Four-stage Runge-Kutta (RK4) is a reasonably good choice since λ1Δt and λ2Δt lie close\nto the boundary of RS=RK4 for |λiΔt|\n1. Figure 21.20(d) shows that, for the problem\nconsidered, RK4 excels at not only preserving the amplitude of the oscillation but also at\nattaining the correct phase.\nNote in the above analysis the absolute stability diagram serves not only to determine stability but\nalso the nature of the discrete solution as regards growth, or decay, or even neutral stability -- no\ngrowth or decay. (The latter does not imply that the discrete solution is exact, since in addition to\namplitude errors there are also phase errors. Our Crank-Nicolson result, shown in Figure 21.20(c),\nin particular demonstrate the presence of phase errors in the absence of amplitude errors.)\n·\nExample 21.3.2 Overdamped spring-mass-damper system: a stiff system of ODEs\nIn our second example, we consider a (very) overdamped spring-mass-damper system with ωn = 1.0\nand ζ = 100. The eigenvalues associated with the system are\nλ1 = -ζωn + ωn\nζ2 - 1 = -0.01\nλ2 = -ζωn - ωn\nζ2 - 1 = -99.99 .\nAs before, we perturb the system by a unit initial displacement. The slow mode with λ1 = -0.01\ndictates the response of the system. However, for conditionally stable schemes, the stability is\ngoverned by the fast mode with λ2 = -99.99. We again consider four different time integrators:\ntwo explicit and two implicit.\n(i) Euler Forward is stable for Δt\n0.02 (i.e. Δtcr = 2/|λ2|). Figure 21.21(a) shows that\nthe scheme accurately tracks the (rather benign) exact solution for Δt = 0.02, but becomes\nunstable and diverges exponentially for Δt = 0.0201. Thus, the maximum time step is limited\nnot by the ability to approximate the system response (dictated by λ1) but rather by stability\n(dictated by λ2). In other words, even though the system response is benign, we cannot use\nlarge time steps to save on computational cost.\n(ii) Similar to the Euler Forward case, the four-stage Runge-Kutta (RK4) scheme exhibits an\nexponentially diverging behavior for Δt > Δtcr ≈ 0.028, as shown in Figure 21.21(b). The\nmaximum time step is again limited by stability.\n(iii) Euler Backward is unconditionally stable, and thus the choice of the time step is dictated\nby the ability to approximate the system response, which is dictated by λ1. Figure 21.21(c)\nshows that Euler Backward in fact produces a good approximation even for a time step as\nlarge as Δt = 5.0 since the system response is rather slow.\np\np\n≲\n≲\n\n(iv) Crank-Nicolson is also unconditionally stable. For the same set of time steps, Crank-Nicolson\nproduces a more accurate approximation than Euler Backward, as shown in Figure 21.21(d),\ndue to its higher-order accuracy.\nIn the above comparison, the unconditionally stable schemes required many fewer time steps\n(and hence much less computational effort) than conditionally stable schemes. For instance, Crank-\nNicolson with Δt = 5.0 requires approximately 200 times fewer time steps than the RK4 scheme\n(with a stable choice of the time step). More importantly, as the shortest time scale (i.e. the largest\neigenvalue) dictates stability, conditionally stable schemes do not allow the user to use large time\nsteps even if the fast modes are of no interest to the user. As mentioned previously, stiff systems are\nubiquitous in engineering, and engineers are often not interested in the smallest time scale present\nin the system. (Recall the example of the time scale associated with the dynamics of a passenger\njet and that associated with turbulent eddies; engineers are often only interested in characterizing\nthe dynamics of the aircraft, not the eddies.) In these situations, unconditionally stable schemes\nallow users to choose an appropriate time step independent of stability limitations.\n·\nIn closing, it is clear even from these simple examples that a general purpose explicit scheme\nwould ideally include some part of both the negative real axis and the imaginary axis. Schemes\nthat exhibit this behavior include AB3 and RK4. Of these two schemes, RK4 is often preferred\ndue to a large stability region; also RK4, a multi-stage method, does not suffer from the start-up\nissues that sometimes complicate multi-step techniques.\n21.4\nIVPs: System of n Linear ODEs\nWe consider here for simplicity a particular family of problems: n/2 coupled oscillators. This family\nof systems can be described by the set of equations.\nd2\n(1)\nu\ndu(j)\n(1)\n(j)\n+ f(1)(t) ,\n= g\n, u\n, 1 ≤ j ≤ n/2\ndt2\ndt\nd2\n(2)\nu\n(2)\ndu(j)\n(j)\n+ f(2)(t) ,\n= g\n, u\n, 1 ≤ j ≤ n/2\ndt2\ndt\n. . .\n(n/2)\nd2u\ndu(j)\n(n/2)\n(j)\n+ f(n/2)(t) ,\n= g\n, u\n, 1 ≤ j ≤ n/2\ndt2\ndt\nwhere g(k) is assumed to be a linear function of all its arguments.\n\n!\n\n!\n\n!\n\n0.6\n0.7\n0.8\n0.9\n1.1\n1.2\nt\nu\n\n∆t=0.0201\n∆t=0.0200\nexact\n0.6\n0.7\n0.8\n0.9\n1.1\n1.2\nt\nu\n\n∆t=0.0280\n∆t=0.0270\nexact\n(a) Euler Forward\n(b) Four-stage Runge-Kutta\n0.6\n0.7\n0.8\n0.9\n1.1\n1.2\nt\nu\n\n∆t=5.0000\n∆t=0.5000\nexact\n0.6\n0.7\n0.8\n0.9\n1.1\n1.2\nt\nu\n\n∆t=5.0000\n∆t=0.5000\nexact\n(c) Euler Backward\n(d) Crank-Nicolson\nFigure 21.21: Comparison of numerical integration schemes for an overdamped spring-mass-damper\nsystem with ωn = 1.0 and ζ = 50. Note that the time step used for the explicit schemes are different\nfrom those for the implicit schemes.\n\nWe first convert this system of equations to state space form. We identify\ndu(1)\n(1)\nw1 = u\n,\nw2 =\n,\ndt\ndu(2)\n(2)\nw3 = u\n,\nw4 =\n,\ndt\n. . .\ndu(n/2)\n(n/2)\nwn-1 = u\n,\nwn =\n.\ndt\nWe can then write our system -- using the fact that g is linear in its arguments -- as\ndw = Aw + F\ndt\n(21.25)\nw(0) = w0\nT\n0 f(1)(t)\n0 f(2)(t)\n0 f(n/2)(t)\nwhere g determines A, F is given by\n. . .\n, and\ndu(1)\ndu(2)\ndu(n/2)\nT\nw0 = u(1)(0)\n(0) u(2)(0)\n(0)\n. . .\nu(n/2)(0)\n(0)\n.\ndt\ndt\ndt\nWe have now reduced our problem to an abstract form identical to (21.20) and hence we may apply\nany scheme S to (21.25) in the same fashion as to (21.20).\nFor example, Euler Forward, Euler Backward, Crank-Nicolson, and AB2 applied to (21.25)\nwill take the same form (21.21), (21.22), (21.23), (21.24), respectively, except that now w ∈ Rn ,\nA ∈ Rn×n , F ∈ Rn , w0 ∈ Rn are given in (21.25), where n/2, the number of oscillators (or masses)\nin our system, is no longer restricted to n/2 = 1 (i.e., n = 2). We can similarly apply AB3 or BD2\nor RK4.\nOur stability criterion is also readily extended. We first note that A will now have in general\nn eigenvalues, λ1, λ2, . . . , λn. (In certain cases multiple eigenvalues can create difficulties; we do\nnot consider these typically rather rare cases here.) Our stability condition is then simply stated:\na time step Δt will lead to stable behavior if and only if λiΔt is in RS for all i, 1 ≤ i ≤ n. If\nthis condition is not satisfied then there will be one (or more) modes which will explode, taking\nwith it (or them) the entire solution. (For certain very special initial conditions -- in which the w0\nis chosen such that all of the dangerous modes are initially exactly zero -- this blow-up could be\navoided in infinite precision; but in finite precision we would still be doomed.) For explicit schemes,\nΔtcr is the largest time step such that all the rays [0, λiΔt], 1 ≤ i ≤ n, lie within RS.\nThere are certainly computational difficulties that arise for large n that are not an issue for\nn = 2 (or small n). First, for implicit schemes, the necessary division -- solution rather than\nevaluation of matrix-vector equations -- will become considerably more expensive. Second, for\nsuch that Δtconservative\nexplicit schemes, determination of Δtcr, or a bound Δtconservative\n≈ Δtcr\ncr\ncr\nand Δtconservative\n, can be difficult. As already mentioned, the full modal decomposition can\ncr\n≤ Δtcr\nbe expensive. Fortunately, in order to determine Δtcr, we often only need as estimate for say the\nmost negative real eigenvalue, or the largest (in magnitude) imaginary eigenvalue; these extreme\neigenvalues can often be estimated relatively efficiently.\n\nFinally, we note that in practice often adaptive schemes are used in which stability and accuracy\nare monitored and Δt modified appropriately. These methods can also address nonlinear problems\n-- in which g no longer depends linearly on its arguments.\n\nChapter 22\nBoundary Value Problems\n\nChapter 23\nPartial Differential Equations\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n2.086 Numerical Computation for Mechanical Engineers\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    }
  ]
}