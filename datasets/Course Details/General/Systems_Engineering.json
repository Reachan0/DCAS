{
  "course_name": "Systems Engineering",
  "course_description": "Systems Engineering is an interdisciplinary approach and means to enable the realization of successful systems. It focuses on defining customer needs and required functionality early in the development cycle, documenting requirements, then proceeding with design synthesis and system validation while considering the complete problem including operations, performance, test, manufacturing, cost, and schedule. This subject emphasizes the links of systems engineering to fundamentals of decision theory, statistics, and optimization. It also introduces the most current, commercially successful techniques for systems engineering.",
  "topics": [
    "Engineering",
    "Systems Engineering",
    "Engineering",
    "Systems Engineering"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 2 hours / session\n\nCourse Objectives\n\nThis course intends to help you develop the capability of systems thinking by introducing classical and advanced systems engineering theory, methods, and tools. After taking this class, you should be able to:\n\nDevelop a systems engineering plan for a realistic project.\n\nJudge the applicability of any proposed process, strategy, or methodology for systems engineering using the fundamental concepts from disciplines such as probability, economics, and cognitive science.\n\nUnderstand system engineers' role and responsibilities. Understand the role of organizations.\n\nApply systems engineering tools (e.g., requirements development and management, robust design, Design Structure Matrix) to realistic problems.\n\nRecognize the value and limitations of modeling and simulation.\n\nFormulate an effective plan for gathering and using data.\n\nKnow how to proactively design for and manage system lifecycle targets.\n\nReading Materials\n\nRequired Textbooks\n\nINCOSE Systems Engineering Handbook, v3.2\n. San Diego, CA: INCOSE, 2010.\n\nMiller, John.\nQBQ! The Question Behind the Question: Practicing Personal Accountability at Work and in Life\n. East Rutherford, NJ: Putnam Publishing Group, 2004. ISBN: 9780399152337.\n\nAltshuller, Genrich, Dana W. Clarke, Uri Fedozeev, and Steve Rodman.\n40 Principles: TRIZ Keys to Innovation\n. Worcester, MA: Technical Innovation Center, Inc., 2005. ISBN: 9780964074057.\n\nA number of technical papers will also be assigned as pre-reading for the lectures.\n\nOverall Semester Plan\n\nLec #1: Course introduction\n\nLec #3: Student project proposal\n\nLec #9: Student midterm proposal\n\nLec #14, 15, and 17: Industry speakers\n\nLec #16: Student case study presentations and discussions\n\nLec #18, and 19: Two 4-hour final presentations\n\nClass Sessions\n\nAn important thing about the lectures, and about the course in general, is that the lecturers will ask for your participation. For every lecture, there will be readings assigned. The readings are focused on the lecture's theme; some were written especially for it. Please read them and come prepared to class because only then will you be able to participate in the class and benefit from what the faculty and your fellow students say.\n\nTime Commitment and Expectations\n\nThe units on an MIT subject correspond to the time that an adequately prepared student is expected to spend in a normal week. This is divided into three numbers associated with the subject (X-Y-Z) with X being class time, Y being laboratory time, and Z being work outside of class. The numbers associated with ESD.33 are (3-0-6) making this a 9-unit subject. However, the summer term is compressed from a regular academic year term as there are 10 weeks as compared to 14 during a regular term. Thus, one must accomplish in 10 weeks what would normally be accomplished in 14 weeks. Consequently, the overall weekly time commitment is expected to be 12.6 hours. This includes 4 hours per week in class and 8.6 hours per week out of class. The out-of-class time will be spent on reading, homework, and project work.\n\nGrading\n\nACTIVITIES\n\nPERCENTAGES\n\nIndividual project proposal\n\n10%\n\nMid-term project presentation\n\n10%\n\nFinal project presentation\n\n20%\n\nHomework assignments (10% each)\n\n50%\n\nParticipation\n\n10%\n\nHomework Assignments\n\nYou will be required to complete 5 homework assignments. The theme of the assignments will be to use various systems engineering techniques to analyze the Toyota safety recall that occurred this past spring. The first four assignments are individual assignments. The fifth will be a team report and presentation. Students may form teams of five as they wish to complete the 5th homework assignment. These teams do not need to be the same as the term project team.\n\nThe manner in which you present your work can be just as important (and in some cases more so) than the overall approach manifested within the response. Be sure to clearly explain your work, the methods used, and the underlying assumptions. Such practices make it possible for us to fairly assess your work and happen also to be good practices for documenting work in industry.",
  "files": [
    {
      "category": "Resource",
      "title": "Course Introduction",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-33-systems-engineering-summer-2010/d9ebd745bd9dbc37604c2a271a866b29_MITESD_33SUM10_lec01.pdf",
      "content": "ESD.33 Systems Engineering\nLecture 1\nCourse Introduc8on\nInstructors:\nDr. Qi Van Eikema Hommes\nMr. Pat Hale\nMr. David Erickson\nTeaching Assistants:\nEllen Czaika\nIpshita Deepak\n\nAgenda\nWelcome and Introduc8on of Teaching Staff\nWhy are we here?\nWhat are Systems?\nWhat is Systems Engineering?\nWhy do we study Systems Engineering?\nCourse Schedule and Logis8cs\nQi Van Eikema Hommes\n(c) June 8, 2010\n\nDr. Qi Van Eikema Hommes\n- ESD Research Associate and Lecturer\n- 8 years of work experiences in automo8ve\ncompanies (Ford and GM)\n- Senior Research Scien8st at GM R&D\n- Powertrain Systems Engineer at Ford\nQi Van Eikema Hommes\nPh.D. and M.S. in\nMechanical Engineering\nB.S. in Mechanical\nEngineering\n(c) June 8, 2010\nMIT\nUniversity of\nKentucky\n\nDr. Pat Hale\n- SDM Director, ESD Senior Lecturer\n- Military experience:\n- 20 years in U.S. Navy: submarines\n- Industry experience:\n- Draper Labs (Director, Systems Engineering)\n- O8s Elevator (first Director, Systems &\nControls Engineering)\n- Past INCOSE president\n(c) June 8, 2010\nQi Van Eikema Hommes\n\nAcademic Background\nB.S. Mechanical Engineering\n\nUniversity of Minnesota\n\nM.S. Mechanical Engineering\n\nEngineer's Degree in Ocean Engineering\n\nMassachusetts Institute of Technology\n\nMBA\n\nCornell University\n(c) June 8, 2010\nQi Van Eikema Hommes\n\nAbout me:\nProduct designer/ manager, systems engineer,\nmobile tech enthusiast, a mother, vocal ar8st and a\nsecond year SDM student\n\n(c) June 8, 2010\nQi Van Eikema Hommes 6\n\nAbout me:\nSDM08\nFormer manager of systems engineering team\nEthnographer\nAthlete (numerous sports: rowing, yoga, skiing/snowboarding,\nhiking, biking, sailing, surfing, etc.)\n\n(c) June 8, 2010\nQi Van Eikema Hommes 7\n\nWhy Are We in This Class?\n(c) June 8, 2010\nQi Van Eikema Hommes 8\n\nQi Van Eikema Hommes\n(c) June 8, 2010\n9Diagram of automobile powertrain.\nImage by MIT OpenCourseWare.\n\nIs This a System and Why?\nhttp://science.howstuffworks.com/power.htm/printable\n(c) June 8, 2010\nQi Van Eikema Hommes 10\nPower grid image removed due to copyright restrictions.\nImage can be found at HowStuffWorks.com.\n\nIs This a System and Why?\n(c) June 8, 2010\nQi Van Eikema Hommes 11\n\nIs This a System and Why?\n(c) June 8, 2010\nQi Van Eikema Hommes 12\nFlow\nchart of co\nrporate\ndepartments\n.\nImage by MIT OpenCourseWare.\n\nIs This a System and Why?\nhttp://ccl.northwestern.edu/netlogo/models/WolfSheepStrideInheritance (ANIMATION)\nWorks in Firefox browser\nWolves eats sheep.\nSheep eat grass.\nWolves and sheep reproduce.\nThey move in random directions.\nTry when there are more wolves than\nsheep.\n(c) June 8, 2010\nQi Van Eikema Hommes 13\n\nWhat Types of Systems Have You\nWorked on?\nWhy do you call them \"systems?\"\n(c) June 8, 2010\nQi Van Eikema Hommes 14\n\nDefini8on of Systems\n- A combina8on of interac8ng elements\norganized to achieve one more stated\npurposes.\n- An integrated set of elements, subsystems, or\nassemblies that accomplish a defined\nobjec8ve. These elements include products\n(hardware, sofware, firmware), processes,\npeople, informa8on, techniques, facili8es,\nservices, and other support element.\nSource: INCOSE SE Handbook, V3.2\n(c) June 8, 2010\nQi Van Eikema Hommes 15\n\nCharacteris8cs of Systems\n- Interac8on\n- Hierarchical\n- Emergent\n- Dynamic\n- Interdisciplinary\n(c) June 8, 2010\nQi Van Eikema Hommes 16\n\nDigital Photography\n(c) June 8, 2010\nQi Van Eikema Hommes 17\nSystems diagram of d\nigital photography ha\nrdware components.\nImage by MIT OpenCourseWare.\n\nSystem of Systems\nLarge‐scale inter‐disciplinary problems involving\nmul8ple, heterogeneous, distributed systems.\n- System elements operate independently.\n- System elements have different life cycles.\n- The iniAal requirements are likely to be ambiguous.\n- Complexity is a major issue.\n- Management can overshadow engineering.\n- Fuzzy boundaries cause confusion.\n- SoS engineering is never finished.\nSource: INCOSE SE Handbook V3.2\n(c) June 8, 2010\nQi Van Eikema Hommes 18\n\nThis Class' Focus\n(c) June 8, 2010\nQi Van Eikema Hommes 19\n\nAgenda\nWelcome and Introduc8on of Teaching Staff\nWhy are we here?\n\nWhat are Systems?\nWhat is Systems Engineering?\nWhy do we study Systems Engineering?\nCourse Schedule and Logis8cs\n(c) June 8, 2010\nQi Van Eikema Hommes 20\n\nWhat is Systems Engineering?\n- Systems engineering is a discipline that concentrates on the\ndesign and applica8on of the whole (system) as dis8nct from\nthe parts. It involves looking at a problem in its en8rety, taking\ninto account all the facets and all the variables and rela8ng\nthe social to the technical aspect.\n- Systems engineering is an itera8ve process of top‐down\nsynthesis, development, and opera8on of a real‐world system\nthat sa8sfies, in a near op8mal manner, the full range of\nrequirements for the system.\nINCOSE SE Handbook V3.2\n(c) June 8, 2010\nQi Van Eikema Hommes 21\n\nWhat is Systems Engineering?\n- Systems engineering is an interdisciplinary approach and\nmeans to enable the realiza8on of successful systems. It\nfocuses on defining customer needs and required\nfunc8onality early in the development cycle, documen8ng\nrequirements, and then proceeding with design synthesis and\nsystem valida8on while considering the complete problem:\nopera8ons, cost and schedule, performance, training and\nsupport, test, manufacturing, and disposal. SE considers both\nthe business and the technical needs of all customers with the\ngoal of providing a quality product that meets the user needs.\nINCOSE SE Handbook V3.2\n(c) June 8, 2010\nQi Van Eikema Hommes 22\n\nApplica8on Domains of Systems\nEngineering\n- Aerospace\n- Urban Infrastructure\n- Communica8ons systems\n- Data and informa8on systems\n- Healthcare systems\n- Electric power systems\n- Produc8on/construc8on systems\n- Waste disposal systems\n- Transporta8on systems\n- Financial systems\n- Educa8on systems\n- ...\nSource: Blanchard, Fabrycky, Systems Engineering and Analysis, 5th ed.\n(c) June 8, 2010\nQi Van Eikema Hommes 23\n\nWaterfall Process Model\nIntroduced by Royce\nin 1970, initially for\nsoftware\ndevelopment.\nSource: Blanchard, Fabrycky, Systems Engineering and Analysis, 5th ed.\n(c) June 8, 2010\nQi Van Eikema Hommes 24\nWaterfall pr\nocess mo\ndel.\nImage by MIT OpenCourseWare.\n\nSpiral Process Model\n- Boehm, 1986.\n- Adapted from\nWaterfall model\n- Itera8ve\n- Prototyping\nSource: Blanchard, Fabrycky, Systems Engineering and Analysis, 5th ed.\n(c) June 8, 2010\nQi Van Eikema Hommes 25\nSpir\nal pro\ncess model.\nImage by MIT OpenCourseWare.\n\n(c) June 8, 2010\nQi Van Eikema Hommes 26\nSystem engineerin\ng implemen\nted in F\nPDS.\nImage by MIT OpenCourseWare.\n\nINCOSE VEE Model\n(c) June 8, 2010\nQi Van Eikema Hommes 27 Diagram of the INCOSE VEE model.\nImage by MIT OpenCourseWare.\n\nIs There a Winner?\n- It is observed that preferences expressed by\nindividuals and groups for one of the system\nmodels is subjec8ve.\n- Research is needed to see which model fits\nwhat situa8on bemer.\n- Class Discussion:\n- What are common among these processes?\n- Is Systems Engineering the same from Product\nDevelopment?\n(c) June 8, 2010\nQi Van Eikema Hommes 28\n\nSystems Engineering vs. Product Development\nPlanning\nConcept\nDevelopment\nSystem-Level\nDesign\nDetail\nDesign\nTesting and\nRefinement\nProduction\nRamp-Up\nMission\nApproval\nConcept\nReview\nSystem Spec\nReview\nCritical Design\nReview\nProduction\nApproval\nProduct Development Process (Ulrich and Eppinger)\n\n(c) June 8, 2010\nQi Van Eikema Hommes 29\nSystem engineerin\ng implemen\nted in F\nPDS.\nImage by MIT OpenCourseWare.\n\nAgenda\nWelcome and Introduc8on of Teaching Staff\nWhy are we here?\n\nWhat are Systems?\n\nWhat is Systems Engineering?\nWhy do we study Systems Engineering?\nCourse Schedule and Logis8cs\n\n(c) June 8, 2010\nQi Van Eikema Hommes 30\n\nThe Value of Systems Engineering\n(c) June 8, 2010\nQi Van Eikema Hommes 31Graph modeling the value of systems engineering.\nImage by MIT OpenCourseWare.\n\nThe Value of Systems Engineering\n- Systems engineering efforts reduce cost and\nschedule overrun.\n- Class discussion: Why? Think back about the\ncharacteris8cs of systems.\n- Interac8on\n- Hierarchical\n- Emergence\n- Dynamic\n- Interdisciplinary\n(c) June 8, 2010\nQi Van Eikema Hommes 32\n\nHistory of Systems Engineering\nThe Machine\nAge\n1940s\nThe Systems\nAge\n\n(c) June 8, 2010\nQi Van Eikema Hommes 33\n\nThe Machine Age\n- Reduc9onism--Everything can be reduced, decomposed, or\ndisassembled to simple indivisible parts.\n- Analy9cal way of thinking\n- Take apart what is to be explained\n- Explain the smaller parts.\n- The whole is the sum of its parts.\n- Mechanism\n- Cause and effect, determinis8c thinking\n- Closed System Thinking--ignore the environment a\nphenomenon is in.\n- Mechaniza9on\n- Industrial revolu8on (18‐19th century)\n- Machine subs8tute people for physical work\n- Dehumaniza8on of work\n(c) June 8, 2010\nQi Van Eikema Hommes 34\n\nExamples of Machine Age Thinking\n- Ancient roots\n- Aristotle (Physics--fire, earth, air, water, aether )\n- Archimedes\n- Biology\n- Study of cells and organs\n- Physics\n- Study of atoms\n- F. W. Taylor \"Scien8fic Management\"\n(c) June 8, 2010\nQi Van Eikema Hommes 35\n\nClass Discussion Points\n- Your examples?\n- Strength and Weakness of Machine Age\nThinking\n(c) June 8, 2010\nQi Van Eikema Hommes 36\n\nThe System Age\n-\nCirca 1940s\n-\nSupplemen8ng the Machine Age thinking\n-\nExpansionism\n- All objects and events, and all experience of them as parts of larger\nwholes.\n- Stochas8c view of the systems.\n-\nSynthe9c Thinking (Systems Thinking)\n- Instead of focusing on explaining the whole but taking it apart,\nsynthe8c thinking focuses on explaining something in terms of its role\nin the larger system.\n- The whole is not equal to the sum of its parts--some8mes more,\nsome8mes less.\n-\nTeleologically oriented\n- Systems have purposes\n- More focuses on the human aspect of organiza8on design and\nmanagement.\n(c) June 8, 2010\nQi Van Eikema Hommes 37\n\nMachine Age vs. Systems Age\nMachine Age Thinking\nSystems Age Thinking\nReduc8onism\nExpansionism\nAnaly8cal thinking\nSynthe8c thinking\nMechaniza8on\nTeleologically Oriented\n- These two eras show continuous human inquiry to\nunderstand the world.\n- They are complementary, not contradictory.\n- System Engineering is a more recent phenomenon.\n- Understanding the history helps us to think critically.\n(c) June 8, 2010\nQi Van Eikema Hommes 38\n\nINCOSE\n- The Interna8onal Council on Systems Engineering (INCOSE) is\na not‐for‐profit membership organiza8on founded to develop\nand disseminate the interdisciplinary principles and prac8ces\nthat enable the realiza8on of successful systems.\n- Mission: Share, promote and advance the best of systems\nengineering from across the globe for the benefit of humanity\nand the planet.\n- Vision: The world's authority on Systems Engineering.\n- hmp://www.incose.org/\n(c) June 8, 2010\nQi Van Eikema Hommes 39\n\nAgenda\nWelcome and Introduc8on of Teaching Staff\nWhy are we here?\n\nWhat are Systems?\n\nWhat is Systems Engineering?\n\nWhy do we study Systems Engineering?\nCourse Schedule and Logis8cs\n\n(c) June 8, 2010\nQi Van Eikema Hommes 42\n\nCourse Learning Objec8ves\n-\nThis course intends to help you develop the capability of systems thinking by\nintroducing classical and advanced systems engineering theory, methods, and\ntools. Afer taking this class, you should be able to:\n- Develop a systems engineering plan for a realis8c project.\n- Judge the applicability of any proposed process, strategy, or methodology for\nsystems engineering using the fundamental concepts from disciplines such as\nof probability, economics, and cogni8ve science.\n- Understand system engineers' role and responsibili8es. Understand the role\nof organiza8ons.\n- Apply systems engineering tools (e.g., requirements development and\nmanagement, robust design, Design Structure Matrix) to realis8c problems;\n- Recognize the value and limita8ons of modeling and simula8on.\n- Formulate an effec8ve plan for gathering and using data.\n- Know how to proac8vely design for and manage system lifecycle targets.\n(c) June 8, 2010\nQi Van Eikema Hommes 43\n\nQi Van Eikema Hommes\n(c) June 8, 2010\nLecture 4\nStakeholder Analysis and\nRequirements Defini8on\nLecture 2\nSystems Engineering\nAs Human Ac8vity\nLecture 13\nDesign Verifica8on\nand\nValida8on, Lifecycle\nManagement\nLecture 5 innova8on in\nSystems Engineering\nLecture 6 Axioma8c\nDesign and DM‐DSM\nMethod\nLecture 8\nTrade Space Explora8on\nConcept Selec8on\nLecture 10 : Experiments\nLecture 11\nLecture 12:\n: Robust Design I\nRobust Design II\nCourse Layout\n\nCourse Materials\n- Textbooks:\n- INCOSE Systems Engineering Handbook, V3.2.\n- \"40 Principles\"\n- QBQ\n- Reference books:\n- Strongly recommended: Blanchard, B. S., and\nFabrycky, W. J., Systems Engineering and Analysis,\n5th edi8on, Pren8ce Hall, 2010.\n(c) June 8, 2010\nQi Van Eikema Hommes 45\n\nCourse Policies\n- Reading -please be prepared for class\ndiscussions\n- Class sessions\n- 2 sessions/week, 2 hours/session\n- Session 3, 3 hours, project proposal\n- Sessions 19 and 20, 4 hours, final\npresenta8ons.\n- Amendance and class par8cipa8on\n- Instructor will randomly pick student names for\nclass discussion\n(c) June 8, 2010\nQi Van Eikema Hommes 46\n\nClass Time Commitment\n- Course is H 3‐0‐6\n- This is a 9 units class in a normal semester (14\nweeks).\n- Summer is 10 weeks, which means this course\nrequires 12.6 hours of work per week.\n- 12.6 hours = 4 hours in class + 8.6 hours\noutside\n- 8.6 hours include reading, homework\nassignments, and project work.\n(c) June 8, 2010\nQi Van Eikema Hommes 47\n\nGrading\n- Project (presenta8ons and reports):\n- Individual Project proposal (presenta8on and 1‐page) 10%\n- Mid‐term (group presenta8on) 10%\n- Final (group presenta8on) 20%\n- Homework Assignments 10% x 5\n- The first four are individual assignments 10% x 4\n- The fifh is a group presenta8on 10%\n- Amendance and class par8cipa8on 10%\n- Each class unamended without instructors' permission\nreduces 1% of the grade\n- Please let the instructor know if you are unable to amend\nthe class.\n(c) June 8, 2010\nQi Van Eikema Hommes 48\n\nTerm Project\n- The goal is to apply the systems engineering\nmethods and tools to a topic that fits your interest /\nyour industry.\n- Acceptable topic examples:\n- Design of a new system (technical, organiza8onal,\nenterprise level, etc.). The project must have\nenough detail so that it can demonstrate the use\nof the methods and tools taught in the class.\n- In‐depth inves8ga8on of a successful or failed\nproject\n- Choose a project that you have access to informa8on\nand data.\n(c) June 8, 2010\nQi Van Eikema Hommes 49\n\nTerm Project Deliverables\n- Proposal (Session 3)\n- Individual students propose project topics\n- Voluntarily form teams of 3‐5. Four‐\nmember teams are strongly encouraged.\n- Submit team forma8on report by Session 5.\n- Mid‐term presenta8on (Session 9)\n- Final presenta8on (Sessions 19 and 20)\n(c) June 8, 2010\nQi Van Eikema Hommes 50\n\nHomework Assignments\n- What if you were called to help NHSTA inves8gate\nthe Toyota sudden accelera8on safety recall?\n- Most of the homework assignments will be centered\naround the ques8on: What could have been done to\nprevent the problem?\n- Your study should not be focused only on Toyota,\nbut automobiles in general.\n- More about the case study in a few slides.\n(c) June 8, 2010\nQi Van Eikema Hommes 51\n\nHomework Requirements\n- Homework is individual‐based. Collabora8on is\nencouraged, but work must be turned in by\nindividuals.\n- Acknowledge all help received.\n- Provide references to data and informa8on sources.\n(c) June 8, 2010\nQi Van Eikema Hommes 52\n\nAgenda\nWelcome and Introduc8on of Teaching Staff\nWhy are we here?\n\nWhat are Systems?\n\nWhat is Systems Engineering?\n\nWhy do we study Systems Engineering?\nCourse Schedule and Logis8cs\n\n(c) June 8, 2010\nQi Van Eikema Hommes 53\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nESD.33 Systems Engineering\nSummer 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Critical Parameter Development & Mgt.",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-33-systems-engineering-summer-2010/95297204c1d43734b72f67193f2aff71_MITESD_33SUM10_lec07.pdf",
      "content": "Critical Parameter\nDevelopment & Mgt.\nDeriving Capability Indices from \"Scratch\"\n\nDesign Capability Studies, Copyright 2006, PDSS Inc.\nAgenda\nDemonstrate the 4 simple steps for deriving a Cp\nIndex from Sample Data\nHow it impacts the 7 Checks for Criticality!\n\nMeasurable?\n\nStable?\n\nAdjustable?\n\nInteractive?\n\nSensitive?\n\nRobust?\nCapable?\n\nDesign Capability Studies, Copyright 2006, PDSS Inc.\nStep 1: Measurement of samples of\nfunctions\nMeasure the function by taking data as random,\nindependent, stable samples of a function within\nthe design...\nDuring a Design Functional Capability Study we\ngather design Functional Response data\nFunction's Distribution\nObservation\nIndividuals\nMU=20.39\nUCL=32.89\nLCL=7.887\n\nStep 2: Assign Natural Tolerance Limits\nto the Function's Distribution...\nDesign Capability Studies, Copyright 2006, PDSS Inc.\nLower\nControl\nLimit\nFunction's Distribution\nUpper\nControl\nLimit\n-3s\n+3s\nY\n99.73% of the FR's data fall within the Control Limits\n(+/- 3 Std. Devs. = Natural Tolerances of the Function)\n\nStep 3: Assign Customer-based Tolerance\nLimits to the Function's Distribution...\nDesign Capability Studies, Copyright 2006, PDSS Inc.\nLower\nSpecification\nLimit\nFunction's Distribution\nUpper\nSpecification\nLimit\n-3s\n+3s\nY\n99.9999998% of the FR's data fall within the Spec. Limits\n(+/- 6 Std. Devs. = Customer-based Tolerances of the Function)\n-6s\n+6s\nLCL\nUCL\n\nStep 4: Recognize the design latitude\nbetween the Control & Spec. Limits...\nDesign Capability Studies, Copyright 2006, PDSS Inc.\nLower\nSpecification\nLimit\nFunction's Distribution\nUpper\nSpecification\nLimit\n-3s\n+3s\nY\nEach side of the Function's distribution has 3s of latitude between\nthe Control Limits & Spec. Limits, when the mean is centered on\nthe VOC Target Value...\n-6s\n+6s\nLCL\nUCL\n\nWhat is Cp?\nDesign Capability Studies, Copyright 2006, PDSS Inc.\nCp is the ratio of....\nFunction's Distribution\nLower\nSpecification\nLimit\nUpper\nSpecification\nLimit\nY\n-6s\n+6s\n6 x σσσσ\nMean is\ncentered on the\ndesired Target.\nDesired\nTarget\n\nDesign Capability Studies, Copyright 2006, PDSS Inc.\nLSL\nUSL\nY = Target\n-6σ\n+6σ\n+3σ\n-3σ\nMeasured\nDesign Performance\nNatural\nTolerances\nMean stays on target in the\nabsence of assignable\ncauses of \"noise\"\nThis is what you develop\n& measure in the Design\nPhase...\nShort Term Capability Performance\n6σ\nLSL\nUSL\nCp\n-\n=\n\nMean shifts\nDesired\nTarget\nWhat is Cpk?\nDesign Capability Studies, Copyright 2006, PDSS Inc.\nCpk is the ratio of....\nFunction's Distribution\nFunction's Distribution\n3 x σ\n3 x σ\nMean - LSL\nUSL - Mean\n\nDesign Capability Studies, Copyright 2006, PDSS Inc.\nLong Term Capability Performance\nLSL\nUSL\nY is 1.5s off-Target\n-6σ\n+6σ\n+3σ\n-3σ\nShifted Design Performance\n1.5σ\nNatural\nTolerances\n+ & - Mean Shifts are\ncaused by assignable\ncauses of \"noise\"\nThis is what you\nintentionally create &\nmeasure in the\nOptimize Phase...\n\n-\n-\n=\n3σ\nY\nUSL\n,\n3σ\nLSL\nY\nMin\nCpk\n\nIntro to CPD&M, Copyright 2010, PDSS Inc.\nForcing Cpk = Cp: Adjustability!\nFunction Adjustment Parameters are\nFR Mean Shifters... driving k = 0!\nCp: Mean\nAdjusted\nto VOC\nTarget\nCpk : Off-Target\nPerformance due to\nUnwanted Variation\n\nIntro to CPD&M, Copyright 2010, PDSS Inc.\nMaximizing Cp:\nLinking Robustness & Adjustability!\nFAPs are CFR\nMean Shifters\nFunctional Robustness Parameters\nare FR Variance Reducers\nMean\nAdjusted\nto VOC\nTarget\nRobust\nagainst\nVariation\n\nRequired KP Mgt. Data for any form of\nCapability Assessment\nIntro to CPD&M, Copyright 2010, PDSS Inc.\nAll FRs or Functional Spec.s must have a\ncapable measurement process\ndocumented & in use\nGage R&R Study\nEach FR or Functional Spec. is placed\nunder stable SPC so the Cp can be\nroutinely quantified for Phase-by-Phase\ngrowth & Life Cycle stability\ncharacterization\nAll FRs & Functional Spec.s are Capable -\ntypically w/ target of Cp = 2 & Cpk of 1.5\nLSL\nU SL\nProc es s Capability A nalysis for C2\nUS L\nT arget\nLS L\nMean\nS am ple N\nS tDev (W ithin)\nS tDev (O verall)\nC p\nC P U\nC P L\nC pk\nC pm\nP p\nP P U\nP P L\nP pk\nP PM < LS L\nP PM > US L\nP PM T otal\nP P M < LS L\nP P M > US L\nP P M Total\nP P M < LS L\nP P M > US L\nP P M Total\n12.0000\n*\n8.0000\n9.9766\n0.447134\n0.458186\n1.49\n1.51\n1.47\n1.47\n*\n1.46\n1.47\n1.44\n1.44\n0.00\n0.00\n0.00\n4.92\n3.02\n7.94\n8.01\n5.03\n13.04\nP roc es s D ata\nPotential (W ithin) C apability\nO v erall Capability\nO bserved P erformance\nE xp. \"W ithin\" P erform anc e\nEx p. \"O verall\" P erformanc e\nW ithin\nO verall\nMisc:\nTo lera nce:\nR eported by:\nD ate of study:\nGage name :\n8.2\n8.1\n8.0\n7.9\nM ary\nJoe\nFred\nXbar Chart by Operator\nSample Mean\nMean=8.044\nUCL=8.102\nLCL=7.986\n0.2\n0.1\n0.0\nM ary\nJoe\nFred\nR Chart by O perator\nSample Range\nR=0.05667\nUCL=0.1459\nLCL=0\n8.2\n8.1\n8.0\n7.9\nPart\nOperator\nOperator*Part Interac tion\nAverage\nFred\nJ oe\nMary\nMary\nJ oe\nFred\n8.3\n8.2\n8.1\n8.0\n7.9\nOperator\nBy Operator\n8.3\n8.2\n8.1\n8.0\n7.9\nPart\nB y Part\n%Contribution\n%S tudy Var\n%Tolerance\nP art-to-P art\nReprod\nRepeat\nGage R& R\nCom ponents of Variation\nPercent\nGage R&R (ANOVA) for Thickness\nSubgroup\n-5\nIndividual Value\nMean=-0.03816\nUCL=5.917\nLCL=-5.994\nMoving Range\nR=2.239\nUCL=7.316\nLCL=0\nI and MR Chart for C2\nGage R&R\nI & MR Chart\nCapability Study\n\nY as a Function of Controlling Xs\nDesign Capability Studies, Copyright 2006, PDSS Inc.\nFor a given Y there can be numerous\ncontrolling Xs....\nThere can be 3 ways for a controlling X to influence Y:\nXi dominates the Mean... for Adjusting\nXj dominates the Standard Deviation... for Robustness\nXk co-contributes to both the Mean & σ... You pick!\nThe question CPD&M asks is \"do you know\nhow Xs affect Ys in light of the 7 Checks???\n- Which ones are out of control!?!?\n\nDesign Capability Studies, Copyright 2006, PDSS Inc.\nSummary\nYou should be able to repeat this explanation\n\nIt is important for you to be able to do this for anyone you work with.\nAn organization practicing CPD&M must understand\nCapability\n\nHow it degrades....\n\nhow it grows & matures due to intentional investment in KP\ndevelopment tasks....\n\nHow it is calculated....\n\nWhat it means in the context of CPD&M....\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nESD.33 Systems Engineering\nSummer 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Experiments: Strategy, Design, Analysis",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-33-systems-engineering-summer-2010/da4f0ab637aecd865f5e29f617ac42f8_MITESD_33SUM10_lec10.pdf",
      "content": "ESD.33 -- Systems Engineering\nExperiments:\nExperiments:\nStrategy, Desiggn, Analyysis\ngy,\n,\n+\nB\n+\nC\n-\n-\n-\nA\n+\nDan Frey\n\n-\nPlan for the Session\nPlan for the Session\nThomke -- Enlightened Experimentation\n- Statistical preliminaries\nStatistical preliminaries\n- Design of experiments\n- History\n- Fundamentals\n- Frey - A role for adaptive one factor at a time\n\nMultiple Roles of Experiments\nin Systems Engineering\n- Promote understanding\n- Calibrate our models\n- Promote innovation\n- Refine the product\n- Evaluation and test\n\n3D Printing\n3D Printing\n1 The Printer spreads a layer of powder from the feed box\n1. The Printer spreads a layer of powder from the feed box\nto cover the surface of the build piston.\n2. The Printer then prints binder solution onto the loose\npowder.\n3. When the cross-section is complete, the build piston is\nlowered slightly and a new layer of powder is spread\nlowered slightly, and a new layer of powder is spread\nover its surface.\n4. The process is repeated until the build is complete.\n5. The build piston is raised and the loose powder is\nvacuumed away, revealing the completed part.\n\n-\n3D Computer Modeling\n3D Computer Modeling\n- Easy visualization of 3D form\n- Automatically calculate physical properties\nAutomatically calculate physical properties\n- Detect interferences in assy\n- Communication!\n- Sometimes used in milestones\nSometimes used in milestones\n\nThomke's Advice\nThomke s Advice\n- Organize for rapid experimentation\n- Fail early and often but avoid mistakes\nFail early and often, but avoid mistakes\n- Anticipate and exploit early information\n- Combine new and traditional technologies\n\n-\nOrganize for Rapid\nExperimentation\n- BMW case study\nBMW case study\n- What was the enabling technology?\n- How did it affect the product?\n- What had to change about the process?\nWhat had to change about the process?\n- What is the relationship to DOE?\n\nFail Early and Often\nFail Early and Often\n- What are the practices at IDEO?\n- What are the practices at 3M?\nWhat are the practices at 3M?\n- What is the difference between a\n\"failure\" and a \"mistake\"?\n\nWhat is This Prototype For?\nWhat is This Prototype For?\nImage removed due to copyright restrictions.\nFrom Ulrich and Eppinger, Product Design and Development.\n\nWhat is this Prototype For?\nWhat is this Prototype For?\nImage removed due to copyright restrictions.\nBall supported at varying locations to\ndetermine effect on \"feel\".\nFrom Ulrich and Eppinger, Product Design and Development.\n\nAnticipate and Exploit Early\nInformation\n- Chrysler Case study\n- What was the enabling technology?\nWhat was the enabling technology?\n- How did it affect the product or process?\n- What is the practice at your companies?\n\nRelative cost of correcting an\nRelative cost of correcting an\nerror\n40-1000\nRelative Cost of Correcting an Error\ntimes\n30 70\n30-70\ntimes\n15-40\ntimes\ntimes\n3-6\ntimes\n1time\nReg.\nDesign\nCode\node\nDev. Test\nSystem\nField\nReg.\nDesign\nDev. Test\nSystem\nField\nTest\nOperation\n\nCombine New and Traditional\nTechnologies\nce\normanc\nOld AND new coordinated\nal perfo\nOld experimentation technology\nNew\nechnica\nOld experimentation technology\nTe\nEffort (elapsed time, cost)\n\nEnlightened Experimentation\nEnlightened Experimentation\n- New technologies make experiments faster and\ncheaper\n- Computer simulations\n- Rapid prototyping\n- Combinatorial chemistry\nCombinatorial chemistry\n- Thomke's theses\n- Experimentation accounts for a large portion of development\ncost and time\n- Experimentation technologies have a strong effect on\ninnovatition as wellll as refifinementt\n- Enlightened firms think about their system for experimentation\n- Enlightened firms don't forget the human factor\n\n-\nPlan for the Session\nPlan for the Session\n- Thomke -- Enlightened Experimentation\nStatistical preliminaries\nStatistical preliminaries\n- Design of experiments\n- History\n- Fundamentals\n- Frey - A role for adaptive one factor at a time\n\nSystems Engineering\nAn interdisciplinary approach and means to enable the\nli\ni\nf\nf l\nrealization of successful systems.\nDesign of Experiments\nStatistics\n- Statistical THINKING is an important part of SE\nStatistical THINKING is an important part of SE\n- This is especially true regarding experimentation\nH\nt ti ti\nl RITUALS\nb\n- However, statistical RITUALS can become\ncounterproductive in SE (and in other pursuits)\n\nGigernezer's Quiz\nSuppose you have a treatment that you suspect may alter\nperformance on a certain task\nperformance on a certain task. You compare the means of your\nYou compare the means of your\ncontrol and experimental groups (say 20 subjects in each sample).\nFurther, suppose you use a simple independent means t-test and\nyour result is significant (t = 2.7, d.f. = 18, p = 0.01). Please mark\neach of the statements below as \"true\" or \"false.\" ...\n1 Y\n1. You hhave abbsolluttelly didisproved th\nd the null h\nll hypoth\nthesiis\n2. You have found the probability of the null hypothesis being true.\n3. You have absolutely proved your experimental hypothesis (that\nth\nthere iis a difference bbetween th\nthe populatition means).\ndiff\nt\nl\n)\n4. You can deduce the probability of the experimental hypothesis\nbeing true.\n5 Y\nk\nif\nd\nid\nt\nj\nt th\nll h\nth\ni\nth\n5. You know, if you decide to reject the null hypothesis, the\nprobability that you are making the wrong decision.\n6. You have a reliable experimental finding in the sense that if,\nhypothetically the experiment were repeated a great number of\nhypothetically, the experiment were repeated a great number of\ntimes, you would obtain a significant result on 99% of occasions.\n\n\"\n\"\nQuiz Results\nQuiz Results\nThe percentages\nof partiticiipantts iin\neach group who\nendorsed one or\nendorsed one or\nmore of the six\nfalse statements\nregarding the\nmeaning of\n\"p\n0 01 \"\np = 0.01.\nGigerenzer, G., 2004,\"Mindless Statistics,\" J. of Socio-Economics 33:587-606.\nGige\nrn\nezer\n's\nQui\nz results\nof psych\nology st\nudents compared to pro\nfessors and lecturers.\nImage by MIT OpenCourseWare.\n\nt\nType III error\nType-III error\n- \"At i\nh\ni th\ni\nf\n\"At issue here is the importance of goodd\ndescriptive and exploratory statistics rather\nthan mechanical hypothesis testing with\nyes-no answers...The attempt to give an\n\"optimal\" answer to the wrong question\nhas been called \"Type-III error\". The\nstatistician John Tukey (e.g., 1969) argued\nfor a change in ppersppective...\"\nGigerenzer, G., 2004,\"Mindless Statistics,\" J. of Socio-Economics 33:587-606.\n\n-\nPlan for the Session\nPlan for the Session\n-\n-\nThomke -- Enlightened Experimentation\nStatistical preliminaries\nStatistical preliminaries\nDesign of experiments\n- History\n- Fundamentals\n- Frey - A role for adaptive one factor at a time\n\n-\n-\nDesign of Experiments\nDesign of Experiments\n- C\nd\nith\nConcerned with\n- Planning of experiments\n- Analysis of resulting data\n- Model building\nModel building\n- A highly developed technical subject\n- A subset of statistics?\n- Or is it a multi disciplinary topic\nOr is it a multi-disciplinary topic\ninvolving cognitive science and\nmanagement?\nt?\n\n\"A\ni\nt i\ni\nl\nti\nt t\nt\n\"An experiment is simply a question put to nature\n... The chief requirement is simplicity: only one\nquestion should be asked at a time \"\nquestion should be asked at a time.\nRussell, E. J., 1926, \"Field experiments: How they are made and\nwhat they are,\" Journal of the Ministry of Agriculture 32:989\n1001.\n\nt\nt\n\"To call in the statistician after the\nTo call in the statistician after the\nexperiment is done may be no more\nth\nki\nhi\nf\nthan asking him to perform a post\nmortem examination: he may be able\nto say what the experiment died of.\"\n- Fisher, R. A., Indian Statistical Congress, Sankhya,\n1938.\n\nEstimation of Factor Effects\n(ab)\n(c)\nSay the independent experimental\n(bc)\n(abc)\nerror of observations\n(b)\nerror of observations\n(a), (ab), et cetera is σε.\n(\n+\nb)\nWe define the main effect estimate Α to\nWe define the main effect estimate Α to\nbe\nB\n(ac)\n+\n-(1)\nA\n(a)\nA ≡ 1 [(abc) + (ab) + (ac) + (a) - (b) - (c) -\n-\n(bc) - (1)]\n+\nThe standard deviation of the estimate is\nThe standard deviation of the estimate is\n1 2σ\nHow does this compared to\nσ\n=\n8σ =\nA\nε\nε\n\"single question methods\"?\nsingle question methods ?\nC\n\nFractional Factorial Experiments\nFractional Factorial Experiments\n\"It will sometimes be advantageous\nIt will sometimes be advantageous\ndeliberately to sacrifice all possibility of\nobt\nbtai i\nining informatition on some points,\ni f\ni t\nthese being confidently believed to be\nunimportant ... These comparisons to be\nsacrificed will be deliberately confounded\nwith certain elements of the soil\nheterogeneity\nSome additional care\nheterogeneity... Some additional care\nshould, however, be taken...\"\nFisher, R. A., 1926, \"The Arrangement of Field Experiments,\"\nJournal of the Ministry of Agriculture of Great Britain, 33: 503-513.\n\nFractional Factorial Experiments\n+\nB\n+\nC\n-\n-\nA\n+\n-\n3 1\n23-1\nIII\nIII\n\n\"\nFractional Factorial Experiments\nFractional Factorial Experiments\nTrial\nA\nB\nC\nD\nE\nF\nG\nFG=-A\n+1\n-1\n-1\n-1\n+1\n+1\n+1\n+1\n+1\n-1 +1\n+1 -1\n-1 +1\n+1\n+1\n+1\n+1\n+1\n+1\n+1\n+1\n-1\n+1\n-1\n-1\n-1\n-1\n-1\n-1\n-1\n+1\n-1\n+1\n+1\n-1\n+1\n+1\n-1 +1\n-1\n+1\n-1 +1\n-1\n+1\n-1 +1\n+1\n-1 +1\n-1\n-1\n+1\n+1\n+1\n+1\n-1\n+1\n+1\n+1\n-1\n-1\n+1\n-1\n+1\n+1\n-1\n+1\n-1\n-1 +1\n-1\n27 4 D\ni\n(\n\"orthogonall array\")\")\n27-4 Design (akka\nth\nEvery factor is at each level an equal number of times (balance).\nHigh replication numbers provide precision in effect estimation.\nResolution III\nResolution III.\n\n-\nPlan for the Session\nPlan for the Session\n- Thomke -- Enlightened Experimentation\n- Statistical preliminaries\nStatistical preliminaries\n- Design of experiments\n- History\n- Fundamentals\nFrey - A role for adaptive one factor at a time\n\nMy Observations of Industry\nMy Observations of Industry\n- Farming equipment company has reliability\nFarming equipment company has reliability\nproblems\n- Large blocks of robustness experiments had been\nLarge blocks of robustness experiments had been\nplanned at outset of the design work\n- M\nth\n50%\nt fi i h\nMore than 50% were not finishedd\n- Reasons given\n- Unforeseen changes\n- Resource pressure\n- Satisficing\n\"Well, in the third experiment, we found a solution that met all\nour needs, so we cancelled the rest of the experiments and\nmoved on to other tasks...\"\n\nt\nMajority View on \"One at a Time\"\nMajority View on One at a Time\nOne way of thinking of the great advances\nof the science of experimentation in this\ncentury iis as h\nthe fifinal d\nl demiise of h\nf the \"\"one\nfactor at a time\" method, although it\nshould be said that there are still\nshould be said that there are still\norganizations which have never heard of\nfactorial experimentation and use up many\nfactorial experimentation and use up many\nman hours wandering a crooked path.\nLogothetis, N., and Wynn, H.P., 1994, Quality Through Design:\nE\ni\nl D\ni\nOff li\nQ\nli\nC\nl\nd T\nhi'\nExperimental Design, Off-line Quality Control and Taguchi's\nContributions, Clarendon Press, Oxford.\n\nMinority Views on \"One at a Time\"\nMinority Views on One at a Time\n\"...the factorial design has certain deficiencies ... It devotes observations to\nexploring regions that may be of no interest\nThese deficiencies\nexploring regions that may be of no interest...These deficiencies ...\nsuggest that an efficient design for the present purpose ought to be\nsequential; that is, ought to adjust the experimental program at each stage\nin light of the results of pprior stagges.\"\nFriedman, Milton, and L. J. Savage, 1947, \"Planning\nExperiments Seeking Maxima\", in Techniques of Statistical\nAnalysis, pp. 365-372.\nAnalysis, pp. 365 372.\n\"Some scientists do their experimental work in single steps. They hope to learn\nsomething from each run ... they see and react to data more rapidly ...If he has\nin fact found out a good deal by his methods, it must be true that the effects are\nat least three or four times his average random error per trial \"\nat least three or four times his average random error per trial.\nCuthbert Daniel, 1973, \"One-at-a-Time Plans\", Journal of the\nAmerican Statistical Association, vol. 68, no. 342, pp. 353-360.\n\nt t\nt\nAd\nAdaptitive OFAT Experiimentation\nOFAT E\ni\nDo an experiment\nCh\nf\nDo an experiment\nCh\nf\nChange one factor\nChange one factor\nIf there is an improvement,\n\nretain the change\n\nIf the response gets worse, go\n\n+\nback to the previous state\no th e pre vious st ae\nk\nt\nB\nStop after you've changed\nStop after you ve changed\n\n-\n-\nA\n+\nevery factor\n\n+\nbac\n+\nbac\nC\n- C\n-\nFrey, D. D., F. Engelhardt, and E. Greitzer, 2003, \"A Role for One Factor at a Time\nExperimentation in Parameter Design\", Research in Engineering Design 14(2): 65-74.\n\nEmpirical Evaluation of\nAdaptive OFAT Experimentation\nMeta-anal\ni\nlysis of 66 responses ffrom\n-\nf 66\npublished,, full factorial data sets\np\n- When experimental error is <25% of the\ncombined factor effects OR interactions\ncombined factor effects OR interactions\nare >25% of the combined factor effects,\nadaptive OFAT provides more\nadaptive OFAT provides more\nimprovement on average than fractional\nfactorial DOE\nfactorial DOE.\nFrey, D. D., F. Engelhardt, and E. Greitzer, 2003, \"A Role for One Factor at a Time\nExperimentation in Parameter Design\", Research in Engineering Design 14(2): 65-74.\n\nDetailed Results\n\nFE\nMS\n4.0\n=\nσ\nFE\nMS\n1.0\n=\nσ\nOFAT/FF\nOFAT/FF\nGray if OFAT>FF\nStrength of Experimental Error\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nMild\n100/99 99/98\n98/98\n96/96\n94/94\n89/92\n86/88\n81/86\n77/82\n73/79\n69/75\nModerate\n96/90\n95/90\n93/89\n90/88\n86/86\n83/84\n80/81\n76/81\n72/77\n69/74\n64/70\nStrong\n86/67\n85/64\n82/62\n79/63\n77/63\n72/64\n71/63\n67/61\n64/58\n62/55\n56/50\nStrong\n86/67\n85/64\n82/62\n79/63\n77/63\n72/64\n71/63\n67/61\n64/58\n62/55\n56/50\nDominant\n80/39\n79/36\n77/34\n75/37\n72/37\n70/35\n69/35\n64/34\n63/31\n61/35\n59/35\n\n=\n=\nA M th\nti\nl M\nl\nti\nOFAT\nA Mathematical Moddel of Ad\nf Adaptive OFAT\ninitial observation\nO = y(~ x ,~ x ,... ~ x )\nn\n~ ~\n~\nobservation with first\nO1 = y(-x1, x 2,...xn )\nfactor toggled\n∗\n~\nfirst factor set\nx1 = x1 sign\nsign{O0 - O1}\nfirst factor set\nfor i = 2...n\n∗\n∗\nOi = y(x\n1,... x\ni -1,- ~ xi , ~ xi+1,... ~ xn )\nrepeat for all remaining\nrepeat for all remaining\nfactors\n∗\n~\nxi = xisign{max(O0,O1,...Oi-1 )- Oi }\nprocess ends after n+1 observations with\nE[y(x ∗ , x2\n∗ ,...xn\n∗)]\nFrey, D. D., and H. Wang, 2006, \"Adaptive One-Factor-at-a-Time\nExperimentation and Expected Value of Improvement\", Technometrics\n48(3):418-31.\n\nA Mathematical Model of a\nPopulation of Engineering Systems\nn\nn-1\nn\ny(x1, x2,...xn ) = ∑βi xi +∑∑βijxix j +εk\ni 1\n=\ni=1 j=i+1\nsystem\nresponse\nε k ~ Ν(0,σε\n2 )\nβ ~ Ν(0,σ\n2 )\nβ ~ Ν(0,σ\n2 )\nexperimental error\ni\nME\nij\nINT\nmain effects\ntwo-factor interactions\nthe largest response within the space of discrete,\ny\n≡\nymax ≡\ncoded, two-level factors\nxi ∈{-1,+1}\nModel adapted from Chipman, H., M. Hamada, and C. F. J. Wu, 2001, \"A Bayesian Variable\nSelection Approach for Analyzing Designed Experiments with Complex Aliasing\",\nTechnometrics 39(4)372-381.\n\nProbability of Exploiting an Effect\nProbability of Exploiting an Effect\n- The ith main effect is said to be \"exploited\" if\n- The two-factor interaction between the ith and\n* >\ni\nix\nβ\njth factors is said to be \"exploited\" if\n>\n∗\n∗\nj\ni\nij\nx\nx\nβ\n- The probabilities and conditional probabilities\nof exploiting effects provide insight into the\nof exploiting effects provide insight into the\nmechanisms by which a method provides\nimprovements\nimprovements\n\nThe Expected Value of the Response After\nThe Expected Value of the Response After\nthe Second Step\n[\n]\n[\n]\n[\n]\n*\n*\n*\n*\n*\n*\n~\n~\nβ\nβ\nβ[\n]\n[\n]\n[\n]\n*\n*\n*\n*\n*\n*\n)\n(\n))\n~\n,\n,\n~\n,\n,\n(\n(\nx\nx\nE\nx\nE\nn\nx\nE\nx\nx\nx\nx\ny\nE\nj\nn\nβ\nβ\nβ\n+\n-\n+\n=\n...\n⎥\n⎤\n⎢\n⎡\n[\n]\n⎥\n⎥\n⎥\n⎥\n⎦\n⎢\n⎢\n⎢\n⎢\n⎣\n+\n-\n+\n=\n∗\n∗\n)1\n(\nε\nσ\nσ\nσ\nσ\nπ\nβ\nINT\nME\nINT\nn\nx\nx\nE\nmain\neffects\ntwo-factor interactions\n[\n]\n[\n]\nj\nj\nj\nj\nx\nx\nE\nx\nx\nE\n~\n~\n∗\n∗\n=\nβ\nβ\n0.8\n\nLegend\nSimulation\n\nTheorem\n1.0\n=\nME\nσ\nσ ε\n×\nTheorem 3\n[\n]\n∗\n1x\nE β\n[\n]\n∗\n=\n2x\nE β\n0.6\nP\n=\nME\nσ\nσ ε\n=\nME\nσ\nσ ε\nSimulation\n\nTheorem\nSimulation\n\nTheorem\n+\nTheorem 3\nTheorem 3\n[\n]\n∗\n∗\nx\nx\nE β\n0.2\n0.4\n0.25\n0.5\n0.75\nME\nINT σ\nσ\n\n⎦\n⎣\n⎥\n⎢\n.0\nσ\nσ\nTheorem\nTheorem\nTheorem\nTheorem\nTheorem\nTheorem\nProbability of Exploiting the First Interaction\n∗\n∗\nPr(β x x > 0 β12 > βij )>\nPr(β12 x1 x2 > 0)= 1 + 1 tan\nσ\n⎛n ⎞\n-x1\n+\n-x2\n2 π\n∗\n∗\n-1\nINT\n⎡\n⎛ 1\nx ⎞⎤\n⎜⎝2 ⎟⎠\n-1\n2σ INT\n2⎛⎜σ ME\n2 +(n-2)σ INT\n2 +1σε\n2 ⎞⎟\ninf inf⎢erf ⎜⎜\n1 ⎟⎟⎥\ne\n⎝\n⎠\nσ\n+ (n -2)σ\n+\nσ\nn\n2 σ INT ⎠⎦\nσ ME + (n 2)σ INT + σ ε\n1 ⎛⎞\n⎣\n⎝\n⎜⎟∫∫\ndx2dx1\nπ ⎝2⎠0 -x2\nσ INT σ ME + (n -2)σ INT + σ ε\n0.9\nLegend\n1.0\n=\nME\nσ\nσε\n×\nTheorem 5\n0.9\nLegend\nSimulation\n=\nME\nσ\nσ\nSimulation\n=\nME\nσ\nσε\n=\nME\nσ\nσε\nME\nε\nSimulation\nSimulation\n+\n×\nTheorem 5\nTheorem 5\nε\n1.0\n=\nME\nσ\nσε\nSimulation\n×\nTheorem 6\nTheorem 6\n0.8\n0.8\n=\nME\nσ\nσε\nSimulation\n+\nTheorem 6\n0.6\n0.7\n0.6\n0.7\n0.5 0\n0.25\n0.5\n0.75\n0.5 0\n0.25\n0.5\n0.75\nσINT σME\nσ INT σME\n\nAnd it Continues\nAnd it Continues\nmain\neffects\ntwo-factor interactions\nn-k\n0 8\n\nLegend\nEqn 20\nk\n0.6\n0.8\nSimulation\n.\n=\nME\nσ\nσ\nε\n5.0\n=\nME\nINT σ\nσ\nEqn. 20\nk\n⎟⎟\n⎠\n⎞\n⎜⎜\n⎝\n⎛\n-\nk\nn\n⎟⎟⎞\n⎜⎜⎛\n-1\nk\n0.2\n0.4\n⎟⎟\n⎠\n⎜⎜\n⎝\nk\n(\n)\n(\n)\nWe can pro e that the probabilit of e ploiting interactions is s stained\n(\n)\n(\n)\n12 1\nPr\nPr\nij\ni\nj\nx x\nx x\nβ\nβ\n∗\n∗\n∗\n∗\n>\n≥\n>\nWe can prove that the probability of exploiting interactions is sustained.\nFurther we can now prove exploitation probability is a function of j only\nand increases monotonically.\n\nFinal Outcome\nFinal Outcome\n\nLegend\nTheorem\nEqn 21\n0.8\nSimulation\n=\nME\nσ\nσ ε\n=\nME\nσ\nσ ε\n\nTheorem\n1.0\n=\nME\nσ\nσ ε\nSimulation\n\nTheorem\nSimulation\n\nTheorem\n+\n×\nEqn 21\nEqn 21\nEqn 21\n0.8\n\nLegend\nSimulation\n=\nME\nσ\nσ\n\nTheorem\n1.0\n=\nME\nσ\nσε\n\nTheorem\n×\nEqn. 20\nEqn.20\n0.4\n0.6\nSimulation\n+\n0.4\n0.6\nME\nσ\nσε\n=\nME\nσ\nσε\nSimulation\nSimulation\n\nTheorem\n+\nEqn.20\n0.2\n0.2\nME\nINT σ\nσ\n0.2\n0.4\n0.6\n0.8\nME\nINT σ\nσ\n0.2\n0.4\n0.6\n0.8\nAdaptive OFAT\nResolution III Design\n\nFinal Outcome\nFinal Outcome\n0.8\n0.6\n0.4\n0.2\nAdaptive OFAT\n~0.25\n0.2\n0.4\n0.6\n0.8\nME\nINT σ\nσ\nResolution III Design\nσ\nσ\n=\nME\nσ\nσε\n\nMore Observations of Industry\nMore Observations of Industry\n- Time for design (concept to market) is going down\n- Fewer physical experiments are being conducted\nphysical experiments are being conducted\nFewer\n- Greater reliance on computation / CAE\n- Poor answers in computer modeling are common\nPoor answers in computer modeling are common\n- Right model → Inaccurate answer\n- Right model →No answer whatsoever\nRight model → No answer whatsoever\n- Not-so right model → Inaccurate answer\n- Unmodeled effects\n- Bugs in coding the model\n\nt\nt\nHuman Subjects Experiment\nHuman Subjects Experiment\n- Hypothhesiis: EEngiineers usiing a flflawedds iimullatiion\nare more likely to detect the flaw while using\nOFAT than while using a more complex design\nOFAT than while using a more complex design.\n- Method: Between-subjects experiment with\nh\nbj\n(\n)\nf\ni\nhuman subjectts (engiineers) performing\nparameter design with OFAT vs. designed\nexperiment\nexperiment.\n\nResults of Human Subjects Experiment\nResults of Human Subjects Experiment\n- Pilot with N = 8\n- Study with N = 55 (1 withdrawal)\n- External validity high\nExternal validity high\n- 50 full time engineers and 5 engineering students\n-\ni\nd f\nt\n40+\nexperience ranged from 6 mo. to 40+ yr.\n- Outcome measured by subject debriefing at end\nMethod\nMethod\nDetected\nDetected\nNot detected\nNot detected\nDetection Rate (95% CI)\nDetection Rate (95% CI)\nOFAT\n(0.3195,0.7133)\nPBL8\nPBL8\n(0 0009 0 1897)\n(0.0009,0.1897)\n\nConclusions\nConclusions\n- Experimentation is a critical part of SE\n- DOE is a useful set of tools for efficient\nDOE is a useful set of tools for efficient\nexploration and model building\n- A new model and theorems show that\nA new model and theorems show that\n- Adaptive OFAT can be more effective if the\ngoal is impprovement in system pperformance\ng\ny\nrather than model building\n- Adaptive OFAT exploits interactions\n- Adaptive OFAT is more effective in helping\nhuman experimenters perceive errors in\ncomputer siimullatitions\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nESD.33 Systems Engineering\nSummer 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Innovation in Systems  Engineering",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-33-systems-engineering-summer-2010/688d747edcfaea3428fa599b88c5a30d_MITESD_33SUM10_lec05.pdf",
      "content": "ESD.33 Systems Engineering\nLecture 5\nInnova'on in Systems\nEngineering\nQi Van Eikema Hommes\n\nCustomer-Centered Products\nCreating Successful Products through Smart\nRequirements Management.\nIvy F. Hooks and Kristin A. Farry\nSample Chapter Titles:\n- Chapter 2: Why Johnny Cannot Write Requirements?\n- Chapter 5: One Day in the Life of a Product\n- Chapter 7: Be Careful What You Ask For\n- Chapter 10: But Will It Work?\n- Chapter 15: Deaths, Taxes, and Requirements Changes\n(c) June 22, 2010\nQi Van Eikema Hommes\n\nLecture 7 CPM and DFSS\nLecture 2\nSystems Engineering\nAs Human Ac'vity\nLecture 4\nStakeholder Analysis and\nRequirements Defini'on\nLecture 5 innova'on in\nSystems Engineering\nLecture 6 Axioma'c\nDesign and DM‐DSM\nMethod\nLecture 8\nTrade Space Explora'on\nConcept Selec'on\nLecture 13\nDesign Verifica'on\nand\nValida'on, Lifecycle\nManagement\nCourse Layout\nQi Van Eikema Hommes\n(c) June 22, 2010\n✔\n✔\n\nLecture Outline\n\nIndividuals' crea'vity in systems design\nKnow your users' needs\nThe characteris'cs of a crea've person\nStructured Innova'on in Systems Design--TRIZ\n\nInnova'on in large systems\nManaging crea'vity\nInnova'on in the context of the technical\nsystems\nArchitectural Innova'on\nThe route of innova'on management\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nKnow Your User (Stakeholder) Needs\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nClass Discussion Ques'ons\n- Do we always know what customers really\nwant?\n- Do we always get to start with a complete set\nof requirements?\n- Are systems always used as they are originally\nintended?\n(c) June 22, 2010\nQi Van Eikema Hommes\n\nLecture Outline\n\nIndividuals' crea'vity in systems design\n\nKnow your users' needs\nThe characteris'cs of a crea've person\nStructured Innova'on in Systems Design--TRIZ\n\nInnova'on in large systems\nManaging crea'vity\nInnova'on in the context of the technical\nsystems\nArchitectural Innova'on\nThe route of innova'on management\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nCharacteris'cs of A Crea've Person\nTeresa Amabile, HBR, 1998\n- Ability to put exis'ng ideas together in new combina'ons.\n- Naturally tries out solu'on that departs from the status quo.\n- Feels comfortable disagreeing with others.\n- Habitually combines knowledge from seemingly disparate\nfields.\n- Perseveres through long dry spells of tedious\nexperimenta'on.\n- I have not failed. I've just found 10,000 ways that won't\nwork. (Thomas Alva Edison)\n- Have intrinsic mo'va'on--passion and interest.\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nCharacteris'cs of A Crea've Person\nSuh, Nam, The Principles of Design, 1991\n- Risk Taker\n- Good memory\n- Good store of knowledge\n- Interpolator / extrapolator\n- Ability to reduce a complex array to a set\n(aggrega'on)\n- Mul'‐disciplinary background\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nIs crea'vity something that one\nwas born with?\nCan One Learn to be Crea've?\nHow did you learn to walk?\nHow did you learn to speak?\nHow did you learn to read?\nHow did you learn to do math?\n(c) June 22, 2010\nQi Van Eikema Hommes\n\nLecture Outline\n\nIndividuals' crea'vity in systems design\n\nKnow your users' needs\n\nThe characteris'cs of a crea've person\nStructured Innova'on in Systems Design--TRIZ\n\nInnova'on in large systems\nManaging crea'vity\nInnova'on in the context of the technical\nsystems\nArchitectural Innova'on\nThe route of innova'on management\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nWhat did Altshuller Believe?\n\"You can wait a hundred\nyears for\nenlightenment, or you\ncan solve the problem\nin 15 minutes with\nthese principles.\"\nQi Van Eikema Hommes\n\n(c) June 22, 2010\n\nGenrikh Altschuller: Father of TRIZ\n- 1926 - Born in Tashkent, USSR\n- 1940 - Invented underwater breathing device at age 14.\n- 1946 - As a Navy patent office, iden'fied \"paqerns of\ninven'on\", laying the founda'on for TRIZ.\n- 1948 - Wrote a leqer to Stalin cri'cal of innova'on in\nthe USSR.\n- 1950 - Sentenced to 25 years of prison in Siberia\n- 1954 - Released from the prison arer Stalin's death.\nProduced his first publica'on on TRIZ.\n- 1989 - first TRIZ Associa'on in Russia\n- 1999 - first TRIZ Ins'tute in US. Altshuller passed away.\nAtshuller, 40 Principles Extended Edition, 2005\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nTRIZ\n- TRIZ--Russian Acronym for Theory of\nInven've Problem Solving.\n- Altschuller reviewed 200,000 patents\n- Algorithm steps for problem solving\n- Database structured means for effec've\nconflict resolu'on\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nTechnical Systems\n- Technical Systems--Everything that performs\na func'on is a technical system.\n- When solving a technical problem, always\nconsider interac'on of the exis'ng technical\nsystem with those systems above and below\nit.\n- TRIZ originated mostly from Mechanical\nSystems, but may be applied to other systems\nas well.\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nFunction 2\n\nConventional thinking: Additional function = additional\nsystem\nTRIZ thinking: Adding function without increasing\nresources (or even use no resource).\n(c) June 22, 2010\nQi Van Eikema Hommes\nFunction 1\nFunction 3\nSystem 1\nSystem 2\nSystem 3\nSystem 1\n\nThe Law of Ideality\n- Any technical system throughout its life'me, tends to become\nmore reliable, simple, and effec've--more ideal.\n- The further a system is away from its ideal state, the more\ncomplex the system will be. To return to ideal state, one may:\n- Increase amount of func'on of the system\n- Transfer as many func'on as possible to that working\nelement which produces the systems' final ac'on.\n- Transfer some func'ons of the system to a super system or\nto the outside environment\n- U'lize internal and external resources that already exist\nand are available.\nQi Van Eikema Hommes\n\n(c) June 22, 2010\n\nIdeality Example\nESD.33 2007 Dan Frey\nThe Russians launched an unmanned Lunar Probe\nto the moon's surface with the inten'on to\ntransmit TV pictures to the Earth. A projector\nusing a light bulb was designed to illuminate the\nlunar surface ahead of the vehicle. However,\nexis'ng light bulbs would not survive the impact\nof landing on the Moon surface.\nEven the most durable bulbs would crack at the joint\nbetween the glass and the screw base during tests.\n(c) June 22, 2010\nQi Van Eikema Hommes\nCourtesy of Daniel Frey. Used with permission.Light bulb.\nImage by MIT OpenCourseWare.\n\nSolu'on\nESD.33 2007 Dan Frey\n(c) June 22, 2010\n\nQi Van Eikema Hommes\n\nCourtesy of Daniel Frey. Used with permission.Lightbulb without casing.\nImage by MIT OpenCourseWare.\n\nIdeality Example\nESD.33 2007 Dan Frey\nTo study the effects of acids on metal alloys,\nspecimens are placed into a herme'cally sealed\nchamber filled with acid. The acid reacts not only\nwith the specimen but also the walls, which\nnecessitates a glass‐coa'ng to protect the walls.\nThe glass coa'ng cracks and has to be reapplied\nrepeatedly for some tests.\nProtective coating\nAcid\nSpecimens\nSealed chamber\n(c) June 22, 2010\nQi Van Eikema Hommes\nCourtesy of Daniel Frey. Used with permission.\n\nSolu'on\nESD.33 2007 Dan Frey\nTransition to an Ideal\nSolution: Chamber is absent\nSpecimen\nAcid\nSpecimen\nAcid\nIdeal Solution:\nSpecimen-Chamber\n(c) June 22, 2010\nQi Van Eikema Hommes\nCourtesy of Daniel Frey. Used with permission.\n\nContradic'on\n- Contradic'on oren\noccurs when we try to\nimprove one\ncharacteris'c, or\nparameter, of a technical\nsystem, and cause\nanother characteris'c or\nparameter of the system\nto deteriorate.\nQi Van Eikema Hommes\nhttp://www.niwotridge.com/images/BLOGImages/SpiderDiagram.jpg\n(c) June 22, 2010\nSpide\nrweb model\nfor contrad\nicti\non.\nImage by MIT OpenCourseWare.\n\nTRIZ Thinking towards\nContradic'ons\n- Conven'onal thinking--find a compromising\nsolu'on.\n- TRIZ thinking--Overcoming technical\ncontradic'ons without compromise.\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nThe Three Steps\n1. Analyze the technical system\na. Determine the elements of the technical system\nb. Iden'fy the origin of the problem\nc. Iden'fy the characteris'cs that need to be\nimproved.\n2. State a technical contradic'on\na. Which characteris'c needs to be improved?\nb. Which characteris'c will deteriorate as a result?\n3. Resolve the technical Contradic'on using the\nTRIZ Principles\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nThe 39 Technical Characteris'cs\nQi Van Eikema Hommes\n1 Weight of a mobile object\n21 Power\n2 Weight of a stationary object\n22 Loss of energy\n3 Length of a mobile object\n23 Loss of substance\n4 Length of a stationary object\n24 Loss of an information\n5 Area of a mobile object\n25 Loss of time\n6 Area of a stationary object\n26 Amount of substance\n7 Volume of a mobile object\n27 Reliability\n8 Volume of a stationary object\n28 Accuracy of measurement\n9 Speed\n29 Accuracy of manufacturing\n10 Force\n30 Harmful factors acting on an object from outside\n11 Tension/Pressure\n31 Harmful factors developed by an object\n12 Shape\n32 Manufacturability\n13 Statility of composition\n33 Convenience of use\n14 Strength\n34 Repairability\n15 Time of action of a moving object\n35 Adaptability\n16 Time of action of a stationary object\n36 Complexity of a device\n17 Temperature\n37 Complexity of control\n18 Brightness\n38 Level of automoation\n19 Energy spent by a moving object\n39 Capacity/Productivity\n20 Energy spent by a stationary object\n(c) June 22, 2010\n\nThe 40 Principles\n- TRIZ Principles--tools used to overcome\ntechnical contradic'ons.\n- They are generic sugges'ons for performing\nan ac'on to, or within, a technical system.\n- They are Altshuller's view of the guiding\nprinciples of technical inven'on, arer\nreviewing 200,000 patents.\nQi Van Eikema Hommes\n\n(c) June 22, 2010\n\nThe 40 Principles\n1 Segmentation\n21 Rushing through\n2 Extraction\n22 Covert harm into benefit\n3 Local quality\n23 Feedback\n4 Asymmetry\n24 Mediator\n5 Consolidation\n25 Self Service\n6 Universality\n26 Copying\n7 Nesting\n27 Dispose\n8 Counterweight\n28 Replacement of mechanical system\n9 Prior counteraction\n29 Pneumatic or hydraulic construction\n10 Prior action\n30 Flexible films or thin membranes\n11 Cushion in advance\n31 Porous materials\n12 Equipotentiality\n32 Changing the color\n13 Do it in reverse\n33 Homogeneity\n14 Spheriodality\n34 Rejecting and Regernating parts\n15 Dynamicity\n35 Transformation properties\n16 Partial or excessive action\n36 Phase transition\n17 Transtion into a new dimension\n37 Thermal Expansion\n18 Mechanical vibration\n38 Accelerated oxidation\n19 Periodic action\n39 Inert environment\n20 Continuity of useful action\n40 Composite materials\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nVise\nPart\nExample Problem\nESD.33 2007 Dan Frey\nQi Van Eikema Hommes\n(c) June 22, 2010\nCourtesy of Daniel Frey. Used with permission.\n\nClass Exercise\n- What are the system characteris'cs that need\nto be improved?\n- Where is the technical contradic'on?\n- What is your solu'on?\n- Form groups of 3 and discuss.\n- Distance students may form groups on their\nown or think through this on their own.\nQi Van Eikema Hommes\n\n(c) June 22, 2010\n\nESD.33 2007 Dan Frey\n(c) June 22, 2010\nQi Van Eikema Hommes\nCourtesy of Daniel Frey. Used with permission.\n\nClass Discussion:\nYour thoughts on TRIZ\n\nFor More Informa'on on TRIZ\n(c) June 22, 2010\nQi Van Eikema Hommes\n2‐day Course\n$750 per person\nCourtesy of Technical Innovation Center. Used with permission.\n\nCrea'vity\nThe Produc'vity Dilemma\nGraph is inspired by Tech Strategy OCW\nQi Van Eikema Hommes\nGoal:\nUnderstand the\nWorld\nGoal: Make the\nWidget Work\nGoal: PresAge,\nfun, the social\ngood\nGoal: Make\n$$\nFirms\nInspired by Tech Strategy OCW\n(c) June 22, 2010\n\nLecture Outline\n\nIndividuals' crea'vity in systems design\n\nKnow your users' needs\n\nThe characteris'cs of a crea've person\n\nStructured Innova'on in Systems Design--TRIZ\n\nInnova'on in large systems\nManaging crea'vity\nInnova'on in the context of the technical\nsystems\nArchitectural Innova'on\nThe route of innova'on management\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nThree Components of Crea'vity for Every Individual\nAmabile, HBR, 1998\nQi Van Eikema Hommes\n(c) June 22, 2010\nThe three\ncompone\nnts of\ncreativit\ny.\nImage by MIT OpenCourseWare.\n\nSix Managerial Prac'ces that Affect\nCrea'vity\n1. Challenge\n2. Freedom\n3. Resources\n4. Work‐group Features\n5. Supervisory Encouragement\n6. Organiza'onal Support\nQi Van Eikema Hommes\n\n(c) June 22, 2010\n\nPrac'ce 1: Challenge\n- Why is it important to give challenging\nassignments to the employees?\n- Do you think there are right and wrong\nchallenges?\n- What does a manager need to do in order to\nprovide the right challenge?\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nPrac'ce 2: Freedom\n- What does mean to give employees freedom\nin their assignments? What are the benefits?\n- As a manager, what can you do to ensure the\nsuccess of this approach?\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nPrac'ce 3: Resources\n- Does providing a lot of resources help improve\ncrea'vity?\n- What does too liqle resource do?\n- Shall you s'll assign resources if the outcome\nof a project is uncertain?\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nPrac'ce 4: Work Group Features\n- Does it help put employees with similar\nbackgrounds and similar interests in the same\nassignment?\n- What are the responsibili'es of managers in\nforming the right group?\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nPrac'ce 5: Supervisory\nEncouragement\n- Is a project successful only when the outcome\nis posi've?\n- As a manager:\n- How to sustain the crea've passion?\n- How do you react to new ideas?\n- Are failed ideas bad ideas?\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nPrac'ce 6: Organiza'onal Support\n- Put in place appropriate systems or\nprocedures and emphasize values that make it\nclear that crea've efforts are a top priority.\n- Properly reward crea'vity\n- Encourage exchange of ideas and collabora'on\n- Intrinsic mo'va'on increases when people are\naware that those around them are excited by their\njobs.\nQi Van Eikema Hommes\n\n(c) June 22, 2010\n\nLecture Outline\n\nCrea'vity in Systems Design\n\nThe characteris'cs of a crea've person\n\nStructured Innova'on in Systems Design\nKnow your users' needs\nTRIZ\n\nInnova'on in Systems design requires more than crea'vity\n\nManaging crea'vity\n\nInnova'on in the context of the technical systems\n\nArchitectural Innova'on\n\nThe route of innova'on management\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nThinking about Innova'on in the Systems\nContext\nQi Van Eikema Hommes\nHenderson and Clark, HBR, 1998\n(c) June 22, 2010\nArchitectur\nal Innovat\nion: The\nReconfi\nguratio\nn of Exist\ning Pro\nduct Techn\nologies and t\nhe Failure\nof Establ\nished Firm\ns.\nImage by MIT OpenCourseWare.\n\nCeiling Fan Example\nQi Van Eikema Hommes\n\n(c) June 22, 2010 Simple ceiling fan.\nImage by MIT OpenCourseWare.\n\nRadical Innova'on\nQi Van Eikema Hommes\nCore concept and architecture are both overturned.\nEstablishes a new dominant design.\n(c) June 22, 2010 Air-conditioning unit.\nImage by MIT OpenCourseWare.\n\nIncremental Innova'on\nQi Van Eikema Hommes\nCore concept reinforced, and architecture unchanged.\nImprovements occurs in individual components.\n.\n(c) June 22, 2010 Improvement in basic ceiling fan design.\nImage by MIT OpenCourseWare.\n\nModular Innova'on\nQi Van Eikema Hommes\nCore concept overturned, but architecture unchanged.\n.\n(c) June 22, 2010 Modular innovation in ceiling fan design.\nImage by MIT OpenCourseWare.\n\nArchitectural Innova'on\nQi Van Eikema Hommes\n.\nCore concept reinforced, but architecture changed.\n(c) June 22, 2010 Architectural innovation in ceiling fans.\nImage by MIT OpenCourseWare.\n\nQi Van Eikema Hommes\n(c) June 22, 2010\nImages by MIT OpenCourseWare.\nIncremental\nInnovation\nUnchanged\nChanged\nModular\nInnovation\nRadical\nInnovation\nArchitectural\nInnovation\nReinforced\nOverturned\nCore Concepts\nLinkages between Core\nConcepts and ComponentsArchitectural innovation in ceiling fans.Modular innovation in ceiling fan design.Improvement in basic ceiling fan design.Air-conditioning unit.\n\nArchitectural Innova'on\n- Successful product development requires:\n- Component knowledge\n- Architectural knowledge\n- We need to be aware of innova'on that use\nmany exis'ng core design concepts in a new\narchitecture and that therefore have a more\nsignificant impact on the rela'onships\nbetween components than on the\ntechnologies of the components themselves.\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nDominant Design\n- A set of core design concepts\n- A single architecture of the product\n- Examples--class discussion?\n- Automobiles\nQi Van Eikema Hommes\n\n(c) June 22, 2010\n\nImplica'on of Dominant Design\n- Progress is made on the improvements of\ncomponents within the framework of a stable\narchitecture.\n- Single stable architecture shapes:\n- An organiza'on's communica'on channel\n- Informa'on filters\n- Problem solving strategies\n- Established firms can work efficiently based on its\nknowledge of the dominant design and stable\narchitecture.\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nProblems Created by Architecture\nInnova'on\n- Hard to iden'fy the innova'on has\narchitectural implica'on, because the core\nconcept seems to be the same.\n- Established organiza'ons have challenges to\nchange its old way to communica'on and\nlearning.\n- New entrants with smaller organiza'on find it\neasier to build the organiza'on knowledge\naround the new architecture.\nQi Van Eikema Hommes\n\n(c) June 22, 2010\n\nSteps of Lithographic Process\nQi Van Eikema Hommes\nHenderson and Clark, 1998\n(c) June 22, 2010\nOverview of step\ns in\nthe\nlithog\nraphi\nc process.\nImage by MIT OpenCourseWare.\n\nAlignment Technology\nQi Van Eikema Hommes\nHenderson and Clark, 1998\n(c) June 22, 2010\nTable summarizing architectural innovation in photolithographic alignment techn\nology.\nImage by MIT OpenCourseWare.\n\nLeading Manufacturers\nQi Van Eikema Hommes\nHenderson and Clark, 1998\n(c) June 22, 2010\nTable of the leading manufacturers of photolithographic alignment equipment.\nImage by MIT OpenCourseWare.\n\nLecture Outline\n\nCrea'vity in Systems Design\n\nThe characteris'cs of a crea've person\n\nStructured Innova'on in Systems Design\nKnow your users' needs\nTRIZ\n\nInnova'on in Systems design requires more than crea'vity\n\nManaging crea'vity\n\nInnova'on in the context of the technical systems\n\nArchitectural Innova'on\n\nThe route of innova'on management\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nFour Criteria of the Value Proposi'on of an\nInnova'on\nQi Van Eikema Hommes\nManiak, Midler, and Lenfle, 2010\n- Customer Value\n- Maturity\n- Integrability\n- Profit\n(c) June 22, 2010\nCourtesy of Remi Maniak, Christophe Midler, and Sylvain Lenfle. Used with permission.\n\nInterplay between Innova'on and Development\nQi Van Eikema Hommes\n\nManiak, Midler, and Lenfle, 2010\n(c) June 22, 2010\nCourtesy of Remi Maniak, Christophe Midler, and Sylvain Lenfle. Used with permission.\n\nLecture Outline\n\nCrea'vity in Systems Design\n\nThe characteris'cs of a crea've person\n\nStructured Innova'on in Systems Design\nKnow your users' needs\nTRIZ\n\nInnova'on in Systems design requires more than crea'vity\n\nManaging crea'vity\n\nInnova'on in the context of the technical systems\n\nArchitectural Innova'on\n\nThe route of innova'on management\nQi Van Eikema Hommes\n(c) June 22, 2010\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nESD.33 Systems Engineering\nSummer 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Operating Operating Windows Windows for Robust Concept Design (and other advanced topics in Robust Design)",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-33-systems-engineering-summer-2010/a3ea8483fe0d1c0aac89e716d7c40951_MITESD_33SUM10_lec12.pdf",
      "content": "ESD.33 -- Systems Engineering\nOperating Windows for\nOperating Windows for\nRobust Concept Design\n(and other advanced topics in\nRobust Design)\nRobust Design)\nDan Frey\n\n-\nPlan for the Session\nPlan for the Session\nFrom last time: a new research result\n- Operating window methods\nOperating window methods\n- Concept design strategies\n- Relax a constraint limit ...\n- Use physics of incippient failure to avoid failure\np y\n- Create two distinct operating modes ...\n- Exploit interdependence\nExploit interdependence ...\n- Adaptive OFAT for robust design\n- Noise strategy\n\nMore Observations of Industry\nMore Observations of Industry\n- Time for design (concept to market) is going down\n- Fewer physical experiments are being conducted\nphysical experiments are being conducted\nFewer\n- Greater reliance on computation / CAE\n- Poor answers in computer modeling are common\nPoor answers in computer modeling are common\n- Right model → Inaccurate answer\n- Right model →No answer whatsoever\nRight model → No answer whatsoever\n- Not-so right model → Inaccurate answer\n- Unmodeled effects\n- Bugs in coding the model\n\nt\nt\nHuman Subjects Experiment\nHuman Subjects Experiment\n- Hypothhesiis: EEngiineers usiing a flflawedds iimullatiion\nare more likely to detect the flaw while using\nOFAT than while using a more complex design\nOFAT than while using a more complex design.\n- Method: Between-subjects experiment with\nh\nbj\n(\n)\nf\ni\nhuman subjectts (engiineers) performing\nparameter design with OFAT vs. designed\nexperiment\nexperiment.\nSavoie, Troy B., 2010, Human detection of computer simulation mistakes in engineering\nexperiments,\" PhD thesis, Massachusetts Institute of Technology.\n\nDevice Used as the Topic of\nConsideration in the Experiment\nCourtesy of Troy B. Savoie. Used with permission.\n\nFactors and their Experimentally\nDetermined Effects\nCourtesy of Troy B. Savoie. Used with permission.\n\nResults of Human Subjects Experiment\nResults of Human Subjects Experiment\n- Pilot with N = 8\n- Study with N = 55 (1 withdrawal)\n- External validity high\nExternal validity high\n- 50 full time engineers and 5 engineering students\n-\ni\nd f\nt\n40+\nexperience ranged from 6 mo. to 40+ yr.\n- Outcome measured by subject debriefing at end\nMethod\nMethod\nDetected\nDetected\nNot detected\nNot detected\nDetection Rate (95% CI)\nDetection Rate (95% CI)\nOFAT\n(0.3195,0.7133)\nPBL8\nPBL8\n(0 0009 0 1897)\n(0.0009,0.1897)\n\nRegistering Surprise\nRegistering Surprise\nCourtesy of Troy B. Savoie. Used with permission.\n\n-\nPreliminary Conclusions\nfrom this Investigation\n- Computer simulations are an increasingly\ncritical part of Systems Engineering\ncritical part of Systems Engineering\n- As confident as you may be in your\nmodels they probably still have mistakes\nmodels, they probably still have mistakes\nin them\n- Simplification of your search strategy will\nSimplification of your search strategy will\nmake you more capable of perceiving\nerrors in computer simulations\nerrors in computer simulations\n\n-\nPlan for the Session\nPlan for the Session\n- From last time: a new research result\nOperating window methods\nOperating window methods\n- Concept design strategies\n- Relax a constraint limit ...\n- Use physics of incippient failure to avoid failure\np y\n- Create two distinct operating modes ...\n- Exploit interdependence\nExploit interdependence ...\n- Adaptive OFAT for robust design\n- Noise strategy\n\nReliability and Systems\nReliability and Systems\nEngineering\nEngineering\n- Reliability is among the most important\nReliability is among the most important\ntopics in systems engineering\n- Reliability is the proper functioning of the\nsystem under the full rangge of conditions\nexperienced in the field\n- Reliability requires robustness\nReliability requires robustness\n\nDefinitions of Reliability\n- In its traditional formulation reliability is\nIn its traditional formulation reliability is\nstated as the probability of failure under\nspecified operating conditions\nspecified operating conditions\n- Here, we explore a concepption of reliabilityy\nas failure-mode avoidance\n\n-\nAdvantages of this Conception\n- Rooted in the physics of the failure\nRooted in the physics of the failure\n- More appropriate to early stages of SE\n- An enhancement to creativity\n- Requires less information\nRequires less information\n\nOne-sided Failure Modes\n- The failure occurs at only one end of a\ni\nf\nt\n'\nnoise factor's range\nResponse\n(\n) U\nY\n<\nZ\nX\nLimiting value\nFailure mode inequality\nResponse\nX1\n(\n)\n,\nU\nY\n<\nZ\nX\nDesign Parameter or\nControl factor\nFailure mode boundary\nNoise factor\nZ1\nClausing, D. and D. D. Frey, D. D., 2004, \"Failures Modes and Two Types of Robustness,\" 14th INCOSE Symposium,\nTolouse, FR.\n\nOperating Windows\n- Operating window = the range of noise\nfactors satisfying all failure mode criteria\nfactors satisfying all failure mode criteria\nY (X Z )> L\nY (X Z )<U\nX1\n(\n)\n,\nU\nY\n<\nZ\nX\n(\n)\n(\n)\n{\n}\nU\nY\nL\nY\n<\n′\n<\n′\nZ\nX\nZ\nX\nZ\n(\n)\n,\nL\nY\n>\nZ\nX\nBroad operating window\n(\n)\n(\n)\n{\nY\n<\n(\n}\nU\nL\nY\n<\nZ\nX\nZ\nX\nZ\n(\n)\n(\n)\n{\n}\n,\n,\n,\nU\nY\nL\nY\n<\n<\nZ\nX\nZ\nX\nZ\n)\n(\n)\n{\n}\n,\n,\n,\nU\nY\nL\nY\n<\n<\nZ\nX\nZ\nX\nZ\nNarrow operating\nwindow\nZ1\n\n′\nConcept Design\nZ2\nZ2\nY3(X′,Z)<U3\nY (X Z)<U\n(\n)\n,\nU\nY\n<\nZ\nX\n(\n)\n(\n)\n,\nU\nY\n<\nZ\nX\n(\n)\n{\n}\nfor\n,\n...\n∈\n∈\ni\nW\nY\ni\ni\nZ\nX\nZ\n(\n)\n,\nL\nY\n>\nZ\nX\n(\n)\n(\n)\n{\n}\n(\n)\n,\nU\nY\n<\n′ Z\nX\n(\n)\nL\nY\n>\n′ Z\nX\n(\n)\n{\n}\nfor\n,\n...\n∈\n∈\n′\ni\nW\nY\ni\ni\nZ\nX\nZ\n(\n)\n(\n)\n,\nL\nY\n>\nZ\nX\nZ1\nZ1\n- A conceptual design change can\ncreate a larger operating window\ncreate a larger operating window\n\nA Theorem\nA Theorem\nOperating Windows and Conceptual Design -- If the conceptual design of a system is\nchanged including a change in functional responses Yi to\niY ′ and corresponding design\n′\nparameter changes from X to X′ and the new operating window holds the old operating\nwindow as a subset\n(\n)\n{\n}∈\n∈\n\nall\nfor\n\n,\ni\nW\nY\ni\ni\nZ\nX\nZ\n(\n)\n{\n}\nall\nfor\n\n,\ni\nW\nY\ni\ni\n∈\n′\n′\nZ\nX\nZ\n, then reliability\nhas improved.\n- Reliability improved regardless of probability\ndistribution\n\nRelax a Constraint Limit on an\nRelax a Constraint Limit on an\nUncoupled Control Factor\n- When a system variable only affects one of\nWhen a system variable only affects one of\nthe ...failure modes, take its value to its\nconstraint limit\nseek new architectures or\nconstraint limit... seek new architectures or\ntechnologies that relax the constraint.\n\nPrimary Example of the Strategy\nWrap angle\nR t\nd R\nFeed Belt\nPaper Stack\nRetard Rollll\nWrap angle\nIt was known that increasing wrap angle tended to\nimprove multifeed reliability and not particularly\nimprove multifeed reliability and not particularly\nhamper misfeed reliability. Still, most copiers only\nhad about 13 degrees of wrap angle.\nCourtesy of Wiley Periodicals. Used with permission.\n\nPrimary Example of the Strategy\nArchitecture with nearly\nArchitecture with looping\nlinear paper path\npaper path\nA newer architecture on the right has a looping\npaper path, which enabled a larger wrap angle,\nPatent # 4,475,732 [Clausing et al, 1984].\nCourtesy of Wiley Periodicals. Used with permission.\n\nSecond Example of the Strategy\nSecond Example of the Strategy\n-\nA critical failure mode of fans is flutter\n- Fl\nib\ni\nd\nh\nl\nh\nf h\nbl d\nd h\nFlutter = vibration due to the length of the blades and theiir\nexposure to inlet flow distortions.\n- It had long been known that increasing the chord of a fan\nblade stiffened the blade and thereby reduced the incidence\nblade stiffened the blade and thereby reduced the incidence\nof the failure mode of flutter, but the chord of the blade was\nlimited by constraints on weight [Koff, 2004].\n- New technologies for manufacturing enabled wide-chord fans\nNew technologies for manufacturing enabled wide chord fans\nwithout added weight [Patent #4,345,877 & Patent\n#4,720,244]\n\nc eas\ns e o t e o e at\ndo\nUse Physics of Incipient Failure to\nUse Physics of Incipient Failure to\nAvoid Failure\nE\nl\nExploit th\nit the phhysiicall mechhaniisms\nassociated with an incipient failure to\noffset the failure mode, thereby\nincreasingg size of the ope\np ratingg window.\n\nExample of the Strategy\nAngled slots in the\ncompressor casing\nRotor blades\n\"G\nt\nbi\ni\nith i\nd\n\"Gas turbine engine with improved compressor\ncasing for permitting higher air flow and\npressure ratios before surge\"\nPatent #4,086,022 [Freeman and Moritz, 1978].\nCourtesy of Wiley Periodicals. Used with permission.\n\nExample of the Strategy\nratio\nrotating annulus of air\ndrop of inlet mass flow\nsurge\nsurge line\noperating line\nsurge line\npressure\np\nsurge\nmargin\nmass flow\nmass flow\nBEFORE casing treatment\n\nExample of the Strategy\nrotating annulus of air\ndrop of inlet mass flow\np\nsurge line\ncasing treatment releases\npressure\nratio\noperating line\nsurge line\npressure\n20% larger\nsurge\np\nmass flow\nsurge\nmargin\nmass flow\nAFTER casing treatment\n\nde\nt o d st ct\nat\nodes so\nEmploy Two Different Operating\nEmploy Two Different Operating\nModes\nModes\nWh\nit i\nt\nibl\nt\ni\nlt\nl\nWhen it is not possible to simultaneously\navoid two one-sided failure modes due\nto a wide range of noise values, consider\ndefiningg two distinct ope\noperatingg modes so\nthat at least one of the failure modes will\nbe moved away from the operating\nbe moved away from the operating\nrange\n\nExample of the Strategy\nR t\nd R\nFeed Belt\nPaper Stack\nRetard Rollll\nDuring normal operation, the sheet rubs over the\nDuring normal operation, the sheet rubs over the\nretard roll. Eventually, wear leads to failure. The\nearly solution was to distribute wear across the\ncircumference, but this was still unsatisfactoryy.\nCourtesy of Wiley Periodicals. Used with permission.\n\nt t\nt\nt\nExample of the Strategy\nExample of the Strategy\nCONTACT\nCONTACT\nFORCE\nFORCE\nPAPER\nROLL/ SHAFT\nPAPER\n\"What is claimed is: a forward rotatable roll retard\nmember ... including a drag brake located interiorly\nthereof, said drag brake being adapted such that\nsingle sheets passing through said retard nip will\nrotate andd retardd rollll andd multif\nltifeedds thhroughh saidid\nretard nip will cause said drag brake to inhibit\nrotation of said retard roll.\nPatent # 4,475,732 [Clausing et. al., 1984]\nImplemented in Xerox 1075 copier\nROLL\nSHAFT\nFIELD\n\nExample of the Strategy\nF\nT\nr\nT<rFμfp\nFeedbelt on paper\nT>rFμpp\nPaper on paper\nPaper on paper\nCourtesy of Wiley Periodicals. Used with permission.\n\no\no se acto s\nIdentify and Exploit Dependencies\nIdentify and Exploit Dependencies\nAmong Failure Modes\nWh\nWhen th\nthere are ddependdenciies among\nfailure modes, look for ways to use those\ndependencies to counteract the effects\nof noise factors\n\n-\nExample of the Strategy\n- First stage turbine\nblades are limited in life\nby oxidation\n- C\nli\nfl\ni\nid\nCooling flow is providedd\nfrom the compressor\n- But the flow is different\nBut the flow is different\nfrom blade to blade due\nto manufacturing\nvariability (cooling\npassages)\nCourtesy of Wiley Periodicals. Used with permission.\n\n-\n=\nExample of the Strategy\n- There exists an\ninterdependdence caused\ni t\nd\nf fl\ni t\nd\nd\ninterdependdence of flow\nby the plenum\nm2\nbetween adjacent blades\ninterdependenc\nthe \"binning\n#1\nexcessive\nlosses in\ntion of blade #\nlosses in\ncompressor\noxidat\nce added by\n\" process\noxidation of blade #2\n- Low flowing blades contribute\nLow flowing blades contribute\nto high pressure in upstream\nplenum\n- \"Binning\" of blades = ensuring\nof blades\nensuring\nBinning\nlow flowing blades are\nadjacent to other low flowing\nblades\nm1\nblades\nm1\n- >50% increase in life\nC. V. Sidwell, On the impact of variability and assembly on\nturbine cooling flow and oxidation life, Ph.D. Thesis, MIT,\n2004.\n\nSummary of Operating Windows\n-\nReliability can be viewed as failure mode avoidance\n-\nThis conception can facilitate innovations that\nincrease the operating window between failure modes\nincrease the operating window between failure modes\n-\nMany of these innovations improve reliability\nregardless of probability distribution\n-\nThe four strategies\n-\nRelax a constraint limit ...\n-\nUse physics of incipient failure to avoid failure\nUse physics of incipient failure to avoid failure\n-\nCreate two distinct operating modes ...\n-\nExploit interdependence ...\n-\nEach strategy has provided large improvements in\nEach strategy has provided large improvements in\nboth jet engines and paper feeding for copiers\n\n-\nPlan for the Session\nPlan for the Session\n- From last time: a new research result\n- Operating window methods\nOperating window methods\n- Concept design strategies\n- Relax a constraint limit ...\n- Use physics of incippient failure to avoid failure\np y\n- Create two distinct operating modes ...\n- Exploit interdependence\nExploit interdependence ...\nAdaptive OFAT for robust design\n- Noise strategy\n\ne O e\nacto at a\ne\no\nAdaptive \"One Factor at a Time\" for\ndapt\nRobust Design\nAgain, run a resolution III on noise\nAgain, run a resolution III on noise\nRun a resollutition III\nIII on noiise\nfactors\nfactors. If there is an improvement, in\ntransmitted variance, retain the change\nChange\nChange\none factor\nIf the response gets worse, go back to\nthe previous state\na\nb\nc\na\nb\nc\nb\nB\nSt\nft\n'\nh\nd\na\nc\nA\nC\nStop after you've changed every\nfactor once\na\nb\nc\nA\nFrey, D. D., and N. Sudarsanam, 2007, \"An Adaptive One-factor-at-a-time Method for Robust Parameter\nDesign: Comparison with Crossed Arrays via Case Studies,\" accepted to ASME Journal of Mechanical\nDesign.\n\nSheet Metal Spinning\nSheet Metal Spinning Sheet metal spinning model.\nImage by MIT OpenCourseWare.\nResults f\nor three met\nhods of r\nobust desi\ng\nn appli\ned\nt\no s\nh\neet\n\nmet\na\nl\nsp\nin\nni\nng\nm\node\nl.\nImage by MIT OpenCourseWare.\n\nPaper Airplane\nResul\nt\ns for t\nh\nree metho\nd\ns of\n\nrobu\ns\nt\n\nd\ne\ns\ni\ng\nn\n\nap\npl\nie\nd\nto\nt\nhe\np\nap\ner\na\nir\npl\nan\ne\nph\nys\nic\nal\ne\nxp\ner\nim\nen\nt.\n\nImage by MIT OpenCourseWare.\n\nResults Across Four Case studies\nFrey, D. D., N. and Sudarsanam, 2006, \"An Adaptive One-factor-at-a-time Method for\nRobust Parameter Design: Comparison with Crossed Arrays via Case Studies,\"\naccepted to ASME Journal of Mechanical Design.\nResults across four case\ns\ntudies of r\nobust de\nsign.\nImage by MIT OpenCourseWare.\n\nEnsembles of aOFATs\nEnsembles of aOFATs\n- Ensemble aOFATs\n(8)\nF\nti\nl F\nt\ni l\n- Ensemble aOFATs\n(4)\nF\nti\nl F\nt\ni l\n- Fractional Factorial\n27-1\n- Fractional Factorial\n27-2\nExpected Value of Largest Control Factor\n= 16\nExpected Value of Largest Control Factor =\nComparing an Ensemble of 4 aOFATs with a 27-2\nComparing an Ensemble of 8 aOFATs with a 27-1\nFractional Factorial array using the HPM\nFractional Factorial array usingg the HPM\nFractional Factorial array using the HPM\n(c) 2008 Nandan Sudarsanam\n\nt\nt\nt\nConclusions on\naOFAT for Robust Design\n- Anew mo ddell andd thheorems shhow thhat\n- Adaptive OFAT plans exploit two-factor\ni t\nti\ni ll\nh\nth\nl\ninteractions especially when they are large\n- Adaptive OFAT plans provide around 80% of\nthe benefits achievable via parameter design\nthe benefits achievable via parameter design\n- Adaptive OFAT can be \"crossed\" with\nfactorial designs which proves to be highly\nfactorial designs which proves to be highly\neffective\nFrey, D. D., and N. Sudarsanam, 2007, \"An Adaptive One-factor-at-a-time Method for Robust Parameter\nDesign: Comparison with Crossed Arrays via Case Studies,\" accepted to ASME Journal of Mechanical\nDesign.\n\n-\nPlan for the Session\nPlan for the Session\n- From last time: a new research result\n- Operating window methods\nOperating window methods\n- Concept design strategies\n- Relax a constraint limit ...\n- Use physics of incippient failure to avoid failure\np y\n- Create two distinct operating modes ...\n- Exploit interdependence\nExploit interdependence ...\n- Adaptive OFAT for robust design\nNoise strategy\n\nCrossed Arrays\nCrossed Arrays\n27-4\nIII\nNoise Factors\nIII\n-1\n-1\n-1\n+1\n+1\nControl Factors\na\n-1\n+1\n-1\n+1\nb\nA\nB\nC\nD\nE\nF\nG\nc\n-1 +1 +1 -1\nA\nB\nC\nD\nE\nF\nG\n-1\n-1\n-1\n-1\n-1\n-1\n-1\n-1\n-1\n-1\n+1 +1 +1 +1\n+1\n+1\n+1\n+1\n-1\n+1\n+1\n-1\n-1\n+1\n+1\n-1 +1 +1 +1 +1 -1\n-1\n+1 -1 +1\n-1 +1 -1 +1\n+1\n-\n+1\n+1\n+1\n+1\n+1\n+1\n-1\n+1\n-1\n+1 +1 -1\n-1 +1 +1 -1\n+1 +1 -1\n+1 -1\n-1 +1\n4 2 -\n- × III\nIII\n\nSingle Arrays\nSingle Arrays\n- Single arrays achieve improved run size\neconomy or resolution\neconomy or resolution\n- Focus on control by noise interactions which are\nessential for robust design\nessential for robust design\n- \"Some of the single arrays ... are uniformly\nbetter than corresponding cross arrays in terms\nbetter than corresponding cross arrays in terms\nof the number of clear main effects and two\nfactor interactions\"\nfactor interactions\n- Example of a suggested design (Wu & Hamada)\n210 5\n210-5\nA=1, B=2, C=3, D=4, E=234, F=134, G=123,\na=5, b=124, c=1245\n\nC\nte act o s\nComparing Crossed & Single Arrays\nComparing Crossed & Single Arrays\nII\n-\nI\n4 × 23\nII\n-\nI\n210-5\n- 32 runs\n- 32 runs\n- All control factors\n- All control factors clear\naliased with CXC\nof 2fi\n- All noise factors\n- All noise factors\nAll noise factors\n- All noise factors\nestimable\nestimable\n- 21 CxN interactions\n- 14 CxN interactions\nclear of 2fi\nclear of 2fi\nclear of CxCxC\nclear of NxNxN\n\nResults\nResults\n\nBasic\nFitted\nMethod\nExperiments\nWH\nlow\n2nd\nWH\nlow\n2nd\nMethod\nExperiments\nWH\nlow\nw\norder\nWH\nlow\nw\norder\n2 ×\n\n1,024\n60%\n81%\n58%\n50%\n58%\n40%\n-\n44%\n80%\n52%\n45%\n58%\n40%\n2 ×\nIII\n44%\n80%\n52%\n45%\n58%\n40%\n-\n8%\n8%\n56%\n18%\n9%\n38%\n-\n9%\n3%\n33%\n16%\n9%\n17%\n-\n9%\n3%\n33%\n16%\n9%\n17%\n-\n-×\nIII\nIII\n\n12%\n8%\n51%\n16%\n25%\n38%\nOFAT\n39%\n56%\n43%\n36%\n42%\n35%\n2 -\n×\nIII\nOFAT\n\n39%\n56%\n43%\n36%\n42%\n35%\nOFAT\nOFAT ×\n\n31%\n37%\n41%\n33%\n31%\n27%\n-\n4%\n4%\n8%\n4%\n2%\n0%\n\nthe world assumed in classical DOE\nour data\n\nWhat is Compound Noise?\nWhat is Compound Noise?\n- Aggregate several noise factors into a\nsingle noise factor\nsingle noise factor\n- Example\n- Temperature, humidity, salinity\n- Compress 3D sppace\ninto a single axis\n- Resollutition IIII outter array\n- Extreme conditions?\nhot wet salty\nhot, wet, salty\ncool, dry, fresh\n\n⎟\n⎜⎟\n⎜\nAn Academic Perspective on\nCompound Noise\nn\nExtreme settings exist iff\nβ j ≥∑γ ijij\nβ j\ni=1\nThe compound noise technique identifies the robust setting (that which\nminimizes variance) iff\nm\nm\n⎛\n⎞⎛\n⎞\n⎜∑β jγ ⎟⎟⎜∑ sgn(β )γ ⎟> 0,\ni =1...l\n⎜∑β jγ ijij ⎜∑sgn(\nj )γ ijij ⎟\ni\n⎝ j=1\n⎠⎟⎝j=1\n⎠\nHou, X. Shirley, 2002, \"On the use of compound noise factor in parameter design\nexperiments\", Applied Stochastic Models in Business and Industry 18:225-243.\n\n-\nAn Academic Perspective on\nCompound Noise\n- Use of compound noise has been widespread\n- Compound noise techniqque can identifyy robust\nsettings only in limited situations\n- Their limited nature suggests they are not often\nTheir limited nature suggests they are not often\nsatisfied in practical experiments\n- The message from this study is that is that\nThe message from this study is that is that\ncompound noise technique does not perform\nvery well in general situations\nvery well in general situations\nHou, X. Shirley, 2002, \"On the use of compound noise factor in parameter design\nexperiments\", Applied Stochastic Models in Business and Industry 18:225-243.\n\nt\nt\nMethod\nMethod\n- S l\nSelect a moddell off engiineeriing systems\n- Create 100 instances\n- 7 control factors\n- 7 noise factors\n7 noise factors\n- Run a full factorial inner array with\n- F ll f\nFull facttoriiall outter array\n- Compound noise outer array\n- Plot and analyze results\n\n=\nResults with Locally Extreme CN\nResults with Locally Extreme CN\nc = 100\nA\nt\nth\nf\nc\ns = 3\nAverage strength of\ninteractions ~0.25\nPercent of possible\nreduction achieved ~80%\n0.25\n0.5\n0.75\nPossible reduction in standard deviation\n~7% \"success\"\nNone had extreme\nsettings\nsettings\n0.75\nd dev\n0.25\n0.5\neduction in std\nRealized re\n0.5\n0.25\n\nStreamlining Robust Design\nStreamlining Robust Design\nSingh, J., R. Jugulum, N. Soderborg, D. E. Whitney, and D. D. Frey, 2007, \"Streamlining\nRobust Parameter Design Efforts,\" Journal of Design Research 5(4):435-448.\nP\nrob\nabi\nlit\ny o\nf a\nn e\nrro\nr i\nn P\na\nr\neto\nor\nder\ning\n\nvs. fraction of possible benefits attained\n.\nImage by MIT OpenCourseWare.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nESD.33 Systems Engineering\nSummer 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "PDSS Critical Parameter Development & Mgt. Process Quick Guide",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-33-systems-engineering-summer-2010/69261b72bed60ec44f5e50c12fa7fade_MITESD_33SUM10_lec07b.pdf",
      "content": "PDSS Critical Parameter Development & Mgt. Process Quick Guide\n12 Steps for a Critical Parameter Development Project (incl. 6 Check Points)\nStep 1: Create a CP Project Charter\n-\nestablish goal, objectives, team members, roles & responsibilities, time line & scope\n-\ndefine clear, specific & measurable CP project results\nStep 2: Create a cross-functional team of experts to help ID a thorough set of CPs\n-\nmake sure they are well balanced, right mix of people (experience & judgment)\n-\ngood at mistake-proofing the list of parameters (methods for mistake-proofing)\nStep 3: Generate / Assess Requirement Clarity, Classification & Flow-down\n-\ndefine Critical System level functional Reqts & their tolerance limits (USL & LSL)\n-\ndefine NUD (Critical) & ECO (non-Critical) requirements as they flow down to subsystems,\nsubassemblies, parts, materials and mfg. /assy./ packaging processes\nScope of CP\nActivity\nStep 4: Generate I-O-C Diagrams, P - Diagram, Noise Diagrams & the Boundary Diagram\n- identify high level mass, energy & information flows into and out of the system, subsystems &\nsubassemblies\n- identify candidate Critical functions, inputs, outputs, controllable parameters & noises\n- Define leading and lagging indicators & their units of measure\n- identify unit-to-unit, external / environmental & deteriorative noise parameters\n- preliminary documentation of required measurement systems\nStep 5: Structure a Critical Parameter Flow-down Tree\n-\nDefine the relationships between Y, ys & their controlling xs\no Function Trees & Functional Flow Diagrams\nCP candidate structure &\nprioritize for focus areas\no Math Models\n-\nDefine macro-relationships aligned with Critical noise parameters; which are NUD?\n-\nPlan to separate which xs dominate & control the mean & which control σ for each Y & sub-y\n-\nConduct Potential Problem Prevention & Impact Mitigation Analysis (P3IMA Table aka FMEA)\no Laws of Unintended Consequences (unwanted functions)\nStep 6: Identify unique sub-areas of focus; lean out, rank & prioritize the areas to work on\n-\nGroup prioritized CP flows with the biggest impact on the reqts; apply 6 Step Prevention Process\n-\nSelect the appropriate groups of flows that matter the most; again - which are NUD?\n-\nAlign critical noise parameters with the appropriate sub-groups\nStep 7: Prove measurement systems are capable\n- MSA & Gage R&R Studies for Critical Ys, sub-ys & controlling Xs (for both leading & lagging indicators)\nStep 8: Design & conduct experiments (problem ID & prevention!)\n-\nscreening experiments (separate signal from random noise)\n-\nmodeling experiments (linear & non-linear effects plus interactivity)\n-\nnoise parameter strength experiments (what shifts the mean or spreads the variance?)\n-\nrobustness experiments\n-\ntolerance sensitivity experiments\nStep 9: Analyze data using ANOVA & other statistical methods that identify sensitivities &\nlevel of capability\n-\ndefine statistical significance (p values)\n-\nMSparameter / MStotal\n-\nCp & Cpk values\n-\nCapability Growth Indices (CGI maturation by development process phase)\nFacts database of CPs &\ntheir relationships\n(c) 2010 PDSS Inc.\npage 1 of 11\n\nPDSS Critical Parameter Development & Mgt. Process Quick Guide\nStep 10: Establish & Verify tolerance ranges & % contribution to variation of critical Ys &\nsub-ys\n-\nUSL & LSL for both nominal conditions & stressful conditions (robust tolerances)\n-\nestablish variance role-up model (s2 total = s21 + s22 + .... + s2 n)\n-\nverify & validate final design & processing set points\nStep 11: Mfg. & Production Implementation Plan for Critical Parameters\n-\nEstablish production & assembly data requirements & data utilization plan\no Agreement on what constitutes a production or assembly CP\nIn-process CPs on the process itself\nWithin-process or post-process CPs (on parts, sub-assy, sub-system\nor system during mfg., assembly, packaging or upon receipt)\no Requirements/Specifications to measure production & assembly CPs against\no SPC & Cp/Cpk Study requirements & procedures\nFrequency of measurements & action based upon data\nCritical Cpk>>>Cp Adjustment parameters (mean shifters)\no Measurement system requirements & acceptable signal/noise resolution\no Contingency & Corrective Action plans\nAlternative action plan\nProcess specific LSS-based corrective action process plan\n- Kaizen event or 6σ Project?\nStep 12: Evaluate Quality and Implement Changes in a Control plan\n-\nDevelop and submit alternate acceptance plans that maintain or improve functional\nquality with reduced acceptance costs\no Select acceptance plan that meets overall program needs\no Verify performance of selected plan\no Implement changes as supported by data per the control plan\nDocumented CP set\npoints\nConduct CP summary\nreviews & make\nCpk>>>Cp adjustments\nas needed during steady\nstate mfg.\nChange Implementation\nand Document Ongoing\nControl Plan\n(c) 2010 PDSS Inc.\npage 2 of 11\n\nPDSS Critical Parameter Development & Mgt. Process Quick Guide\nCP Step\nEnabling Tools, Methods or Best Practices\nStep 1: Create\na CP Project\nCharter\nProject Planning tools (MS Project); Monte Carlo Simulations\nof Critical the Path of Task Flows (@Risk Software Tool;\nPalisades), Cost Estimation, SMART Problem & Goal\nIdentification, Intro. to CP Module\nStep 2: Create\na cross-\nfunctional team\nof experts to\nhelp ID a\nthorough set of\nCPs\nSpecific Experience, Technical Expertise & Judgment, Prefer\nDFLSS trained individuals on the IPT; can be trained and\nmentored JIT as required\nStep 3:\nGenerate /\nAssess\nRequirement\nClarity,\nClassification &\nFlow-down\nDocumentation\nCustomer/Stakeholder ID, Interviewing Methods, KJ Method,\nNUD vs. ECO Classification, Kano Method, Quality Function\nDeployment (QFD) & the Houses of Quality, DOORS Reqts.\nSoftware Tool, CP Reqt. Database Documentation, CP\nReqts. Worksheets\nStep 4:\nGenerate I-O\nC Diagrams, P-\nDiagrams,\nNoise\nDiagrams,\nBoundary\nDiagrams &\nMath Models\nI-O-C Diagramming, P-Diagramming, Noise Diagramming,\nSystem Noise Mapping, Boundary & Interface Diagramming,\n1st Principles Modeling & Simulations\nStep 5:\nStructure a\nCritical\nCharacteristics\nFlow-down\nTree\nFunctional Diagramming, FAST Diagramming, Tree\nDiagramming, Flow Diagramming, CocCPit CPM Software\nTool (Cognition), CP Data Base Construction Module, CP\nScore Card Structuring Module, CP Reqts. & Measured Y\nWorksheets\nStep 6: Identify\nunique sub\nareas of focus;\nlean out, rank\n& prioritize the\nareas to work\nNUD vs. ECO Classification, Kano Classification, Pareto\nProcess, QFD Reqts. Ranking & Prioritization, Function\nTrees, Noise Diagrams, FMEAs\nStep 7: Prove\nmeasurement\nsystems are\ncapable\nMeasurement System Analysis, Gage R&R Studies\n(c) 2010 PDSS Inc.\npage 3 of 11\n\nPDSS Critical Parameter Development & Mgt. Process Quick Guide\nStep 8: Design\n& conduct\nexperiments\nSPC Studies, Capability Studies, Sample-size Determination,\nSample Data Parameter & Distribution Characterization\nStudies, Multi-vari Correlation Studies, t-Tests for 2 Way\nComparisons, DOE Methods: Full & Fractional Factorial\nDesigns, Screening Experiments, Modeling Experiments,\nOptimization Experiments, Mixture Experiments, Robustness\nDevelopment Experiments, System Integration Sensitivity\nExperiments, Tolerance Balancing Experiments, ALT, HALT\n& HAST, Duane Plotting\nStep 9:\nAnalyze data\nusing ANOVA\n& other\nstatistical\nmethods that\nidentify\nsensitivities &\nlevel of\ncapability\nDescriptive, Graphical & Inferential Statistical Data Analysis\nMethods, Confidence Interval Analysis, ANOVA, Regression,\nMain Effects & Interaction Plotting, CP Documentation & CP\nScorecards\nStep 10:\nEstablish &\nVerify\ntolerance\nranges & %\ncontribution to\nvariation of\ncritical Ys &\nsub-ys\nScreening DOEs (Plackett-Burman Arrays), ANOVA, Taguchi\nLoss Function, Additive Variance Modeling, SPC & Capability\nStudies, CP Documentation & CP Scorecards\nSteps 11-12:\nMfg. &\nProduction\nImplementation\nPlan\nControl Planning, Quality Planning, SPC Studies, Capability\nStudies, CP Allocation for Production & Assembly Processes,\nCP Documentation & CP Scorecards, CP Deployment in\nProduction & Supply Chain Environments Module\n(c) 2010 PDSS Inc.\npage 4 of 11\n\nσ\nLSL\nUSL\nCp\n-\nσ\nLSL\nUSL\nCp\n-\nPDSS Critical Parameter Development & Mgt. Process Quick Guide\nRecommendation for linking NUD requirements to CPs for Capability tracking\n=\n=\nWhat is Required?\nWhat is Measured?\nCustomer Level (USL - LSL)\nCustomer Level (Avg & σ)\nSystem Level (USL - LSL)\nSystem Level (Avg & σ)\nSubsystem Level (USL - LSL)\nSubsystem Level (Avg & σ)\nSubassembly Level (USL - LSL)\nSubassembly Level (Avg & σ)\nComponent Level (USL - LSL)\nComponent Level (Avg & σ)\nMfg. Process Level (USL - LSL)\nMfg. Process Level (Avg & σ)\nFrom this comparison we can document performance Capability\n\n-\nσ\n,\nX\nUSL\nLSL\n1 0\n1 1\n1 2\nL SL\nU S L\nP ro c e ss C a p a b ilit y A n a ly s is f o r C2\nU S L\nT a r ge t\nL S L\nM e an\nS am ple N\nS tD ev ( W ith in )\nS tD ev ( O ve ra ll)\nC p\nC P U\nC P L\nC p k\nC p m\nP p\nP P U\nP P L\nP pk\nP P M < L S L\nP P M > US L\nP P M T o t al\nP P M < L S L\nP P M > US L\nP P M T ot al\nP P M < L S L\nP P M > US L\nP P M T ot al\n1 2 .0 00 0\n*\n8 .0 00 0\n9 .9 76 6\n10 0\n0 .4 4 7 13 4\n0 .4 5 8 18 6\n1 .4 9\n1 .5 1\n1 .4 7\n1 .4 7\n*\n1 .4 6\n1 .4 7\n1 .4 4\n1 .4 4\n0 .0 0\n0 .0 0\n0 .0 0\n4. 92\n3. 02\n7. 94\n8 .0 1\n5 .0 3\n1 3 .0 4\nP ro c e ss D a ta\nP o te nt ial (W ith in) C a pa b ility\nO v er a ll C a pa b ility\nO b s e rv ed P er fo r m a n ce\nE xp . \" W ith in \" P e r fo rm a nc e\nE xp . \"O v er a ll\" P e r fo rm an c e\nW ithi n\nOve ral l\n1 0\n1 1\n1 2\nL SL\nU S L\nP ro c e ss C a p a b ilit y A n a ly s is f o r C2\nU SL\nT a r ge t\nL SL\nM e an\nS am ple N\nS tD ev ( W ith in )\nS tD ev ( O ve ra ll)\nC p\nC PU\nC PL\nC p k\nC p m\nP p\nP PU\nP PL\nP pk\nPPM < L SL\nPPM > US L\nPPM T o t al\nPP M < L SL\nPP M > US L\nPP M T ot al\nPPM < L SL\nPPM > US L\nPPM T ot al\n1 2 .0 00 0\n*\n8 .0 00 0\n9 .9 76 6\n10 0\n0 .4 4 7 13 4\n0 .4 5 8 18 6\n1 .4 9\n1 .5 1\n1 .4 7\n1 .4 7\n*\n1 .4 6\n1 .4 7\n1 .4 4\n1 .4 4\n0 .0 0\n0 .0 0\n0 .0 0\n4. 92\n3. 02\n7. 94\n8 .0 1\n5 .0 3\n1 3 .0 4\nP ro c e ss D a ta\nP o te nt ial (W ith in) C a pa b ility\nO v er a ll C a pa b ility\nO b s e rv ed P er fo r m a n ce\nE xp . \" W ith in \" Pe r fo rm a nc e\nE xp . \"O v er a ll\" Pe r fo rm an c e\nW ithi n\nOve ral l\nUSL -LSL\nCp =\n6σ\nX -\nCpk = Min\n3σ\nSummary of Critical CPM Actions:\nCPM Actions\nReliability Actions\nMetrics: scalars & vectors; continuous variables\nMetrics: time-based failures; discrete events\nY=f(x) physics -based models\nAdditive / Product Functions; serial / parallel\nTime-To-Failure models\nP-Diagrams\nReliability Block Diagrams\nNoise Diagrams\nFMEA, FMECA & Fault Tree Analysis\nFunction Trees\nDuane Reliability Growth Plots\nFunctional Flow Diagrams\nNormal Reliability Tests\nForm Hypotheses & prioritize evaluations\nAccelerated Reliability Tests\nScreening & Modeling DOEs under nominal\nconditions\nHALT, HASS & HAST evaluations\nRobustness experiments under stressful\nconditions\nFRACAS\nTolerance balancing experiments under nominal\n& stressful conditions\n(c) 2010 PDSS Inc.\npage 5 of 11\n\n-\nPDSS Critical Parameter Development & Mgt. Process Quick Guide\nProblem Prevention Steps:\nThe 6 Steps for Problem Prevention:\n- Design a Diagram of detailed functionsin their serial & parallelflows\nPlan &\n- These are value-addedfunctionsthatpossess inherentrobustness\nRank\n- Rank& prioritize the value of each function relative to one another\nTasks\n- Define potential problems that can occur within & between the functions\nDefine\n- A statement of the mistakes or errors that characterize the problem\nPotential - Identification of LeadingIndicatorsthatmeasure the on-setof a problem\nProblems\n- Evaluate & document the root causes of the potential problems\nEvaluate - Understand the mechanisms behind all impending problems\nCauses\n- Define preventive actions for effectiveness & value\nDefine\nPreventive - Finalize, measure & track leading indicators - be proactively efficient\nActions\n- Define contingencyplans if the problem actually occurs\nDefine\n- Finalize,Measure & track leading & lagging indicators - be reactively effectiveafter\nContingent\nindicators reach a trigger point.\nActions\n- Re-use the lessons learned for future use & reactivity\nRe Use\n- Continuously improve the problem prevention process\nLearning\nThe P3IMA Table to help with the Problem Prevention Steps\nThe Potential Problem Prevention & Impact Mitigation Analysis (P3IMA)\n(a derivative of FMEA)\nCritical\nPotential\nLikely\nProbabilityof\nPreventive\nAbility to\nSeverity of Contingency\nFunction\nProblem\nCauses\nOccurrence\nAction\nDetect\nImpact\nAction\nOnset\n(c) 2010 PDSS Inc.\npage 6 of 11\n\n-1\n-1\n-1\n-1\n-1\nPDSS Critical Parameter Development & Mgt. Process Quick Guide\nWhat do I keep track of? & how do I do it? 7 Things to prove you are ok!\n\nMeasure\nHow?\nMeasurability\nMSA: Gage R&R Study\nStability\nSPC Chart: I & MR\nTunability\nDOE, RSM, Regression Y=F(CAPs)\nSensitivity & Stat. Significance\nDOE, p-Value, ANOVA:DY/DX\nInteractivity\nDOE, ANOVA: Xa * Xb\nCapability\nCapability Indices: Cp & Cpk\nRobustness\nDOE, S/n: COV, std. deviation\n\nIf these items are problematic and not in control then these are NUD parameters that are very good\ncandidates for Critical Parameter status... until proven under control and able to be re-classified as\nEasy, Common & Old.\n\nMeasurability:\nGage name :\nD ate of study:\nGage R&R (ANOVA) for Thickness\nR eported by:\nMis c :\nTo lera nc e:\n1 00\nC om ponents of Variation\n%C o nt rib utio n\n%S tu dy Var\n8 .3\n8 .2\nB y Part\nSample Mean\nSample Range\nPercent\n%To le ra nce\n8.1\n8 .0\n7.9\nGage R& R\nRepeat\nReprod\nP art-to-P art\nPart\nR Chart by O perator\nBy Operator\n0.2\nFred\nJoe\nM ary\n8.3\nUCL =0.1459\n8.2\n0.1\n8.1\nR = 0 .0 5 66 7\n8 .0\n0.0\nLCL =0\n7 .9\nOperator Fred\nJ oe\nMary\nXbar Chart by Operator\nOperator*Part Interac tion\nOperator\nFred\nJ oe\n8.2\nFred\nJoe\nM ary\n8.2\n8.1\nUCL =8.102\nM e a n= 8. 0 44\n8 .0\nL C L = 7. 98 6\nAverage\n8 .1\n8 .0\nM a ry\n7 .9\n7 .9\nPart\n\nStability:\nI and MR Chart for C2\nUCL=5.917\nIndividual Value\nMean=-0.03816\n-5\nLCL=-5.994\nSubgroup\nMoving Range\nUCL=7.316\nR=2.239\nLCL=0\n\nTunability:\nANOVA: Y plus Noise versus A, B, C\nMain Effects Plot - Data Means for Yplus Noise\nFactor Type Levels Values\nA fixed 2 -1 1\nB fixed 2 -1 1\nC fixed 2 -1 1\nSurface Plot of Cool Tim\nA\nB\nC\n\nAnalysis of Variance for Y plus N\n\nSource DF SS MS F P\nA 1 69.82 69.82 196.14 0.000\nB 1 401.70 401.70 1128.38 0.000\nC 1 1620.35 1620.35 4551.60 0.000\nY plus Noise\nA*B 1 27.82 27.82 78.14 0.000\nA*C 1 110.85 110.85 311.38 0.000\nB*C 1 0.00 0.00 0.00 0.969\nA*B*C 1 0.00 0.00 0.00 0.967\nError 8 2.85 0.36\nTotal 15 2233.39\nInteraction Plot (data means) for Y plus Noise\nCool Time (sec)\nA\nEffect\nSum of Squares\nepsilon2\n%epsilon2\nA\n69.82\n69.82/2233.39=0.031\n3.1%\nB\n401.70\n401.70/2233.39=0.18\n18%\nB\n-2\n-1\nTemp\nC\n1620.35\n1620.35/2233.39=0.72\n72%\n-1\n-2\nAC\n27.82\n27.82/2233.39=0.012\n1.2%\nSpeed\n-1\nAB\n110.85\n110.85/2233.39=0.05\n5%\nC\nTotal\n2233.39\n\nHold values: Vol: 0.0\n\n(c) 2010 PDSS Inc.\n\npage 7 of 11\n-1\n\nPDSS Critical Parameter Development & Mgt. Process Quick Guide\nInteractivity:\nANOVA: Y plus Noise versus A, B, C\nFactor\nType Levels Values\nA\nfixed\n-1\nB\nfixed\n-1\nC\nfixed\n-1\nAnalysis of Variance for Y plus N\nSource\nDF\nSS\nMS\nF\nP\nA\n69.82\n69.82 196.14 0.000\nB\n401.70\n401.70 1128.38 0.000\nC\n1620.35\n1620.35 4551.60 0.000\nA*B\n27.82\n27.82\n78.14 0.000\nA*C\n110.85\n110.85 311.38 0.000\nB*C\n0.00\n0.00\n0.00 0.969\nA*B*C\n0.00\n0.00\n0.00 0.967\nError\n2.85\n0.36\nTotal\n2233.39\nA\nB\nC\n-1\n-1\n-1\nY plus Noise\nMain Effects Plot - Data Means for Yplus Noise\n-1\n-1\nA\nB\nC\n-1\n-1\nInteraction Plot (data means) for Y plus Noise\nEffect\nSum of Squares\nepsilon2\n%epsilon2\nA\n69.82\n69.82/2233. 39=0.031\n3. 1%\nB\n401. 70\n401.70/2233.39=0.18\n18%\nC\n1620.35\n1620. 35/2233.39=0.72\n72%\nAC\n27.82\n27.82/2233. 39=0.012\n1. 2%\nAB\n110. 85\n110.85/2233.39=0.05\n5%\nTotal\n2233.39\nSensitivity & Statistical Significance:\n-\nResistor G\n[36,960/105,227] x [100] = 35%\n-\nResistor I\n[29,843/105,227] x [100] = 28%\n-\nResistor D\n[14,945 /105,227] x [100]= 14%\n-\nCapacitor C\n[10,764/105,227] x [100]= 10%\n-\nResistor B\n[6,281/105,227]\nx [100]= 6%\n-\nResistor A\n[3,335/105,227]\nx [100]= 3%\n-\nTransistor C\n[1,580/105,227]\nx [100]= 1.5%\n-\nTransistor F\n[716/105,227]\nx [100]= 0.68%\nSource\nDF\nSeq SS\nAdj SS\nAdj MS\nF\nP\nRes A\n24.88 0.002\nRes B\n46.85 0.000\nCap C\n80.29 0.000\nRes D\n111.48 0.000\nTrans F\n5.34 0.054\nRes G\n275.69 0.000\nRes I\n222.60 0.000\nTrans K\n11.79 0.011\nError\nTotal\nTotal MS\n28.44\n14.24\n10.26\n5.99\n3.18 1.5 0.68 0.39\n35.23\nResistor G\nResistor I\nResistor D\nCap. C\nResistor B\nResistor A\nTrans. K\nTrans. F\nVoltage L\n% Contribution\nCapability:\nL S L\nUS L\nP ro c e s s C a p a b ilit y A n a ly s is fo r C 2\nU SL\nT ar get\nLS L\nMe an\nS am ple N\nS tD ev ( W ith in)\nS tD ev ( O ve rall)\nC p\nC P U\nC P L\nC p k\nC p m\nP p\nP PU\nP PL\nP pk\nPP M < L SL\nPP M > U S L\nPP M T ot al\nP P M < L SL\nP P M > U S L\nP P M T ot al\nPP M < L SL\nPP M > U S L\nPP M T ot al\n12. 00 00\n*\n8. 00 00\n9. 97 66\n1 00\n0 .4 471 34\n0 .4 581 86\n1. 49\n1. 51\n1. 47\n1. 47\n*\n1. 46\n1. 47\n1. 44\n1. 44\n0 .0 0\n0 .0 0\n0 .0 0\n4 .9 2\n3 .0 2\n7 .9 4\n8. 01\n5. 03\n13. 04\nP roc es s D at a\nPo te nt ial (W it hin) C apa bilit y\nO v era ll C apa bilit y\nO bs e rv ed P erf or m a nc e\nE xp . \"W it hin \" Pe rf orm an c e\nEx p. \"O v era ll\" Pe rf orm an c e\nW ith in\nO ve ra ll\nRobustness:\nYavg\nSensitivity to\nNoise!\nA1\nCritical Functional\nRobustness\nParameter (CFRP)\nA2\nRobustness\nN1\nN2\nCompounded\nNoise Factors\n(c) 2010 PDSS Inc.\npage 8 of 11\n\nPDSS Critical Parameter Development & Mgt. Process Quick Guide\nExample of getting Functions right and driving your CP development methodology:\nIf I have 5 Functions, then I have at least 5 measurable ys.\nEach y variable is dependent on one or more X variables.\nFirst, we define all 5 functions verbally using verb-noun pairs on Post It notes. This results in\nvertical branches of lists of functions called Function Trees. The top of the tree is a big Y, which is\nyour business or VOC based requirement. This is usually not stated in physics terms but rather\nquality, financial or some other non-physics form of units of measure. We MUST state our functions\nin fundamental units of physical measure. You can have multiple branches of functions coming\nfrom multiple Voice of Business (VOB) goals or Voice of Customer (VOC) requirements...\nY = Business Goal 1 (VOB) or Customer Reqt. 1 (VOC)\nFunction Tree Diagram\nF1\nF2\nF3\nF4\nF5\nF1\nF2\nF3\nF4\nF5\ntime\nFunctional Flow Diagram\nNext, we rearrange the Post It notes containing the Functions into their horizontal flow relationships\nover time. This will result in a serial-parallel flow diagram of exactly how the functions occur over\ntime.\nEach function is quantified as a y variable and is stated in its physics-based units of measure (a\nscalar or vector). We add the y variables and their units of physical measure to the Post It notes.\nF1...y1\n(c) 2010 PDSS Inc.\npage 9 of 11\n\nPDSS Critical Parameter Development & Mgt. Process Quick Guide\nNext we must define each X variable that controls or influences each y...\nX variables come in 4 varieties:\nX mean shifter = controllable parameter that has a strong ability to move the mean of y\nX std. dev. shifter = controllable parameter that has a strong ability to move the value of σ\nX COV shifter = controllable parameter that has a strong ability to move both the mean of y and the\nvalue of σ (a coupled affect on both statistical parameters! Called the Coefficient of Variation: COV\n= (σ/mean)\nX noise inducer = an uncontrollable parameter that has a strong ability to either move the mean of y,\nthe value of σ or the COV. They come from either External, Unit-Unit or Deteriorative sources.\nSo for each X we can create a Post It note to align with each y...\nXa = ...\nXb = ...\nXn = ...\nTo define the candidate critical parameter ys & Xs; we lay out the functional relationships\nF1...y1\nXa = ...\nXb = ...\nXn = ...\nFor each function you develop a Y = f(X...) model. This is a set of \"hypotheses\" that must be\nproven to be complete and true. DOEs will answer the following questions...\ny1 = f(Xa, Xb, ...)\nΔy1 = f(ΔXa, ΔXb, ...); σ2 of y1 = f(σ2 from ΔXa, σ2 from ΔXb,...)\ny2 = f(Xa, Xb, ...)\nΔy2 = f(ΔXa, ΔXb, ...); σ2 of y2 = f(σ2 from ΔXa, σ2 from ΔXb,...)\ny3 = f(Xa, Xb, ...)\nΔy3 = f(ΔXa, ΔXb, ...); σ2 of y3 = f(σ2 from ΔXa, σ2 from ΔXb,...)\ny4 = f(Xa, Xb, ...)\nΔy4 = f(ΔXa, ΔXb, ...); σ2 of y4 = f(σ2 from ΔXa, σ2 from ΔXb,...)\ny5 = f(Xa, Xb, ...)\nΔy5 = f(ΔXa, ΔXb, ...); σ2 of y5 = f(σ2 from ΔXa, σ2 from ΔXb,...)\nWe will know the model is complete by developing both analytical & empirical models. If our\ncorrelation coefficient (R2) for the empirical model is high, then we know very little of the data is\nattributable to missing Xs and in fact the error on the model is due to random effects and not\nmissed X parameters. If random error is small, then our model is good and our data acquisition\nsystem is too. If random error is high and our GR&R is over 10-20% we have a measurement\nsystem problem to correct!\nWe will know the model is true because the terms, coefficients, linearity or curvature in the\nanalytical and empirical models are in agreement and that the X parameters are all statistically\nsignificant - a parsimonius or efficient model! Assumptions will have been proven or corrected.\n(c) 2010 PDSS Inc.\npage 10 of 11\n\nPDSS Critical Parameter Development & Mgt. Process Quick Guide\nWhat about Noise and its affect of the Functions (ys) and the relationship of (X * Noise)\ninteractions.\nThe Noise Diagrams:\nFor the Function, what noises cause it to vary?\nUnit-Unit\nNoises\nFunction\nΔy = f(Xs)\nExternal\nNoises\nMean of\ny & σ\nDeterioration\nNoises\nFor any X variable that is not a Noise Parameter, what noises cause it to vary? X variations\nΔXn\nUnit-Unit\nNoises\nExternal\nNoises\nMean of\ny & σ\nDeterioration\nNoises\nWe must know what noise parameters really affect our Xs & Ys so we can conduct robust design\nexperiments to assess interactivity between the Xs & the Noises. These noises will also impact k in\nCpk assessment because they are able to cause both mean shifts and variance growth.\n(c) 2010 PDSS Inc.\npage 11 of 11\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nESD.33 Systems Engineering\nSummer 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Requirements Driven Systems Design",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-33-systems-engineering-summer-2010/93a63108bb30c1041d93b024e4cbcf35_MITESD_33SUM10_lec06.pdf",
      "content": "ESD.33 Systems Engineering\nLecture 6\nRequirements Driven Systems\nDesign\nQi Van Eikema Hommes\n\nCourse Layout\nQi Van Eikema Hommes\n6/24/10\nLecture 7 CPM and DFSS\nLecture 2\nSystems Engineering\nAs Human AcKvity\nLecture 4\nStakeholder Analysis and\nRequirements DefiniKon\nLecture 5 innovaKon in\nSystems Engineering\nLecture 6 AxiomaKc\nDesign and DM‐DSM\nMethod\nLecture 8\nTrade Space ExploraKon\nConcept SelecKon\nLecture 10: Experiments\nLecture 11: Robust Design I\nLecture 12: Robust Design II\nLecture 13\nDesign VerificaKon\nand\nValidaKon, Lifecycle\nManagement\n✔\n✔\n✔\n\nLecture Outline\nIntroducKon to AxiomaKc Design\n\nFour domains\n\nAxiom 1--Independence Axiom\n\nDesign Matrix\n\nZigzagging\n\nConstraints\n\nAxiom 2--InformaKon Axiom\nDesign Structure Matrix for Technical\nSystems\nDM--DSM Method\nQi Van Eikema Hommes\n6/24/10\n\nThe Founder of AxiomaKc Design Theory\n-\nNam Pyo Suh--MIT Professor Emeritus.\n-\nB.S., Mechanical Engineering, 1959, M.S., Mechanical Engineering, 1961, MIT\n.\n-\nPh.D, Mechanical Engineering, 1964, Carnegie Mellon University.\n-\nFrom 1965‐1969, Suh served as a professor at the University of South Carolina. In 1970\nhe began his professional career at MIT‐‐ serving as director of the MIT‐Industry\nPolymer Processing Program from 1973‐1984; director of the Laboratory for\nManufacturing and ProducKvity from 1977‐1984; and Mechanical Engineering\nDepartment Head from 1991 to 2001. Although sKll keeping the Ktle of Ralph E.\nCross Professor of Mechanical Engineering at MIT, Suh is now president of KAIST.\nQi Van Eikema Hommes\n6/24/10\n\nThe Goals of AxiomaKc Design\n- Establish a scienGfic basis for design\n- Improve design acKviKes by providing the\ndesigner with a theoreKcal foundaKon based on\nlogical and raGonal thought processes and tools.\n- Make human designers more creaGve\n- Reduce the random search process\n- Minimize the iteraKve trial and error process\n- Determine the best designs among those\nproposed\nQi Van Eikema Hommes\nSuh, Axiomatic Design, 2000, page 5\n6/24/10\n\n- an interplay between what we want\nachieve and how we will achieve it.\nWhat\n6/24/10\nQi Van Eikema Hommes\n\nThe Four Domains of Design\nQi Van Eikema Hommes\n6/24/10\nMapping\nbetwee\nn the f\nour d\nomain\ns.\nImage by MIT OpenCourseWare.\n\nDefiniKons\n- Customer AOribute (CA)--what customer desire\nfrom a product\n- FuncGonal Requirement (FR)--minimum set of\nindependent requirements that completely\ncharacterize the funcKonal needs of the product in\nthe funcKonal domain.\n- Design Parameter (DP)--Key physical variables in the\nphysical domain that characterize the design that\nsaKsfies the specified FRs.\n- Process Variables (PV)--key variables in the process\ndomain that characterize the process that can\ngenerate the specified DPs.\nQi Van Eikema Hommes\n6/24/10\n\nBenefits of the Domains\n- Customer Needs are stated in the customer's\nlanguage\n- FuncKonal Requirements and Constraints are\ndetermined to saKsfy Customer Needs\n- \"The FRs must be determined in a soluKon neutral\nenvironment\" (or, in other words, say \"what\" not\n\"how\")\n- BAD = the adhesive should not peel\n- BETTER = the amachment should hold under the\nfollowing loading condiKons\n- Provide Requirements Traceability\nQi Van Eikema Hommes\n6/24/10\n\nLecture Outline\nIntroducKon to AxiomaKc Design\n\nFour domains\n\nAxiom 1--Independence Axiom\n\nDesign Matrix\n\nZigzagging\n\nAxiom 2--InformaKon Axiom\nDesign Structure Matrix for Technical\nSystems\nDM--DSM Method\nQi Van Eikema Hommes\n6/24/10\n\nAxiom\n- Axioms are truths that cannot be derived but\nfor which there are no counter examples or\nexcepKons.\n- Examples of Axioms:\n- First and second law of thermodynamics\n- Newton's three law of mechanics\nQi Van Eikema Hommes\n6/24/10\n\nHow were the Design Axioms\nCreated?\n- IdenKfying the common elements that are\npresent in all good designs:\n- How did I make such a big improvement in a\nprocess?\n- How did I create the process?\n- What are the common elements in good designs?\n- Use logical reasoning process to reduce the\nobservaKons to two Axioms.\nQi Van Eikema Hommes\n6/24/10\n\nThe Two Axioms\n- Axiom 1: Independence Axiom--maintain the\nindependence of funcKonal requirements\n(FRs).\n- Axiom 2: The InformaGon Axiom--minimize\nthe informaKon content of the design.\nQi Van Eikema Hommes\n6/24/10\n\nMapping\nbetwee\nn the f\nour d\nomain\ns.\nImage by MIT OpenCourseWare.\n\nDesign Matrix\n{FR} = [A] {DP}\nQi Van Eikema Hommes\nFR1\nFR2\nFR3\n\n=\nA11\nA12\nA13\nA21\nA22\nA23\nA31\nA32\nA33\n\n-\nDP1\nDP2\nDP3\n\n6/24/10\n\nDesign Matrix Example\n- FR1 = Provide access to the items\nstored in the refrigerator\n- FR2 = Minimize energy loss\n- DP1 = VerKcally hung door\n- DP2 = Thermal insulaKon material in\nthe door\n6/24/10\nQi Van Eikema Hommes\nFR1\nFR2\n\n= x\nx\nx\n\nDP1\nDP2\n\nSuh, Axiomatic Design, 2000 Image of traditional refrigerator design.\nImage by MIT OpenCourseWare.\n\nA Different Design\n- FR1 = Provide access to the items\nstored in the refrigerator\n- FR2 = Minimize energy loss\n- DP1 = Horizontal door\n- DP2 = Thermal insulaKon material\nin the door\n6/24/10\nQi Van Eikema Hommes\nFR1\nFR2\n\n= x\nx\n\nDP1\nDP2\n\nAlternative refrigerator design with horizontal door.\nImage by MIT OpenCourseWare.\n\nA11\nA22\nA33\n\nA11\nA12\nA13\nA21\nA22\nA23\nA31\nA32\nA33\n\nA11\nA21\nA22\nA31\nA32\nA33\n\nUncoupled\nDesign\nDecoupled\nDesign\nCoupled\nDesign\nFR\nDP\n6/24/10\nQi Van Eikema Hommes\n\nAxiom 1: Independence Axiom\n- To saKsfy the Independence Axiom, the design\nmatrix must be either diagonal or triangular.\nQi Van Eikema Hommes\nA11\nA22\nA33\n\nA11\nA21\nA22\nA31\nA32\nA33\n\nUncoupled\nDesign\nDecoupled\nDesign\n6/24/10\n\nWater Faucet Example\n- FuncKonal Requirements:\n- FR1: Adjust the water temperature (T)\n- FR2: Adjust the water volume (Q)\nQi Van Eikema Hommes\n6/24/10\n\nWhat is the Design Matrix?\nQi Van Eikema Hommes\n6/24/10 Classic example of a water faucet.\nImage by MIT OpenCourseWare.\n\nWhat is the Design Matrix?\nQi Van Eikema Hommes\n6/24/10 Horizontal water faucet.\nImage by MIT OpenCourseWare.\n\nWhat is the Design Matrix?\nQi Van Eikema Hommes\n6/24/10 Modern faucet image.\nImage by MIT OpenCourseWare.\n\nFuncKonal Coupling vs Physical\nCoupling\nQi Van Eikema Hommes\n# of parts = # of DPs\n6/24/10 Image of an open can opener, with a bottle opener at the end of one handle.\nImage by MIT OpenCourseWare.\n\nWhy MeeKng Axiom 1 is\nDesirable?\n6/24/10\nQi Van Eikema Hommes\n\nLecture Outline\nIntroducKon to AxiomaKc Design\n\nFour domains\n\nAxiom 1--Independence Axiom\n\nDesign Matrix\n\nZigzagging\n\nConstraints\n\nAxiom 2--InformaKon Axiom\nDesign Structure Matrix for Technical\nSystems\nDM--DSM Method\nQi Van Eikema Hommes\n6/24/10\n\nZig Zagging\nQi Van Eikema Hommes\n6/24/10\nDi\nagr\nam o\nf zig\n-zaggi\nng bet\nween\nthe\nfunct\nion\nal\nan\nd ph\nysica\nl doma\nins of\ndes\nign.\nImage by MIT OpenCourseWare.\n\nRefrigerator Design Example\n- FR1 = Freeze food for long‐term\npreservaKon\n- FR2 = Maintain food at cold temp for\nshort‐term preservaKon\n- DP1 = the freezer secKon\n- DP2 = the chiller (refrigerator) secKon\nQi Van Eikema Hommes\n6/24/10\nFR1\nFR2\n\n= x\nx\n\nDP1\nDP2\n\nImage of traditional refrigerator design.\nImage by MIT OpenCourseWare.\n\nDecompose the System\nFR1 = Freeze food for long term preservaKon\nFR11 = Control freezer temp\nFR12 = Maintain uniform freezer temp\nFR13 = Control freezer humidity\nFR2 = Maintain food at cold temp for short term preservaKon\nFR21 = Control chiller temp\nFR22 = Maintain uniform chiller temp\nDP1 = The freezer secKon\nDP11 = Sensor/compressor system for freezer secKon\nDP12 = Air circulaKon system for freezer secKon\nDP13 = Condenser that condenses the moisture in the air when dew\npoint is exceeded\nDP1 = The chiller secKon\nDP21 = Sensor/compressor for chiller secKon\nDP22 = Air circulaKon system for chiller secKon\nQi Van Eikema Hommes\n6/24/10\n\nWhat Does The Design Matrix Look Like?\n\nQi Van Eikema Hommes\n6/24/10\nSchematic diagrams of refrigerat\nor cooling\nsys\ntems.\nImage by MIT OpenCourseWare.\n\nDP1\nDP2\nFR1\nFR2\nDP12\nDP11\nDP13\nDP22\nDP21\nFR11\nFR13\nFR22\nFR21\nFR12\n6/24/10\nQi Van Eikema Hommes\n\nCan We Save the Cost of a Fan?\nQi Van Eikema Hommes\n6/24/10\nSchematic designs of a co\nnventional\nref\nrigerato\nr.\nImage by MIT OpenCourseWare.\n\n6/24/10\nQi Van Eikema Hommes\nDP1\nDP2\nDP12\nDP11\nDP13\nDP22\nDP21\nFR1\nFR12\nx\nFR11\nx\nx\nFR13\nx\nx\nFR2\nFR22\nx\nFR21\nx\nx\nX\nX\nX\nX\nCoupled design!\n\nBenefits So Far from Axiom 1\n- Reduce system coupling early on.\n- Start the design with requirements first.\n- Think about the design concept first before\napplying robust engineering or opKmizaKon\nblindly.\n- Zig‐zagging instead of staying in one domain.\n- Requirements traceability and raKonale.\nQi Van Eikema Hommes\n6/24/10\n\nClass Discussions\n- How does Zig‐zagging help design synthesis?\n- How does your organizaKon decompose\nsystems and requirements?\n- Does this help with requirements traceability\nthroughout the design?\n- How does AxiomaKc Design differ from QFD?\nQi Van Eikema Hommes\n6/24/10\n\nLecture Outline\nIntroducKon to AxiomaKc Design\n\nFour domains\n\nAxiom 1--Independence Axiom\n\nDesign Matrix\n\nZigzagging\n\nConstraints\n\nAxiom 2--InformaKon Axiom\nDesign Structure Matrix for Technical\nSystems\nDM--DSM Method\nQi Van Eikema Hommes\n6/24/10\n\nConstraints in AxiomaKc Design\n- Constrant (C)--are bounds on acceptable\nsoluKons. Input constraints are imposed as\npart of the design specificaKon. System\nconstraints are constraints imposed by the\nsystem in which the design soluKon must\nfuncKon.\nQi Van Eikema Hommes\n6/24/10\n\nConstraints\n- Two types of constraints:\n- Input constraints--specific to the overall design\ngoals (all design proposed must saKsfy these).\n- Example: cost\n- System constraints--specific to a given design\n(they are the result of design decisions made).\n- Example: Diesel engine tailpipe emission standards\nfor diesel engines\n- What kind of constraint is Safety?\n6/24/10\nQi Van Eikema Hommes\n\nWhat AxiomaKc Design Says about\nConstraints\n- \"Constraints provide bounds on the\nacceptable design soluKons and differ from\nthe FRs in that they do not have to be\nindependent.\"\n6/24/10\nQi Van Eikema Hommes\n\nLecture Outline\nIntroducKon to AxiomaKc Design\n\nFour domains\n\nAxiom 1--Independence Axiom\n\nDesign Matrix\n\nZigzagging\n\nAxiom 2--InformaKon Axiom\nDesign Structure Matrix for Technical\nSystems\nDM--DSM Method\nQi Van Eikema Hommes\n6/24/10\n\nInformaKon Content\n- InformaKon Content Ii for a given FRi is defined in\nterms of the probability Pi of saKsfying FRi:\nIi = log2(1/Pi)=‐ log2(Pi)\n- When there are m FRs,\nQi Van Eikema Hommes\nIsys = -log2(Pm) = -\nlog2 Pi\ni=1\nm\n∑\n6/24/10\nGrap\nh illustrati\nng system ra\nnge vs. probability\ndensi\nty.\nImage by MIT OpenCourseWare.\n\nAxiom 2 InformaKon Content\n- The InformaKon Axiom--Minimize\ninformaKon content I.\n- Maximize the probability of meeKng FRs.\nQi Van Eikema Hommes\nIsys = -log2(Pm) = -\nlog2 Pi\ni=1\nm\n∑\n6/24/10\n\nExample of Buying a House\nSuh, AxiomaKc Design, 2001\n- FR1: Commute Kme 15 - 30 minutes\n- FR2: Quality of School (65% or more highschool graduates go\nto colleges)\n- FR3: Quality of air is good over 340 days a year\n- FR4: price of house (4 BR, 3000 x^2, less than 650K)\nQi Van Eikema Hommes\nTown\nFR1 =\ncommute\nKme (min)\nFR2=Quality\nof schools (%)\nFR3=Quality\nof air (days)\nFR4=Price($)\nA\n20‐40\n50‐70\n300‐320\n450‐550k\nB\n20‐30\n50‐75\n340‐350\n450‐650k\nC\n25‐45\n50‐80\n350+\n600‐800k\n6/24/10\n\nInformaKon Content CalculaKon\nSuh, AximaKc Design, 2001\nQi Van Eikema Hommes\nTown\nI1 [bits]\nI2 [bits]\nI3 [bits]\nI4 [bits]\nSum (I)\n[bits]\nA\n1.0\ninfinite\nInfinite\nB\n1.32\n1.32\nC\n2.0\n1.0\nI1 = -log2[(30-20) / (40-20)] = -log2(0.5) = 1\nDesign Range\nSystem Range\n6/24/10\n\nAxiom 2 and Robust Design\n- \"The InformaKon Axiom provides a theoreKcal\nfoundaKon for robust design.\"\n- EliminaKon of bias\n- ReducKon of Variance\n- Reduce sensiKvity to variaKon\n- MeeKng the Independence Axiom\n- Minimize random variaKon\n- Increase design range\n- Integrate DP in a single physical part\nQi Van Eikema Hommes\n6/24/10\n\nComparison of AxiomaKc Design\nwith Other Methods (Suh, 2001)\n- Robust design cannot be accomplished by\napplying the Taguchi method if the design\nviolates the Independence Axiom.\n- OpKmizaKon of a bad design may lead to an\nopKmized bad design or minor improvements.\n- How is AxiomaKc Design similar/different from\nQFD?\nQi Van Eikema Hommes\n6/24/10\n\nQuesKons about the Axioms\n- Too good to be true? What about constraints?\n- Are interacKons so bad? That's what makes a\nsystem great!\n- DefiniKon of System‐‐A combinaKon of interacKng\nelements organized to achieve one more stated\npurposes.\nQi Van Eikema Hommes\n6/24/10\n\nLecture Outline\nIntroducKon to AxiomaKc Design\n\nFour domains\n\nAxiom 1--Independence Axiom\n\nDesign Matrix\n\nZigzagging\n\nConstraints\n\nAxiom 2--InformaKon Axiom\nDesign Structure Matrix for Technical\nSystems\nDM--DSM Method\nQi Van Eikema Hommes\n6/24/10\n\nMatrix Representation of a Network\n--The Design Structure Matrix (DSM)\nQi Van Eikema Hommes\nT\nh\ne\n\nd\ne\ns\ni\ng\nn\n\ns\nt\nr\nu\nc\nt\nu\nr\ne\n\nm\na\nt\nr\ni\nx\n.\nImage by MIT OpenCourseWare.\n\n6/24/10\nQi Van Eikema Hommes\nParKKoning a DSM\nBefore Partition\nAfter Partition\nPartitioning identifies truly coupled elements.\nD\ne\ns\ni\ng\nn\n\nm\na\nt\nr\ni\nx\n\ns\nt\nr\nu\nc\nt\nu\nr\ne\ns\n\nb\ne\nf\no\nr\ne\n\na\nn\nd\n\na\nf\nt\ne\nr\n\np\na\nr\nt\ni\nt\ni\no\nn\n.\nImage by MIT OpenCourseWare.\n\n6/24/10\nQi Van Eikema Hommes\nCar Door System Design\nDiagram of\ncomponent syste\nms in car do\nor.\nImage by MIT OpenCourseWare.\n\n6/24/10\nQi Van Eikema Hommes\nCar Door System Engineering Process (Before\nParKKoning DSM)\nSheet Metal\nSubsystem\nMoveable Glass\nSubsystem\nElectrical\nSubsystem\n50+ people system\ninterface engineering\nmeetings\n\n6/24/10\nQi Van Eikema Hommes\nCar Door System Engineering Process\n(Axer ParKKoning)\nBelt and Above Belt Frame\nGlass and Track\nPower and Motion\nElectrical Packaging\n\n4/8/2010\nCopyright Qi D. Van Eikema Hommes\nThe Control Soxware System\n- What can I do about this web of interacKons?\n- How can I convince management that changes are needed?\n- How do I know I actually improved the architecture?\n- 1 production-level software\n- 117 software modules (red dots)\n- 1423 binary interactions (black lines)\n- 39 such production\nsoftware releases\nper year\n- <2 weeks\nper release\n\n4/8/2010\nCopyright Qi D. Van Eikema Hommes\nDSM of the Control System Soxware\n-\nWhat can I do about this web of interactions?\n-\nHow do I know I actually improved the architecture?\n\n4/8/2010\nCopyright Qi D. Van Eikema Hommes\nComparison of Various Modularity Metrics\nUse Whitney Index and\nChange Cost to measure\nmodularity improvements.\nUse network centrality\nindices to identify system\nelements for improvement.\nDETC2008-DTM-49140\n\n4/8/2010\nCopyright Qi D. Van Eikema Hommes\nWhitney Index Comparison\nEmbedded\nSoftware\nSystem A\nEmbedded Software\nSystem B\n\n4/8/2010\nCopyright Qi D. Van Eikema Hommes\nChange Cost Comparison\nObservation: Embedded control software\nsystems are more like hardware systems,\nless like pure software products.\n\n4/8/2010\nCopyright Qi D. Van Eikema Hommes\nNetwork Centrality--Degree Centrality\nIn degree--how many others pass\ninformation to the element of\ninterest.\nOut degree--how many others\ndepend on the element of interest\nfor information.\nDegree Centrality identifies which\nfew elements, if any, in the system\nhave a central effect on the rest of\nthe systems.\nHowever, the metrics values don't\ncorrelate well with components\nmodularity.\n(Sosa, Eppinger, Rowles 2007, Borgatti, Everett, and Freeman, 2002, UCINET)\nM\na\nt\nr\ni\nc\ne\ns\n\na\nn\na\nl\ny\nz\ni\nn\ng\n\nF\nr\ne\ne\nm\na\nn\n\nc\ne\nn\nt\nr\na\nl\ni\nt\ny\n.\nImage by MIT OpenCourseWare.\n\n4/8/2010\nCopyright Qi D. Van Eikema Hommes\nNetwork Centrality\n- Network centrality metrics can idenKfy the few\nelements that have the largest impact on the\nsystem.\n- If the network has central players, the network\nmay be bus‐modular.\n- If the network does not have central player, the\nnetwork system is either not connected, or highly\nintegral.\n- Central players can be the priority for system\ncomplexity reducKon strategy.\n(Sosa, Eppinger, Rowles 2007, Borgatti, Everett, and Freeman, 2002, UCINET)\n\nDSM Method\n- Capture system interacKons\n- Analyze and improve system architecture and\nsystem interfaces.\nQi Van Eikema Hommes\n6/24/10\n\nLecture Outline\nIntroducKon to AxiomaKc Design\n\nFour domains\n\nAxiom 1--Independence Axiom\n\nDesign Matrix\n\nZigzagging\n\nConstraints\n\nAxiom 2--InformaKon Axiom\nDesign Structure Matrix for Technical\nSystems\nDM--DSM Method\nQi Van Eikema Hommes\n6/24/10\n\nExisKng Methods Concerning System\nInteracKons\nDesign\nStructu\nre\nMatrix\n(DSM)\nAxiomatic\nDesign's\nDesign\nMatrix\n(DM)\nRequireme\nnts\nManageme\nnt\nWhat\nWe\nWant\nProvide analytical\nsystem analysis\nYes\nYes\nAllow iterations and\nfeedback loops\nYes\nYes\nRelate the\nrequirements to the\nsystem design\nYes\nYes\nCan be applied in the\nearly design phases\nYes\nYes\nYes\nProvide complete\nunderstanding of all\nrequirements\nYes\nYes\n6/24/10\nQi Van Eikema Hommes\n\nSolving System of Linear EquaKons\nQuestion: 3 * x1 + 5 * x2 = 6\n(1)\n2 * x1 - x2 = 4\n(2)\nWhat is x1 and x2?\nSolving by substitution:\nSelect x1 as the output variable in (1):\nx1 = (6 - 5 * x2 ) / 3\n\nSelect x2 as the output variable in (2):\nx2 = 2 * x1 - 4 = 2 * (6-5*x2)/3 - 4\nx1=2 x2=0\n6/24/10\nQi Van Eikema Hommes\n\nConverKng a DM into a DSM\n1.\nConstruct an Axiomatic\nDesign's Design Matrix.\n2.\nSelect Output Variables.\nDP3 = f (FR1, DP1)\nDP1 = f (FR2, DP2)\nDP2 = f (FR3, DP3)\n3.\nPermute the matrix by row\nso that the output variables\nare on the diagonal. We\nget a precedence matrix\n(DSM) of the Design\nParameters.\n6/24/10\nQi Van Eikema Hommes\nX\nX\nFR3\nX\nX\nFR2\nX\nX\nFR1\nDP3\nDP2\nDP1\nX\nX\nFR3\nX\nX\nFR2\nX\nX\nFR1\nDP3\nDP2\nDP1\nX\nX\nDP3\nX\nX\nDP2\nX\nX\nDP1\nDP3\nDP2\nDP1\n\nSelecKng Output Variables\n6/24/10\nQi Van Eikema Hommes\nDP2\nDP4\nDP3\nDP4\nDP3\nDP2\n\nCVC Cluster Machines\nCentral\nWafer\nHandler\nWafer\nProcessing\nModule\n6/24/10\nQi Van Eikema Hommes\nCourtesy of KDF electronics. Used with permission.\n\nCVC Electro‐staKc Chuck (ESC)\nWafer\nElectro-statically charged\nplate\nCooling Plate\nPlate for interface with\nvarious process\nmodules\nStandard interface on all\nprocess modules\nBackside Gas,\nCooling Water,\nElectricity\nProcess Chamber\nBackside gas channel\nESC\n6/24/10\nQi Van Eikema Hommes\n\nSystem View of ESC\n6/24/10\nQi Van Eikema Hommes\nProcess\nModule\nProcess\nModule\nProcess\nModule 3\nProcess\nModule\nWafer\nTransport\nRobot\nControl\nand\nLogistics\nWafer Processing\nCluster Machine\nESC\nESC\nESC\nESC\n\nDesign Structure Matrix Built from\nDesign Matrix\nHeat Transfer\nPackage the ESC into the\nExisting Process Modules\nControl Circuit\nDesign\nHeat Transfer\nPackaging into the\nModules\nControl Circuit\n6/24/10\nQi Van Eikema Hommes\n\nThe SelecKon of Output Variables\nChoosing non-diagonal elements in\nthe DM as output variable set is like\ndesigning components not for their\nmain functional purposes, but for their\nside effects. The resulting DSM is a\nnon-executable design process.\n6/24/10\nQi Van Eikema Hommes\n\nThe SelecKon of Output Variables\n6/24/10\nQi Van Eikema Hommes\nDP1 = 1/0.75 * ! FR1 - 0.2/0.75* DP2\nDP2 = 1/0.9 * ! FR2 - 0.2/0.9 * DP1\nEigen Value = 0.243\nThis process converges.\nEigen Value = 4.1\nThis process does NOT converge.\nDP1 DP2\nFR1 0.75 0.2\nFR2 0.2\n0.9\nDP1\nDP2\nDP1\n0.2/0.75\nDP2\n0.2/0.9\nDP1 DP2\nFR1 0.75 0.2\nFR2 0.2\n0.9\nDP1 = 1/0.2 * ! FR1 Ð 0.75/0.2*\nDP2\nDP2 = 1/0.2 * ! FR2 - 0.9/0.2* DP1\nDP1\nDP2\nDP1\n0.75/0.2\nDP2\n0.9/0.2\nΔ\nΔ\nΔ\nΔ\nΔ\nΔ\nΔ\nΔ\nΔ\nΔ\nΔ\nΔ\nΔ\nΔ\nΔ\nΔ\n\nThe Interchangeability of DM and DSM\nDM\nDSM\nThe diagonal elements in the DM are the\ndominant elements in their corresponding\nrows.\n6/24/10\nQi Van Eikema Hommes\n\nJohnson and Johnson Ortho‐Clinical\nDiagnosKcs OASIS Analyzer\n6/24/10\nQi Van Eikema Hommes\nImage of Vitros 5.1 cluster removed due to copyright restrictions.\n\nOASIS Major Subsystems\nMachine Control\n(MACO)\nApplication\nServices (APPS)\nSample\nHandling\n(SAHA)\nPower\nDistributio\nn (POWR)\nPrimary\nSample\nMetering\n(SRME)\nReagent\nSupply\n(RGSU)\nSecondary\nSample\nMetering\n(SRME)\nFrame and\nCabinetry\n(STRU)\nCuvette\nIncubator\n(CUIN)\nAliquot\nBuffer\n(ALBU)\nSlide\nIncubator\n(SLIN)\nPhotometer\n(PHMT)\nMicrotip\nLoading\n(MTLD)\nSample\nIntegrity\n(SAIN)\nVitros Tips\nLoader\n(VTLD)\nSlide\nSupply\n(SLSU)\n6/24/10\nQi Van Eikema Hommes\n\nCase Study ObjecKves\n1. Build a DSM from requirements using the DM‐\nDSM conversion method;\n2. Compare the resulKng DSM with the DSM\nexperts built using tradiKonal DSM construcKon\nmethod.\n3. Understand which types of requirements can be\nused to predict system interacKons. Judge\nwhether the predicKon DSM is complete.\n4. Aid the system integraKon manager's work on\nplanning and managing OASIS subsystem\ninterfaces.\n6/24/10\nQi Van Eikema Hommes\n\nDSM Constructed from Requirements\n6/24/10\nQi Van Eikema Hommes\n\nCompare Requirements DSM with Expert DSM\nSystem Interactions Predicted by DSM from requirements.\nSystem Interactions Predicted by JNJ engineers.\nSystem Interactions Predicted by both the requirements and JNJ engineers.\n6/24/10\nQi Van Eikema Hommes\n\nHow Many Marks Match\n6/24/10\nQi Van Eikema Hommes\nThere are 54 marks captured by\nboth the experts DSM and the\nDSM from requirements.\nThe requirements\nprediction DSM\nmissed 118\ninteractions captured\nby the experts.\nThe experts did not\ncapture 75 interfaces\npredicted by the\nrequirements.\n\nAnalyzing the Unmatched Marks\n6/24/10\nQi Van Eikema Hommes\n\nThe Achievable PotenKal\nProviding:\n- JNJ engineers involve soxware engineers in the\nDSM building exercise\n- Chemists write assay requirements\n- JNJ updates the trace‐ability between product\nlevel requirements and subsystem level\nrequirements\n6/24/10\nQi Van Eikema Hommes\nJNJ experts miss\n6 marks.\nDSM from\nrequirements misses\n26 marks.\n\nLimitaKon of the Method\nCan all requirements be decomposed to\npredict system interactions?\n6/24/10\nQi Van Eikema Hommes\nRequirements\nDM\nDSM\n\nRequirements DecomposiKon\nCan predict system\ninteractions\nCannot predict\nsystem interactions\nCan be decomposed\nin the same way as\nthe FR's in the\nAxiomatic Design\n\nFunctional,\nMaintainability,\nOperational,\nEnvironment\nExpandability,\nAppearance\nNone\nCan be decomposed\nbut not in the same\nway as\ndecomposing the\nFR's in the\nAxiomatic Design\nPerformance\n(Modeling)\nPackaging (DFC, DSM)\nDesign Constraints\n(DSM)\nReliability (budgeting)\nSize (budgeting)\nWeight (budgeting)\nCost (budgeting)\nDifficult to\ndecompose\nNone\nInstallation\nStandards\nSafety\nDFMAS\nComponent Reuse\nOperability\nShipping\nNo strong evidence\nin this case study\nDisposal\nDistribution\nTraining\nBudget and Timing\nPatents\n6/24/10\nQi Van Eikema Hommes\n\nComparison of the Three Methods\nAxiomaKc Design\nMatrix (DM)\nUncoupled\nDesign\nDecoupled\nDesign\nDM - DSM\nReduce the amount of\ncoupling through\ngood design.\nManage the inevitable\ncoupling when a\ncoupled design\nmakes more\nbusiness sense.\nDSM shows the\nbottleneck in systems\nand ultimately drive\npeople toward\nAxiomatic Design\npreferred results.\nDSM\nAvoids coupling by\nsmart engineering\ndesign.\nAccepts coupling and\nmanage it by\nstreamlining the\nprocess, or\nmodularizing the\nsystem architecture.\n6/24/10\nQi Van Eikema Hommes\nD\ne\ns\ni\ng\nn\n\nm\na\nt\nr\ni\nx\n\ns\nt\nr\nu\nc\nt\nu\nr\ne\ns\n\na\nf\nt\ne\nr\n\np\na\nr\nt\ni\nt\ni\no\nn\n.\nImage by MIT OpenCourseWare.\nX\nX\nX\nX\nX\n\nSummary of DM‐DSM Method\n- We can get a DSM from a DM\n- The diagonal elements are the output\nvariables in matrix conversion\n- Not all system interacKons can be predicted\nfrom DM\n- Coupled design can be managed and\nimproved using DSM.\n- Do think about reducing system coupling by\nexploring alternaKve design concepts first.\nQi Van Eikema Hommes\n6/24/10\n\nLecture Summary\nIntroducKon to AxiomaKc Design\n\nFour domains\n\nAxiom 1--Independence Axiom\n\nDesign Matrix\n\nZigzagging\n\nAxiom 2--InformaKon Axiom\nDesign Structure Matrix for Technical\nSystems\nDM--DSM Method\nQi Van Eikema Hommes\n6/24/10\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nESD.33 Systems Engineering\nSummer 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Systems Engineering as a Human Activity",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-33-systems-engineering-summer-2010/e0fd3c785c2d27e3d9599172487e016f_MITESD_33SUM10_lec02.pdf",
      "content": "ESD.33 Systems Engineering\nLecture 2\nSystems Engineering as a Human\nAc2vity\nQi Van Eikema Hommes\n\nLecture Topics\nRole of Human in Systems Engineering\nThe Human Cogni2ve Limita2on\nChallenges facing organiza2ons designing\nlarge systems\nChallenges facing systems engineers\nIntroduc2on to Automo2ve Powertrain\nSystem\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nSystems Engineering is a Human Ac2vity\n- Users*\n- Designers--Focus of this lecture*\n- Manufacturer*\n- Part of the system of systems\n* Baldwin, C., and K. Clark, Design Rules, The MIT Press, 2000.\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nHuman as Users of Systems\nNot the Focus of this Lecture\n- Clip from the Modern Times.\nhcp://www.youtube.com/watch?\nv=AvNQiF89Pek&feature=related (un2l 3'32\")\n- Stakeholder needs analysis, requirements development\n- Will discuss in the next lecture\n- User interface design / Human‐machine interface design\n- Not the focus of this class.\n- Professor Missy Cummings\n- 16.400 Human Factors Engineering\n- 16.422J Human Supervisory Control of Automated\nSystems\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nHuman as Manufacturers of Systems\nNot the Focus of this Lecture\n- Clip from the Modern Times.\nhcp://www.youtube.com/watch?\nv=AvNQiF89Pek&feature=related (star2ng at about\n4')\n- Taylorism\n- Henry Ford's Assembly Line\n- Toyota Produc2on System\n- 2.810 Manufacturing Process and Systems\n- 2.852 Manufacturing Systems Analysis\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nSystems Engineering is a Human Ac2vity\n- Users*\n- Designers--Focus of this lecture*\n- Manufacturer*\n- Part of the system of systems\n* Baldwin, C., and K. Clark, Design Rules, The MIT Press, 2000.\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nLecture Topics\nRole of Human in Systems Engineering\nThe Human Cogni2ve Limita2on\nChallenges facing organiza2ons designing\nlarge systems\nChallenges facing systems engineers\nIntroduc2on to Automo2ve Powertrain\nSystem\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nInput\nInformation\nTransmitted\nInformation\nInformation Theoretical View\n(c) June 10, 2010\nQi Van Eikema Hommes\n\nThe Limita2on of Human Cogni2on\nMiller, G. A. (1956), \"The Magic Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Informa2on.\" The\nPsychological Review, Vol. 63, pp81‐97.\nQi Van Eikema Hommes\nInput Information = log2(number of distinctive categories)\nChannel Capacity of a Human Listener\n(c) June 10, 2010\nCourtesy of American Psychological Association. Used with permission.\n\nThe Magic Number Seven\n- The Span of Absolute Judgment is the\naccuracy with which we can iden2fy\nabsolutely the magnitude of a unidimensional\ns2mulus variable.\n- The span of absolute judgment and the span\nof immediate memory impose severe\nlimita2on on the amount of informa2on that\nwe are able to receive, process, and\nremember.\n-\nMiller, G. A. (1956), \"The Magic Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Informa2on.\"\nThe Psychological Review, Vol. 63, pp81‐97.\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nComplexity is Related to Human\nCogni2ve Limita2on\n- Class Discussion:\nWhen Do You Start Calling Something\nComplex?\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nComplexity\n- The point at which an ar2fact can no\nlonger be\n- made by a single person\n- Comprehended by a single person\nQi Van Eikema Hommes\nSimple\nComplex\nBaldwin, C., and K. Clark, Design Rules, The MIT Press, 2000.\n(c) June 10, 2010\n\nComplexity and Systems Engineering\n- Complexity calls for\n- Division of labor\n- Division of knowledge and effort that\ngo into crea2ng a design\nQi Van Eikema Hommes\nBaldwin, C., and K. Clark, Design Rules, The MIT Press, 2000.\n(c) June 10, 2010\n\nTopics\n\nRole of Human in Systems Engineering\n\nThe Human Cogni2ve Limita2on\nChallenges facing organiza2ons designing\nlarge systems\n\nChallenges facing systems engineers\n\nIntroduc2on to Automo2ve Powertrain\nSystem\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nFord Product Development\nOrganiza2on Breakdown\nSource: Michelle Sackas, A Systems Engineering Approach to Improve Vehicle NVH AHribute Management.\nMIT SDM Thesis, 2008.\nQi Van Eikema Hommes\n(c) June 10, 2010\n\n(c) June 10, 2010\n\"Classical Project Organiza2ons\"\nOli de Weck, ESD.36 Lecture 5\n- Dedicated Project Organiza2on\n- Team members work 100% for the project\n- Empowered project manager\n- Organiza2onally recognized unit for a certain 2me\n- Matrix Organiza2on\n- Project manager has tasking and budget authority\n- Line manager has func2onal authority, promo2ons\n- Team members remain in their func2onal organiza2ons (have 2 bosses)\n- Poten2al for conflicts\n- Influence (Func2onal) Project Organiza2on\n- Weakest form of project organiza2on\n- \"func2onal\" organiza2on, workers are \"on loan\" to project\n- Project coordinator, but has no budget or tasking authority\nQi Van Eikema Hommes\nCourtesy of Oliver de Weck. Used with permission.\n\nCEO\nPM\nDiv1\nDiv2\nDiv3\nInfluence PO\nGM\nPMs\nPM\nPM\nFM\nFM\nFM\nPM\nMatrix PO\nPM\nTL1\nTL2\nTL3\nStaff\nProject\nCustomer\nSteering\nCommittee\nDedicated PO\nPO = Project Organization\nCEO = chief executive officer\nGM = general manager\nPM = project manager\nFM = functional manager\nTm= Team Leader\nOrganizational Charts\nOli de Weck, ESD.36 Lecture 5\nQi Van Eikema Hommes\nCourtesy of Oliver de Weck. Used with permission.\n\nDo You Need an Introduc2on to\nDesign Structure Matrix (DSM)?\n\nQi Van Eikema Hommes\n(c) June 10, 2010\nThis image is in the public domain and can be found at wikipedia.org\n\n(c) June 10, 2010\nQi Van Eikema Hommes\nCar Door System Design\nDiagram of\ncomponent syste\nms in car do\nor.\n\n(c) June 10, 2010\nQi Van Eikema Hommes\nCar Door System Engineering Process (Before\nPar22oning DSM)\nSheet Metal\nSubsystem\nMoveable Glass\nSubsystem\nElectrical\nSubsystem\n50+ people system\ninterface engineering\nmeetings\n\nProbability of Communica2on vs. Distance\nQi Van Eikema Hommes\nAllen, T., 1997. Architecture and Communication among Product Development Engineering, Sloan Working Paper 3983, 1997.\n(c) June 10, 2010\n\nProbability of Communica2on Across\nOrganiza2onal Boundary\nQi Van Eikema Hommes\nAllen, T., 1997. Architecture and Communication among Product Development Engineering, Sloan Working Paper 3983, 1997.\n(c) June 10, 2010\n\nThe Rework Cycle\nDelay!\nESD.36 Lecture 3 Fall 2009\n(c) June 10, 2010\nQi Van Eikema Hommes\nCourtesy of James Lyneis. Used with permission.\n\nChanges (and management responses) create rework ...\nSo, What Happens on Projects?\nESD.36 Lecture 3 Fall 2009\n(c) June 10, 2010\nQi Van Eikema Hommes\nCourtesy of James Lyneis. Used with permission.\n\nQi Van Eikema Hommes\nPat Hale, ESD.33, Summer 2009\n(c) June 10, 2010\n\nThe Goal of Good Systems\nEngineering Efforts\n- Address system integra2on issues as early as\npossible, and reduce late rework.\n- Good understanding of the system interac2ons\n- Good coordina2on among organiza2ons\nQi Van Eikema Hommes\n(c) June 10, 2010\n\n(c) June 10, 2010\nQi Van Eikema Hommes\nCar Door System Engineering Process (Ater\nPar22oning)\nBelt and Above Belt Frame\nGlass and Track\nPower and Motion\nElectrical Packaging\n\nTwo Types of Itera2ons\nPlanned Itera2on\n- Caused by needs to \"get it\nright the first 2me.\"\n- We know where these\nitera2ons occur, but not\nnecessarily how much.\n- Planned itera2ons should\nbe facilitated by good\ndesign methods, tools,\nand coordina2on.\nUnplanned Itera2on\n- Caused by errors and/or\nunforeseen problems.\n- We generally cannot\npredict which unplanned\nitera2ons will occur.\n- Unplanned itera2ons\nshould be minimized.\n(c) June 10, 2010\nQi Van Eikema Hommes\n\nMapping Out Deliverables in a PD\nProcess\nQi Van Eikema Hommes\n\nHow Many Interfaces Were Truly\nUnderstood?\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nCourtesy of Antoine D. Guivarch. Permission for use granted to MIT.\n\nComplexity and Systems Engineering\n- Complexity calls for\n- Division of labor\n- Division of knowledge and effort that\ngo into crea2ng a design\nQi Van Eikema Hommes\nBaldwin, C., and K. Clark, Design Rules, The MIT Press, 2000.\n(c) June 10, 2010\n\nHow Well System Level Knowledge is\nDocumented (Ford Throcle Body Design)\nFord Throttle Body Data\n(c) June 10, 2010\nQi Van Eikema Hommes\n\nHow Well Companies Document System Level\nKnowledge (Based on Three Case Studies)\n(c) June 10, 2010\nQi Van Eikema Hommes\n\nQi Van Eikema Hommes\nSystem Interface Requirements\nReconcilia2on\n- System Interface Requirements are requirements\nwhose fulfillment involve mul2ple subsystems.\nNot all subsystems involved own the requirement.\n- Example: The Oxygen sensor must reach degrees\nbefore closed‐loop engine control starts. Required of\nCalibra2on, by Powertrain Electrical System. Owned by\nPowertrain Electrical System.\n- Interface requirements reconcilia:on requires\nagreement among mul2ple subsystem\nrequirement authors who may not have the same\ninterest.\n(c) June 10, 2010\n\nQi Van Eikema Hommes\nProject Objec2ves\n- Discover the true workload associated with\ninterface requirements reconcilia2on so as to:\n- correctly report the progress made.\n- make correct staffing decisions.\n- bridge the understanding between the\nrequirement authors and the managers.\n(c) June 10, 2010\n\nQi Van Eikema Hommes\nWhat Would You Do?\n- Assume you are an engine subsystem\nmanager. How would you es2mate how\nmuch workload there is in your engine\nsubsystem requirements document?\n(c) June 10, 2010\n\nQi Van Eikema Hommes\nAn Example of a Resul2ng DSM\n(c) June 10, 2010\n\nQi Van Eikema Hommes\nThe DSM view of the Three Responsibili2es\n(c) June 10, 2010\n\nQi Van Eikema Hommes\nResults\n- Verified the findings with requirements authors.\n- Proposed improvements on the exis2ng workload accoun2ng\nsystem, and the improvements were accepted by the\nrequirement authors and their manager.\n- Provided Ford engineers and managers a mental model and a\nvocabulary to understand the workload associated with\ninterface requirement reconcilia2on.\n- Summarized the current requirement reconcilia2on status\namong major PT subsystems.\n- Iden2fied areas in the exis2ng PT requirements that need to\nbe improved.\n(c) June 10, 2010\n\nWhat have We Learned So Far?\n- Large organiza2ons are needed to design large\nsystems.\n- Organiza2on boundaries causes inefficiency in\ndesign informa2on flow.\n- System design knowledge is dispersed across\norganiza2on in a tacit form.\n- Managing the system design requires insights\ninto the system interac2ons and their\nramifica2ons.\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nWhat DSM can Help with?\n- Map out interac2ons\n- Get people actually talking to one another\n- Guide work process\n- Knowledge management\n- Should be vs As‐is interac2ons (DSM exercises\nhelp with the understanding of how the team\nshould work together)\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nClass Discussion Topics\n- How do systems architecture design\nand modularity help?\n- What about globaliza2on of\nengineering efforts? What is the\nimpact?\n- What is the value of systems\nengineering?\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nTopics\n\nRole of Human in Systems Engineering\n\nThe Human Cogni2ve Limita2on\nChallenges facing organiza2ons designing\nlarge systems\n\nChallenges facing systems engineers\n\nIntroduc2on to Automo2ve Powertrain\nSystem\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nComplexity and Systems Engineering\n- Complexity calls for\n- Division of labor\n- Division of knowledge and effort that go into\ncrea2ng a design\n- System engineers have to work with:\n- A lot of people\n- Different kinds of people\n- People from different func2ons\n- People from different disciplines\n- ...\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nSystems Engineering is about\nWorking with People\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nThe Interdisciplinary Nature of SE\n- Must know many things, but don't have to be\nthe expert in every field.\n- Must work with many people in different org\nand from different disciplines.\n- Exci2ng and challenging at the same 2me.\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nQBQ--Ques2on behind the\nQues2on\n- Making becer choices by asking becer\nques2ons.\n- Begin with \"What\" or \"How\" (not \"Why\", \"When\",\nand \"Who\").\n- Contain and \"I\" (not \"they\", \"them\", \"we\", or\n\"you\")\n- Focus on ac2on\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nQBQ Class Exercises\n- Why didn't they tell me they have changed the\ndesign?\n- Why aren't they wri2ng proper requirements?\n- Why don't customers follow instruc2ons?\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nQBQ Class Exercises\n- When will they take care of the problem?\n- When are they going to give us the answer?\n- When are we going to get becer sotware for\nthis?\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nQBQ Class Exercise\n- Who dropped the ball?\n- Who made these mistakes?\n- A poor sailor blames the wind.\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nDale Carnegie Principles\nGain the Willing Coopera2on of Others\n1. Get The Other Person Saying \"Yes, Yes\" Immediately.\n2. Try Honestly To See Things From The Other Person's\nPoint Of View.\n3. Be Sympathe2c With The Other Person's Ideas And\nDesires.\n4. Appeal To The Nobler Mo2ves.\n5. Drama2ze Your Ideas.\n6. Throw Down A Challenge\n(c) June 10, 2010\nQi Van Eikema Hommes\n\nMaking the Short Talk to Get Ac2on\n1. Give your example, an incident from your life.\n- Build your example upon a single personal\nexperience\n- Start your talk with a detail of your example\n- Fill your example with relevant details\n- Relive your experience as you relate it\n2. State your point with force and convic2on\n3. Give the reason or benefit the audience may\nexpect\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nClass Exercise for Making a Short\nTalk to Get Ac2on\n\nWhat Kind of Inter‐personal\nCommunica2on Method has\nWorked for You?\nClass Discussion\n\nGentry Lee's Cri2cal Behaviors of\nSystems Engineering\n(c) June 10, 2010\nQi Van Eikema Hommes\nIntellectual Curiosity -\nability and desire to learn\nnew things\nwide connec:ons\nAbility to make system‐\nComfortable with\nuncertainty and\nunknowns\nProper Paranoia - expect\nthe best, but plan for the\nworst\nStrong team member and\nleader\nSelf Confidence and\nDecisiveness - short of\narrogance\nto stop\nrigor and knowing when\nApprecia:on for Process -\nCommunicator\nExcep:onal Two‐way\ntechnical judgment\nDiverse Technical Skills -\nability to apply sound\nComfortable with change\ndetails\nPicture - yet get into the\nAbility to See the Big\nEngineer\na Good Systems\nCharacteris:cs of\nBehavioral\n\nSummary\n- Human needs is the mo2va2on for developing\nlarge complex systems.\n- Human limita2on is the cause of the many\nchallenges in the development of large\ncomplex systems.\n- System engineering is about understanding\nand managing the human ac2vity of the\ndesign and development of large systems\n- Organiza2on design and management\n- Individual system engineers' development\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nTopics\n\nRole of Human in Systems Engineering\n\nThe Human Cogni2ve Limita2on\nChallenges facing organiza2ons designing\nlarge systems\n\nChallenges facing systems engineers\n\nIntroduc2on to Automo2ve Powertrain\nSystem\nQi Van Eikema Hommes\n(c) June 10, 2010\n\nIntroduc2on to Automo2ve\nPowertrain System\n\nReference Book\n-\nInternal Combus2on Engine\nHandbookBasics, Components,\nSystems, and Perspec:vesAUTHORs:\nRichard Van Basshuysen, Fred\nSchaefer\n-\nPublished By: SAE Interna2onal and\nProfessional Engineering\nPublishingPublished: December\n2004Pages: 868Binding:\nHardboundProduct Code:\nR‐345Product Status: Available\nQi Van Eikema Hommes\n(c) June 10, 2010"
    },
    {
      "category": "Resource",
      "title": "Requirements Engineering Part 1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-33-systems-engineering-summer-2010/1292005d75bbb1badef7f9416fca2a1d_MITESD_33SUM10_lec04a.pdf",
      "content": "ESD.33 -- Systems Engineering\nSession #4\nRequirements Engineering\nPat Hale\n\nAs stated in ISO/IEC 15288:2008: The purpose of the\nStakeholder Requirements Definition Process is to define\nthe requirements for a system that can provide the\nservices needed by users and other stakeholders in a defined\nenvironment. It identifies stakeholders, or stakeholder\nclasses, involved with the system throughout its life cycle,\nand their needs, expectations, and desires. It analyzes\nand transforms these into a common set of stakeholder\nrequirements that express the intended interaction\nthe system will have with its operational environment and\nthat are the reference against which each resulting operational\nservice is validated\nPurpose\n\nWhat is the RE Process?\nINCOSE Systems Engineering Handbook version 3.2 January 2010\nFlowch\nart of the Require\nments Engineering pr\nocess.\nImage by MIT OpenCourseWare.\n\nWhy 'Engineer' Requirements?\n- Provide early assurance that all top-level requirements are\nfully satisfied in the product, with traceability to where they\nare satisfied.\n- Prevent unintentional addition of cost (avoid 'gold plating').\n- Establish clear responsibility for requirements\nimplementation.\n- Provide clear visibility across teams into requirements\nallocation and cross-functional interactions.\n- Easily and quickly assess the impact of changes to\nrequirements.\n- Provide data for early and thorough validation and\nverification of requirements and design artifacts.\n- Avoid unpleasant downstream surprises!\n\nRequirements Management\n-\nSystem/Product needs are captured from the market, business\nstrategy, customers and other sources.\n-\nRequirements are synthesized from captured needs and the\nmeanings and interpretations are validated with the original sources.\n-\nCommitment to requirements is obtained from management and\nproject personnel.\n-\nA history of changes and change rationale is maintained as\nrequirements evolve.\n-\nBi-directional traceability is maintained among requirements, project\nplans and work products.\n-\nInconsistencies are identified and resolved among requirements,\nproject plans and work products.\nRequirements Management is the process by which:\n\nWhat is a Requirement?\n- Well-stated requirements exhibit the following\nattributes:\n- The requirement is Necessary\n- What would happen if you didn't include this requirement?\n- The requirement is Verifiable\n- How will you know you have met the requirement?\n- The requirement is Attainable\n- Requirements are concise and unambiguous\n- Good requirements are solution-neutral\n- Requirements are consistent (non-contradictory)\n\nRequirements Semantics\n- Requirements use 'shall'\n- The system shall provide...\n- The system shall be capable of...\n- The system shall weigh...\n- Statements of fact use 'will'\n- Often part of a lead-in scenario prefacing one or more\nrequirements\n- Goals use 'should'\n- Used for design goals where quantifiable\nrequirements cannot be applied to a desired attribute\n\nSummary: Attributes of Good Requirements\n- What...not how\n- Unambiguous, clear and complete\n- Verifiable by test or independent analysis\n- Necessary and appropriate for system\nhierarchy level\n- Feasible\n- Consistent (traceable) with requirements\nabove and below in the system hierarchy\n\nRequirements Baselines\nINCOSE Systems Engineering Handbook version 3.2 January 2010 The requirements baselines vee.\nImage by MIT OpenCourseWare.\n\nConcept\nDesign\nOptimize\nSub-\nSystems\nOptimize\nSystem\nVerify\nProduct\nDesign\nVerify\nProduction\nProcess\nProduct Commercialization\nPhases 1-6:\n\nRequirements Baselines in CDOV\nVOC\n1- Initial baseline\n\n4- Allocated baseline (PAS)\n2- Validated baseline (Contract)\n5- Component baseline\n3- System functional baseline (PFS) 6- Verified product baseline\nFRS\n\nSystem Life Cycle\nConceptual Design\nPreliminary Design\nDetail Design\nand Development\nProduction/\nConstruction\nOperational Use\nand System Support\nRet.\nNeed Identification: Requirements Analysis;\nOperational Requirements; Maintenance and\nSupport Concept; Evaluation of Feasible\nTechnology Applications; Selection of Technical\nApproach; Functional Definition of System:\nSystem/Program Planning\nFunctional Analysis; Requirements\nAllocation; Trade-off Studies; Synthesis;\nPreliminary Design; Test and Evaluation of\nDesign Concepts (Early Prototyping);\nAcquisition Plans; Contracting; Program\nImplementation; Major Suppliers and\nSupplier Activities\nSubsystem/Component Design; Trade-off\nStudies and Evaluation of Alternatives;\nDevelopment of Engineering and\nPrototype Models; Verification of\nManufacturing and Production Processes;\nDevelo0pmental Test and Evaluation;\nSupplier Activities; Production Planning\nProduction and/or construction of\nSystem components; Supplier\nProduction Activities; Acceptance\nTesting; System Distribution and\nOperation; Developmental/Operational\nTest and Evaluation; Interim Con-\ntractor Support; System Assessment\nSystem Operation in the User\nEnvironment: Sustaining Maintenance\nand Logic Support; Operational Testing;\nSystem Modifications for Improvement;\nContractor Support; System\nAssessment (Field Data Collection and\nAnalysis)\nSystem/Program Milestones\nMilestone I\nFunctional Baseline\nMilestone II\nAllocated Baseline\nMilestone III\nProduct Baseline\nMilestone IV\nUpdated Product Baseline\nSystem Specification\n(TYPE A)\nDevelopment, Process, Product, Material\nSpecifications (TYPES B, C, D and E)\nProcess/Product, Material\nSpecifications (TYPES C to E)\nSystem Management Plan\nSystem Engineering Management Plan (SEMP)\nTest and Evaluation Master Plan (TEMP)\nConceptual Design Review (System Requirements Review)\nSystem Design Review\n\nEquipment/Software Design Reviews\n\nCritical Design Review\nSystem Engineering Requirements\nRequirements Analysis\nFunctional Analysis\nN\nE\nE\nD\nRequirements Allocation\nTrade-Off Studies\nSynthesis\nEvaluation\nType A\nSpecification\nDesign\nReview's)\nSystem Level\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nRefined Functional Analysis\nRefined Requirements\nAllocation\nDetailed Trade-Off\nStudies\nSynthesis (CI)\nEvaluation\n(Engineering Models)\nType B\nSpecification\nDesign\nReview's)\nSubsystem Level\n1.1\n1.2\n1.3\n1.4\n1.5\n1.6\n1.7\nDetailed Design\nDetailed Synthesis\nEvaluation (Prototype\nModels)\nTypes B to E\nSpecifications\nDesign\nReview's)\nComponent Level\n2.1\n2.2\n2.3\n2.4\n2.5\n2.6\nProposed Design\nModification's)\nSynthesis of\nModification\nPrototype\nModifications\nTest and Evaluation\n(Production Model)\nConfiguration\nItem Reviews\n3.1\n3.2\n3.3\n3.4\n3.5\n3.6\nR\nE\nT\nI\nR\nE\nM\nE\nN\nT\nfeedback\nfeedback\nModifications for Improvement\nIncorporation of\nModification's)\nProposed Design\nModification's)\nSynthesis of\nModification\nPrototype\nModifications\nTest and Evaluation\n(Operational Model)\nSystem Evaluation\n(Field Assessment\n4.1\n4.2\n4.3\n4.4\n4.5\n4.6\nModifications for Improvement\nIncorporation of\nModification's)\nfeedback\nfeedback\nfeedback\nAdapted from Systems Engineering lecture slides at University of Witwatersrand, Johannesburg, South Africa (Dr. R. Siriram)\n\nRequirements Hierarchy & Traceability\nSource Needs\nCritical Issue\nDecision\ndocuments\nsatisfied by\nallocated to\ngenerates\ntraces to\ntraces to\nincorporates\nincorporates\nOriginating\nRequirement\nFunction\nSubsystem\ndecomposed\nfrom\nValidation\nRequirement\nTest Method\n& Criteria\nAssembly\nbuilt from\nComponent\nbuilt from\nintegrates to\nVOC\nContract\nRequirements\nAnalysis &\nConcept Trades\nPFS\nSubsystem &\nComponent\nDesign\nSystem\nFunctional Design\nDetailed\nDesign\nANALYSIS\nCYCLE\nAllocation\nPAS\nLevel 4\n:\n:\nintegrates to\n\nExisting Documents\nDOORS (Requirements)\n\nDOORS (Test)\nVOC/Business Plan\nSystem HOQ\nSystem Requirements\nSubsystem\nAllocation\nSubsystem Design Req'ts\nSystem\nRequirements\nSpec\nSystem\nMaster Test\nPlan\nAllocated\nSystem Req'ts\nss1\nss2\nss(n)\nss1\nss2\nss(n)\nPrimary Requirements Flow\nReport Generation\nTest Linkages\nDesign Artifacts\nTest Procedures\nSystem\nIntegration\nTest Cases\n(Subsystem Test Cases)\n(Updates)\n(Baseline)\nThe requirement is Verifiable\n\nRequirements Change Authority\nVOC\nContract\nRequirements\nAnalysis &\nConcept Trades\nPFS\nSubsystem &\nComponent\nDesign\nSystem\nFunctional Design\nAllocation\nPAS\nLevel 4\n:\nDetailed\nComponent/Part\nSpecifications\nPre-PAS:\n- Changes/new requirements proposed by any\ndevelopment team member\n- Review by Systems team and other\nStakeholders (e.g. PMT members) as\nrequired\n- Approval by Systems team/Chief Systems\nEngineer\nPost-PAS:\n- Changes/new requirements proposed by any\ndevelopment team member\n- Review by Subsystem team with appropriate\nrepresentation from other affected teams\n- Decision by Subsystem team leader with\nprimary design responsibility\n- Weekly review of changes and change\nproposals by Systems team\nBaseline\n\nJW, Cons.\nLD\nJW, SS, Cons.\nJC\nJW, SS, KH,\nCons.\nJW, DD, Mkt,\nTest\nNGD Team\nImplementation Plan\n-\nPropose Draft RM process\n-\nSelect DOORS versions, obtain\ntraining\n-\nDevelop requirements schema for\nRM & CPM (link, no common schema)\n-\nReview and Approve Change\nReview Process\n-\nReview/Import existing\nrequirements, refine to meet RM\ncriteria\n-\nCertify PFS baseline in DOORS\n-\nFull process implementation\n-\n10/31/2003\n-\n11/3/2003\n-\n11/12/2003\n-\n11/17/2003\n-\n12/28/2003\n-\n1/10/2004\n-\n1Q04\nTask Description\n\nWho?1\nTarget Date\n\nSystem-level Implementation\n(Example from a backup tape drive project)\n\nDocuments to DOORS Modules\nDocuments to\nDOORS Modules\nImage by MIT OpenCourseWare.\n\nNGD Doors Directory Structure\nNGD\nDO\nORS di\nrectory s\ntru\nct\nur\ne.\nImage by MIT OpenCourseWare.\n\nFormatting PAS in Word\nfor Export into Doors\nKeep heading styles in the following form:\nHeading 1, Heading 2, Heading 3, ...,etc.\nNotes:\n- Framemaker documents use Sec-#, Sec-#.#,\nSec-#.#.#. Export Framemaker documents to\nWord and convert them to Heading 1,\nHeading 2, etc. before exporting into Doors.\n- Keep all other styles consistent throughout\n(e.g. figure heading, table heading, etc.)\n\nSteps of the systems e\nngineering process.\nImage by MIT OpenCourseWare.\n\nAnother View of the 'V' Model\n\nNGD Requirements Structure & Links\nProduct\nContract\nPFS\nPASSS\nLevel 4\nIntegrated\nTest Plan\nDetailed\nTest Plans\nTest\nSuites\nTest\nCases\nLibrary\nTest Plans\nTest\nSuites\nHost\nApplications\nNetwork\nInfrastructure\nDesign\nNGD Test\nLibrary Test 3rd Party Certs\n?\n?\n?\n?\n?\nRequirements Links\nTest Links\nReq'ts-Test Links\n\nModule Schema\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nESD.33 Systems Engineering\nSummer 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Requirements Engineering Part 2",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-33-systems-engineering-summer-2010/cefc678e701b9e7501b5ca98fba89080_MITESD_33SUM10_lec04b.pdf",
      "content": "Commercial Systems Engineering Process\nSteps of the systems e\nngineering process.\nImage by MIT OpenCourseWare.\n\nSystems Engineering cycles iterated\nin each development phase\nIterations of the\nsystem\ns engineering\nproces\ns.\nImage by MIT OpenCourseWare.\n\nKey areas for impact\n- Requirements come from\nmany stakeholder classes\n- Upstream processes feed\nin business requirements\n- As important as needs\nare constraints\n- Don't forget 'non-\nfunctional' requirements\n- QFD is a proven method\nto translate needs to\nrequirements\n\nQFD Quick Review &\nFunctional Modeling\n\nCustomer-Focused Design\n- Focus on \"what\" needs\nto be achieved not \"how\"\n- Helps to organize teams,\ntasks and processes\n- Enhances creativity by\ndecomposing problems\n- Function or function sets derived from\ncustomer needs defines subsystems that\nminimize the number of internal interfaces\n(system engineering)\n- Interface specifications and protocols\ndefinition can begin prior to form design\nMap customer needs to functional descriptions\nOverall\nFunction\nFunction\nFunction\nFunction\nFunction\nFunction\nSub\nfunction\nSub\nfunction\nSub\nfunction\nSub\nfunction\nOverall\nFunction\n(c) PDSS (Creveling, Otto) - used with permission\n\n\"Rooms\" in the House of Quality\nDiagram of t\nhe \"rooms\n\" in the H\nouse of Q\nuality.\nImage by MIT OpenCourseWare.\n\nExample Relationship Matrix\nIndicates a strong positive\nrelationship\nIndicates a medium positive\nrelationship\nX Indicates a strong negative\nrelationship\nX Indicates a medium negative\nrelationship\nNote the objective\nmeasures of ECs\nAfter Hauser & Clausing, 1988\nRelationshi\np matr\nix in the\nHouse of\nQuality.\nImage by MIT OpenCourseWare.\n\nQFD Context\n(Figure from Lou Cohen) Diagram of the \"rooms\" in the House of Quality.\nImage by MIT OpenCourseWare.\nDiagram of t\nhe \"rooms\n\" in the H\nouse of Q\nuality.\n\nThe Roof of the House\nIndicates a positive\nrelationship\nX Indicates a negative\nrelationship\n- Is the roof matrix a\nfunction of the\nrelationships matrix?\n- Is it an Axiomatic Design\nmatrix?\n- Is it a Design Structure\nMatrix?\nEngineering\nchara\ncteristic\ns matrix i\nn the House of Quality.\nImage by MIT OpenCourseWare.\n\n\"Rooms\" in the House of Quality\nFigure from Lou Cohen.\nDiagram of t\nhe \"rooms\n\" in the H\nouse of Q\nuality.\nImage by MIT OpenCourseWare.\n\nFlow Down Requirements from\nthe System House of Quality\nSystem HOQ 1\nSubsystem\nHOQ 2\nComponent\nHOQ 3\nMfg. Process\nHOQ 4\nVoice of the\nCustomer\nSystem Requirements\nSystem\nRequirements\nSub-system\nRequirements\nSub-system\nRequirements\nComponent\nRequirements\nComponent\nRequirements\nMfg. Process\nRequirements\n\nWhat is the QFD for?\nQFD is for\n-\nCoordinating skills within an\norganization\n- Serves as a lingua franca\n- Helps break down the functional\nsilos\n- Encourages real teamwork\n-\nDesigning goods that customers\nwant to purchase\n- Creates external focus\n- Provides immersion in the\nspecifications\n-\nTarget setting for mature\nproducts\nQFD is NOT for\n-\nAutomatic decision making\n- \"the house absolves no one of\nthe responsibility of making tough\ndecisions\"\n-\nImplementing a quick fix\n- \"None of this is simple...\"\n- \"An elegant idea ultimately\ndecays into process...\"\n- \"What is also not simple is\ncreating an organization capable\nof absorbing elegant ideas\"\n-\nMore difficult to use for highly\nnovel / unprecedented functions\nHauser and Clausing, 1988, \"The House of Quality\", Harvard Business Review.\n\nFunctional & Analytical\nModeling\nModel formulation\nin the model gen\neration process.\nImage by MIT OpenCourseWare.\n\nFunctions\nFunctions should be expressed in terms of\nmeasurable effects\nTypical function expression: active verb - noun\n\"increase pressure\"\n\"transfer torque\"\n\"store energy\"\n\"cool liquid\"\n\nFunction Modeling Basics\nProduct Function - What the product does. A statement of\nthe relationship between available input and desired output,\nindependent of any particular form. (Overall Function)\nMake prints Tell time Water Turf Generate BHP Stop Vehicle\nChop\nBeans\nTransport\nPeople\nAccept\nHuman\n\nNORMAL RUN SCENARIO\nN\normal ru\nn scenario\nin function\na\nl modeling\n.\nImage by MIT OpenCourseWare.\n\nFunctional Modeling Example:\nPower Nailer Senco power nailer.\nImage by MIT OpenCourseWare.\n\nProblem Decomposition:\nFunction Diagram\nFunctional diagr\nam of powe\nr nail\ner example.\nImage by MIT OpenCourseWare.\n\nFunctional Modeling for CPM uses\nConservative Law Based Metrics...\n- Energy: ...measure the flow, transformation & state\nof energy (mechanical, magnetic, electrical, chemical,\nthermal, fluidic...)\n- Mass: ...measure the dynamic or static state of the\nflow & transformation of mass (material deflection,\nelongation, volumetric or mass flow rates, liquid-to-\ngas, solid-to-liquid & solid-to-gas transformations...)\n- Information: ...measure the flow & transformation of\ndigital & analog electronic, mechanical, magnetic,\nphotonic, etc. signals intended to control a function\nrelated to mass &/or energy transformation & flow.\n\nDefining Critical Input/Output Parameters\nfor Design Projects\nInput-Output-Constraint (IOC[N]) Diagrams...\nMass\nEnergy\nInformation\nInformation\nEnergy\nMass\nIncoming Desired\nFunctional Measures:\nOutgoing Desirable\nFunctional Measures:\nSystem\nSubsystem or\nSubassembly\nOutgoing Un-Desirable\nFunctional Measures:\nIncoming Un-Desired\nFunctional Measures:\nTransformations\nTransformations\nConstraining Reqts:\n1. Size\n2. Weight\n3. Power Consumption\n4. etc., etcEE.\nNOISE\nNOISE\nNOISE\nNOISE\nNOISE\nNOISE\n\nFunctional Flow Diagrams can be created\nby linking I-O-C Diagrams\nSubsystem or Sub-function #1:\nInput-Output-Constraint\nDiagram\nSubsystem or Sub-function #2:\nInput-Output-Constraint\nDiagram\nSubsystem or Sub-function #3:\nInput-Output-Constraint\nDiagram\nSubsystem or Sub-function #4:\nInput-Output-Constraint\nDiagram\nSubsystem or Sub-function #5:\nInput-Output-Constraint\nDiagram\nSubsystem or Sub-function #6:\nInput-Output-Constraint\nDiagram\n\nFunction Classes - Basic Functions\n\nSummary of System Analogs\nFrom Lewis, \"Modeling Engineering Systems\"\n\nFunction Structure\nEnergy\nEnergy\nMaterial\nMaterial\nInformation\nInformation\nSub-function\nSub-function\nSub-function\nSub-function\nWe show composition with area boundaries, not links. We show\nphysics of the functions with flows, to initiate our development of the\ncritical parameter trees. The flows can be measured.\nOverall Function\n\nStresses in Systems Engineering\nFunction\nSystem Requirements\nPerformance Specification\nHuman Needs\nComplexity\nNew Technology\nTop Down Plan\nConservative Design\nContinuous Evolution\nMinimal Interfacing\nProcess Characterization\nAvoid Complexity\nLow Level Decisions\nSpecialized Manufacturing\nCost and Schedule\nPerformance\nFit\nBalance\nCompromise\nFlexible Manufacturing\nStrict Process Control\nManage Complexity\nProcess Revolution\nTight Integration\nProduct Stability\nRisk of Overdesign\nBottom Up Implementation\nFamiliar Technology\nSimplicity\nAffordability\nStrict Acceptance Criteria\nEnvironmental Imperatives\nForm\nAdapted from Systems Engineering lecture slides at University of Witwatersrand, Johannesburg, South Africa (Dr. R. Siriram)\n\nSimulation\nDesign matu\nrity fl\now diagr\nam.\nImage by MIT OpenCourseWare.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nESD.33 Systems Engineering\nSummer 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Critical Parameter Management",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-33-systems-engineering-summer-2010/1e402d072db996218dd0376008907432_MITESD_33SUM10_read07.pdf",
      "content": "CRITICAL PARAMETER MANAGEMENT\nDon Clausing and Dan Frey\nEarly in the systems engineering process many decisions are made. When these decisions are\nmade well, they strongly contribute to success, but only if they are carried through in detailed\ndesign and transition to production. It is therefore necessary to work out the implications of the\ncritical early decisions on myriad detailed decisions.\nCritical Parameter Management (CPM) is an engineering practice specifically aimed at\nmaintaining the robustness of the system through detailed design and manufacturing. In the early\ndevelopment, ideally during technology development, the critical parameters have their values\noptimized to achieve robust performance of the system. Subsequently during detailed design of\nthe product system, production development and operation, and field-service development and\noperation it is all too easy to lose the optimized values of the critical parameters. When that\nhappens, the system no longer has robust performance, and the development is delayed, with\ngreat risk of excessive warranty costs once the system reaches the field.\nThe first distinction to be made is between a critical parameter and a critical specification.\nCritical parameters are the functional variables that control the physics (and chemistry and\nbiology) of the system. Many of them never appear on the production drawings. For example, a\nforce between a feed belt and a paper stack is critical to the physics of paper handling. This\nforce is therefore a critical parameter of the paper feeder system. This force is determined by a\nspring constant and some geometric parameters of the design. These parameters do appear on\ndrawings (or are implied by part numbers on a bill of materials). The details on the drawing and\nbill of materials are called critical specifications.\nTable 1 shows how critical parameters are transformed during multiple phases of systems\nengineering. During detailed design, engineers mapping from critical parameters to critical\nspecifications. During this mapping it is important to maintain the needed nominal values of the\nparameters and manage the associated variations. Similarly, subsequent transformations must\ncarry the implications all the way to the factory floor.\nTable 1. From critical parameters to quality: requiring parameter management through detailed\ndesign, production system design, and manufacturing operations.\nFrom\nTo\nPhase of\nSystems Engineering\nCritical parameter\nCritical specification\nDetailed design\nCritical specification\nProduction process\nProduction system design\nProduction process\nQuality\nManufacturing operations\n\nThe objective of Critical Parameter Management is to assure that the optimized values of the\ncritical parameters are sustained, which requires that the critical parameters are flowed down\nproperly to set manufacturing precision levels that assure the customer satisfaction that was\nenabled by the robust design. Ideally the production process that is used to produce each critical\nspecification is in control and capable. A manufacturing process that is in control is undergoing\nonly random variations. A manufacturing process that is capable exhibits a standard deviation\nsmall enough compared to tolerances.\nTHE CRITICAL-PARAMETER DRAWING\nThe core of Critical Parameter Management is the Critical-Parameter Drawing. It is also the\noldest in practice, having been implemented at the Xerox Corporation in the late 1970s. It was\nimplemented in response to the type of problems that have already been alluded to. An example\nis shown in Figure 1.\nFigure 1. Critical-parameter drawing of paper feeder.\nFigure 1 shows the nominal values of an example of some of the critical parameters. In the actual\ncritical-parameter drawing there were about 30 such critical parameters, and a range, or\ntolerance, was also given for each critical parameter. Here it has been simplified to concentrate\non the basic principles. We will return to the subject of the acceptable range around a critical\nparameter.\nThe first characteristic to note is that some of these critical parameters are not critical\nspecifications; i.e., they do not appear on any production drawing. An example is belt tension,\nwhich is specified as 15 Newtons. At this stage of development all that we care is that in order\nfor the feeder to work well, the tension in the belt must be close to 15 Newtons.\nIt is left up to the subsequent detailed design to determine the mechanism that will produce the\n15 Newtons. In Figure 1 the roller that is pressing up against the belt will produce the tension.\nThe upward force on the roller has to be resisted by the two downward force vectors produced by\n2 Critical parameter drawing of a paper feeder.\nImage by MIT OpenCourseWare.\n\nthe tension in the belt on both sides of the roller. The upward force on the roller can be produced\nby a spring, gravity, pneumatic actuator, solenoid, or other means. The detailed design has to be\nsimple and inexpensive, and consistently produce the necessary upward force that produces 15\nNewtons tension in the belt.\nHowever, experience has taught that it is just here that trouble starts to enter in. The detailed\ndesigner is usually working in a trade-off space in which the robustness of the system is not\nincluded. Rather the emphasis is on characteristics such as manufacturability, maintainability,\nergonomics, and safety. In his or her concentration to do well on these characteristics it is easy to\nlose sight of the ultimate goal - to produce 15 Newtons of tension in the belt.\nThis is the purpose of the critical-parameter drawing, to keep attention focused on the\nfunctionality of they system. It says to the detailed designers, production designers, and\nproduction operation people, that they can use their best practices to achieve the other types of\ncharacteristics, but they must produce the functional values that are on the critical-parameter\ndrawing.\nCUSTOMER SATISFACTION\nThe critical-parameter drawing is essential to customer satisfaction. In the beginning we\ndeployed the customers' needs into engineering characteristics in the House of Quality. In\nresponse to those characteristics we selected and integrated technologies that we judged would\nprovide a strong market-attack plan (MAP). Robust design was done so that the integrated\ntechnologies would adhere to customer-satisfaction values in the realistic conditions, which have\nlarge variations that tend to throw performance off.\nHaving done this early work well, now adherence to the critical-parameter drawing will provide\nfunctionality that will live up to our expectations when we selected and integrated the\ntechnologies. Thus the critical-parameter drawing enables the subsequent activities to achieve\nvalues that will provide customer satisfaction.\nOne approach is to simply include all of the critical parameters in the design matrices of QFD. In\nprinciple this seems as though it might work. However, experience has shown that it is beneficial\nto have critical-parameter drawings to emphasize the necessary attention.\nThe subsequent activities after the critical parameters have been optimized in robust design are:\n1. Detailed design\n2. Production design\n2.1.\nProcess selection\n2.2.\nTooling design\n2.3.\nOnline quality control design\n3. Production operations - Online quality control operation\nThis can be further extended to include field operations.\n\nFROM CRITICAL PARAMETERS TO THE FACTORY FLOOR\nThe first step is the detailed design. Let's assume, for example, that the detailed design has six\ncritical specifications (x1 through x6), which control the force against the roller Fr that produces\nthe belt tension of 15 Newtons.\nFr = Fr (x1, x2, x3, x4, x5, x6)\nDoing the detailed design so that belt tension is nominally 15 Newtons is relatively simple. A\nmuch greater challenge, not well understood by most engineers, is managing variation away\nfrom nominal. A little history will help explain the current situation.\nUntil the late 18th century all manufactured artifacts were made by craftsmen. If parts had to fit\ntogether, he hand tooled them until they fit. Naturally the parts from one craftsman did not match\nthe parts from another craftsman. Even successive items from one craftsman, even though\nnominally the same, would have parts that could not be interchanged between the two items. The\nhand tooling was always a little different for any two items.\nCirca 1765 Jean-Baptiste de Gribeauval, a General in the French Army, concluded that they\nshould have muskets with interchangeable parts. His primary objective was to be able to repair\nmuskets in the field. After a battle there would be two broken muskets. If the parts were\ninterchangeable, they could be combined so that there would be one good musket.\nThe production technology of that time was not up to the task. However, the dream marched on.\nIt was carried into America by French officers who aided the colonists in their battle for freedom\nfrom Britain. It took much difficult work, but by 1850 the arsenals at Springfield, Massachusetts\nand Harpers Ferry, Virginia could produce some interchangeable parts. However, it was\nexpensive to do so, and this approach was slow to spread to other industries. However, by the\nearly 20th century Henry Ford had to have interchangeable parts to operate his famous assembly\nline.\nHow were interchangeable parts achieved? By rigorous application of go/no-go gaging. If a\nshaft had to fit into a hole, both were made to tight upper and lower limits such that the shaft\nwould always fit into the hole with a functional clearance. Thus came about the engineers'\nobsession with tolerances. If the nominal (target) diameter of a shaft is 25.000 mm, then a\ntolerance is applied to that; e.g., ± 0.025 mm. This says that all shafts that used should be within\nthat range. That is the no/no-go culture that was started by General de Gribeauval.\nIn the 1920s Dr. Shewhart at the Bell Labs realized that production processes have some natural\nvariation, which can be characterized by the standard deviation, σ. He also observed that the\nproduction processes can have variation due to special causes (also known as assignable\nvariations). The effects of the special causes can be eliminated in the short term, while the\nnatural standard deviation can only be improved by longer-term quality improvements.\nAny feature on a part can be produced by one of several production processes. Therefore,\nproduction-process selection is an important decision. Each process is characterized by its cost\n\nand its precision; i.e., standard deviation. For more than a century engineers have put tolerances\non drawings. When they did that, they implicitly chose a production process. As product\nengineers became more and more separated from production, they often did not understand this\nconnection very well. This led to battles between the design engineers and manufacturing\nengineers. When the design engineers don't understand production and the manufacturing\nengineers don't understand the justification of the design, a standoff frequently ensues as\ndepicted in Figure 2.\nNow let's seek a more effective process than we see in Figure 2. One is suggested by a story\nfrom Don Clausing. Circa 1984 Clausing took Dr. Taguchi to the countryside south of\nRochester. They hiked and then went to a country restaurant for lunch. Summarizing a common\nview of a good systems engineering process, Don said, \"First we do robust design, and then we\nput tolerances on the drawings.\" Taguchi replied, \"No.\" Don repeated that thought in various\nways, always with the response, \"No.\" Finally they got into a dialogue, from which Don emerged\nwith a new understanding of what to do after robust design -- select the production process to\nattain optimum overall economy!\nHere is how we view the situation. For each feature to be produced we have several production\noptions. To simplify the primary point, let's assume that there are two production options. For\nexample, a 25 mm shaft could be turned on a lathe or it could be ground in a cylindrical grinder.\nTurning will typically achieve precision of 0.05mm on a 25mm diameter. Cylindrical grinding\ncan typically achieve precision of 0.01mm. Such values are readily available for most\nmanufacturing processes as depicted in Figure 3. But the added precision comes at a cost,\nperhaps a factor of two or three times the cost of turning. Cost implications of process precision\ncan be estimated (roughly!) with charts such as Figure 4. In fact, the dependence of cost on\nprecision more complex - it is not so smooth as in Figure 4 because at some point you are forced\nFigure 2 removed due to copyright restrictions.\n\nto \"jump\" from one process to a fundamentally different process. But for an initial estimate, cost\nmodels as depicted in Figure 4 are fine.\nNote, however, how deeply tolerance based thinking is rooted in the current culture of\nengineering. Figures 3 and 4 label axes with \"dimensional tolerance\" when standard deviation or\nprecision would be a more accurate label!\nFigure 3. Process selection and precision\n(from Kalpakjian,1992).\nFigure 4. Process cost vs precision (from\nKalpakjian,1992).\nNow let's return to the choice between turning and grinding. Is the improvement in precision for\ngrinding worth the incremental cost? That is the core of the issue. The economically-based\ndecision method is to minimize the total cost, which is the sum of manufacturing process cost\nand quality loss due to variations. To estimate total cost, we must flow down from the quality\nlosses due to deviation from ideal function to variation in critical parameters then down to\ncritical specifications. In our example of the roller with a force applied, we have six critical\nspecifications. If we assume that there are two production-process options for each of the six\ncritical specifications, then we have 64 total options. Fortunately, it is generally not necessary to\nconsider all 64 options and pick the overall winner. The quality loss implications of each critical\nspecification can generally be allocated and each one can separately be optimized to minimize\nthe overall cost. This is a consequence of the fact that within the small range of manufacturing\nvariations, most engineering systems behave almost linearly. If this assumption holds, the details\nof the total cost calculation work out as follows:\n- Recall that the critical parameter, force, is a function of six critical specifications, that is,\nF = F (x1, x2, x3, x4, x5, x6)\n(c) Addison-Wesley Publishing. All rights reserved.\nThis content is excluded from our Creative Commons\nlicense. For more information, see http://ocw.mit.edu/fairuse.\n\n- The quality loss because of not meeting the target value is proportional to the variance\nwith some constant measured in dollars per Newton squared. A useful way to estimate\nthis constant is to consider a \"customer tolerance\" ΔC which prompts a typical customer\nto seek rework and a cost (economic loss) to do the rework, LC\noss)\n(Quality L\nF\nC\nC\nL\nE\n!\n\"\n=\n- The variance of the critical parameter is a linear combination of the variances in the\ncritical specifications.1 The weightings on each term correspond to a squared sensitivity\nof force, F, to each critical specification, x1, x2... x6.\nx\nx\nx\nx\nx\nx\nF\nx\nF\nx\nF\nx\nF\nx\nF\nx\nF\nx\nF\n!\n!\n!\n!\n!\n!\n!\n\"\"\n#\n$\n%%\n&\n'\n(\n(\n+\n\"\"\n#\n$\n%%\n&\n'\n(\n(\n+\n\"\"\n#\n$\n%%\n&\n'\n(\n(\n+\n\"\"\n#\n$\n%%\n&\n'\n(\n(\n+\n\"\"\n#\n$\n%%\n&\n'\n(\n(\n+\n\"\"\n#\n$\n%%\n&\n'\n(\n(\n=\n- Therefore quality loss due to variance in each critical specification xi is simply\nix\ni\nC\nC\nx\nF\nL\n!\n\"\"\n#\n$\n%%\n&\n'\n(\n(\n)\n-\n.\nAnd the minimum overall cost requires minimization of each total cost which is the sum\nof the quality loss and production cost for that each critical specification xi.\nIn some cases, the \"total cost minimization\" approach to selecting the manufacturing processes is\nreplaced by other processes. For example, for some systems the performance demanded is set by\na contract. In other cases, management has set a firm target based on a forecast of the\ncompetitor's capabilities which must be matched. For example, for a space-based imaging\nsystem may have clear specifications on pointing accuracy. In such cases, it may be preferable\nto view the performance needed as fixed and to minimize production cost. This approach is\ntraditionally called error budgeting because it seems to suggest that error is a fixed quantity to be\nallocated across the system. However, for most systems engineering in competitive commercial\nindustries a better solution can be attained by minimizing the sum of production cost and quality\nloss.\nThe other method for the selection of production processes is knowledge-based engineering\n(KBE). For specifications that are not critical, this is almost always the method that is used. It\ncan also be used for some critical specifications, but caution is needed. All too often such\ndecisions have been based solely on either initial cost or on quality, with very bad results.\nAfter the production processes are chosen, the production tooling is designed and put into use to\nmake parts. The production online quality control is designed and implemented in production.\nAny and all of this is referred to as critical-parameter management, or similar names such as\n1 This equation entered into the engineering literature as early as 1953 (Kline and McClintock 1953). The\nequation is valid only if the critical specifications are independent (see Frey, 2004). This will not be\napplicable for example to resistances on an integrated circuit. When Equation 2 is inadequate, the\nvariance can be determined by several different means including Monte Carlo simulation, Latin\nHypercube Sampling, or using orthogonal arrays (for an example see Phadke, 1989; pp. 190-193).\n\ncritical-parameter implementation or critical-parameter deployment. The exact names that are\nused is not important. It all has to be done.\nCRITICAL-SPECIFICATION TOLERANCES\nAlthough the selection of the right process (or grade) is usually the most important step, it is also\nnecessary to determine the best tolerance value that will go on the production drawing. This can\nbe used to sort the good from the bad when it is required.\nThere are three \"tolerances\" (Figure 5). We start with the customer tolerance.\nLC\nLM\nD\nQUALITY\nLOSS\n!C\n!M\nFigure 5. Three-tiered Tolerances.\nAgain, the customer tolerance (ΔC) is the value at which the average customer (sometimes\nthought of as the 50th percentile customer) will be sufficiently dissatisfied so that they will call\nfor corrective action. Associated with the customer tolerance is a quality loss in dollars (LC) that\nis the cost of the countermeasure in response to the customer. This cost will be relatively large\nbecause of the field logistics that will be involved.\nThe same countermeasure could have been done much more cheaply in the factory. This much\nsmaller quality loss in manufacturing (LM) has associated with it a manufacturing tolerance (ΔM).\nThe manufacturing tolerance will be much smaller than the customer tolerance because it costs\nmuch less to implement the countermeasure in the factory. This is the tolerance that goes on the\ndrawing.\nWe can save still more money by using the adjustment limit D to limit variation during\nproduction. The customer tolerance and the quality loss that would be incurred at the customer's\nsite establish the quality loss function. In factory operations we limit the usual variation to the\nrange of ±D, the adjustment limit. As is indicated in Figure 5, we save a great deal of money in\nquality loss avoidance by limiting the range to ±D instead of ±ΔC.\n\nThis concept of three-tiered tolerances based on the quality loss function clearly leads to\nproduction operations with the units of production bunched tightly around the customer-\nsatisfaction target value.\nThe manufacturing tolerance is calculated to minimize the total cost. The quality loss is given by\nthe quadratic relationship:\nL = Lc\n!c\n2 !2\nwhere L is the expected quality loss, LC, the loss at the customers' tolerance (in other words the\ncost of the countermeasure in the field), ΔC the customers' tolerance, and Δ the actual deviation\nfrom the customer-satisfaction target for a specific unit of production.\nThe countermeasure can be performed in the factory at a much lower cost, LM, than in the field,\nand this defines the manufacturing tolerance. Putting the cost of the countermeasure in the\nmanufacturing site and the unknown value of manufacturing tolerance into the loss function\ngives\n!M =\nLM\nLc\n!c\nwhich establishes the value of the manufacturing tolerance. If a specific unit of production has a\nmeasured value of ∆ that is greater than ∆M, then it should not be shipped. It is cheaper to fix it\nin the factory at a cost of LM than incur the greater value of the quality loss in the field.\nConversely, if the value of ∆ is less than ∆M, then the product should be shipped. The quality\nloss in the field will be less than the cost of the countermeasure in the factory, LM. Thus the\nvalue of ∆M is the boundary between products that should be shipped, and the products that\nshould be reworked.\nBecause the cost of the countermeasure in the manufacturing site will usually be much less than\nthe cost of the countermeasure at the customer's site, the manufacturing tolerance is significantly\nless than the customer tolerance. If the repair work (countermeasure) in the factory is very cheap,\nit pays to \"repair\", or adjust, nearly all of the units. Then the manufacturing tolerance becomes\nvery small, so that only the units that are already very good do not have the inexpensive\nadjustment that improves customer satisfaction. The manufacturing tolerance is the tolerance that\nis put on the drawing. If the product has to be inspected, no product outside of the\nmanufacturing tolerance should be shipped.\nIn actual practice, the value of the performance parameter is usually held to the tighter range of\nthe adjustment limit, ±D, during on-line QC. Therefore, there should never be any products\noutside of the manufacturing tolerance, and inspection (after production is complete) should not\nbe needed. The only operational use for the manufacturing tolerance is in the unusual case that\nthe on-line adjustment process failed. Then the products that have been made while the\n\nadjustment process is not operational will have to be inspected, and the manufacturing tolerance\nis then used to determine whether they should be shipped or reworked.\nTo summarize the selection of production processes and the establishment of tolerances we\ncompare the traditional approach with the approach that has been featured here.\nTRADITONAL APPROACH\nSUGGESTED APPROACH\n1. Put tolerance on drawing\n1. Select production process\n(Usually very tight)\n(Minimize total cost)\n2. Select production process\n2. Put tolerance on drawing\n(By negotiation; see Figure 2, usually\n(Based on economics; product\nleads to changing the tolerance on the\nengineers and production engineers\ndrawing.)\ndo not need to negotiate.)\n3. Inspect production parts to assure that\n3. Use on-line quality control to detect\nthose outside of tolerance are not used.\nspecial causes. Inspect only in\nextraordinary circumstances or where\ncapable processes do not exist.\nDOCUMENTATION\nThe objective of the documentation is to focus attention on the critical parameters during the\ndetailed design, production-tooling design, and online QC design and implementation. All too\noften in the past this work has inadvertently changed the optimized values of the critical\nparameters, with devastating results.\nThe core of the documentation to focus attention on the critical parameters is the critical-\nparameter drawing. This is the beacon during all subsequent work. It keeps the importance and\nthe values of the critical parameters visibly in front of everyone whose work has some influence\non them.\nBeyond the critical-parameter drawing, there is much supplementary documentation that can be\nvery useful. The critical specifications can display their effect on the failure modes. For example,\nlet's assume that the detailed design includes a spring and lever to create the force on the roller,\nFr. Then a critical specification is the spring constant K. If the nominal value of K is 10\nnewtons/mm, then a value somewhat less than 10 will cause the failure mode of multifeeds. (Too\nlittle tension in the belt will produce too little force against the retard roll, and thus let the second\nsheet through too frequently.) Let's assume that happens at 9 newtons/mm. On the other hand a\nvalue of 11 newtons/mm will produce excessive damage to the sheets of paper, and excessive\nwear on the belt and/or the retard roll. This can be displayed as:\n\"1.0 (multifeeds)\n+1.0 (Damage & wear)\nThis can be displayed on the production drawing or on an enhanced version of the production\ndrawing that is kept in a critical-parameter-management database. This keeps the failure modes\nvisible and prominent in the thinking of the people who subsequently do the tooling design,\ncomponent purchasing, and online QC. This states loud and clear: DO NOT allow the spring\nconstant to exceed 11, or excessive wear and damage will cause customer dissatisfaction. DO\n\nNOT allow the spring constant to be less than 9, or excessive multifeeds will cause customer\ndissatisfaction.\nAnother form of CPM documentation is the failure-mode catalog. This is a data base that shows\nall of the failure modes of the system. For each failure mode the relevant critical-parameter\ndrawing is referenced. The relevant critical specifications can also be referenced.\nThe exact details of the CPM documentation can be varied and still be successful. The guiding\nprinciple is to keep the organization focused on the critical parameters and their values that are\nrequired for successful performance and reliability.\nSUMMARY\nThe total practice is summarized in Figure 6. The system architecture and selected technologies\ndetermine the ultimate potential system performance and reliability. No amount of subsequent\ngood work can make a silk purse out of a sow's ear. The objective of the subsequent work is to\ncapture as much of the inherent ultimate performance and reliability as possible.\nRobust design attempts to optimize the values of the critical parameters. If they are completely\noptimized, then all of the ultimate potential system performance and reliability will be enabled.\nThe objective of the subsequent work is to carry this out to the factory floor and then to the\ncustomers. Critical Parameter management therefore begins after robust design and is intended\nto deliver the quality made possible by the earlier steps. If CPM is done well, then the optimized\nvalues of the critical parameters will be achieved for the customers. That is the goal of CPM.\nFigure 6. Total process.\nThe complete\nprocess of\ncritical parameter manag\nement.\nImage by MIT OpenCourseWare.\n\nSome authors include Robust Design as part of CPM; i.e., they extend the scope to the left in\nFigure 3. Exactly what is called CPM, and exactly what name is used, is not important. It is\nimportant to do the complete process.\nThis course note provides the basic principles and motivation of CPM. One brand of CPM is\npresented in great detail in Creveling, et al (2003; pp. 249-336).\nCritical-parameter management is essential to successful system-engineering practice. It helps to\ngreatly reduce development time, improve customer satisfaction, and reduce life-cycle costs.\nREFERENCES\nCreveling, C. M., Slutsky, J. L., and Antis, D. Jr., Design for Six Sigma, Prentice Hall PTR,\n2003.\nFrey, D. D. 2004, \"Error Budgeting,\" in CRC Handbook of Robotics and Automation.\nKalpakjian, S., 1992, Manufacturing Engineering and Technology, Addison-Wesley, Reading,\nMA.\nKline, S. J. and McClintock, F. A., \"Uncertainties in Single Sample Experiments,\" Mechanical\nEngineering, January 1953.\nPhadke, Madhav, Quality Engineering Using Robust Design, Prentice Hall, 1989.\nTaguchi, Genichi, Taguchi on Robust Technology Development, ASME Press, 1993.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nESD.33 Systems Engineering\nSummer 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    }
  ]
}