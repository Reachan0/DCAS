{
  "course_name": "Linguistic Phonetics",
  "course_description": "This course is about the study of speech sounds; how we produce and perceive them and their acoustic properties. Topics include the influence of the production and perception systems on phonological patterns and sound change, students learn acoustic analysis and experimental techniques. Students taking the graduate version complete different assignments.",
  "topics": [
    "Humanities",
    "Linguistics",
    "Phonology",
    "Humanities",
    "Linguistics",
    "Phonology"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nCourse Description\n\nWe will be considering three fundamental questions:\n\nHow do we produce speech?\n\nHow do we perceive speech?\n\nHow does the nature of these processes influence the sound patterns of languages?\n\nWe will also be learning experimental and analytical techniques that enable us to address these (and other) questions.\n\nPrerequisites\n\n24.900 Introduction to Linguistics\nor equivalent. I will assume a basic knowledge of articulatory phonetic description, transcription and phonological theory.\n\nTopics To Be Covered\n\nPhonetic Theory\n\n1. Overview of 'the speech chain':\n\nArticulatory phonetics,\n\nBasic acoustics, waveforms and spectrograms,\n\nAudition and perception.\n\n2. Phonetics in relation to the rest of grammar\n\nCan we distinguish phonetic and phonological components of grammar?\n\nDo phonetic considerations affect phonological patterning?\n\n3. Articulatory-acoustic relations\n\nThe acoustic theory of speech production (Fant 1960, etc).\n\n4. Speech production--what do we control when we talk?\n\nAnatomy, coarticulation, the status of targets in speech production, articulatory phonology, timing and prosody.\n\n5. Speech perception\n\nCues and the perceptual space of speech sounds.\n\nLexical access--the role of phonetic and phonological grammars in interpretation of speech signals.\n\n6. What is a possible speech sound?\n\nFeature theory\n\nSteven's quantal theory, Lindblom's dispersion theory\n\n7. Phonetics and sound change\n\nExperimental Phonetics\n\n1. Experimental design and elementary statistics\n\n2. Digital Signal Processing\n\nSampling theory\n\nFFT, LPC, spectrograms, pitch tracking\n\nUsing PRAAT speech analysis software\n\nGrading\n\nREQUIREMENTS\n\nPERCENTAGES\n\nAssignments (8)\n\n50%\n\nFinal paper / project: May be experimental or literature based\n\n50%\n\nReadings and class discussions are required, but not part of the grading rubric.",
  "files": [
    {
      "category": "Assignment",
      "title": "Liprounding Assignment",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-915-linguistic-phonetics-fall-2015/ff98482be53cfa8a08b2e39b4826d6cd_MIT24_915F15_Assignment3.pdf",
      "content": "24.915/24.963\nAcoustics assignment\nFlemming\nAcoustics Assignment 2: Due 10/15\nThe goal of this assignment is to investigate alternative models of the acoustic effects of\nlip rounding by trying to account for the observed formant frequencies of rounded and\nunrounded vowels.\nA. Generating the data:\nTry the following:\n1. Produce an [i] vowel, then round the lips while keeping the position of your\ntongue unchanged, producing [y], then unround the lips again (hopefully returning\nto the original [i] quality).\n2. Produce an [u] vowel, then unround the lips while keeping the position of your\ntongue unchanged, producing [ ], then round the lips again.\nI recorded myself following these directions - the sound file is in the Assignment section for\nthis course.\nMeasure F1, F2 and F3 during [i], [y], [u] and [ ].\nB. Model the formant data.\nModel F2 and F3 of the unrounded vowels using the two-tube model for non-low vowels:\n-\nF2 and F3 should the be the first resonances of the front and back cavities (F1\nshould be the helmholtz resonance of the back cavity plus constriction - you don't\nneed to model that).\n-\nEstimate the lengths of the front and back cavities on this basis. For [i], F3 is\nsupposed to be a front cavity resonance, but you should check. For back\nunrounded [ ], F2 is a front cavity resonance.\n-\nTry to derive the effects of lip-rounding on F2 and F3. I.e. try to derive the\nmeasured F2 and F3 values of [y] and [u] by modifying the vocal tract models\nyou estimated for their unrounded counterparts [i] and [ ]. Try two modelling\nstrategies:\no\nIncreasing the effective length of the front cavity - models the effects of a\nmodest lip constriction and/or lip protrusion.\no\nAdding a narrow constriction to the front cavity. Treat the front cavity as a\ntube closed at both ends, and the front cavity plus lip constriction as a\nImage by MIT OpenCourseWare.\n\n24.915/24.963\nAcoustics assignment\nFlemming\nHelmholtz resonator. In calculating the helmholtz resonance of the front\ncavity you have quite a few variables to play with. Reasonable values:\nlength of the lip constriction: about 1cm, area of the lip constriction are\naround 0.3 - 0.6 cm2, cross-sectional area of the front cavity about 2-3 cm2.\n-\nBoth models predict that back cavity resonances should be unaffected by lip-\nrounding, except via acoustic coupling. I.e. if a front cavity resonance gets close\nto the frequency of a back cavity resonance, they will be pushed apart.\n-\nReport the results of both modeling strategies, and discuss how well they account\nfor the observed formant frequencies. Which model provides the best account?\n-\nNOTE: lip-rounding may change the cavity affiliation of F2 and F3 - whichever\nresonance is lower is F2. For example, if, in an unrounded vowel, the first\nresonance of the front cavity is higher than first (non-Helmholtz) resonance of the\nback cavity, then the front cavity resonance is F3. If lip-rounding lowers the first\nresonance of the front cavity below the first resonance of the back cavity, then the\nfront cavity resonance becomes F2.\nImage by MIT OpenCourseWare.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n24.915 / 24.963 Quantum Optical Communication\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Acoustics 4",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-915-linguistic-phonetics-fall-2015/75280579e48fb8a9175513e45d9b5e0b_MIT24_915F15_Assignment5.pdf",
      "content": "24.915/24.963 Linguistic Phonetics\nAcoustics assignment\nFlemming\nAcoustics Assignment 4: Due 11/3\n1. The figure below shows a simple tube model for the high front vowel [i]. Ignoring the\neffects of acoustic coupling, F3 is the first resonance of the front cavity, F2 is the first\nresonance of the back cavity, and F1 is the helmholtz resonance of the back cavity\nand constriction.\n0.2cm2\n5.5cm2\nThe dimensions of this vocal tract are appropriate for an adult male. A typical\nfemale vocal tract might be about 90% of this size.\n(i) What are the proportional changes in F2 and F3 if the dimensions of this vocal\ntract shape are shortened by this amount? (You shouldn't need to calculate the actual\nformant frequencies to work this out).\n(ii) What is the proportional change in F1 if all dimensions are reduced by this\namount (including constriction length and tube widths - NB cross-sectional areas will\nbe reduced in two dimensions)\nPeterson and Barney (1952) measured average formant frequencies for English\nvowels spoken by women and men. Average values for [i] are as follows, together\nwith the ratio female/male formant frequency, for each formant:\nF1\nF2\nF3\n[i]\nMales\nFemales\nRatio\n1.15\n1.22\n1.10\n(iii) How do the relative magnitudes of the ratios for each formant compare with the\npredicted results of shortening the vocal tract, calculated in (ii)? (I.e. don't worry too\nmuch about the absolute values of the ratios because we could change our predictions\nof those by choosing a scaling factor other than 90%. We are more concerned about\nthe predicted relationships between ratios for different formants: How do the\nobserved values of the ratios for each formant compare to each other? How do your\ncalculated values of the ratios for each formant compare to each other? Any\ndifference?)\n8 cm\n4cm\n4cm\n\n24.915/24.963 Linguistic Phonetics\nAcoustics assignment\nFlemming\n(iv) Physiological data indicates that the female vocal tract is not uniformly smaller\nthan the male vocal tract. Generally the pharynx is smaller relative to the mouth\ncavity in females, so the difference in pharynx size between males and females is\nbigger than the difference in mouth size (Chiba and Kajiyama 1941). Explain how\nthis fact can help explain the discrepancy between observed and predicted\nfemale:male ratios for F2 and F3. (The story on F1 is different).\n2. For students in 24.963 (optional extra credit question for students in 24.915):\nAnalyze the form of locus equations for F2 in [b]-vowel sequences using simple tube\nmodels of the vocal tract.\nThe figure shows the locus equation for bilabial stop [b] from Fowler (1994). Full\ndata are at the end of the handout. Similar patterns have been found across languages.\nF2C = 228 + 0.80 F2V\nTry to model the behavior of labial stops by assuming that they involve the same\nvocal tract shape as the following vowel, but with a constriction at the lips. The effect\nof this constriction can be modeled as equivalent to lengthening the front cavity. How\nwell does this model account for the observed locus equation? Does it predict a\nprecisely linear relationship between F2 onset and vowel F2? Does it account for the\nobserved slope and intercept? Explore explanations for any gaps between predictions\nand observations.\nImage by MIT OpenCourseWare.\n\n24.915/24.963 Linguistic Phonetics\nAcoustics assignment\nFlemming\nImage removed due to copyright restrictions. Please refer to Appendix for Values of\nF2 at Onset and F2 at Midpoint averaged over 10 subjects, found in: Fowler, C. A.\n(1994). Invariants, specifiers, cues: An investigation of locus equations as\ninformation for place of articulation. Perception & Psychophysics, 55(6), 597-610.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n24.915 / 24.963 Quantum Optical Communication\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "24.915 Linguistic Phonetics Acoustics assignment 3",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-915-linguistic-phonetics-fall-2015/a513dddc02357f5826b88f81c35bcb4d_MIT24_915F15_Assignment4.pdf",
      "content": "24.963 Linguistic Phonetics\n\nAcoustics assignment\nFlemming\nAcoustics Assignment 3: Due 10/22\n1. We are planning to digitize a recording and we need to be able to measure the first\ntwo formants of vowels produced by the speaker, who has a vocal tract of about 15\ncm in length. What is the minimum sampling rate that we could use, given the\nexpected maximum F2 for this speaker? Assume a maximum constriction length of 4\ncm in calculating the expected maximum F2 for the speaker.\n2. Sound waves reach the eardrum through the ear canal (or external auditory meatus).\nGiven that the ear canal is a tube of about 2.5cm long, open at one end, what effect\nwill it have on sound waves? (Be as precise as possible - i.e. use a simple calculation\nto estimate the effect).\n3. What is the interval between spectral points (analysis components) in an FFT\nspectrum if the sampling rate is 11 kHz and the analysis window is 512 samples long?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n24.915 / 24.963 Quantum Optical Communication\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "24.915 Linguistic Phonetics Affricate Voicing Experiment",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-915-linguistic-phonetics-fall-2015/2f6b25b7adcc98a6ce12beae4a50dcb3_MIT24_915F15_Assignment6.pdf",
      "content": "Study of the voicing contrasts in English affricates\nDue 11/12\nThe full set of voicing minimal pairs is as follows:\nchoke joke\nchain Jane\nchar\njar\nchest jest\nchunk junk\ncheer jeer\nchin gin\n\nWe use minimal pairs to try to control for any factors that might affect the realization of\nthe affricates other than their underlying voicing (e.g. following vowel quality might\naffect VOT or intensity of affrication).\nWe will record these words in two carrier phrases, one in which the target word follows a\nvoiceless stop, and another in which it follows a vowel:\nType \"X\" for me.\nSay \"X\" for me.\nThe main focus of interest is the first sentence because we expect the voiced affricates to\nbe devoiced following a voiceless stop, and we wan to study how the contrast between\n/tS/ and /dZ/ is realized when /dZ/ is devoiced. I've added the second carrier phrase to see\nif we can compare devoiced and voiced /dZ/ (assuming word-initial /dZ/ is voiced between\nvowels). That will allow us to see if any differences between devoiced /dZ/ and /tS/, e.g. in\nduration of affrication, are similar to differences observed where [dZ] is voiced.\n\nThe last two pages contain the lists of sentences to record for the experiment, one in\npseudo-random order, and the other in reverse order (to try to counter-balance any effects\nof position on the list). I've added an extra item to the end of each list in case the\nspeakers use different prosody on the last item in a list. Don't measure these items (chive,\njive)\nProcedure: I suggest that you work in pairs, with at least one native speaker of English\n(any variety) in each pair. That way you can work together to make the recording, and\ncan each measure half of the data (one full set of items). If you would like help making\nrecordings, contact Leo Rosenstein, leaena@mit.edu, the lab manager for the linguistics\ndepartment.\nMeasurements\nFor each target word, measure the following:\n-\nVoice Onset Time - duration from the release of the stop closure to the onset of\nclear periodicity at the beginning of the following vowel.\n\n-\nIntensity during frication - measure intensity away from effects of the release\nburst and the following vowel. If this leaves any choice about where to measure,\ntake the highest intensity value. NB You must adjust the window length over\nwhich rms intensity is calculated: Go to 'Pitch' menu, select 'Pitch settings',\nchange the lower value of 'Pitch range' to 200 Hz.\n-\nF1 at voice onset (or at onset of F1 if F1 is not apparent at voice onset).\n-\nClassify voicing of stop closure and affrication of each affricate\nClosure: full, part, or none\nAffrication: full, part, or none\n- do not count a period or so of voicing at frication offset as partial voicing\nRecord the measurements in a spreadsheet/tab separated text file with one item in each\nrow, and measurements arranged in columns, e.g.\nWord\nContext Repetition\nVOT (s)\nIntensity (dB) F1 (Hz)\nclos. voice affric. voice\nchoke\nstop\n0.096\n56.3\nnone\nnone\n\nSay \"chunk\" for me.\nSay \"jest\" for me.\nSay \"gin\" for me.\nSay \"Jane\" for me.\nSay \"chest\" for me.\nSay \"choke\" for me.\nSay \"cheer\" for me.\nSay \"char\" for me.\nSay \"joke\" for me.\nSay \"jar\" for me.\nSay \"chain\" for me.\nSay \"junk\" for me.\nSay \"chin\" for me.\nSay \"jeer\" for me.\nType \"junk\" for me.\nType \"jest\" for me.\nType \"joke\" for me.\nType \"chin\" for me.\nType \"jeer\" for me.\nType \"Jane\" for me.\nType \"char\" for me.\nType \"chunk\" for me.\nType \"chain\" for me.\nType \"jar\" for me.\nType \"gin\" for me.\nType \"chest\" for me.\nType \"cheer\" for me.\nType \"choke\" for me.\nType \"chive\" for me.\n\nType \"choke\" for me\nType \"cheer\" for me\nType \"chest\" for me\nType \"gin\" for me\nType \"jar\" for me\nType \"chain\" for me\nType \"chunk\" for me\nType \"char\" for me\nType \"Jane\" for me\nType \"jeer\" for me\nType \"chin\" for me\nType \"joke\" for me\nType \"jest\" for me\nType \"junk\" for me\n\nSay \"jeer\" for me\nSay \"chin\" for me\nSay \"junk\" for me\nSay \"chain\" for me\nSay \"jar\" for me\nSay \"joke\" for me\nSay \"char\" for me\nSay \"cheer\" for me\nSay \"choke\" for me\nSay \"chest\" for me\nSay \"Jane\" for me\nSay \"gin\" for me\nSay \"jest\" for me\nSay \"chunk\" for me\nSay \"jive\" for me.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n24.915 / 24.963 Quantum Optical Communication\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "24.915 Linguistic Phonetics Basic Acoustics",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-915-linguistic-phonetics-fall-2015/615deb3507925ca3ca108a8030b7c069_MIT24_915F15_Assignment1.pdf",
      "content": "24.915/24.963 Linguistic Phonetics\n\n9/15/13\nFlemming\n\nAssignment 1 - Basic Acoustics\ndue Tues 9/22\n\n1. The figure below shows a short section of the waveform of an utterance of the vowel [œ].\nWhat is its fundamental frequency?\nTime (s)\n0.05035\n-0.312\n0.3336\n0.005\n0.01\n0.015\n0.02\n0.025\n0.03\n0.035\n0.04 0.045\n0.05\n2. (a) Draw (or print) the waveform of the complex wave produced by adding sine waves of\n300 and 500 Hz (both with peak amplitude of 1). What is the fundamental frequency of this\ncomplex wave?\n(b) Draw the spectrum of the complex wave in (a).\n3. Standard analog telephones filter out frequencies below 400 Hz. For most speakers most of the\ntime, fundamental frequency is below 400 Hz, so how can we hear pitch over the telephone?\n5. What is the best signal-to-noise ratio (in dB) that we can get with a signal digitized with (a) 8\nbit quantization, and (b) 16 bit quantization? That is - assume a maximum amplitude signal,\nand that the only source of noise is quantization noise (Johnson pp.57f.). Give your answers\nin dB.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n24.915 / 24.963 Quantum Optical Communication\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "24.915 Linguistic Phonetics Final Project",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-915-linguistic-phonetics-fall-2015/66399021a4367f55b37ce3edaff91427_MIT24_915F15_FinalProject.pdf",
      "content": "Final Project Guidelines\nThe final project usually involves a small experiment or other phonetic study, on some topic\nrelevant to the course. Students identify topics through discussion and submit a report on\ntheir study.\n\nHere are some examples of titles:\n'The Affrication of Stops in Scottish and American English'\n\n'Vowel Duration Before Ejective Stops in Georgian'\n\n'Vowel length does not cue stress in a language with phonemic vowel length: A study of\nMi'gmaq'\n\n'Using Formant Synthesis to Investigate Vowel Perception'\n\n'Comparing glides /wa/ /wi/ and /ju/ in Korean and English'\n\n'Individual Phonetic Variation: Affricate Velarization'\n\n'Vowel Reduction in the Thai language'\n\n'Palatalization in Russian'\n\n'Utterance Final Pitch Patterns in Echo and Particle Questions in Chinese'\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n24.915 / 24.963 Quantum Optical Communication\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "24.915 Linguistic Phonetics Mandarin VOT Assignment part 1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-915-linguistic-phonetics-fall-2015/c28d74d4fd398822c7d5058ca9b30e23_MIT24_915F15_Assignment2_1.pdf",
      "content": "24.915/963 Linguistic Phonetics\nAspiration contrasts in Mandarin Chinese\ndue 9/29\nI have recorded a speaker of Taiwanese Mandarin reading a list of words illustrating the\naspiration contrasts in this language in a variety of vowel contexts (full list below).\nMandarin is usually described as contrasting the following aspirated and unaspirated\nplosives:\nalveolo-\nbilabial\nalveolar\nretroflex\nvelar\npalatal\nstop\np ph\nt th\nk kh\naffricate\nts tsh\nʈʂ ʈʂh\ntɕ tɕh\nThe assignment has two parts:\n1. For the stops: Measure Voice Onset Time (VOT). Send the results to me as a text file\nwith one word on each line and the word separated from the VOT measurement by a tab,\nor an Excel spreadsheet (files can be submitted through Stellar).\n2. For the affricates: compare the aspirated and unaspirated affricates using waveforms\nand spectrograms and try to identify acoustic properties that differentiate the two classes.\nIs the contrast among affricates parallel to the contrast between aspirated and unaspirated\nstops (as implied by standard transcriptions of these sounds)?\n- Does voicing play any role in either contrast?\n- Is it possible to identify an interval of aspiration following the 'aspirated' affricates.\n(Related question: Can we measure VOT of affricates? If so, how do we identify\noffset of frication - i.e. where do we start measuring VOT?)\nTips:\nA. It can be difficult to identify periodic voicing in the waveform of a fricative because it\ncan be obscured by the frication noise. Voicing in a fricative is generally more visible in\nthe spectrogram where any voicing striations will be most prominent at low frequencies,\nwhereas the frication noise is predominantly at high frequencies.\nB. If there is any aspiration following an affricate, it should be similar to aspiration\nfollowing a stop, so you can use the spectrograms of the aspirated stops as guides to what\nyou should expect the spectral properties of aspiration noise to look like. The spectrum of\naspiration depends on the following vowel, so compare words with the same vowel (e.g.\nexamine [tha] to get some idea of what aspiration might look like in [tsha].\n\nC. Some of the differences between frication and aspiration may be more obvious above\n5000 Hz. By default, Praat plots spectrograms from 0-5000 Hz, so you will need to\nmodify the spectrogram settings to see anything above 5000 Hz: In the edit window, go\nto the Spectrum menu. Select 'Spectrogram settings...'. Change the upper limit of the\nview range to 8000 Hz.\nCome to class prepared to discuss your observations. You will write up your observations\nfor the following week (you only need to submit your measurements on 9/29).\n\n24.915/963 Linguistic Phonetics\nRecordings:\nThe words were recorded in the following carrier phrase:\nwo ʂwo\nkei ni thin\nI say give to you hear\nThe following is the full list of words, in the order in which they were recorded:\nI say give to you hear\n\npa\npi\npu\npha\nphi\nphu\ntha\nta\nku\nkhu\ntsa\nʈʂa\ntɕa\ntsha\nʈʂha\ntɕha\ntsu\nʈʂu\ntɕi\nʈʂhu\ntshu\ntɕhi\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n24.915 / 24.963 Quantum Optical Communication\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-915-linguistic-phonetics-fall-2015/81c9d59190795ad560724b3cdd65050b_MIT24_915F15_lec1.pdf",
      "content": "24.915/24.963\nLinguistic Phonetics\n\nIntroduction: Phonetics and\nThis image is in the public domain.\nSource: Poul la Cour, \"Tidens naturlære,\" (1903).\nGrammar\n(c) Source Unknown. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/.\n\nPhonetic Grammars\n- Phonetics is part of grammar and the study of the linguistic\nphonetics is in many respects similar to phonology.\n- Phonological grammars must account for the distribution of\nsounds in languages.\n- E.g. Russian voiced and voiceless stops\n\n_V\n_#\n\n(gen.sg.)\n(nom.sg.)\nvoiceless brata\nbrat\n'\n\nbrother\nvoiced\nvraga\nvrak\ng 'enemy\n*vra\n- [+voice, -sonorant] → [-voice]/ _ #\n- Ident(voice)/_V >> *[+voice, -sonorant] >> Ident(voice)/_#\n\nPhonetic Grammars\n- Phonological grammars must account for the distribution of\nsounds in languages.\n- Allophonic variation, e.g. nasalized vowels in English\nvowels are nasalized before nasals [hœ)m] *[hœm]\noral elsewhere [hœd] *[hœ)d]\n- Grammar:\n[vowel] → [+nasal]/ _ [+nasal]\n*OralV-N >> *NasalV >> Ident(nasal)\n\nPhonetic grammars\n- There is allophonic variation in much finer phonetic details,\ne.g. formants at the release of a stop, e.g [d].\n[did] deed\nm\nspectrogram\nfrequency\nformantsm\n(Hz)\n8.57261\n8.8872\nTime (s)\ntime (s)m\n\nPhonetic grammars\n- The frequency of the second formant (F2) at the release of a\n[d] varies depending on the following vowel.\n- allophonic variation in the realization of [d]\nF2(V)\nF2(C)\n8.57261\n8.8872\n10.4582\n10.7544\n12.4125\nTime (s)\nTime (s)\nTime (s)\ndid\nd£d\ndt\n- We can state a simple rule to describe this pattern of\nvariation quite accurately:\n\nF2(C) = 0.52F2(V) + 931\n12.7061\n\nPhonetic grammars\nF2(C) is a linear function of F2(V) (Krull 1987, etc).\n-\n- It is not feasible to transcribe this variation in the pronunciation\nof [d], but we can measure it.\n- It would not be desirable to describe it using a symbolic re-\nwrite rule because it involves a multiplicative relationship\nbetween two continuous variables F2(C) and F2(V).\n- But it must be derived in some way in the grammar of English\nFigure removed due to copyright restrictions.\nSource: Figure 1, Fowler, Carol A. \"Invariants, specifiers, cues: An\ninvestigation of locus equations as information for place of articulation.\"\nAttention, Perception, & Psychophysics 55, no. 6 (1994): 597-610.\n\nPhonetic grammars\n- F2(C) after stops is a linear function of F2(V) in CV\nsequences in all languages that have been studied, but the\nslope and intercept of that function differ from language to\nlanguage.\n- Thai [d1]\nF2(C) = 0.3F2(V) + 1425\n(0.24-0.33)\n- Urdu [d1]\nF2(C) = 0.5F2(V) + 857\n(0.43-0.57)\n- Sussman et al (1993).\n- Averages over 6 and 5 speakers respectively. Both stops are reported\nto be dental.\n- So these different patterns must be derived from differences\nbetween the grammars of these languages.\n- What is the form of this phonetic grammar?\n\nPhonetic grammars\n- To study phonetic grammar we need to be able to describe\nspeech (quantitatively) - acoustically and articulatorily.\n- E.g. spectrograms, formants.\n- Phonetics is also relevant to other areas of linguistics,\nparticularly phonology.\n\nThe phonetics and phonology of retroflex\nconsonants\ndental [l1]\n\nretroflex [ɭ]\nMRI images of Tamil laterals (Narayanan et al 1999)\nReproduced from Srikanth, Byrd and Kaun. (1999) \"Geometry, kinematics, and acoustics of tamil liquid consonants.\"\nThe Journal of the Acoustical Society of America, with the permission of the Acoustical Society of America.\n\nThe phonetics and phonology of retroflex\nconsonants\napical alveolar [t]\n\nretroflex [E]\nMalayalam\nCourtesy of Ashtu Killimangalam. Used with permission.\n\nDistribution of retroflexion contrasts in\nGooniyandi (Steriade 1995)\n- Contrast between retroflex and apical alveolar:\nV_V\nOutu\n'straight'\nOu∂u '?\nwila 'finish'\nwilla 'back'\nV_#\njawan (subsection term) jilNi= 'dew'\nV_C\nOunOunanaOgu\ngamburOuwa\n'pardalote'\n\n(toponym)\n- No contrast elsewhere:\n#_\nEu...wu... ~ tu...wu...\n'cave'\n=a...gø ~ na...gø\n'dress'\nC_\nba=∂i 'spider'\n* ba=di\njambijindi\n* jambijinqi\n\nDistribution of retroflexion contrasts in\nGooniyandi\nSummary:\n- Contrast between retroflex and apical alveolar after vowels\nV_#, V_V, V_C\n- No contrast elsewhere #_, C_\n- This pattern of distribution is common in Australian and\nDravidian languages.\n- Probable universal: If a language contrasts retroflexes and\napical alveolars in contexts with no preceding vowel, then it\nalso contrasts these sounds following vowels.\nWhy?\n\nDistribution of retroflexion contrasts\nOutline explanation (Steriade 1995, 2001 etc):\n- Contrasts preferentially appear in environments where they\nare easier to distinguish perceptually.\n- i.e. where listener is less likely to be confused about\nwhich sound they are hearing.\n- Apical alveolars are more distinct from retroflexes when\nthey are preceded by a vowel.\n- Therefore some languages only allow the contrast in this\ncontext.\n\nPerception of retroflexion contrasts - Anderson 1997\nstimulus placem\nPerception in Arrernte\nVCVm\nperceived\nplacem\n- Perception of [t, ʈ]\nas dental vs. apical\ndepends on duration\nCVm\nof voiceless closure\nCourtesy of Eurospeech. Used with permission.\nSource: Anderson, Victoria B. \"The perception of coronals\nin Western Arrernte.\" In EUROSPEECH. 1997.\n\nDistribution of retroflexion contrasts\nWhy are apical alveolars more distinct from retroflexes where\nthey follow a vowel?\n- The primary cues to the contrast between retroflex and\napical alveolar are located in the VC transitions (unlike\nmajor place contrasts.\n- This pattern has a basis in the production of these sounds:\n- Most retroflex consonants are retroflexed at closure, but\nthe tongue tip moves forward during closure.\n- At release tongue tip position is similar to an apical\nalveolar, consequently the release and CV transitions of\nthe two consonant types are similar.\n\nThe phonetics and phonology of retroflex\nconsonants\napical alveolar [t]\nretroflex [ʈ]\nMalayalam\nCourtesy of Ashtu Killimangalam. Used with permission.\n\nElectropalatography\n(c) Blackwell Publishing. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\nSource: Ladefoged, Peter. Phonetic Data Analysis: An Introduction to Fieldwork and\nInstrumental Techniques/Peter Ladefoged. Oxford: Blackwell, 2003.\n\n307 CLO 308\n313 MAX 314\n320ı\n334ı\n348ı\n354 MAX 355\n357 Rel 358\n362ı\nWarlpiri [E] from onset of closure to post-release: Butcher 1993\nImage by MIT OCW.\nAdapted from Butcher, Andrew. \"The Phonetics of Australian languages.\" Unpublished manuscript. Flinders University, South Australia, 1993.\n\n307 CLO 308\n313 MAX 314\n320ı\n334ı\n348ı\n354 MAX 355\n357 Rel 358\n362ı\nWarlpiri [t] from onset of closure to post-release\nImage by MIT OCW.\nAdapted from Butcher, Andrew. \"The Phonetics of Australian languages.\" Unpublished manuscript. Flinders University, South Australia, 1993.\n\nDistribution of retroflexion contrasts\n- Acoustic studies provide evidence concerning the\ndifferences between apical alveolar and retroflex\nconsonants.\n- Articulatory studies help to explain the observed acoustic\npatterns.\n- Perceptual studies confirm that retroflexion contrasts are\nmore difficult to discriminate in the absence of a preceding\nvowel.\n- Phonological theory relates these properties to the\nobserved distribution of retroflexion contrasts.\n\nDistribution of retroflexion contrasts\nMoral:\n- The details of the articulation, acoustics and\nperception of retroflexes are crucial to\nunderstanding their phonological properties.\n- We will start with a rapid overview of the\n'speech chain', then focus on the acoustics\nof speech, introducing the spectrogram.\n\nImage by MIT OCW.\nAdapted from Denes, Peter B., and Elliot N. Pinson. The Speech Chain: The physics and biology\nof spoken speech. 2nd ed. New York, NY: W. H. Freeman, 1993. ISBN: 9780716723448.\nLinguistic\nLevel\nPhysiological\nLevel\nAcoustic\nLevel\nPhysiological\nLevel\nLinguistic\nLevel\nSound Waves\nEar\nEar\nSensory\nNerves\nSensory Nerves\nBrain\nBrain\nFeedback\nLink\nMotor\nNerves\nVocal\nMuscles\nListener\nSpeaker\nThe Speech Chain\n\nReadings from Johnson for next week:\n- Chapter 1\n- Chapter 3 pp. 49-68\n- Chapter 4\n\nArticulation-\nThe speech production system\nHard Palate\nNasal Cavity\nNostril\nLip\nTongue\nTeeth\nOral (or Buccal) Cavity\nJaw\nTrachea\nLung\nDiaphragm\nSoft Palate\n(Velum)\nPharyngeal Cavity\nLarynx\nEsophagus\nImage by MIT OCW.\n\nThe vocal tract\nImage by MIT OCW.\nAlveolar ridge\nUpper gums\n(alveolus)\nTeeth\nLips\nLower jaw\nHyoid\nThyroid cartilage\nNasal cavity\nPalate\nSoft palate\nVelum\nUvula\nTonsils\nTongue\nPharynx\nEpiglottis\nVocal cords\n(glottis)\nLarynx\nEsophagus\nVocal tract configuration with raised soft palate for articulating non-nasal sounds.\n\nArticulatory description of speech sounds\nConsonants:\n- Voicing\n- Place of articulation\n- Manner\n- Lateral/Central\n- Nasal/Oral\n- [s] voiceless alveolar central oral fricative\n\nArticulatory description of speech sounds\nVowels:\n- High-low\n- Front-back\n- Rounded-unrounded\n- [e] mid front unrounded vowel\n(c) Source Unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\n(c) Center for Digital Humanities. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see http://ocw.mit.edu/help/\nfaq-fair-use/.\n\nIntroduction to acoustics\n- Sound consists of pressure fluctuations in a\nmedium (usually air).\nanimation\n\nSpeech acoustics\n- Movements at a source produce a sound\nwave in the medium which carries energy to\nthe perceiver.\n- Pressure fluctuations move through space,\nbut each air particle moves only a small\ndistance.\n(c) Source Unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nRepresenting sound waves\nImage by MIT OCW.\nAdapted from The Physics Classroom Tutorial.\nTime\nPressure\nC = Compression\nR = Rarefaction\nC\nC\nC\nC\nC\nR\nR\nR\nR\nR\nSound is a Pressure Wave\n\nPeriodic sounds\n- A waveform is periodic if it repeats at regular intervals.\n- Frequency of a wave is the number of cycles occurring per\nunit of time.\n- Units: 1 Hertz (Hz) is 1 cycle/second\nImage by MIT OCW.\n\nPeriodic sounds\n- Voiced sounds have complex (quasi-)periodic wave forms.\n- The perceived pitch of a sound depends on its frequency.\nSegment of [\nC\n]\nImage by MIT OCW.\n.01\n.02\n.03 s\n- Air pressure +\nTime in seconds\n\nAperiodic sounds\n- Aperiodic sounds have waveforms that do not repeat.\n- Fricative noise is aperiodic.\n0.1253\n-0.09549\n0.0115323\nTime (s)\nSegment of [s]\n\nWaveform of a sentence\nPlease pass me my book\nImage by MIT OCW.\n\nSpectrums and spectrograms\n- The spectrum of a sound plays a central role\nin determining its quality or timbre.\n\nSpectral representation\n- Any complex wave can be analyzed as the combination of\na number of sinusoidal waves of different frequencies and\nintensities (Fouriers theorem).\n- In the case of a periodic sound like a vowel these will be\n- the fundamental frequency\n- multiples of the fundamental frequency (harmonics)\n- The quality of a periodic sound depends on the relative\namplitude of its harmonics.\n\nSpectral representation\n-2\n-1.5\n-1\n-0.5\n0.5\n1.5\n0.005\n0.01\n0.015\n0.02\n\n-2\n-1.5\n-1\n-0.5\n0.5\n1.5\n0.005\n0.01\n0.015\n0.02\nFundamental frequency\n-2\n-1.5\n-1\n-0.5\n0.5\n1.5\n0.005\n0.01\n0.015\n0.02\n\n2nd harmonic\n-2\n-1.5\n-1\n-0.5\n0.5\n1.5\n0.005\n0.01\n0.015\n0.02\n\n-2\n-1.5\n-1\n-0.5\n0.5\n1.5\n0.005\n0.01\n0.015\n0.02\n1.5\n0.5\n-0.5\n-1\n-1.5\n-2\n0.005\n0.01\n0.015\n0.02\n\n-2\n-1.5\n-1\n-0.5\n0.5\n1.5\n0.005\n0.01\n0.015\n0.02\n-2\n-1.5\n-1\n-0.5\n0.5\n1.5\n0.005\n0.01\n0.015\n0.02\n\n-2\n-1.5\n-1\n-0.5\n0.5\n1.5\n0.005\n0.01\n0.015\n0.02\n-2\n-1.5\n-1\n-0.5\n0.5\n1.5\n0.005\n0.01\n0.015\n0.02\n\nSpectral representation\n-\nPhase differences are relatively unimportant to sound quality, so key\nproperties of a complex wave can be specified in terms of the\nfrequencies and amplitudes of its sinusoidal components.\nFrequency Amplitude\n(Hz)\n0.6\n0.45\n0.3\n0.1\n0.2\n0.4\n0.6\n0.8\n1.2\nfrequency (Hz)\nAmplitude\nPower spectrum\n\nIdealized vowel spectrum\nImage by MIT OCW.\nIntensity level (decibels)\nFrequency (Hertz)\n\nvowel spectrum\nFrequency (Hz)\n[æ]\n\nVowel quality\n- The quality of a vowel depends on the shape\nof its spectrum.\n- The shape of the spectrum depends on the\nshape of the vocal tract.\n[æ]\n[]\nFrequency (Hz)\nFrequency (Hz)\n\nVowel quality\n- The peaks in the spectrum of a vowel are\ncalled formants.\n- Perceived vowel quality depends primarily\non the frequencies of the first three\nformants.\n[æ]\n[]\nFrequency (Hz)\nFrequency (Hz)\n\nSpectrograms\n(c) Source Unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nSpectrograms\n0.004\n0.952\nImage by MIT OCW.\n\nFigure removed due to copyright restrictions.\nSource: Figure 8.16, Ladefoged, Peter, and Keith Johnson.\nA course in phonetics. Nelson Education, 2014.\n\nFrequency (Hz)\nFrequency (Hz)\n-20\nFrequency (Hz)\nnarrow band\n(long window)\nbroad band\n(short window)\n\nFrequency (Hz)\n-20\nFrequency (Hz)\nFrequency (Hz)\n-20\nTime (s)\n3.46955\n3.7731\n3.55\n3.59\n3.69\n\nFigure removed due to copyright restrictions.\nSource: Figure 8.4, Ladefoged, P., and K. Johnson.\n\"A Course in Phonetics (Cengage Learning).\" (2010).\n\nF2 (Hz)\nF1 (Hz)\nImage by MIT OCW.\nAdapted from Peter Ladefoged. A Course in Phonetics. 5th ed. Berlin, Germany: Heinle, 2005.\nISBN: 9781413006889. Available at: http://www.phonetics.ucla.edu/course/contents.html.\ni\nu\nI\nε\nΩ\nc\nϪ\næ\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n24.915 l 24.963 Linguistic Phonetics\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms ."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 2",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-915-linguistic-phonetics-fall-2015/9032198e0b0693a6de4dd0fba674d0f3_MIT24_915F15_lec2.pdf",
      "content": "24.963\nLinguistic Phonetics\nBasic Audition\n\nDiagram of the inner ear removed due to copyright restrictions.\n\n- Reading: Keating 1985\n\n.963 also read Flemming 2001\n\n- 24\n- Assignment 1 - basic acoustics. Due 9/22.\n\nAudition\n\nAnatomy\n\nAnantomy of the\nouter, m\niddle,\nan\nd inner e\nar.\nImage by MIT OCW.\n\nAuditory 'spectrograms'\n\nThe auditory system performs a running frequency analysis of\nacoustic signals - cf. spectrogram.\n\n- But the auditory spectrogram differs from a regular\nspectrogram in significant ways, e.g.:\n\n- Frequency - a regular spectrogram analyzes frequency bands\nof equal widths, but the peripheral auditory system analyzes\nfrequency bands that are wider at higher frequencies.\n\n- Loudness is non-linearly related to intensity\n\n- Masking effects (simultaneous and non-simultaneous).\n\n- It is useful to bear these differences in mind when looking at\nacoustic spectrograms.\n\n- It is possible to generate 'auditory spectrograms' based on\nmodels of the auditory system.\n\nLoudness\n\n- The perceived loudness of a sound depends on the\namplitude of the pressure fluctuations in the sound\nwave.\n\n- Amplitude is usually measured in terms of root-\nmean-square (rms amplitude):\n\n- The square root of the mean of the squared amplitude\nover some time window.\n\nrms amplitude\n\n-\nSquare each sample in the analysis window.\n\n-\nCalculate the mean value of the squared waveform:\n\n- Sum the values of the samples and divide by the number of\nsamples.\n\n-\nTake the square root of the mean.\n\n-1.5\n-1\n-0.5\n0.5\n1.5\n0.05\n0.1\n0.15\n0.2\ntime\npressure\npressure\npressure^2\nrms amplitude\n\nrms amplitude\n\nSte\nep\ns\nine-like waves. The x-axis is time in seconds.\nImage by MIT OCW.\nAdapted from Johnson, Keith. Acoustic and Auditory Phonetics.\nMalden, MA: Blackwell Publishers, 1997. ISBN: 9780631188483.\n\nIntensity\n\n- Perceived loudness is more closely related to intensity\n(power per unit area), which is proportional to the square\nof the amplitude.\n\n- relative intensity in Bels =\nlog10(x2/r2)\n\n- relative intensity in dB =\n10 log\n10(x /r2)\n\n= 20 log10(x/r)\n\n- In absolute intensity measurements, the comparison\namplitude is usually 20μPa, the lowest audible pressure\nfluctuation of a 1000 Hz tone (dB SPL).\n\nlogarithmic scales\n\n- log xy = log x + log y\n\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n1.6\n1.8\nx\nlog(x)\n\nLoudness\n\n- The relationship between intensity and perceived loudness\nof a pure tone is not exactly logarithmic.\n\n- Loudness of a pure tone (> 40\ndB) in Sones:\n\n- Loudness is defined to be 1 sone\nfor a 1000 Hz tone at 40 dB SPL\n\nN = 2\ndB-40\n(\n)\nPressur\ne vs. Son\nes and vs\n. dB SPL\ns\nh\now\nin\ng\nso\nme\nwh\nat\nl\nog\nrit\nh\nm\ni\nc\n\nre\nla\nti\non\nsh\nip\n. Two separate\nlines\n.\nImage by MIT OCW.\nAdapted from Johnson, Keith. Acoustic and Auditory Phonetics.\nMalden, MA: Blackwell Publishers, 1997. ISBN: 9780631188483.\n\nLoudness\n\n- Pure tones: 131-2092 Hz\n- Which sounds loudest?\n\nLoudness\n\n- Loudness also depends on frequency.\n- equal loudness contours for pure tones:\n(c) Springer. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\n\nLoudness\n\n- At short durations, loudness also depends on duration.\n- Temporal integration: loudness depends on energy in the\nsignal, integrated over a time window.\n- Duration of integration is often said to be about 200ms, i.e.\nrelevant to the perceived loudness of vowels.\n\nPitch\n\n- Perceived pitch is approximately linear with respect to\nfrequency from 100-1000 Hz, between 1000-10,000 Hz the\nrelationship is approximately logarithmic.\nF\nr\ne\nq\nue\nnc\ny\n(k\nH\nz\n)\n\nv\ns\n.\n\nF\nre\nquency (Bark) s\nhowing logrithmic relationship.\nImage by MIT OCW.\nAdapted from Johnson, Keith. Acoustic and Auditory Phonetics.\nMalden, MA: Blackwell Publishers, 1997. ISBN: 9780631188483.\n\nPitch\n\n-\nThe non-linear frequency response of the auditory system is related to the\nphysical structure of the basilar membrane.\n-\nbasilar membrane uncoiled :\nImage by MIT OCW.\nAna\ntom\nica\nl i\nllust\nratio\nn of\near c\nanal.\n'\n'\nDiagram of the inner ear removed due to copyright restrictions.\n\nFrequency resolution\n\n- In the same way, the structure of the basilar membrane\naffects the frequency resolution of the auditory\n'spectrogram'.\n- An acoustic spectrogram represents the variation in intensity\nover time in a set of frequency bands.\n- E.g. a standard broad-band spectrogram might use frequency bands of\n0-200 Hz, 200-400 Hz, 400-600 Hz, etc.\n- The ear represents loudness in frequency bands that are\nnarrower at low frequencies and wider at high frequencies.\n- ?-100Hz, 100-200 Hz, ..., 400-510 Hz, ...1080-1270 Hz, ...\n12000-15500.\n- These 'critical bands' correspond to a length of about 1.3mm along\nthe basilar membrane (Fastl & Zwicker 2007: 162)\n(\n)\n)\nAna\ntom\nica\nl i\nllust\nratio\nn of\near c\nanal.\nImage by MIT OCW.\n\nAuditory spectra\n\nNu\nmb\ner\no\nf\nER\nBs\nv\ns.\ne\nxc\nit\nat\nio\nn\nle\nve\nl\n\n(\nd\nB): two curves pe\naking at 50 dB and 8\n0 dB, the\nn dropping off and rising again.\nFrequ\nency\n(Hz)\nvs. L\nevl (\ndB),\ndots,\nwi\nt\nh\na\npa\ntt\ner\nn\nma\nki\nng\na\nlarge trough\nat ~1250\ndB.\nImage by MIT OCW.\nAdapted from Moore, Brian. The Handbook of Phonetic Science. Edited by William J.\nHardcastle and John Laver. Malden, MA: Blackwell, 1997. ISBN: 9780631188483.\nImage by MIT OCW.\nAdapted from Moore, Brian. The Handbook of Phonetic Science. Edited by William J.\nHardcastle and John Laver. Malden, MA: Blackwell, 1997. ISBN: 9780631188483.\n\nItalian vowels\ni\ne\n\na\n\no\nu\nF2 (Hz)\nF1 (Hz)\nERB scales\nF2 (E)\nF1(E)\nE(F1)\n\n(c) Wiley-Blackwell. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\nSource: Johnson, K. (2011) \"Acoustic and Auditory Phonetics, 3rd ed. Wiley-Blackwell, Oxford.\n\nMasking - simultaneous\n\n- Energy at one frequency can reduce audibility of\nsimultaneous energy at another frequency (masking).\n- Single tone, followed by the same tone and a higher-\nfrequency tone, repeated with progressive reduction in the\nintensity of the higher tone\n- For how many steps can you hear two tones?\n- Same pattern, same amplitude tones, but greater difference in\nthe frequencies of the tones\n- For how many steps can you hear two tones?\n\nMasking - simultaneous\n\n- Energy at one frequency can reduce audibility of\nsimultaneous energy at another frequency (masking).\nStevens\n(1999)\n\nGrap\nh: f\nrequ\nency\nof\nmask\ned t\none\nvs. masking. A peak at\n1200 Hz\n.\nImage by MIT OCW.\nAdapted from Stevens, Kenneth N. Acoustic Phonetics. Cambridge,\n\nMA: MIT Press, 1999. ISBN; 9780262194044.\n\nTime course of auditory nerve response\nResponse to a noise burst:\n\n- Strong initial response\n- Rapid adaptation (~5 ms)\n- Slow adaptation (>100ms)\n- After tone offset, firing rate\nonly gradually returns to\nspontaneous level.\nKiang et\nal (1965)\n\nTwo\ngr\nids\n,\nsh\nowi\nng\na\n\nsh\nade\nd peaked block in the lower left corner.\nImage by MIT OCW.\nAdapted from Kiang et al. (1965)\n\nInteractions between sequential sounds\n\n- A preceding sound can affect the auditory nerve response\nto a following tone (Delgutte 1980).\nL\nine\ngr\naph\ns s\nhow\ni\nng\ndis\nc\nha\nrge ra\nte, most peaks\naround 375 dB SPL.\nImage by MIT OCW.\nAdapted from Stevens, Kenneth N. Acoustic Phonetics. Cambridge, MA: MIT Press, 1999. ISBN; 9780262194044, after Delgutte, B. \"Representation\nof speech-like sounds in the discharge patterns of auditory-nerve fibers.\" Journal of the Acoustical Society of America 68, no. 3 (1980): 843-857.\n\nCourtesy of the MIT Press from Schnupp, Jan, Israel Nelken, and Andrew King. Auditory\nneuroscience: Making sense of sound. MIT press, 2011. Used with permission.\nSource: Schnupp, Nelken & King (2011) \"Auditory Neuroscience: Making Sense\nof Sound. MIT Press.\n\n24.963\nLinguistic Phonetics\nAnalog-to-digital conversion of\nspeech signals\nAnalog acoustic signal (jagged curve) and sampled quantized digital signal (vertical lines).\nImage by MIT OCW.Analog acoustic signal (jagged curve) and sampled quantized digital signal (vertical lines).\n.01\n.02\n.03 s\n- Air pressure +\nTime in seconds\n\nAnalog-to-digital conversion\n\n- Almost all acoustic analysis is now computer-based.\n- Sound waves are analog (or continuous) signals, but digital\ncomputers require a digital representation - i.e. a series of\nnumbers, each with a finite number of digits.\n- There are two continuous scales that must be divided into\ndiscrete steps in analog-to-digital conversion of speech: time\nand pressure (or voltage).\n- Dividing time into discrete chunks is called sampling.\n- Dividing the amplitude scale into discrete steps is called\nquantization.Analog acoustic signal (jagged curve) and sampled quantized digital signal (vertical lines).\nImage by MIT OCW.Analog acoustic signal (jagged curve) and sampled quantized digital signal (vertical lines).\n.01\n.02\n.03 s\n- Air pressure +\nTime in seconds\n\nSampling\n\n- The amplitude of the analog\nsignal is sampled at regular\nintervals.\n- The sampling rate is measured\nin Hz (samples per second).\n- The higher the sampling rate,\nthe more accurate the digital\nrepresentation will be.\nT\nhre\ne l\nine\ngra\nphs\n\nsho\nwin\ng a\ncon\nsta\nn\nt h\nori\nzon\nal l\nine\nthrough the center, with fluctuations around it.\nImage by MIT OCW.\nAdapted from Ladefoged, Peter. L104/204 Phonetic Theory\nlecture notes, University of California, Los Angeles.\n\nSampling\n\n-\nIn order to represent a wave\ncomponent of a given frequency, it\nis necessary to sample the signal\nwith at least twice that frequency\n(the Nyquist Theorem).\n-\nThe highest frequency that can be\nrepresented at a given sampling rate\nis called the Nyquist frequency.\n-\nThe wave at right has a significant\nharmonic at 300 Hz\n- (a) sampling rate 1500 Hz\n- (b) sampling rate 600 Hz\n- (c) sampling rate 500 Hz\nT\nhre\ne l\nine\ngra\nphs\n\nsho\nwin\ng a\ncon\nsta\nn\nt h\nori\nzon\nal l\nine\nthrough the center, with fluctuations around it.\nImage by MIT OCW.\nAdapted from Ladefoged, Peter. L104/204 Phonetic Theory\nlecture notes, University of California, Los Angeles.\n\nWhat sampling rate should you use?\n\n- The highest frequency that (young, undamaged) ears can\nperceive is about 20 kHz, so to ensure that all audible\nfrequencies are represented we must sample at 2×20 kHz =\n40 kHz.\n- The ear is relatively insensitive to frequencies above 10\nkHz, and almost all of the information relevant to speech\nsounds is below 10 kHz, so high quality sound is still\nobtained at a sampling rate of 20 kHz.\n- There is a practical trade-off between fidelity of the signal\nand memory, but memory is getting cheaper all the time.\n\nWhat sampling rate should you use?\n\n- For some purposes (e.g. measuring vowel formants), a high\nsampling rate can be a liability, but it is always possible to\ndownsample before performing an analysis.\n- Audio CD uses a sampling rate of 44.1 kHz.\n- Many A-to-D systems only operate at fractions of this rate\n(44100 Hz, 22050 Hz, 11025 Hz).\n- For most purposes, use a sampling rate of 44.1 kHz.\n\nAliasing\n\n- Components of a signal which are above the Nyquist\nfrequency are misrepresented as lower frequency\ncomponents (aliasing).\n- To avoid aliasing, a signal must be filtered to eliminate\nfrequencies above the Nyquist frequency.\n- Since practical filters are not infinitely sharp, this will\nattenuate energy near to the Nyquist frequency also.\n31Line graph of time vs. amplitude, with a steep sine-like wave and another with a greater interval intersecting at 4 points.\nTime (ms)\nAmplitude\nImage by MIT OCW.\nAdapted from Johnson, Keith. Acoustic and Auditory Phonetics.\nMalden, MA: Blackwell Publishers, 1997. ISBN: 9780631188483.\n\nQuantization\n\n- The amplitude of the signal at each sampling point must be\nspecified digitally - quantization.\n- Divide the continuous amplitude scale into a finite number\nof steps. The more levels we use, the more accurately we\napproximate the analog signal.\nLi\nne\ng\nr\na\nph of ti\nme vs. am\nplitude,\nsine-like wave with a horizonal line dividing it.\nImage by MIT OCW.\nAdapted from Johnson, Keith. Acoustic and Auditory Phonetics.\nMalden, MA: Blackwell Publishers, 1997. ISBN: 9780631188483.\n\nQuantization\n\n- The number of levels is specified in terms of the number of\nbits used to encode the amplitude at each sample.\n- Using n bits we can distinguish 2n levels of amplitude.\n- e.g. 8 bits, 256 levels.\n- 16 bits, 65536 levels.\n- Now that memory is cheap, speech is almost always\ndigitized at 16 bits (the CD standard).\n\nQuantization\n\n- Quantizing an analog signal necessarily introduces\nquantization errors.\n- If the signal level is lower, the degradation in signal-to-\nnoise ratio introduced by quantization noise will be greater,\nso digitize recordings at as high a level as possible without\nexceeding the maximum amplitude that can be represented\n(clipping).\n- On the other hand, it is essential to avoid clipping.\nLine grap\nh\n\nof\nt\nim\ne\nvs. amplitude, sine-like wave with a horizonal line dividing it.\nImage by MIT OCW.\nAdapted from Johnson, Keith. Acoustic and Auditory Phonetics.\nMalden, MA: Blackwell Publishers, 1997. ISBN: 9780631188483.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n24.915 / 24.963 Linguistic Phonetics\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 3",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-915-linguistic-phonetics-fall-2015/f49dce3ff5d1b89045e258cb2c762f8d_MIT24_915F15_lec3.pdf",
      "content": "24.963\nLinguistic Phonetics\nThe position of phonetics in\ngrammars\n\nCha\nrt (left to right): binary\nand scalar phonolog\ny, phonetic transcript\nion, universal phonetic\ns.\nImage by MIT OCW.\nAdapted from Keating, P. \"Universal phonetics and the organization of grammars.\"\nIn PhoneticLinguistics. Edited V. Fromkin. Indianapolis, IN: Academic Press, 1985,\npp. 115-32.\n\n- Reading for next week: Johnson chapter 2.\n\n- Assignment: Mandarin aspiration, due 9/29.\n\nPhonetic and phonological representations\n\n- The study of linguistic sound patterns is traditionally\ndivided into two sub-fields: phonetics and phonology.\n\n- Phonology specifies the sounds that a language uses, the\ndistribution of those sounds, and alternations in the\nrealization of morphemes (among other things).\n\n- What is left for phonetics?\n\n- If the 'sounds' whose distribution is specified in the\nphonology are characterized in sufficient physical detail,\nthen phonology should describe all aspects of the sound\nstructure of a language.\n\n- But phonology traditionally operates in terms of rather\ncoarse-grained descriptions of sounds, so a lot of detail is\nleft out.\n\nPhonetic and phonological representations\n\n- Example - phonological representations in\nChomsky and Halle (1968):\n\n- strings of segments, essentially as in IPA-style\ntranscription.\n\n- each segment is specified as a matrix of binary\nfeature specifications.\n\n- Features are defined phonetically, but in rather\nbroad terms.\n\nPhonetic and phonological representations\n\nE.g. Halle and Clements (1983):\n\nTable l\nisting \"features\" and \"de\nfinitions\nof the value\" for phonetic\nand phonological representations.\nImage by MIT OCW.\nAdapted from Halle, M., and N. Clements. Problem Book in Phonology: A Workbook for Courses\nin Introductory Linguistics and Modern Phonology. Cambridge, MA: MIT Press, 1983.\n\nPhonetic and phonological representations\n\nTable listing \"features\" and \"definitions of the value\" for phonetic an\nd phonolo\ngical representations.\nImage by MIT OCW.\nAdapted from Halle, M., and N. Clements. Problem Book in Phonology: A Workbook for Courses\nin Introductory Linguistics and Modern Phonology. Cambridge, MA: MIT Press, 1983.\n\nPhonetic and phonological representations\n\n- So standard phonological representations can characterize\nspeech to about the same level of detail as a broad phonetic\ntranscription. The remaining detail is generally held to be\nthe subject matter of phonetics.\n\n- Chomsky and Halle proposed an intervening step: phonetic\ndetail rules convert binary feature specifications into scalar\nvalues.\n\n- However, hardly anybody has actually adopted this\nproposal.\n\n- The remaining detail is supposed to be a matter of universal\nphonetics, and therefore not really part of grammar.\n\nPhonetics and phonology\n\n- The question that Keating (1985) addresses\nis how much phonetic detail can be supplied\nby 'universal phonetics'.\n\n- The short answer: not much.\n\n- Implication: Most aspects of phonetic\nrealization must be specified in grammar,\neither in phonology or in a phonetic\ncomponent.\n\nWidespread tendencies are subject to language-\nspecific variation\n\nCase study: Voicing effects on vowel duration.\n\n- Vowels are shorter before voiceless obstruents than before\nvoiced obstruents or sonorants in many languages (Chen\n1970)\n\n- E.g. English [E] is shorter in shorter in 'bet' than in\n'bed' and 'ben' (ratio is approx. 0.8).\n\n- Language-specific variation:\n\n- Effect is greater in English\n\n- No effect in Polish, Czech, Saudi Arabic\n\n- Some evidence that the effect is conditioned by\nunderlying voicing in Russian, German, English\n\n- There are many more examples of language-specific\nrealization of similar phonological categories (below).\n\nMechanical physiological effects\n\n- What could give rise to universal phonetic effects?\n\n- Keating: mechanical physiological effects.\n\n- If a pattern of realization is a consequence of basic\nphysiology then it should be observed in all languages.\n\nKeating: Mechanical physiological effects\n\nCase study: Intrinsic vowel duration\n\n- Across languages, lower vowels are longer, other things\nbeing equal.\n\n- Lehiste (1970): low vowels generally involve greater\narticulatory movement from/to adjacent consonants.\n\n- If articulator velocities are constrained, lower vowels will\ntake longer to produce.\n\n- Hypothesized physiological basis: If only the magnitude, but\nnot duration, of force input to jaw varies, low vowels will be\nlonger (Lindblom 1967).\n\nKeating: Mechanical physiological effects\n\nTest: Electromyographic (emg) study of muscle activity in jaw\nlowering.\n\n- Lower jaw position is correlated with longer duration in\nEnglish\n\n- The difference in duration was due to difference in\nmovement duration, not duration of steady state.\n\n- But low vowels show longer and higher amplitude of muscle\nactivity\n\n- i.e. variation in duration is under the control of the speaker.\n\n- The correlation between vowel height and duration could\nstill be related to differences in movement distance, but the\nlinkage does not have the hypothesized mechanical basis.\n\n- Could involve a dispreference for the effort involved in\nfast movements.\n\nPhonetic and phonological representations\n\nE.g. Halle and Clements (1983):\n\n5Table listing \"features\" and \"definitions of the value\" for phonetic and phonological representations.\nFeature\nDefinition of the + value\n[syllabic]\n'Constitute syllable peaks'\n'Sustained vocal tract constriction at least equal to that required\n[consonantal]\nin the production of fricatives'\n[sonorant]\n'Air pressure inside and outside the mouth is approximately equal\n[coronal]\n'Raising the tongue blade towards the teeth or the hard palate'\n[anterior]\n'Primary constriction at or in front of the alveolar ridge'\n[labial]\n'With a constriction at the lips'\n'With a constriction that extends for a considerable distance along\n[distributed]\nthe midsaggital axis of the oral tract'\n[high]\n'Raising the body of the tongue toward the palate'\n[back]\n'With the tongue body relatively retracted'\n'Drawing the body of the tongue down away from the roof of the\n[low]\nmouth'\n[round]\n'With protrusion of the lips'\n'Allowing the air stream to flow through the midsaggital region\n[continuant]\nof the oral tract'\nImage by MIT OCW.\nAdapted from Halle, M., and N. Clements. Problem Book in Phonology: A Workbook for Courses\nin Introductory Linguistics and Modern Phonology. Cambridge, MA: MIT Press, 1983.\n\nThe nature of phonetic universals\n\n- The failure of phonetic universals to place hard constraints\non cross-linguistic variation is unsurprising. E.g:\n\n- Phonetic universal: There are limits on the rate of f0\nchange.\n\n- Xu & Sun (2002) asked subjects to imitate a fast,\nalternating high-low pitch pattern, with various pitch\nranges between H & L.\n\n- Mean time (ms) to complete a pitch change of d\nsemitones:\n\n- Rising: t = 89.6 + 8.7d\n\n- Falling: t = 100.4 + 5.8d\n\n- E.g. a fall from 200 Hz to 100 Hz (12 s.t.) takes at least\n~170 ms.\n\nTone coarticulation in Cantonese\n- So it's no surprise that there are transitions between\ntones of different levels.\n(c) ISCSLP. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\nSource: Li, Lee & Qian (2002) \"Acoustical F0 analysis of continuous Cantonese\nspeech.\" International Symposium on Chinese Spoken Language Processing.\n\nTonal coarticulation\n-\nBut there is no obvious physiological constraint that determines how\nf0 transitions should be timed with respect to the segmental string.\n\nduring syll1?\n\nduring syll2?\nacross the boundary?\n\n-\nDifferent patterns are observed in different languages.\n\nTone coarticulation in Cantonese\n- In Cantonese transition towards a tone does not begin\nuntil the onset of the syllable containing that tone (Li\net al 2004).\n\n- Also in Mandarin (Xu 1997), Thai (Gandour et al 1994),\nVietnamese (Brunelle 2003).\n\n(c) ISCSLP. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\nSource: Li, Lee & Qian (2002) \"Acoustical F0 analysis of continuous Cantonese\nspeech.\" International Symposium on Chinese Spoken Language Processing.\n\nTonal coarticulation in Kinyarwanda\n\nKinyarwanda (Myers 2003), L, H tones:\n\n- In an L.H sequence, the rising transition begins well\nbefore the onset of the H tone syllable, half way through\nthe low syllable, or earlier.\n\n- Falling transition carries over into a following L syllable.\n\nsyllable onset\nbeginning of rise\nH\n(c) International Society of Phonetic Sciences, Karger. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\nSource: Myers, Scott. \"F0 timing in Kinyarwanda.\" Phonetica 60, no. 2 (2003): 71-97.\n\nTonal coarticulation\n\n- Transitions between tones are universal, but the timing of\nthose transitions is language-specific and must be\nspecified in the grammar.\n\n- Physiological limitations constrain phonetic realization,\nbut they cannot determine it.\n\nPhonetic grammars\n\n- Hypothesis: phonetic grammars operate by balancing\nconflicting constraints enforcing preferred properties for\nphonetic realizations.\n\n- Two basic classes of constraints:\n\n- Minimize Effort - physiological limitations, etc.\n\n- Faithfulness constraints - require accurate realization of\nperceptual targets for speech sounds.\n\n- Phonetic realizations are selected to so as to minimize\nviolation of these constraints.\n\n- Cross-linguistic variation derives from different\nweightings of these constraints.\n\n- Weights may correlate with phonological properties.\n\nTonal coarticulation\n\n- Tonal targets extend through the syllable (Xu & Liu 2006)\n\n- Faithfulness: Do not deviate from tonal targets.\n\n- Effort: limits on rate of change of F0\n\n- These constraints conflict - transitions result in deviation\nfrom the tone targets.\n\n- Specific patterns of timing result from more specific\nfaithfulness constraints that penalize deviations from\nparticular kinds or parts of targets.\n\nTonal coarticulation\n\nThe Cantonese pattern:\n\n- faithful realization of tonal targets is more important in\nthe rime than in the onset (Flemming 2011)\n\n- The rime is generally the region of highest intensity periodicity,\nand therefore the place where tone is most perceptible (cf.\nZhang 2004).\n\n- Realizing transitions at the beginnings of syllables\nminimizes violation of faithfulness to rime targets:\n\nuleast deviation\nin rime\n\nugreatest deviation\nin rime\n\nudeviation in rime\n\nPhonetic realization as an optimization problem\n\n- This analysis can be given a precise formulation as an\noptimization problem.\n\n- Effort: assume a maximum rate of F0 transition.\n\n- So transition between level tones takes the form shown\nbelow.\n\n0.1\n0.2\n0.3\n0.4\ntime (s)\nF0 (Hz)\n\nFaithfulness constraints\n\n- Ident-T: The F0 contour must match the tone target, T.\n\n- Cost of violation is proportional to the squared\ndifference between the target and the actual F0\ncontour, integrated over the duration of the target.\n\n- Multiplied by a language-specific weight.\n\n- Ident-T-rime: The F0 contour must match the tone target\nduring the rime.\n\n- Cost calculated in the same way.\n\n- Also weighted.\n\n- Select the timing of the F0 transition that minimizes the\nsummed violations of the faithfulness constraints, subject\nto the effort constraint on maximum rate of F0 transition.\n\nExample: Realization of H.L\n\n- Ident-T has a weight of 1\n\n- Ident-T-rime has a weight of 0\n\n0.1\n0.2\n0.3\n0.4\ntime (s)\nF0 (Hz)\n0.1\n0.2\n0.3\n0.4\ntime (s)\nF0 (Hz)\n- Ident-T has a weight of 0.01\n\n- Ident-T-rime has a weight of\n0.99.\n\nTonal coarticulation\nThe Kinyarwanda pattern:\n\n- faithfulness to H tone targets is more important than\nfaithfulness to L tone targets.\n- Only one H tone per morpheme, so H tones are much more\ninformative than L tones in distinguishing words from each\nother\n- Realizing transitions during L tone syllables minimizes\nviolation of faithfulness to H tone targets.\nuleast deviation\nfrom H target\n\nugreatest deviation\nfrom H target\n\nudeviation from H\ntarget.\n\nThe nature of phonetic universals\n- Phonetic universals are constraints, not patterns of\nphonetic realization.\n- Patterns of phonetic realization derive from the\ninteraction of multiple constraints.\n- They are language-specific because the\nprioritization of constraints differs across\nlanguages.\n\nThe nature of phonetic universals\n- Phonetic universal: full retroflexion is not\ncompatible with a high front tongue position [i].\n(The tongue tip/blade and tongue body cannot\nsimultaneously form constrictions with the hard\npalate).\nLine drawings illustrating tongue positions for Tamil speakers.\nImages by MIT OCW.\nLeft figure adapted from Ladefoged, Peter, and Ian Maddieson. The Sounds of the World's Languages.\nMalden, MA: Blackwell, 1996. Right figure adapted from Stevens, Kenneth N. Acoustic Phonetics.\nCambridge, MA: MIT Press, 1999.\n\nThe nature of phonetic universals\n- This constraint has a variety of consequences in front vowel/\nretroflex sequences:\n- Kodagu (Emeneau 1970) - vowels are retracted\npreceding retroflexes.\n- Gugada (Platt 1972) - partial backing and lowering of\nvowel [i ∂] (cf. English).\n- Mantjiltjara (Marsh 1969) - retroflexion is 'very weak'\nafter [i].\n- Gujarati - reduced retroflexion following [i] observable\nin palatograms in Dave (1977).\n- Effort constraint: minimize peak velocity of articulator\nmovements (tongue tip, body).\n- Faithfulness to C targets, Faithfulness to V targets.\n- Different patterns result from different constraint weights.\n\nEvidence for language-specific phonetic detail\n- Cross-linguistic variation in the realization\nof phonological categories\n\n- Aspirated and unaspirated voiceless stops\n- [p vs. ph]\n- Background: Voice Onset Time\n\nVoice Onset Time\n\n- English utterance-initial stops\nVoiceless unaspirated\nVoiceless aspirated\n\nTime (s)\n1.1154\n1.27558\n-0.471\n0.3268\nTime (s)\n1.1154\n1.27558\nTime (s)\n4.26614\n4.42706\n-0.3718\n0.1853\nTime (s)\n4.26614\n4.42706\n22 ms\n86 ms\n\ndie\n\ntie\n\nTime (s)\n547.195\n547.485\n-0.1468\n0.2644\nTime (s)\n547.195\n547.485\nVOT, closure voicing\n\n-\nEnglish intervocalic stops can be fully voiced\n- VOT is 0 ms in 2nd and 3rd stops\nbrigadoo(n)\n\nVOT, closure voicing\n\n-\nHindi - three-way contrast\n-\nrecordings from Ladefoged http://www.phonetics.ucla.edu/vowels/chapter12/hindi.html\nbal\n\nhair\nTime (s)\n0.231127\n-0.4972\n0.494\nTime (s)\n0.231127\nTime (s)\n0.113588\n-0.4971\n0.3851\nTime (s)\n0.113588\nTime (s)\n0.13828\n-0.475\n0.2819\nTime (s)\n0.13828\npal\n\ntake care of\n\nphal\nknife blade\n\n'\n'\n'\n'\n'\n'\n\nCross-linguistic variation in voiceless stops\n\n- Standard phonological representations use a single\nfeature, [+/-spread glottis] to distinguish aspirated\nand unaspirated stops.\n- If phonetics is universal, these categories should be\nrealized similarly in all languages.\n- In fact VOT of voiceless unaspirated and aspirated\nstops varies significantly between languages.\n\n- Voiceless aspirated\nand unaspirated\nvelar stops (Cho and\nLadefoged 1999, Ladefoged\nand Cho 2001).\nCross-linguistic variation in voiceless stops\n\nFigure removed due to copyright restrictions.\nSource: Ladefoged, Peter, and Taehong Cho. \"Linking linguistic contrasts to\nreality: The case of VOT.\" UCLA Working Papers in Phonetics (2000): 1-9.\n\n- Conflicting constraints?\n- Distinctiveness of voicing/aspiration contrasts (favors\nlonger VOT for aspirated stops, shorter VOT for\ncontrastively unaspirated stops).\n- Preference for fully voiced vowels (faithfulness to vowel\ntargets).\n- And/or faithfulness to place of articulation targets:\naspiration makes formant transitions less clear.\nCross-linguistic variation in voiceless stops\n\nVOT duration/voiced vowel duration trade-off\n- Port and Rotunno (1979)\nfound that in English VOT\nincreases with duration of the\nfollowing vowel,\n- but VOT is not a fixed\nproportion of the vowel.\n- This pattern could represent a\ntrade-off between a\npreference for distinct voicing\ncontrasts (long VOT) and\nfaithfulness to vowel targets\n(preference for fully voiced\nvowels).\nGr\nap\nh (\nvow\nel\ndur\nati\non\nvs.\nVOT\n): 3\nstr\naig ht lines of 3 intiial stops with final consonants.\nImage by MIT OCW.\nAdapted from Port, Robert F., and Rosemarie Rotunno. \"Relation between\nvoice-onset time and vowel duration.\" The Journal of the Acoustical\nSociety of America 66, no. 3 (September 1979): 654-662.\n\n- 'VOT' in ejectives (a.k.a. glottal lag)\n- Examples: Montana Salish\nCross-linguistic variation in the realization of\nphonological categories\n\nTime (s)\n4.19613\n4.77223\nTime (s)\n0.598413\npʼum\nt'a!q' n\n\nVOT in ejectives\n\n- Navaho [k'a.../] vs. Hausa [k'a...ra~...]\n- Navajo 94ms vs. Hausa 33ms\nSp\neakin\ng patterns showing moda\nl voic\ne through i\nllustrated oscillati\non.\nImage by MIT OCW.\n\n- Cho and Ladefoged (1999)\nVOT in ejectives\n\n- Standard phonological features treat all ejectives\nas [+constricted glottis] stops.\n- but there are significant language-specific differences in\nphonetic realization within this category.\nVoice Onset Time (ms) for Ejectives in Six Languages\nLanguage\nBilabial\nAlveolar\nVelar\nUvular\nApache\nHupa\nMontana Salish\nNavajo\nTlingit\nYapese\nImage by MIT OCW.\nAdapted from.Cho, Taehong, and Peter Ladefoged. \"Variations and universals in VOT:\nEvidence from 18 languages.\" Journal of Phonetics 27 (1999): 207-229\n\nDegrees of retroflexion\n\nTwo (or more) degrees of retroflexion\n\n- Apical post-alveolar, e.g. Hindi, vs. Sublaminal\npost-alveolar, e.g. Telugu (Ladefoged and Bhaskararao\n1983)\n- Phonologically: both [+coronal, -anterior, -\ndistributed]?\nLine\ndrawi\nngs of\napico retroflex of Hindi, Tamil, and Telugu.\nImage by MIT OCW.\nAdapted from Ladefoged, Peter, and Ian Maddieson. The Sounds of the World's Languages. Malden, MA: Blackwell, 1996.\nBased on Ladefoged, Peter, and Peri Bhaskararao. \"Non-quantal aspects of consonant production: A study of retroflex\nconsonants.\" Journal of Phonetics 11 (1983): 291-302.\n\nVowel quality\n\n- Similar front vowels of Danish\n(dotted) and English (solid)\n(Disner 1978, 1983).\n- Danish vowels are\nsystematically higher than their\nEnglish counterparts.\nElip\nses\non a\ngra\nph\nwit\nh f\nreq\nuen\nce\nin\nHz\non\nthe\ny-ax\nis.\nImage by MIT OCW.\nAdapted from Disner (1983).\n\nCross-linguistic variation in contextual\nphonetic effects\n\n- Coarticulation\n- e.g. Nasalization adjacent to nasals (Cohn 1990,\n1993).\nLine graphs showing l\nevel of nasal\ni\nz\na\nt\ni\no\nn\n.\nImage by MIT OCW.\nAdapted from Cohn, A. Nasalization in English: Phonology or phonetics? Phonology 10 (1993): 43-81.\n\nLanguage-specific variation in stop-vowel\ncoarticulation\n\n- F2 at the release of a stop, F2(C), varies as a linear\nfunction of F2 at the middle of the following vowel, F2(C)\n(1st lecture)\nTime (s)\n12.4125\n12.7061\nTime (s)\n10.4582\n10.7544\nTime (s)\n8.57261\n8.8872\ndid\n\ndɛd\ndɑt\nF2(C)\n\nF2(V)\n\nFigure removed due to copyright restrictions.\nSource: Figure 1, Fowler, Carol A. \"Invariants, specifiers, cues: An\ninvestigation of locus equations as information for place of articulation.\"\nAttention, Perception, & Psychophysics 55, no. 6 (1994): 597-610.\n\n- F2(C) after stops is a linear function of F2(V) in CV\nsequences in all languages that have been studied, but the\nslope and intercept of that function differ from language to\nlanguage for similar sounds.\n- Thai [d]\n\nF2(C) = 0.3F2(V) + 1425\n(0.24-0.33)\n- Urdu [d]\n\nF2(C) = 0.5F2(V) + 857\n(0.43-0.57)\n- Sussman et al (1993). Averages over 6 and 5 speakers respectively.\nBoth stops are reported to be dental.\n- So the specific patterns must be specified in the grammars\nof these languages.\nLanguage-specific variation in stop-vowel\ncoarticulation\n\nClosed syllable shortening\n\n- Thai: long vowels are\nsubstantially shorter in\nclosed syllables (Moren &\nZsiga 2006)\n\n- Navajo: long vowel\nduration is similar in closed\nand open syllables (Zhang\n2001)\n\n46Bar graphs showing Thai, Navajo, and Cantonese sonorous rime duration.\nCV\nCVN\nCVVN\nCVO\nCVVO\nLH ok\nLH not ok\n(2) Speaker VV\nCV\nCVN\nCVVN\nCVO\nCVVO\nLH ok\nLH not ok\n(1) Speaker YS\nThai sonorous rime duration (ms):\nCV\nCVO\nCVR\nCVV\nCVVO CVVR\nContour not ok\nContour ok\nNavajo sonorous rime duration (ms) (EN data):\na\nam\na:m\nap\na:p\nContour not ok\nContour ok\nCantonese sonorous rime duration (ms):\nImage by MIT OCW.\nAdapted from Zhang, Jie. The effects of duration and sonority\non contour tone distribution: A typological survey and formal\nanalysis. New York, NY: Routledge, 2002.\n(c) Springer. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\nSource: Moren, Bruce, and Elizabeth Zsiga. \"The lexical and post-lexical phonology of\nThai tones.\" Natural Language & Linguistic Theory 24, no. 1 (2006): 113-178.\n\nSummary\n\n- There is language-specific variation in matters of\nrelatively fine phonetic detail.\n- Standard phonological representations cannot\nencode all of this detail.\n- Therefore - either:\n- phonological representations need to be\nenriched, or\n- we should posit a language-specific phonetic\ncomponent of grammar,\n- Either way, phonetics is part of grammar.\n\nReferences\n\n- Cho, T., and P. Ladefoged (1999). Variations and universals in VOT: evidence from 18\nlanguages. Journal of Phonetics, 27, 207-229.\n- Cohn, A. (1990) Phonetic and Phonological Rules of Nasalization. UCLA Working Papers\nin Phonetics 76.\n- Cohn, A. (1993). Nasalization in English: Phonology or phonetics? Phonology 10, 43-81.\n- Dave, Radhekant (1977). Retroflex and dental consonants in Gujarati. A palatographic and\nacoustic study. Annual Report of the Institute of Phonetics, University of Copenhagen 11:\n27-156.\n- Disner, S. (1978) Vowels in Germanic Languages. UCLA Working Papers in Phonetics 40.\n- Disner, Sandra F. (1983). Vowel quality: The relation between universal and language-\nspecific factors. Ph.D. dissertation, University of California, Los Angeles.\n- Flemming, E. (2001). Scalar and categorical phenomena in a unified model of phonetics\nand phonology. Phonology 18..\n- Keating, P. (1985). Universal phonetics and the organization of grammars. V.Fromkin\n(ed.) Phonetic Linguistics. Academic Press, 115-32.\n\nReferences\n\n- Ladefoged, Peter, and Peri Bhaskararao (1983). Non-quantal aspects of\nconsonant production: A study of retroflex consonants. Journal of Phonetics 11:\n291-302.\n- Ladefoged, P. & T. Cho (2001) Linking linguistic contrasts to reality: The case\nof VOT. In N. Gronnum & J. Rischel (eds.), Travaux Du Cercle Linguistique\nDe Copenhague, vol. XXXI. (To Honour Eli Fischer-Forgensen.) C.A. Reitzel,\nCopenhagen.\n- Li, Y, Lee, T, & Qian, Y. (2004). Analysis and modeling of f0 contours for\nCantonese text-to-speech. ACM Transactions on Asian Language Information\nProcessing, 3(3), 169-180.\n- Marsh, J. (1969). Mantjiltjara phonology. Oceanic Linguistics 8.2.\n- Platt, J.T. (1972). An Outline Grammar of the Gugada Dialect: South Australia. Australian\nAboriginal Studies, No. 48, Australian Institute of Aboriginal Studies, Canberra.\n- Zhang, Jie (2002). The effects of duration and sonority on contour tone distribution--A\ntypological survey and formal analysis. Routledge, New York.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n24.915 / 24.963 Linguistic Phonetics\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 4",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-915-linguistic-phonetics-fall-2015/8f4e9d5d8ea634dbbf0e2da8b92675ea_MIT24_915F15_lec4.pdf",
      "content": "24.915/24.963!\nLinguistic Phonetics!\nThe source-filter model of speech\nproduction\"Multiple graphs showing glottal airflow, output from lips, source spectrum, and output spectrum.\n1Multiple graphs showing glottal airflow, output from lips, source spectrum, and output spectrum.\n0.1\n0.2\n0.3\nOutput from lips\nGlottal airflow\nTime (in secs)\n1000 2000 3000\nFrequency (Hz)\nFrequency (Hz)\nFrequency (Hz)\nSource Spectrum\nOutput Spectrum\nResonances =\nFormant Frequencies\nVocal Tract\nFilter Function\nImage by MIT OCW.\n\n- Readings for next week: Ladefoged\n(1996)Elements of Acoustic Phonetics (2nd edn)\nch. 10 from p.160, ch. 11 to p.183.\"\n- Ladefoged FFT, Ladefoged LPC\"\n- optional: read the rest of chapter 11 (on LPC).\"\n- Assignment: Write up a discussion of aspiration in\nMandarin affricates, answering question 2 (due\n10/6).\"\n\"\n\"\n\nSource-Filter Model of Speech Production\"\n3Multiple graphs showing glottal airflow, output from lips, source spectrum, and output spectrum.\n0.1\n0.2\n0.3\nOutput from lips\nGlottal airflow\nTime (in secs)\n1000 2000 3000\nFrequency (Hz)\nFrequency (Hz)\nFrequency (Hz)\nSource Spectrum\nOutput Spectrum\nResonances =\nFormant Frequencies\nVocal Tract\nFilter FunctionMultiple graphs showing glottal airflow, output from lips, source spectrum, and output spectrum.\nImage by MIT OCW.\n\nSources\"\n- A source is an input of acoustic energy into\nthe speech production system. \"\n- There are two basic types:\"\n- Voicing\"\n- Noise\"\n\nVoice source\"\n- Voicing is a periodic source produced by modulation of the\nairflow from the lungs by the vocal folds.\"\n- The vocal folds are muscular folds located in the larynx.\"\n- The space between the vocal folds is the glottis.\"Anatomy diagram showing epiglottis, vocal folds and trachea.\nlocation of the larynx:\"\nview of the vocal folds looking down into the larynx: \"\nmid-coronal section through\nthe larynx:\nfolds\"\nopen\"\nfolds\"\nclosed\"\nglottis\"\n(c) Northwestern University. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\n(c) Northwestern University. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.Anatomy diagram showing epiglottis, vocal folds and trachea.\n(c) Greater Baltimore Medical Center. All rights reserved.\nThis content is excluded from our Creative Commons\nlicense. For more information, see http://ocw.mit.edu/\nhelp/faq-fair-use/\n\nVoice source\"\n- If the vocal folds are close together, then air pressure from\nthe lungs can cause them to vibrate periodically,\ngenerating voicing.\"\nImage of human vocal folds removed due to copyright restrictions.\nImage by MIT OCW.\n6Open and closed positions of vocal cords; glottal stops.Open and closed positions of vocal cords; glottal stops.\n(1)\n(2)\n(3)\n(4)\n(5)\n(6)\n(7)\n(8)\n(9)\n(10)Open and closed positions of vocal cords; glottal stops.\n\nVoicing source\"\n- Vocal fold vibration produces a complex periodic wav\nwhose spectrum contains energy at the fundamental\nfrequency of laryngeal vibration and multiples of the e,\nfundamental frequency (harmonics).\n\"\nTime (s)\n0.02688\n-1\n0.35\nglottal volume velocity spectrum\"\nacoustic wave of unfiltered source\"\n75 glottal volume velocity waveforms from inverse-filtering volume velocity at mouth: 3 peaks each.\n0.5\n0.5\n0.5\n0.5\nmsec\n0.5\nLITERS SEC\nSPEAKER P.B.\nFUNDAMENTAL\nFREQUENCY\nSUBGLOTTAL\nPRESSURE\n107 Hz\n97 Hz\n94 Hz\n89 Hz\n83 Hz\n8.6 cm H2O\n8.4 cm H2O\n8.1 cm H2O\n7.3 cm H2O\n6.9 cm H2O\nGlottal volume velocity waveforms obtained by inverse-filtering the volume velocity at the mouth.\nFrom five successive repetitions of the phrase /bap/ (from top to bottom). Time in each trace runs\nfrom left to right. Waveforms traced from original.\nImage by MIT OCW.\nAdapted from Rothenberg, M. \"The Glottal Volume Velocity Waveform\nDuring Loose and Tight Glottal Adjustments.\" Proceedings of the VII\nInternational Congress of Phonetic Sciences (1971): 380-388.\nUniversity of Chicago Press. All rights reserved. This content is\nexcluded from our Creative Commons license. For more information,\nsee https://ocw.mit.edu/help/faq-fair-use/.\n\nNoise source\"\n- Air turbulence generated at an obstruction involves random\n(aperiodic) pressure fluctuations over a wide range of\nfrequencies. \"\n- Noise generated at the glottis is called aspiration, while\nnoise generated elsewhere is called frication. \"\n8Frequency (kHz) vs. Frequency (Bark) showing logrithmic relationship.\nImage by MIT OCW. Adapted from Johnson, Keith. Acoustic and\nAuditory Phonetics. Malden, MA: Blackwell Publishers, 1997.\n\nSource\"\nA sound may involve more than one source. \"\n- E.g. a voiced fricative combines voicing and\nfrication noise\"\n- breathy voice can combine voicing and aspiration\nnoise. \"\n- voiceless fricatives can have noise generated at the\nglottis and at the supralaryngeal constriction.\"\n\nFilters\"FIR high pass filter (normalized frequency vs. magnitude): small rise/fall, steep rise, rise/fall\n- The vocal tract acts as a filter, modifying the source\nwaveform.\"\n- An acoustic filter is a device which passes certain\nfrequencies and attenuates others. \"\n- An important characteristic of a filter is its transfer\nfunction - the ratio of the output to the input depending on\nfrequency.\"\n10FIR high pass filter (normalized frequency vs. magnitude): small rise/fall, steep rise, rise/fall.\n1.4\n1.2\n0.8\n0.6\n0.4\n0.2\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nMagnitude\nNormalized frequency\nFIR High Pass FilterFIR high pass filter (normalized frequency vs. magnitude): small rise/fall, steep rise, rise/fall.\n1.4\n1.2\n0.8\n0.6\n0.4\n0.2\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nMagnitude\nNormalized frequency\nStopband Filter\nImage by MIT OCW.\nImage by MIT OCW.\n\nThe vocal tract as a filter\"\n- The sound wave at some distance from the speaker is the\nresult of filtering the source with the vocal tract filter, plus\nthe radiation characteristics of the lips/nose.\"\n- How does the vocal tract operate as a filter?\"\n- What determines the characteristics of the filter?\"\nOutline\"\n- Resonators are filters.\"\n- The column of air in the vocal tract is a resonator, hence a\nfilter.\"\n- The characteristics of the filter depend on the shape of the\nvocal tract - we will explore the relationship by considering\nsimple cases.\"\n\nResonators\"\n- A body, like a mass of air in a tube, naturally vibrates at one\nor more frequencies. \"\n- If a pulse of energy is imparted to the air, it will vibrate at\nthese natural frequencies. \"\n- If a source (driving force) which is vibrating at a natural\nfrequency of the body is applied to it (e.g. a tuning fork is\nheld over the tube of air), the body will resonate with the\nsource, i.e. vibrate strongly at the same frequency. \"\n- If a source of a different frequency is applied to the body it\nwill vibrate with less amplitude.\"\n\nResonators\"\n- We can plot the response of a resonator to a range of input\nfrequencies. Peaks mark the resonant frequencies.\"\n- Resonators vary in the range of frequencies they will\nrespond strongly to\"\n!a sharply tuned resonator only responds strongly to\nfrequencies very close to the resonant frequency (it has a\nnarrow bandwidth).\"\n!A resonator with a wide bandwidth will vibrate strongly\nin response to a wider range of input frequencies.\"\n13Axis with three arches: from very steep to very wide.\n95-105\n175-225\n350-550\nImage by MIT OCW.\nAdapted from Ladefoged, P. Elements of Acoustic Phonetics, 2nd ed. University of Chicago Press, 1996.\n\nResonators are filters\"\nA resonator acts as an acoustic filter:\"\nConsider the vibration of a column of air driven by a vibrating source. \"\nThe source is the input to the filter. This input produces vibration in the\ncolumn of air. \"\nThis vibration produces a sound wave in the external air - the output of\nthe filter.\"\nThe strength with which an input frequency is output from the filter will\ndepend on the resonance characteristics of the air column - if it is near a\nresonant frequency, it will be passed through to the output at full\nstrength, if it is not near a resonant frequency, it will have low amplitude\nin the output.\"\n-\n-\n-\n-\n\nThe vocal tract is a filter\"\n- In speech the input has energy at a range of frequencies\n(voicing or noise, or both) and the resonator has multiple\nresonant frequencies of varying bandwidths.\"\n- The amplitude in the output wave of each frequency\ncomponent of the source depends on the extent to which the\nair in the vocal tract resonates at that frequency. Thus the\nvocal tract filters the source.\"\n- The resonances of the vocal tract are called formants.\"Source spectrum, resonances = formant frequences, output spectrum.\n15Source spectrum, resonances = formant frequences, output spectrum.\nSource Spectrum\nFrequency (Hz)\nFrequency (Hz)\nFrequency (Hz)\nOutput Spectrum\nResonances =\nFormant Frequencies\nImage by MIT OCW.\n\nResonant frequencies of air in a tube\"\nWhat determines the resonant frequencies of a mass of air in a\ntube?\"\n- The resonant frequencies (formants) of air in the vocal tract\ndepend on how the cross-sectional area of the vocal tract\nvaries over its length. \"\n- The relationship between vocal tract shape and transfer\nfunction is complex - we will start by considering the simple\ncase of a uniform tube.\"\n\nHow air in a uniform tube vibrates\"\n- The vocal tract in a vowel can be approximated by a tube\nwhich is closed at one end (the glottis) and open at the other\n(the lips).\"\n- A compression or rarefaction travelling down a tube is\nreflected off the ends of the tube. \"\n- There is reflection even at the open end of a tube, but with a\nchange of phase - a compression is reflected as a rarefaction,\nand vice versa.\"\nMode\nling\nvocal\ntract a\ns a 17.5 cm long\nx 1 cm tube, closed with slit at one end and open at the other.\nImage by MIT OCW.\nAdapted from Ladefoged, P. Elements of Acoustic Phonetics. 2nd ed. Chicago, IL:\nUniversity of Chicago Press, 1996.\n\nHow air in a tube vibrates\"\n18Short vertical lines with above arrows above a few, accompanied by horizonal lines with arches.\n(1)\n(2)\nReflection of a compressinoal pulse in a slinky spring off a fixed end (1) and a\nfree end (2). Reflection from a free end = phase change in pressure or density.\nTransverse Representation\nImage by MIT OCW.\nAdapted from Berg, Richard E., and David G. Stork. The Physics of Sound. New York,\nNY: Prentice-Hall, 1982.\n\nResonance in a uniform tube, open at one end\"\n- For resonance to occur, compressions must reach the closed\nend at the same time as the excitation source produces\nanother compression peak, and rarefactions must reach the\nclosed end at the same time as the source produces a\nrarefaction.\"\n- In a tube which is open at one end:\"\ni.\na compression is reflected from the open end as a\nrarefaction. \"\nii. This rarefaction is reflected back off the closed end.\"\niii. The rarefaction is then reflected from the open end as a\ncompression.\"\n! rarefactions do the opposite.\"\n- So source and reflected wave will interfere constructively if,\ne.g., the time it takes for the wave to travel 2 times up and\ndown the tube is equal to the half the period of the wave.\"\n\nResonance in a tube open at one end\"\n\nResonance in a tube open at one end\"\n- Source and reflected wave will interfere constructively if,\ne.g., the time it takes for the wave to travel 2 times up and\ndown the tube is equal to the half the period of the wave.\"\n- For a tube of length L, for a wave with period T, travelling\nwith speed c,\"\nT\n2 = 2L\nc\n- f = 1/T so this resonant frequency F = c/4L!\n- 17.5cm is a reasonable figure for length of a (large) vocal\ntract, speed of sound in air is approximately 35000cm/s.\"\n\nResonance in a tube open at one end\"\n- This is only one resonant frequency (the lowest, or first,\nresonance)\"\n- The general requirement is that compressions emitted from\nthe source must coincide with reflected compressions\n(likewise for rarefactions) - they don't have to coincide with\nevery reflected compression.\"\n- So the time it takes the wave to travel 2L must be equal to\n1/2, 3/2, 5/2 .... i.e. (2n-1)/2 periods of the source wave.\"\n(2n -1)T\n= 2L\nc\nT =\n4L\n(2n -1)c\nFn = (2n -1)c\n4L\nso:\"\n\nStanding waves\"\n- Under the conditions for resonance, the air in a tube vibrates\nin a standing wave.\"\n- Standing waves arise when identical waves are travelling in\nopposite directions - e.g. a wave and its reflection from a\nsurface. standing wave demo\"\n- A standing wave contains fixed points at which air particles\ndo not move (velocity nodes). Movement is maximal\nbetween the nodes (at the velocity anti-nodes).\"\n- Velocity anti-nodes correspond to pressure nodes - pressure\ndoes not change - and velocity nodes correspond to pressure\nanti-nodes.\"\n\nStanding waves and resonance in tubes \"\n- The air in a tube which is open at one end naturally vibrates\nin standing waves.\"\n- There must be a velocity node at the closed end since the\nfixed end prevents particle movement.\"\n- There must be a pressure node at the open end - pressure is\nalways equal to external pressure.\"\n- The simplest wave that meets these conditions is a standing\nwave that goes from maximum pressure at the glottis to zero\n(atmospheric pressure) at the lips.\"\nvelocity\"\npressure\"\n\nStanding waves and resonance in tubes \"\nWhat is the frequency of this wave?\"\nvelocity\"\npressure\"\n\nRelating frequency to wavelength \"\n- The distribution of pressure fluctuations in space due to a\nsound wave depends on the frequency of the wave and the\nspeed at which the wavefront travels.\"\n- Consider a wave with frequency f Hz and speed c cm/s.\"\n- In one second it travels c cm.\"\n- In one second it goes through f cycles.\"\n- So there are f cycles in c cm.\"\n- So the length of one cycle (the wavelength) is c/f.\"\n- Usual formulation:\" c = fλ\n\"Where λ is wavelength\"\n\"Harmonic wave with horizontal line drawn across dividing into top/bottom halves.\n26Harmonic wave with horizontal line drawn across dividing into top/bottom halves.Harmonic wave with horizontal line drawn across dividing into top/bottom halves.Harmonic wave with horizontal line drawn across dividing into top/bottom halves.\nImage by MIT OCW.\n\nStanding waves and resonance in tubes \"\nWhat is the frequency of this wave?\"\n- The transition from maximum to zero pressure is only one\nquarter of a cycle.\"\n- For a tube of length L, L = λ/4\"\n- λ = 4L!\n- f = c/λ = c/4L\"\nvelocity\"\npressure\"\n\nStanding waves and resonance in tubes\n- Other standing waves that meet the boundary conditions:\n- In general, air in a tube of length L, closed at one end, will\nhave resonant frequencies (formants) at: Fn = (2n -1)c\n4L\nGr\nap\nhe\nd curve\ns s\nhowing diffe\nrent\n\nw\navelengths\no\nf\n\ndifferent v\no\nc\na\nl tract res\no\nn\na\nnces.\nImage by MIT OCW.\nAdapted from Johnson, Keith. Acoustic and Auditory Phonetics. Malden, MA: Blackwell Publishers, 1997.\n\nTubes models of the vocal tract\"\n- The vocal tract in vowels can be approximated by a tube that\nis closed at one end and open at the other.\"\n\"\n- The cross-sectional area of the vocal tract is closest to being\nuniform in a mid central vowel [ ] as in RP English bird [b\n%d], or at the end of sofa [soUf ].\"\n- Caution: Most things that are transcribed as schwa do not\nhave a uniform vocal tract.\"\n\"\nFn = (2n -1)c\n4L\nMode\nling\nvocal\ntract a\ns a 17.5 cm long\nx 1 cm tube, closed with slit at one end and open at the other.\nImage by MIT OCW.\nAdapted from Ladefoged, P. Elements of Acoustic Phonetics. 2nd ed. Chicago, IL:\nUniversity of Chicago Press, 1996.\n\nTubes models of the vocal tract\"\n- Another simple tube model that approximates a vocal tract\nshape is a tube (almost) closed at both ends.\"\n- This is similar to a sound made with a narrow constriction at\nthe lips, or the cavity behind an interior constriction.\"\n- Air in a tube closed at both ends naturally vibrates in\nstanding waves with nodes at both ends.\"Top rectangle has downward arch, bottom rectangle has sine wave.\n30Top rectangle has downward arch, bottom rectangle has sine wave.\nDiagrams of the standing waves in a tube closed at both ends (almost)\nImage by MIT OCW.\nAdapted from Ladefoged, Peter. L104/L204 Phonetic Theory course notes,\nUniversity of California, Los Angeles.\n\nTubes models of the vocal tract\"\n-\nL = nλ/2\"\n-\nλ = 2L/n!\n-\nFn = c/λ!\nFn = nc\n2L\nDiagrams of the standing waves in a tube closed at both ends (almost)\nImage by MIT OCW.\nAdapted from Ladefoged, Peter. L104/L204 Phonetic Theory course notes,\nUniversity of California, Los Angeles.\n\nSource-Filter Model of Speech Production\"\nImage by MIT OCW.\n32Multiple graphs showing glottal airflow, output from lips, source spectrum, and output spectrum.\n0.1\n0.2\n0.3\nOutput from lips\nGlottal airflow\nTime (in secs)\n1000 2000 3000\nFrequency (Hz)\nFrequency (Hz)\nFrequency (Hz)\nSource Spectrum\nOutput Spectrum\nResonances =\nFormant Frequencies\nVocal Tract\nFilter FunctionMultiple graphs showing glottal airflow, output from lips, source spectrum, and output spectrum.Multiple graphs showing glottal airflow, output from lips, source spectrum, and output spectrum.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n24.915 / 24.963 Quantum Optical Communication\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 5",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-915-linguistic-phonetics-fall-2015/9132fcf389544afbd25e805ea355bbbe_MIT24_915F15_lec5.pdf",
      "content": "24.963\nLinguistic Phonetics\nThe acoustics of vowels\n\n- No class on Tuesday 10/13 (Tuesday is a Monday)\n\nReadings:\n\n- Johnson chapter 6 (for this week)\n\n- Liljencrants & Lindblom (1972) (for next week)\n\nAssignment:\n\n- Modeling lip-rounding, due 10/15\n\n(c) Nelson Education. All rights reserved. This content is excluded from our Creative Commons license. For more information, see http://\nocw.mit.edu/help/faq-fair-use/\n\nF2 (Hz)\nF1 (Hz)Graph with data points (no line connecting them) in general shape of a V.\ni\nu\nI\nε\nΩ\nc\nϪ\næ\nImage by MIT OCW.\nAdapted from Peter Ladefoged. A Course in Phonetics. 5th ed. Berlin, Germany: Heinle, 2005.\nISBN: 9781413006889. Available at: https://www.phonetics.ucla.edu/course/contents.html.\n\nThe Acoustics of Vowels\n\nSource-Filter models:\n\n- Source: voicing (usually)\n\n- Filter characteristics can be given a basic but\nuseful analysis using simple tube models.\n\n- Tube models can be supplemented by perturbation\ntheory for approximate analysis of the effects of\nwide constrictions.\n\nLow vowels [A, a, œ]\n\n- Pharyngeal constriction\n\n-\nSince the back tube is much narrower than the front tube, each can\nreasonably be approximated by a tube closed at one end and open at\nthe other.\n\n-\nThe resonances of the combined tubes deviate from the values we\nwould calculate for these configurations in isolation because the\nresonators are acoustically coupled.\n\n-\nThe degree of coupling depends on the difference in cross-sectional\nareas.\n\nL\nine drawing of mouth/vocal tract and two tubes.\nImage by MIT OCW.\n\nLow vowels [A, a, œ]\n\nFn = (2n -1)c\n4L\nnomogram\n\nNa\nr\nr\now rectangular tube that then becomes larger, with elipses in each section.\nA\nA\nBack cavity length vs.\nfrequency graph: curve\nd lattice patte\nrn.\nImage by MIT OCW.\nAdapted from Johnson, Keith. Acoustic and Auditory Phonetics.\nMalden, MA: Blackwell Publishers, 1997. ISBN: 9780631188483.\nImage by MIT OCW.\nAdapted from Johnson, Keith. Acoustic and Auditory Phonetics.\nMalden, MA: Blackwell Publishers, 1997. ISBN: 9780631188483.\n\nNon-low vowels (e.g. [i, e])\n\n- Short constriction in the mouth\n\n-\nThe back cavity can be approximated by a tube closed at\nboth ends.\n\n-\nThe front cavity is approximated by a tube closed at one\nend.\n\n-\nNeglects coupling. The degree of coupling depends on the\ncross-sectional area of the constriction.\n\n-\nHow do we account for the F1 of high vowels?\n\nFn = nc\n2L\nFn = (2n -1)c\n4L\nTu\nbe\n,\nna\nrr\now connection, tube again with elipses in each section.\nImage by MIT OCW.\nAdapted from Johnson, Keith. Acoustic and Auditory Phonetics.\nMalden, MA: Blackwell Publishers, 1997. ISBN: 9780631188483.\nL\ni\nn\ne\n\nd\nr\nawing of mouth position.\nImage by MIT OCW.\nAdapted from Ladefoged, Peter. Elements of Acoustic Phonetics.\n2nd ed. Chicago, IL: University of Chicago Press, 1996.\n\nHelmholtz resonators\n- The back cavity and the constriction together form a\nresonant system called a Helmholtz resonator.\n\n- If the length of the constriction is short, the air in it\nvibrates as a mass on the 'spring' formed by the air in\nthe back cavity.\n\n- Resonant frequency,\nf =\nc\n2π\nVl =\nc\nc\n2π\nAblblc\nc\nA\nc\nA\n9 Tube, narrow connection, tube again with elipses in each section.Line drawing of mouth position.\n\nTu\nbe\n,\nna\nrr\now connection, tube again with elipses in each section.\nImage by MIT OCW.\nAdapted from Johnson, Keith. Acoustic and Auditory Phonetics.\nMalden, MA: Blackwell Publishers, 1997. ISBN: 9780631188483.\nL i\nn\ne\nd\nr\nawing of mouth position.\nImage by MIT OCW.\nAdapted from Ladefoged, Peter. Elements of Acoustic Phonetics.\n2nd ed. Chicago, IL: University of Chicago Press, 1996.\n\nNon-low vowels - nomogram\n\nf = c\n2π\nAc\nAblblc\nFn = nc\n2L\nFn = (2n -1)c\n4L\nfront cavity\n\nback cavity\n\nback cavity + constriction\n\n- How would you model a mid vowel?\n\n10Tube, narrow connection, tube again with elipses in each section.\nlb\nlc\nAb\nAc\nAf\nlf\nImage by MIT OCW.\nAdapted from Johnson, Keith. Acoustic and Auditory Phonetics.\nMalden, MA: Blackwell Publishers, 1997. ISBN: 9780631188483.\nFront cavity resonances\nBack cavity resonances\nFrequency (kHz)\nBack cavity length (cm)\nF3\nF2\nF1\nImage by MIT OCW.\nAdapted from Johnson, Keith. Acoustic and Auditory Phonetics.\nMalden, MA: Blackwell Publishers, 1997. ISBN: 9780631188483.\n\nPerturbation Theory (Chiba and Kajiyama 1941)\n\n- Constriction near a\npoint of maximum\nvelocity (Vn) lowers the\nassociated formant\nfrequency.\n\n- Constriction near a\npoint of maximum\npressure raises the\nassociated formant\nfrequency.\n\nLi\nne\nd\nra\nwi\nng\ns\nof\nm\nou\nth\npo\nsit\nion\ns,\ndif\nfer\nent\nwave\ns ass\nociat\ned w\nit' each.\nImage by MIT OCW.\nAdapted from Johnson, Keith. Acoustic and Auditory Phonetics. Malden,\nMA: Blackwell Publishers, 1997. Based on Chiba and Kajiyama 1941.\n\nPerturbation Theory (Chiba and Kajiyama 1941)\n\n- What is the effect of a\npharyngeal constriction?\n\n- Does this correspond to the\ntube model above?\n\n- How do you raise F2\nmaximally?\n\nLi\nne\nd\nra\nwi\nng\ns\nof\nm\nou\nth\npo\nsit\nion\ns,\ndif\nfer\nent\nwave\ns ass\nociat\ned w\nit' each.\nImage by MIT OCW.\nAdapted from Johnson, Keith. Acoustic and Auditory Phonetics. Malden,\nMA: Blackwell Publishers, 1997. Based on Chiba and Kajiyama 1941.\n\nPerturbation Theory vs. two-tube models\n\n- Our simple tube models ignore acoustic coupling and are\ntherefore most valid where constrictions are narrow.\n\nPerturbation theory accounts for the effects of small\nperturbations of a uniform tube, and thus is most accurate\nfor open constrictions.\n\nMrayati et al (1988): perturbation theory is generally valid\nfor constrictions greater than 0.8 cm2, and two-tube\nmodels are valid for a constriction of 0.05 cm2 or less,\nwith a transitional region in between.\n\nMrayati, Carre & Guerin (1988). Distinctive regions and modes.\nSpeech Communication 7, 257-286.\n\n-\n-\n-\n\nAmerican English [ɹ]\n\n- American English [ɹ] is characterized by an exceptionally\nlow F3 (<2000 Hz).\n\nReproduced from Espy-Wilson, Carol Y., Suzanne E. Boyce, Michel Jackson, Shrikanth Narayanan, and Abeer Alwan.\n\"Acoustic modeling of American English/r.\" The Journal of the Acoustical Society of America 108, no. 1 (2000):\n343-356. doi: https://doi.org/10.1121/1.429469, with the permission of the Acoustical Society of America.\n\n- American English [ɹ] is\nproduced in a variety of\nways across speakers and\ncontexts (Alwan et al 1997\nJASA, Westbury et al 1998,\nSpeech Comm.).\n\n- A basic distinction that is\noften made: 'bunched'\nvs. 'retroflex'.\n\n- But there appears to be a\ncontinuum of variants.\n\nReproduced from Narayanan, Shrikanth S., Abeer A. Alwan, and Katherine Haker.\n\"Toward articulatory-acoustic models for liquid approximants based on MRI and\nEPG data. Part I. The laterals.\" The Journal of the Acoustical Society of America\n101, no. 2 (1997): 1064-1077. doi: https://doi.org/10.1121/1.418030, with\nthe permission of the Acoustical Society of America.\n\nPerturbation Theory (Chiba and Kajiyama 1941)\n\nA nice story about Am. Eng.\n[(r)]\n\n- Three constriction: labial\n(lip protrusion/rounding),\npalatal (bunching or\nretroflexion), and\npharyngeal.\n\n- All 3 are near velocity\nmaxima for F3, hence very\nlow F3.\n\n- But Espy-Wilson et al\n(2000) argue actual\nconstrictions are in the\nwrong place\n\nLi\nne\nd\nra\nwi\nng\ns\nof\nm\nou\nth\npo\nsit\nion\ns,\ndif\nfer\nent\nwave\ns ass\nociat\ned w\nit' each.\nImage by MIT OCW.\nAdapted from Johnson, Keith. Acoustic and Auditory Phonetics. Malden,\nMA: Blackwell Publishers, 1997. Based on Chiba and Kajiyama 1941.\n\nEspy-Wilson et al (2000) argue\nfrom MRI data that:\n\n-\nActual constrictions are in the\nwrong places, e.g. pharyngeal\nconstriction is too high.\n\n-\nConstrictions are too narrow\nto apply perturbation theory.\n\n-\nArgue that F3 is a front cavity\nresonance.\n\n-\nLow due to length (bunched)\nor sub-lingual cavity (retro) +\nlip constriction. (How long?)\n\n-\nOr: lip constriction is narrow\nenough for the front cavity to\nform a Helmholtz resonator.\n\nReproduced from Narayanan, Shrikanth S., Abeer A. Alwan, and Katherine Haker.\n\"Toward articulatory-acoustic models for liquid approximants based on MRI and\nEPG data. Part I. The laterals.\" The Journal of the Acoustical Society of America\n101, no. 2 (1997): 1064-1077. doi: https://doi.org/10.1121/1.418030, with\nthe permission of the Acoustical Society of America.\n\nConstriction locations and area functions for [i]\nvowels\nStory et al\n(1998), MRI\nLadefoged &\nMaddieson\n(1996) - mean\ntongue positions\n\nFant (1960), Russian [i]\nF2 2250 Hz, F3 3200 Hz\n\n.\n(c) Journal of the Acoustical Society of America. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\nSource: Story, Brad H., Ingo R. Titze, and Eric A. Hoffman. \"Vocal tract area functions for an adult female speaker\nbased on volumetric imaging.\" The Journal of the Acoustical Society of America 104, no. 1 (1998): 471-487.\n(c) Walter de Gruyter. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/\n(c) MIT Press. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/\n\nHillenbrand et al (1995) - Michigan English vowel formants\n\nF3(Hz)\n\nF2 (Hz)\na\nø\nU\nO\nu\noU\ni\neI\nI\nœ\nœ\nE\nCourtesy of The Acoustical Society of America. Used with permission.\nSource: Hillenbrand, James, Laura A. Getty, Michael J. Clark, and Kimberlee\nWheeler. \"Acoustic characteristics of American English vowels.\" The Journal\nof the Acoustical society of America 97, no. 5(1995): 3099-3111.\n\nLip rounding\n\n- Lip-rounding also involves lip protrusion so it both\nlengthens the vocal tract and introduces a constriction at\nthe lips.\n\n- Perturbation theory: All formants have a velocity\nmaximum at the lips, so a constriction at the lips should\nlower all formants.\n\n- Lengthening the vocal tract also lowers formants.\n\n- Tube models: The effect of a constriction at the lips is\nequivalent to lengthening the front cavity. Protrusion\nactually lengthens the front cavity.\n\n- This lowers the resonances of the front cavity - in front\nvowels the lowest front cavity resonance is usually F3, in\nback vowels it is F2.\n\nLip rounding\n\n- Tube models 2: Fant (1960) suggests the front cavity plus\nlip constriction can form a helmholtz resonator.\n\nFant's (1960) nomograms\n- A more complex tube model for vowels:\nCur\nve\nin\nthe\ns\nhape of many steps: a rise, a wide trough, then a rise and plateau.\nImage by MIT OCW.\nBased on Fant, Gunnar. Acoustic Theory of Speech Production. The Netherlands: Mouton De Gruyter, 1960.\n\nNomogram showing variation in constriction location and lip-rounding -\nnarrow constriction (Amin = 0.65 cm2)\n\n5 se\nts of\nwave\ns, gr\nouped\ntoge\nther,\none\nset w\nith o\nne s\nteep\nw\nave, the res\nt all mild\n, like w\nater wav\nes\n.\nImage by MIT OCW.\nBased on Fant, Gunnar. Acoustic Theory of Speech Production. The Netherlands: Mouton De Gruyter, 1960.\n\nNomogram showing variation in constriction location and lip-rounding -\nwider constriction (Amin = 2.5 cm2)\n\nse\nts\nof wave\ns, grou\nped toget\nher, no\nthing terribly\nsteep - looks like water waves\nImage by MIT OCW.\nBased on Fant, Gunnar. Acoustic Theory of Speech Production. The Netherlands: Mouton De Gruyter, 1960.\n\nNomogram showing variation in constriction location and degree.\n\nse\nts\nof wave\ns, with\ntwo sets\nmeet\ning at peak and\ntrough.\nImage by MIT OCW.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n24.915 / 24.963 Linguistic Phonetics\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 6",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-915-linguistic-phonetics-fall-2015/78f61398c66588fb29664f345ce41262_MIT24_915F15_lec6.pdf",
      "content": "24.963\nLinguistic Phonetics\nSpectral Analysis\n\n-20\nFrequency (Hz)\nFrequency (Hz)\n\nReading for next week:\n\n- Liljencrants & Lindblom 1972.\n\nAssignment:\n\n- Lip-rounding assignment, due 10/15.\n\nSpectral analysis techniques\n\nThere are two major spectral analysis techniques used with\nspeech:\n\n- Fourier analysis\n\n- Linear Predictive Coding (LPC)\n\n- Fourier analysis is used to calculate the spectrum of an\ninterval of a sound wave.\n\n- LPC attempts to estimate the properties of the vocal tract\nfilter that produced a given interval of speech sound.\n\nFourier Analysis\n\n- A complex wave can be analyzed as the\nsum of sinusoidal components.\n\n- Fourier analysis determines what those\ncomponents are for a given wave.\n\n- The procedure we will use is the Discrete\nFourier Transform.\n\nFourier Analysis\n\n- The basic idea is to compare the speech wave with\nsinusoidal waves of different frequencies to\ndetermine the amplitude of that component\nfrequency in the speech wave.\n\n- What do we compare with what?\n\n- A short interval ('window') of a waveform with:\n\n- Sine and cosine waves with a period equal to the\nwindow length and\n\n- sine and cosine waves with multiples of this first\nfrequency.\n\nFourier Analysis\n\n- For each analysis frequency, we calculate how well the\nsine and cosine waves of that frequency correlate with the\nspeech wave.\n\n- This is measured by multiplying the amplitude of each\npoint of the speech wave by the amplitude of the\ncorresponding point in the sinusoid and summing the\nresults (dot product).\n\n- Intuitively:\n\n- if the waves are similar, they will be positive at the same time and\nnegative at the same time, so the multiplications will yield large\nnumbers.\n\n- if the waves are moving in opposite directions, the multiplications\nwill yield negative numbers.\n\nFourier Analysis\n\n- The degree of correlation indicates the relative\namplitude of that frequency component in the\ncomplex wave.\n\n- The correlation between two sinusoidal waves of\ndifferent frequencies is always zero - i.e. the\ncontribution of each frequency component to a\ncomplex wave is independent of the other\nfrequency components.\n\nWindow length\n\n- Window length is often measured in points (1\npoint = 1 sample).\n\n- e.g. 256 points at a sampling rate of 10 kHz is\n0.0256s (25.6 ms).\n\n- Most speech analysis software uses the Fast\nFourier Transform algorithm to calculate DFTs.\n\n- This algorithm only works with window lengths\nthat are powers of 2 (e.g. 64, 128, 256 points).\n\nFrequency resolution\n\n- The interval between the frequencies of successive\ncomponents of the analysis depends on the window\nlength.\n\n- The first component of the analysis is a wave with period\nequal to the window length\n\n= 1/window duration\n\n= sampling rate/window length\n\n- E.g. with window length of 25.6ms, the first component of\nthe DFT analysis has a frequency of 1/0.0256 s = 39 Hz.\n\n- The other components are at multiples of this frequency:\n78 Hz, 117 Hz,...\n\n- so the components of the analysis are 39 Hz apart.\n\nFrequency resolution\n\n- A shorter window length implies that the first component\nhas a higher frequency, so the interval between\ncomponents is larger.\n\n- So there is a trade-off between time resolution and\nfrequency resolution in DFT analysis.\n\nWindow length Interval between components\n\n50 ms\n\n20 Hz\n\n25 ms\n\n40 Hz\n\n12.5 ms\n\n80 Hz\n\n6.4 ms\n\n160 Hz\n\nDFT - window length\n\nFrequency (Hz)\n-20\n23 ms\n\nFrequency (Hz)\n-20\n46 ms\n\n12 ms\n\nFrequency (Hz)\n-20\nFrequency (Hz)\n-20\n5 ms\n\nFrequency resolution\n\n- A spectrogram consists of a sequence of fourier\nspectra.\n\n- The bandwidth of a spectrogram depends on the\nwindow length used to calculate the spectra.\n\nFast Fourier Transform\n\n- The Fast Fourier Transform (FFT) is an efficient algorithm\nfor calculating the discrete Fourier transform\n\n- But it only works on windows of 2n samples.\n\n- If you select a different window length, most acoustic\nanalysis software adds zero samples to the end of the\nsignal to pad it out to 2n samples.\n\n- This does not alter the overall shape of the spectrum.\n\n- PRAAT will calculate DFT (no zero padding) and FFT\n(zero padding as required).\n\nWindow function\n\n- If we take n samples directly from a waveform, it may begin\nand end abruptly.\n\nAs a result, the spectrum of such a wave would include\nspurious high frequency components.\n\nTo avoid this problem we multiply the signal by a window\nfunction that goes smoothly from 0 to 1 and back again.\n\nThere are many such window functions (Hamming, Hanning\n'\n-\n-\n-\netc). It doesn t matter much which you use, but use one.\n\nImage by MIT OCW.\nwaveform, bell curve, waveform\n\nWindow function\n\n- Tapering the window only reduces the amplitude of spurious\ncomponents, it does not eliminate them.\n\ngr\naphs\n: FF\nT of\nrec\ntang\nular\nsin\ne wa\nve\ni\nn dB.\n2 g\nrap\nhs:\nFF\nT o\nf\nre\nctan\ngula\nr si\nne\nwav\ne i\nn dB\n.\nWindow function\nImage by MIT OCW.\nImage by MIT OCW.\n\nLinear Predictive Coding\n\n- The source-filter theory of speech production analyzes speech\nsounds in terms of a source, vocal tract filter and radiation\nfunction.\n\nSource-Filter Model of Speech Production\n\nSou\nrce\n-fi\nlte\nr m\nodel of speech p\nroduction: glot\ntal airflow to\nl\nip\no\nut\npu\nt\nis\nd\nif\nf\ne\nr\ne\nnt.\nImage by MIT OCW.\n\nLinear Predictive Coding\n\n- The source-filter theory of speech production analyzes speech\nsounds in terms of a source, vocal tract filter and radiation\nfunction.\n\n- Linear Predictive Coding (LPC) analysis attempts to\ndetermine the properties of the vocal tract filter through\n'analysis by synthesis'.\n\nLinear Predictive Coding\n\n- If we knew the form of the source and the output waveform, we could\ncalculate the properties of the filter that transformed that source into that\noutput.\n\n- Since we don't know the properties of the source, we make some simple\nassumptions: There are two types of source; flat spectrum 'white noise'\nfor voiceless sounds, and a flat spectrum pulse train for voiced sounds.\n\n- The spectral shape of the source can then be modeled by an additional\nfilter.\n\n- Thus the filter calculated by LPC analysis includes the effects of source\nshaping, the vocal tract transfer function, and the radiation characteristics.\n\n- However, both of these typically affect mainly spectral slope (for vowels,\nat least), so the locations of the peaks in the spectrum of the LPC filter\nstill generally correspond to resonances of the vocal tract.\n\nLinear Predictive Coding\n\n- The various techniques for calculating LPC spectra are based\naround minimizing the difference between the predicted\n(synthesized) signal and the actual signal (i.e. the error).\n\n§* (Actually the squared difference is minimized).\n\nLinear Predictive Coding\n\n- The type of digital filter used to model the vocal tract filter in\nLPC (an 'all pole' filter) can be expressed as a function of the\nform:\n\ns(n) = -\naks(n -k) + Gu(n)\nk=1\nN\n∑\n- So an LPC filter is specified by a set of coefficients ak\n\n- The number of coefficients is called the order of the filter and\nmust be specified prior to analysis.\n\n- Each pair of coefficients defines a resonance of the filter.\n\nAll-pole filter\n\ns(n)=0.4s(n-1)-0.7s(n-2)+0.6s(n-3)-0.1s(n-4)+u(n)\n\nLPC spectrum\n\nFrequency (Hz)\n-20\nFrequency (Hz)\n\nPractical considerations\n\nWhat filter order should one use?\n\n- Each pair of LPC coefficients specifies a resonance of the\nfilter.\n\n- The resonances of the filter should correspond to the formants\nof the vocal tract shape that generated the speech signal, so the\nnumber of coefficients we should use depends on the number\nof formants we expect to find.\n\n- The number of formants we expect to find depends on the\nrange of frequencies contained in the digitized speech signal -\ni.e. half the sampling rate.\n\n- Generally we expect to find ~1 formant per 1000 Hz.\n\n- So a general rule of thumb is to set the filter order to the\nsampling rate in kHz plus 2\n\n- 2 for each expected formant, plus two to account for the\neffects of higher formants and/or the glottal spectrum.\n\nFilter order\n\n- In any case, try a range of filter orders and see what works\nbest.\n\n- Problems for this rule of thumb can arise if there are zeroes in\nthe speech signal. These can be introduced by nasalization,\nlaterals, or breathiness.\n\n- Note that in general it is a bad idea to fit an LPC spectrum to\nthe full frequency range of your recording - there are not\nlikely to be clear formants above ~5 kHz.\n\n- Down-sample before performing LPC analysis.\n\n- If you use too many coefficients, there may be spurious peaks\nin the LPC spectrum, if you use too few, some formants may\nnot appear in the LPC spectrum.\n\nLPC: filter order\n\nFrequency (Hz)\n-20\nFrequency (Hz)\nFrequency (Hz)\nN = 12\n\nN = 10\n\nN = 12\n\nFrequency (Hz)\nFrequency (Hz)\nFrequency (Hz)\nN = 18\n\nPre-emphasis\n\n- The spectrum of the voicing source falls off steadily as\nfrequency increases.\n\n- LPC analysis is trying to model vocal tract filter.\n\n- This is often more successful if the spectral tilt of the glottal\nsource is removed before LPC analysis.\n\n- This is achieved by applying a simple high-pass filter (pre-\nemphasis):\n\ny(n) = s(n) - ps(n-1)\n\n- where p is between 0 and 1.\n\n- p = 1 yields the greatest high frequency emphasis. Typical\nvalues are between 0.9 and 0.98.\n\nPre-emphasis\n\n-1.5\n-1\n-0.5\n0.5\n1.5\n10 13 16 19 22 25 28 31 34 37 40 43 46 49 52 55 58 61 64 67 70 73 76 79\npre-emphasis=0\npre-emphasis=1\npre-emphasis=0.5\ny(n) = s(n) - ps(n-1)\n\nLPC analysis\n\n- LPC analysis is based on a simple source-filter model of\nspeech (the vocal tract is a lossless all-pole filter), so it should\nbe well-suited to the analysis of speech as long as the\nassumptions of the model are met.\n\n- However we have to specify the filter order, and it may be\ndifficult to determine the correct order.\n\n- This is especially problematic where the actual vocal tract\nfilter contains zeroes, violating the assumptions of the model.\n\nFormant tracking in Praat\n\n-\n-\n-\n-\nThe formant tracking algorithm in Praat is based on LPC\nanalysis.\n\nFormants are identified by finding the peaks in LPC spectra\ncalculated from a series of windows.\n\nThere are two basic parameters that you need to set:\n\nØ Maximum formant (Hz): The frequency range that you\nwant to analyze.\n\nØ Number of formants: The number of formants you want\nPraat to look for = half of the LPC filter order\n\nThe manual recommends leaving number of formants at the\ndefault value of 5, and adjusting the maximum formant\nfrequency.\n\n- Default is 5500 Hz, raise for smaller vocal tracts, lower\nfor longer vocal tracts.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n24.915 / 24.963 Linguistic Phonetics\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 7",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-915-linguistic-phonetics-fall-2015/dcf3776c10820c7c7b48e5cac2a9c48e_MIT24_915F15_lec7.pdf",
      "content": "24.963\nLinguistic Phonetics\nThe Theory of Adaptive\nDispersion\n(c) Language. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\nSource: Liljencrants, Johan, and Bjorn Lindblom. \"Numerical simulation of vowel quality\nsystems: The role of perceptual contrast.\" Language (1972): 839-862.\n\nReading:\n- Johnson chapters 7 and 8.\n- Assignment: acoustics 3, due 10/22\n\nLindblom's Theory of Adaptive Dispersion\n- Liljencrants and Lindblom (1972), Lindblom 1986, 1990a,b\n- Try to explain why vowel systems are the way they are.\n- Observation: vowels in an inventory tend to be evenly\ndispersed through the vowel space (cf. Disner 1984).\n\nLindblom's Theory of Adaptive Dispersion\n- Common vowel inventories - vowels relatively evenly dispersed over the whole\nvowel space.\ni\nu\ni\nu\ni\nu\ne\no\ne\no\nE\nO\na\na\na\nArabic,\nSpanish,\nItalian,\nNyangumata,\nSwahili,\nYoruba,\nAleut, etc.\nCherokee, etc.\nTunica, etc.\n- Unattested vowel inventories - poorly dispersed.\ni\ni\n\ni\nu\ne\ne\nØ\nI\nU\na\na\n\nLindblom's Theory of Adaptive Dispersion\n- Try to explain why vowel systems are the way they are.\n- Observation: vowels in an inventory tend to be evenly\ndispersed through the vowel space (cf. Disner 1984).\n- Hypothesis: this facilitates efficient communication by\nminimizing the likelihood of confusing vowels.\n- Vowels that are closer in the perceptual space are more\neasily confused.\n- Confusions between contrasting sounds impair\ncommunication.\n- So contrasting vowels should be as far apart as possible\n(dispersion) - 'maximize distinctiveness of contrasts'\n\nLiljencrants & Lindblom (1972)\nApproach to exploring dispersion hypothesis:\n- Modeling\n- Simulation\n- Comparison of simulation results to impressionistic\ndescriptions of a large sample of vowel inventories.\n\nThe vowel space\n- L&L propose a measure for\ndistinctiveness of a vowel system.\n- Prediction: Inventory of N vowels\nshould have those vowels located in\nperceptual vowel space so as to\nmaximize distinctiveness (minimize\nconfusability).\n1st\nfo\nrma\nnt\nvs.\n2nd\nform\nant:\nla\nrge\nsh\nade\nd r\negi\non\nin\nthe upper center,\nshaped like a ca p\nital D.\nImage by MIT OCW.\nAdapted from Liljencrants, Johan, and Bjorn Lindblom. \"Numerical Simulation of Vowel Quality\nSystems:\n:\nThe Role of Perceptual Contrast.\" Language 48, no. 4 (December 1972): 839-862.\n\nThe vowel space\n- Why does the range of possible F2\nvalues taper as F1 increases?\n- How do you achieve maximum and\nminimum F1?\n- How do you achieve maximum and\nminimum F2?\n1st\nfo\nrma\nnt\nvs.\n2nd\nform\nant:\nla\nrge\nsh\nade\nd r\negi\non\nin\nthe upper center,\nshaped like a ca p\nital D.\nImage by MIT OCW.\nAdapted from Liljencrants, Johan, and Bjorn Lindblom. \"Numerical Simulation of Vowel Quality\nSystems:\n:\nThe Role of Perceptual Contrast.\" Language 48, no. 4 (December 1972): 839-862.\n\nLiljencrants and Lindblom (1972)\n- Perceptual distinctiveness of contrast between Vi and Vj:\ndistance between vowels in perceptual vowel space\nr =\nij\n(x\n)2\n)2\ni - xj\n+ (yi - yj\nF2′\nwhere xn is F2′ of Vn in mel\n\nyn is F1 of Vn in mel\n- mel is a perceptual frequency\nscale, similar to Bark.\n- F2′ is the 'effective second\nformant' - combination of F2 and\nF3.\nF1\n\nDistinctiveness of a vowel system\n- Maximize distinctiveness: select N vowels so as to\nminimize E\nE =\nr 2\nij\nF1 (mel)\nj =0\ni -1\n∑\ni =1\nn-1\n∑\ni\nj\nrij\n1/rij\nu(1)\ni(0)\n0.0000012\na(2)\ni(0)\n0.0000018\nu(1)\n0.0000027\nE\n5.7×10-6\nF2' (mel)\nF1 (mel)\ni\nj\nrij\n1/rij\nu(1)\ni(0)\n0.0000020\na(2)\ni(0)\n0.0000028\nu(1)\n0.0000045\nE\n9.3×10-6\n\nDistinctiveness of a vowel system\n- Maximize distinctiveness: select N vowels so as to\nminimize E\nE =\nr 2\nij\nj =0\ni -1\n∑\ni =1\nn-1\n∑\ni\nj\nrij\n1/rij\nu(1)\ni(0)\n0.0000012\na(2)\ni(0)\n0.0000018\nu(1)\n0.0000027\nE\n5.7×10-6\nF2' (mel)\nF1 (mel)\n(\n)\nF1 (mel)\ni\nj\nrij\n1/rij\ne(1)\ni(0)\n0.0000098\na(2)\ni(0)\n0.0000018\ne(1)\n0.0000054\nE\n1.7×10-5\n\nMinimizing E - stochastic search\n- Start with vowels arranged in a circle near the center of the vowel space.\n(Random arrangement might be better?)\n- Pick a vowel at random.\n- Try small movements of that vowel in 6 directions (within the vowel\nspace)\n- Select the direction that results in greatest reduction in E.\n- Move vowel in that direction until E stops decreasing, or a boundary\nis reached.\n- Repeat for all vowels.\n- Cycle through the vowels until no further reduction in E can be\nachieved.\n- Should be repeated multiple times, preferably with different starting\nconfigurations.\n- More sophisticated search strategies are possible, e.g. simulated\nannealing or more sophisticated procedures for identifying best change\nat each stage.\n\n- Predicted optimal\ninventories\n- Reasonable\napproximations to\ntypical 3 and 5\nvowel inventories\nare derived.\n- Preference for [i, a,\nu] is derived.\n- Problem: Too\nmany high, non-\nperipheral vowels.\n- Not enough mid\nnon-peripheral\nvowels.\n1st\nfo\nrma\nnt\nvs\n. 2\nnd\nfor\nman\nt:\nse\nrie\ns o\nf g\nra\nph\ns\nwi\nth\nc\nlo\nse\nd\ncu\nrv\nes\ns\nhaped like a capital\nD.\nAdapted from Liljencrants, Johan, and Bjorn Lindblom. \"Numerical Simulation of Vowel Quality\nSystems: The Role of PerceptualContrast.\" Language 48, no. 4 (December 1972): 839-862.\nImage by MIT OCW.\n\nToo many high non-peripheral vowels\n- All inventories larger than 5 are predicted to contain one or\nmore high vowels between [i] and [u], e.g. [y, ɨ, ɯ].\n- E.g. prediction for 7 vowels (unattested):\n- Common 7 vowel inventories:\ni y u i u\ne P o e\nE\no\nO\na\na\n\n(c) Language. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\nSource: Liljencrants, Johan, and Bjorn Lindblom. \"Numerical simulation of vowel quality\nsystems: The role of perceptual contrast.\" Language (1972): 839-862. Harvard\n\nToo many high non-peripheral vowels\n- The excess of central vowels arise because measuring\ndistinctiveness in terms of distance in formant space gives\ntoo much weight to differences in F2.\n- In general, languages have more F1 contrasts than F2 contrasts.\n- Why are F1 differences more distinct than F2 differences?\n- One factor: auditory sensitivity to frequency (next slide).\n- But L&L already took this into account - mel scaled formant\nfrequencies.\n\nItalian vowels\nF2 (Hz)\ni\ne\nϯ\na\nе\no\nu\nERB scales\nF2 (E)\nF1(E)\nE(F1\nF1 (Hz)\nF\nr\ne\nq\nue\nnc\ny\n(k\nH\nz\n)\n\nv\ns\n.\n\nF\nre\nquency (Bark) s\nhowing logrithmic relationship.Frequency (kHz) vs. Frequency (Bark) showing logrithmic relationship.\nAdapted from Johnson, Keith. Acoustic and Auditory Phonetics.\nMalden, MA: Blackwell Publishers, 1997. ISBN: 9780631188483.\nImage by MIT OCW.\n\nToo many high non-peripheral vowels\n- Recent work by Diehl, Lindblom and Creeger (2003)\nsuggests that the greater perceptual significance of F1\nprobably follows from the higher intensity of F1 relative to\nF2.\n- F1 should be more salient auditorily and more robust to noise.\nFrequency (Hz)\nFrequency (Hz)\n\nToo many high non-peripheral vowels\n- New simulations of 7 vowel system by Diehl, Lindblom\nand Creeger (2003)\n- incorporate background noise\n- perceptual distance is calculated as difference between auditory\nspectra.\n1st\nfo\nrma\nnt\nvs\n.\n2n\nd\nfo\nrm\nan\nt:\nD\n\ns\nhaped closed curve with dots c\nonnected to form shape.\nImage by MIT OCW.\nAdatped from Diehl, R.L., B. Lindblom, and C. P. Creeger. \"Increasing realism\nof auditory representations yields further insights into vowel phonetics.\"\nProceedings of the 15th International Congress of Phonetic Sciences,\nvol. 2, Adelaide, Australia: Causal Publications, 2003, pp.1381-1384.\n\nThe 'corner' vowels [i, a, u]\n- Considerations of formant intensity might also help to\naccount for some exceptions to the generalization that every\nlanguage includes the 'corner' vowels [i, a, u].\n- L&L predict that this should be the case, and most\nlanguages do include all three, but a number of languages\nlack [u]:\n- [i, a, o], e.g. Piraha, Axeninca Campa\n- [i, e, a, o], e.g. Navajo, Klamath\n- [i, e, a, o, ], e.g. Tokyo Japanese\n- In general F1 is more intense where it is higher, and this\nalso raises the intensity of all higher formants. In [u], both\nF1 and F2 are low, resulting in a low intensity vowel, with\nlow intensity F2.\n\nToo few interior vowels\n- When an inventory has mid vowels [e, o] and front rounded vowel [y],\nit often has mid front [ø] as well (Finnish, German, French, etc)\n- L&L predict that interior vowels only appear with 10 or more vowels.\n- The absence of interior vowels [ə, ø] is a result of the way in which\noverall distinctiveness is calculated.\n- Each vowel contributes to E based on its distance from every other\nvowel.\n- Interior vowels have a high cost because they are relatively close to all\nthe peripheral vowels.\n- Perhaps the measure of distinctiveness, E, can be improved on.\ni y\ne P\na\nu\no\ni\ne\nE\n\na\nu\no\n\nAlternative measures of distinctiveness\n- L&L's measure E is based on an analogy to dispersion of charged\nparticles - it is not derived from anything based on vowel perception.\n- It has the important property that distinctiveness 'cost' increases more\nrapidly as two vowels become closer - 1/rij\n- I.e. vowels are only likely to be confused if they are quite similar.\nLikelihood of confusion drops of quickly as distance increases.\n- But perhaps 1/rij\n2 doesn't drop off quickly enough - the lack of interior\nvowels results from giving too much weight to vowel pairs that are not\nvery close.\n- An alternative (Flemming 2005): only consider the closest pair of\nvowels in the inventory.\n- Compromise (to be explored): 1/rij\n2n, n > 1.\n\nAlternative measures of distinctiveness\n- Maximize the minimum distance (Flemming 2005)\n- favors even distribution of vowels over the vowel space, i.e. distances\nbetween vowel and their nearest neighbors are equal.\nF2 (Bark)\n2.5\n3.5\n4.5\n5.5\nstressed\nunstressed\nF1 (Bark)\n\nProblems with Adaptive Dispersion\n- Specific instantiations of the model have made specific incorrect\npredictions (but some of the broad predictions are correct and models\nare improving).\n- TAD predicts a single best inventory for each inventory size. Why\nwould languages have sub-optimal inventories?\n- The unattested inventories shown earlier are obviously very poorly\ndispersed, but there are a variety of attested inventory patterns for any\ngiven number of vowels.\n- Warping of the perceptual space by perceptual learning?\n- The model answers an inobvious question: 'Given N vowels, what\nshould they be?' - what determines the size of inventories?\n\nInventory size\n- What determines the size of vowel inventories?\n- A step towards an answer (Flemming 2004 etc): there is a trade-\noff between distinctiveness of contrasts and number of\ncontrasts.\n- Maximize the distinctiveness of contrasts\n- Maximize the number of contrasts\n- Increasing the number of contrasting vowels increases the\ninformation content of a vowel (increases the number of words\nthat could be differentiated by uttering a vowel).\nwn\nminimize\n2 +\nV\ndmin\nn\n\nExtending Adaptive Dispersion\n- If perceptual distinctiveness is important in shaping vowel\ninventories, then it should play a similar role in shaping\nconsonant inventories.\n- It is harder to develop quantitative models in this area\nbecause it is less clear what the perceptual dimensions are.\n- Especially because many consonants cannot be treated\nas static, e.g. stops.\n- Note that this is an issue for vowels also - how do\ndiphthongs and vowel duration contrasts fit into the\nmodel?\n\nReferences\n-\nDiehl, R.L., Lindblom, B., & Creeger, C.P. (2003). Increasing realism of\nauditory representations yields further insights into vowel phonetics.\nProceedings of the 15th International Congress of Phonetic Sciences, Vol. 2, pp.\n1381-1384. Adelaide: Causal Publications.\n-\nDisner, Sandra (1984). Insights on vowel spacing. In I.M. Maddieson, Patterns\nof Sounds, CUP.\n-\nFlemming, E. (2005).\nA phonetically-based model of phonological vowel reduction. Ms.\n-\nLindblom, Bjorn (1986). Phonetic universals in vowel systems. J.J. Ohala and\nJ.J. Jaeger (eds.) Experimental Phonology. Academic Press.\n-\nLindblom, Bjorn (1990). Phonetic content in phonology. PERILUS 11,\n101-118.\n-\nLindblom & Engstrand (1989). In what sense is speech quantal? Journal of\nPhonetics 17.\n-\nStevens, K.N. 1989. On the quantal nature of speech. Journal of Phonetics 17,\n3-46.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n24.915 / 24.963 Linguistic Phonetics\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 8",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-915-linguistic-phonetics-fall-2015/d9c4c35c4cf8ec0f9566e2a6a8762981_MIT24_915F15_lec8.pdf",
      "content": "24.915/24.963\nLinguistic Phonetics\nSource-filter analysis of fricatives\n\nFigure removed due to copyright restrictions.\n\nReadings:\n- Johnson chapter 5 (speech perception)\n- 24.963: Fujimura et al (1978)\n\nNoise source\n- Turbulence noise - random pressure fluctuations.\n- Turbulence can result when a jet of air flows out of a\nconstriction into a wider channel (or open space).\nFr\neq\nue\nn\ncy\nv\ns\n.\n\nre\nlative level: downw\nard curve.\nImage by MIT OCW.\nAdapted from Stevens, K. N. \"On the quantal nature of speech.\" Journal of Phonetics 17 (1989): 3-46.\n\nNoise source\n- Turbulence can result when a jet of air flows out of a\nconstriction into a wider channel (or open space).\n- The intensity of turbulence noise depends on particle\nvelocity.\n- For a given volume velocity, particle velocity will be greater\nif the channel is narrower, so for a given volume velocity,\nnarrower constrictions yield louder frication noise.\ngr\na\np\nhs\nwit\nh 2\ncu\nrve\ns\nea\nch,\non\ne p\neak\ns early and steady\ndecline, the othe\nr steady incline.\nm\nImage by MIT OCW.\nStevens, K. N. Acoustics Phonetics. Cambridge, MA: MIT Press, 1999.\n\nNoise source\n- Turbulence is also produced when an airstream strikes an\nobstacle (e.g. the teeth in [s]).\n- The orientation of the obstacle to the direction of flow\naffects the amount of turbulence produced - the teeth are\nmore or less perpendicular to the airflow in [s] and thus\nproduce significant turbulence.\n- The louder noise of strident fricatives is a result of\ndownstream obstacles. three tubes, narrowing, then opening again\nImage by MIT OCW.\nStevens, K. N. Acoustic Phonetics. Cambridge, MA: MIT Press, 1999.\n\nFilter characteristics\n- The noise sources are filtered by the cavity in front of the\nconstriction.\n- In [h] the noise source is at the glottis, so the entire\nsupralaryngeal vocal tract filters the source, just as in a\nvowel.\n- So [h] has formants at the same frequency as a vowel with\nthe same vocal tract shape, but the formants are excited by a\nnoise source instead of voicing.\n- The noise source generated at the glottis has lower intensity\nat low frequencies, so F1 generally has low intensity in [h].\nkHz vs.\ndB: periodi\nc source\ncurve\n\nd\ne\nc\nr\ne\nas\nes\n,\nov\ner\nal\nnoise source p\nlateaus.\nImage by MIT OCW.\n\n[h]\n- The noise source generated at the glottis has lower intensity\nat low frequencies, so F1 generally has low intensity in [h].\ngr\nap\nh\ns\nwi\nth\n\nc\nu\nr\nves each,\nkHz vs.\ndB. smal\nl pe\naks\nan\nd t\nrou\nghs but general decrease overall.2 graphs with 2 curves each, kHz vs. dB. small peaks and troughs but general decrease overall.kHz vs. dB: periodic source curve decreases, overal noise source plateaus.2 graphs with 2 curves each, kHz vs. dB. small peaks and troughs but general decrease overall.\nImage by MIT OCW.\nImage by MIT OCW.\nStevens, K. N. Acoustic Phonetics. Cambridge, MA: MIT Press, 1999.\nkHz vs.\ndB: periodi\nc source\ncurve\n\nd\ne\nc\nr\ne\nas\nes\n,\nov\ner\nal\nnoise source p\nlateaus.2 graphs with 2 curves each, kHz vs. dB. small peaks and troughs but general decrease overall.\n\n[h]\nheed\nhoed\n13.686\nTime (s)\n14.1873\n17.5452\nTime (s)\n18.0608\nHoyd\nhoard\n15.4067\n15.9137 19.5239\n20.0263\nTime (s)\nTime (s)\n\nFilter characteristics\n-\n\nAs the place of articulation shifts forward, the cavity in front\nof the noise source is progressively smaller.\n- A smaller cavity has higher resonances, so other things\nbeing equal, the concentration of energy in the fricative\nspectrum is higher the closer the place of articulation is to\nthe lips.\nkH\nz\nvs\n.\nd\nB\n:\n\nu\np\nper\nar\nch,\nse\nv\neral curves with pe\naks and troughs below - peaks intersect upper arch.\n0-2 s\nFrequency (kHz)\ns\nx\nImage by MIT OCW.\nImage by MIT OCW.\nAdapted from Stevens, K.N. \"On the quantal nature\nof speech.\" Journal of Phonetics 17 (1989): 3-46.\n\nFilter characteristics\n- The front cavity of a labial is so short (first resonance ~10\nkHz) that it has little effect on the fricative spectrum,\nresulting in fricative noise spread over a wide range of\nfrequencies with a broad low-frequency peak.\n- This picture can be complicated by acoustic coupling with\nback cavity.\n-\n8000 12.0111\n12.7989\nFrequency (Hz)\nTime (s)\n\n0.641297\n1.9567\nTime (s)\nsi\nsu\nsi\n-20\n-40\nFrequency (Hz)\n-20\nsu\n-40\n\nFilter characteristics\n- Lip rounding lowers the resonant frequencies of the front\ncavity, just as in vowels.\n\nFrequency (Hz)\n\nFilter characteristics\n- In coronals, the presence or absence of a sublingual cavity\nhas a significant effect on the size of the front cavity.\n(c) Blackwell Press. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\ngr\nap\nhs\nwi\nt\nh\n\nm\naj\nor\nc\nu\nr\nv\nes\n\nand oscillations paralleling the curves; 2 main peaks per curve.\nImage by MIT OCW.\n\nLip rounding/protrusion as an enhancement of\nsibilant contrasts\n- Postalveolar fricatives in English and French are produced with lip-\nrounding/protrusion (Ladefoged & Maddieson 1996:148), as are\nretroflex fricatives in Polish (Puppel et al 1977:157).\n- This realization can be analyzed as enhancing the perceptual\ndistinctiveness of the contrast with sibilants with smaller front cavities\n(e.g. anterior sibilants)\n-English, French: [s], Polish [s1, C]\n- [S] has larger front cavity than [s] - [S] has posterior constriction, sub-\nlingual cavity - and thus has lower spectral peaks.\n- Lip rounding further lowers the resonant frequencies of the front cavity,\nincreasing this difference.\ngr\nap\nhs\nwi\nt\nh\n\nm\naj\nor\nc\nu\nr\nv\nes\n\nand oscillations paralleling the curves; 2 main peaks per curve.\nImage by MIT OCW.\n\nΚ\nSource-filter analysis of stops\n\ns\npect\nogra\nms w\nith\n3 separate bands of blurs.\nImage by MIT OCW.\n\nStops\n- Stops are complicated in that they involve a series of rapid\nchanges in acoustic properties, but each component can be\nanalyzed in similar terms to vowels and fricatives.\n- A stop can consist of four phases: implosion (closure)\ntransitions - closure - burst - release transitions\n\n0.129852\nTime (s)\n0.479959\nComponents of a stop\nclosure\nrelease\ntransitions closure\nburst transitions\n\n0.494\n-0.4972\n0.231127\nTime (s)\n0.231127\nTime (s)\nbal\n\nClosure\n- Only source of sound is voicing, propagated through the\nwalls of the vocal tract.\n- The walls of the vocal tract resonate at low frequencies, so\nmainly low-frequency sound is transmitted ('voice bar).\n\nBurst\n- Consists of a transient, due to abrupt increase in pressure at\nrelease, followed by a short period of frication as air flows at\nhigh velocity through the narrow (but widening)\nconstriction.\n- Transient source is an impulse (flat spectrum) filtered by the\nfront cavity.\n- The frication is essentially the same as a fricative made at\nthe same place of articulation.\n- Alveolars have high frequency, high intensity bursts.\n- Velar bursts are concentrated at the frequency of F2 and/or\nF3 at release.\n- Labial bursts are of low intensity, with energy over a wide\nrange of freqeuncies, with a broad, low-frequency peak.\n\nRelease transitions\n- As the constriction becomes more open, frication ceases.\n- The source at this time is at the glottis - either voicing or\naspiration noise. This source excites the entire vocal tract as\nin a vowel (or [h]).\n- The shape of the vocal tract, and thus the formants, during\nthis phase are basically determined by the location of the\nstop constriction and the quality of adjacent vowels.\n- The formants move rapidly as the articulators move from the\nposition of the stop to the position for the vowel. The\nformant movements are usually called 'formant transitions.\n\nS\ne\nr\nie s\nof\nsp ec\ntog\nram\ns, w\nher\ne s\nhade\nd ba\nnds\nare\nc\no\nn\ncent\nrate\nd to\ngeth\ner a\nnd t\nhen\nsepa\nrate\nand\nmov\ne do\nwn t\nhe g\nraph\ns.\nImage by MIT OCW.\n\nAdapted from Ladefoged, Peter. Phonetic Data Analysis. Malden, MA: Blackwell, 2003.\n\nRelease transitions\n- In alveolar stops the formant transitions due to release of the\ntongue tip constriction are probably very rapid (Manuel and\nStevens 1995), so the observed formant transitions appear to\nbe due to tongue body movements.\n- The tongue body is generally relatively front to facilitate\nplacement of the tongue tip//blade, thus there is a relatively\nhigh F2 at release (~1800-2000 Hz) and high F3.\n- Labial stops involve a constriction at the lips. The tongue\nposition is determined by adjacent vowels, so the exact\nformant frequencies at release depend on these vowel\nqualities.\n- The labial constriction always lowers formants, so F2 and\nF3 are generally lower at release of a labial than in the\nfollowing vowel.\n\nRelease transitions\n- Velar stops involve a dorsal constriction, but the exact\nlocation of this constriction depends on the neighbouring\nvowels.\n- So the formant transitions of velars vary substantially,\napproximately tracking F2 of the adjacent vowel.\n- F2 and F3 are often said to converge at velar closure. Under\nwhat conditions should this occur?\n- Similar transitions are observed into and out of any\nconsonant with a narrow constriction, e.g. fricatives, nasal\nstops.\n\nLocus equations\n- Typically F2 at the release of a consonant is a linear\nfunction of F2 at the midpoint of the adjacent vowel\n(Lindblom 1963, Klatt 1987, etc).\n- The slope and intercept of this function depend on the\nconsonant.\nbid\nbOd\n1.96743\n2.42708\n11.3647\n11.8142\nTime (s)\nTime (s)\n\nLocus equations\n- The slope and intercept of this function depend\non the consonant.\nFowler (1994)\nGrap\nhs o\nf /b\n/, /\nd/,\n/g/\n(vo\nwel\nvs.\nonse\nnt)\nshow\ning\nposi\ntive slo\npe straight line\nin all three grap\nhs.\nImage by MIT OCW.\nAdpated from Fowler, C. A. \"Invariants, specifiers, cues: An investigation of locus equations as\ninformation for place of articulation.\" Perception and Psychophysics 55, no. 6 (1994): 597-610.\n\nAffricates\n- The frication portion of the release of the stop is prolonged\nto form a full-fledged fricative.\n- The fricative portion of an affricate is distinguished from a\nregular fricative by its shorter duration, and perhaps by the\nrapid increase in intensity at its onset (short rise time).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n24.915 / 24.963 Linguistic Phonetics\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 9",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-915-linguistic-phonetics-fall-2015/1681570d3f89ea52907a8a9ae5956445_MIT24_915F15_lec9.pdf",
      "content": "24.963\nLinguistic Phonetics\nPerception - cues\n16 graphs: 3 discrimination (each with 2 sharp peaks) and 3 identification (inverse bell curves).\nPercent correct\nPercent /b.d.g./\n+8\nDL\n-6\n+8\nPG\n-6\n+8\nHC\n-6\nHC\n+8\n-6\nPG\n+8\n-6\nDL\n+8\n-6\nDiscrimination\nIdentification\n/b/\n/d/\n/g/\nImage by MIT OCW.\nAdapted from Liberman, A. M. \"Some characteristics of perception in the speech mode.\"\nPerception and its Disorders 48 (1970): 238-254. And Liberman, A. M. \"Discrimination\nin speech and nonspeech modes.\" Cognitive Psychology 2 (1970): 131-157.\n\n- Reading for next week: Johnson ch. 9\n- Assignments:\n- Acoustics assignment 4, due 11/3\n- Talk to me about a paper topic.\n\nSpeech perception\n- The problem faced by the listener: To extract meaning\nfrom the acoustic signal.\n- This involves the recognition of words, which in turn\ninvolves discriminating the segmental contrasts of a\nlanguage.\n- Much phonetic research in speech perception has been\ndirected toward identifying the perceptual cues that\nlisteners use.\n\nPerceptual Cues\n- Production studies can reveal differences between\nminimally contrasting words, e.g. aspirated and\nunaspirated stops in Mandarin differ in VOT.\n- Are listeners sensitive to these differences in speech\nperception?\n- Most direct test of perceptual significance of an acoustic\nproperty: manipulate the acoustic property synthetically (or\nby editing, resynthesis) and see if perceptual response is\naffected.\n- E.g. vary VOT in synthetic CV syllables (or by\nediting natural utterances), and have listeners classify\nthe syllables as voiced or voiceless.\n\nVOT as a cue to stop voicing and aspiration contrasts\n- Lisker & Abramson (1970)\n- Synthesized a VOT continuum for /Ta/ syllables.\n- Three steady state formants for [a]\n- Formant transitions for labial, coronal, dorsal stop places (3\ncontinua)\n- 37 VOT variants -150 ms to +150 ms\n-\nNegative VOT = voicing bar during stop closure\n-\nPositive VOT filled with aspiration noise\n-\n10 ms steps, except 5 ms steps from -10 to +50.\n- Stimuli presented to\n- 5 speakers of Latin American Spanish\n- 12 speakers of American English\n- 8 speakers of Thai\n- Subjects classified stimuli using orthographic labels (forced choice).\n- e.g. 'ba', 'pa'\n\nVOT - Lisker & Abramson (1970)\n- Histograms show\nfrequencies of different\nVOT ranges from a\nproduction study.\n- Lines are identification\nfunctions for voiced\n(dashed) and voiceless\n(solid).\n- Spanish contrasts voiced vs.\nvoiceless unaspirated [b vs.\np]\nCourtesy of Arthur Abramson and Leigh Lisker. Used with permission.\nSource: Lisker, Leigh, and Arthur S. Abramson. \"The voicing dimension: Some\nexperiments in comparative phonetics.\" In Proceedings of the 6th international\ncongress of phonetic sciences, pp. 563-567. Academia Prague, 1970.\n\nVOT - Lisker & Abramson (1970)\n- In initial position,\nEnglish usually contrasts\nvoiceless unaspirated\nwith aspirated [p, ph],\nwith the occasional\nvoiced stop [b~p].\n- Place affects VOT in\nproduction and\ninterpretation of VOT in\nperception\nVelar > alveolar > labial\nCourtesy of Arthur Abramson and Leigh Lisker. Used with permission.\nSource: Lisker, Leigh, and Arthur S. Abramson. \"The voicing dimension: Some\nexperiments in comparative phonetics.\" In Proceedings of the 6th international\ncongress of phonetic sciences, pp. 563-567. Academia Prague, 1970.\n\nVOT - Lisker & Abramson (1970)\n- In initial position, Thai\ncontrasts voiced,\nvoiceless unaspirated and\naspirated stops [b, p, ph].\nCourtesy of Arthur Abramson and Leigh Lisker. Used with permission.\nSource: Lisker, Leigh, and Arthur S. Abramson. \"The voicing dimension: Some\nexperiments in comparative phonetics.\" In Proceedings of the 6th international\ncongress of phonetic sciences, pp. 563-567. Academia Prague, 1970.\n\nExcursus: Categorical perception\n- Strict categorical perception is said to occur where\ndiscrimination performance is limited by identification\nperformance, i.e. listeners only have access to category\nlabels, so stimuli can only be distinguished if they are\nidentified as belonging to different categories.\n- Tested in two stages:\n- Identification of a synthetic continuum\n- Discrimination of stimuli from the continuum\n\nCategorical perception\n- E.g. Liberman (1970) place of articulation F2\ntransition continuum, b-d-g.\nTim\ne v\ns. Hz: line\ns (-\n\nto\n+9)\nconv\ner\nge\n,\nth\nen\nh\nor\niz\non\nta\nl\nli\nne\n.\nal\ns\no: s\nharp rise and horizontal line.\nImage by MIT OCW.\nAdapted from Liberman, A. M. \"Some characteristics of perception in the speech mode.\"\nPerception and its Disorders 48 (1970): 238-254.And Liberman, A. M. \"Discrimination\nin speech and nonspeech modes.\" Cognitive Psychology 2 (1970): 131-157.\n\nCategorical perception\n- Identification: Subjects identify stimuli as b, d, g\n- Discrimination: Subjects are presented with pairs of stimuli and asked\nto judge whether they are the same or different.\n- Relatively abrupt\ntransitions in\nidentification functions.\n- Peaks in discrimination\nfunction at the category\nboundary\n116 graphs: 3 discrimination (each with 2 sharp peaks) and 3 identification (inverse bell curves).\nPercent correct\nPercent /b.d.g./\n+8\nDL\n-6\n+8\nPG\n-6\n+8\nHC\n-6\nHC\n+8\n-6\nPG\n+8\n-6\nDL\n+8\n-6\nDiscrimination\nIdentification\n/b/\n/d/\n/g/\nImage by MIT OCW.\nAdapted from Liberman, A. M. \"Some characteristics of perception in the speech mode.\"\nPerception and its Disorders 48 (1970): 238-254. And Liberman, A. M. \"Discrimination\nin speech and nonspeech modes.\" Cognitive Psychology 2 (1970): 131-157.\n\nCategorical perception\n- Discrimination has never been found to be precisely\npredictable from identification - Discrimination is always\nbetter than predicted.\n- More loosely, categorical perception is sometimes said to\nbe exhibited where there is a discrimination peak at the\ncategory boundary determined by identification, even if the\nrelationship is not precisely as predicted by strict\ncategorical perception.\n- A sharp transition in the 'identification function' for a\nstimulus continuum is not categorical perception in any\ntechnical sense.\n\nWhy is categorical perception significant?\n- The (loose) categorical perception pattern contrasts with the\npattern observed in psychophysical experiments using non-\nspeech stimuli:\n\"Typically, nonspeech stimuli that vary acoustically\nalong a single continuum are perceived continuously,\nresulting in discrimination functions that are monotonic\nwith the physical scale\" (Luce and Pisoni, p.31).\n- This contrast was used by Liberman and others to argue\nthat speech perception is 'special' - i.e. it uses special\nmechanisms, not the general mechanisms of non-speech\nauditory perception.\n\nWhy is categorical perception significant?\n- Vowels are not usually perceived categorically, even in the loose sense\n(Luce and Pisoni and refs there).\n- The argument for specialness from categorical perception has been\nweakened by:\n-Evidence for categorical perception of non-speech sounds (noise-\nbuzz, Miller et al 1976).\n-Evidence that Chinchillas perceive a VOT continuum categorically\n(Kuhl and Miller 1975).\n- It has been argued that perception is actually essentially continuous,\nwith categorical effects arising from a categorical decision (natural or\nexperimentally imposed) (e.g. Massaro).\n\nModeling categorical perception\n- 'Noisy' continuous perception plus a decision criterion can\naccount for the shape of identification functions\nga\nka\n- Doesn't explain discrimination peak at boundry.\n(c) Source Unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\n\nModeling categorical perception\n- The occurrence of discrimination peaks at category boundaries follows\nfrom a Bayesian model of discrimination (Feldman et al 2009).\n- When presented with two stimuli in a discrimination task, the listener is\ntrying to locate the stimuli on a perceptual dimension (e.g. VOT).\n- Given the presence of noise in the signal (and perceptual process), the\nperceived VOT of a stimulus may differ from the actual VOT.\n- Listener has to estimate the most likely VOT for that stimulus given the\nperceived value, and their knowledge of the prior probabilities of\ndifferent values of VOT.\n- Best estimate of VOT is shifted towards values with higher\nprobability.\n\n-\nModeling categorical perception\nVOT values close to the category boundary have a low probability, so\nperceived VOT values near the boundary are shifted towards the\ncategory centers, resulting in better discrimination\nCourtesy of Arthur Abramson and Leigh Lisker. Used with permission.\nSource: Lisker, Leigh, and Arthur S. Abramson. \"The voicing dimension: Some\nexperiments in comparative phonetics.\" In Proceedings of the 6th international\ncongress of phonetic sciences, pp. 563-567. Academia Prague, 1970.\n\nCues\n- Perception experiments based on synthetic/edited speech\nhave been used to establish the perceptual significance of a\nwide variety of acoustic correlates of linguistic contrasts.\n\nCues to consonant contrasts\n- Place cues (Wright, Frisch and Pisoni 1999)\n19Vocal chord illustrations showing stop release burst, fricative noise, and spacing.\nStop release burst\nFricative noise\nF2 Transitions\nNasal pole and zero\nRelative spacing of F2 and F3\nF3\nF2\nF1\na\na\na\na\na\nt\na\na\na\ns\nn\nl\nImage by MIT OCW.\nAdapted from Wright, R., S. Frisch, D. B. Pisoni. \"Speech Perception.\" In Wiley Encyclopedia of Electrical\nand Electronics Engineering, Vol. 20. New York, NY: John Wiley and Sons, 1999, pp. 175-195.\n\nCues to consonant contrasts\n- Manner cues (Wright, Frisch and Pisoni 1999)\nVocal chords showi\nng abruptness and att\nenuation, nasa\nlization, formant s\ntr\nuc\ntu\nr\ne\n.\nImage by MIT OCW.\nAdapted from Wright, R., S. Frisch, D. B. Pisoni. \"Speech Perception.\" In Wiley Encyclopedia of Electrical\nand Electronics Engineering, Vol. 20. New York, NY: John Wiley and Sons, 1999, pp. 175-195.\n\nCues to consonant contrasts\n- Obstruent voicing cues (Wright, Frisch and Pisoni 1999) Vocal chords showing aspiration noise and vowel and stricture duration.\n21Vocal chords showing aspiration noise and vowel and stricture duration.Vocal chords showing aspiration noise and vowel and stricture duration.\nRelease burst amplitude\nF3\nF2\nF1\nAspiration noise\nVowel duration\nStricture duration\nPeriodicity\nVOT\nVowel durationVocal chords showing aspiration noise and vowel and stricture duration.Vocal chords showing aspiration noise and vowel and stricture duration.\nImage by MIT OCW.\nAdapted from Wright, R., S. Frisch, D. B. Pisoni. \"Speech Perception.\" In Wiley Encyclopedia of Electrical\nand Electronics Engineering, Vol. 20. New York, NY: John Wiley and Sons, 1999, pp. 175-195.\n\nThe nature of acoustic cues\n- Properties of cues:\n- There are multiple cues to every contrast\n- these cues combine to distinguish sounds\n- cues can vary in their relative strengths\n- Individual cues can vary in strength - e.g. longer VOT is a\nstronger cue to voicelessness.\n\nThe nature of acoustic cues\n-\nThere are multiple cues to every contrast\n-\nE.g. stop voicing in English\n1.\nLow-frequency spectral energy, periodicity (Stevens and\nBlumstein 1981:29)\n2.\nVoice onset time (Lisker & Abramson 1970)\n3.\nAmplitude of aspiration (Repp 1979)\n4.\nAmplitude of release burst (Repp 1979)\n5.\nClosure duration (Lisker 1957)\n6.\nDuration of the preceding vowel (Massaro and Cohen 1983)\n7.\nF1 adjacent to closure (Lisker 1975, Kingston and Diehl 1995)\n8.\nf0 adjacent to the closure (Haggard, Ambler and Callow 1970)\n9.\nAmplitude of F1 at release (Lisker 1986).\n\nF0 as a cue to stop voicing\nvoiceless\nvoiced\nOhde (1984)\n- F0 is higher after voiceless obstruents than after voiced\nobstruents (other things being equal)\n(c) The Journal of the Acoustical Society of America. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\nSource: Ohde, Ralph N. \"Fundamental frequency as an acoustic correlate of stop consonant voicing.\"\nThe Journal of the Acoustical Society of America 75, no. 1 (1984): 224-230.\n\nF0 as a cue to stop voicing\n% \"p\"\nresponse\nVOT\n- This differences is exploited as a cue - higher F0 onset results in\nmore voiceless percepts, for a given VOT.\n- Whalen et al (1993): Synthetic [ba-pa] cotinuum.\n- varied VOT\n- varied F0 onset, with a linear trajectory to 114 Hz over the first 50 ms of\nthe vowel\n(c) The Journal of the Acoustical Society of America. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\nSource: Whalen, Douglas H., Arthur S. Abramson, Leigh Lisker, and Maria Mody. \"F 0 gives voicing information even\nwith unambiguous voice onset times.\" The Journal of the Acoustical Society of America 93, no. 4 (1993): 2152-2159.\n\nFigure removed due to copyright restrictions.\nSource: Figures 1 & 2, Raphael, Lawrence J. \"Preceding vowel duration as a cue to the\nperception of the voicing characteristic of word-final consonants in American English.\"\nThe Journal of the Acoustical Society of America 51, no. 4B (1972): 1296-1303.\n\nCue strength\n- The multiple cues to voicing all contribute to voicing\njudgments\n- 20 ms VOT, 98 Hz is ambiguous (~55% voiceless)\n- 20 ms VOT, 120 Hz is less ambiguous (>70% voiceless)\n- Cues can differ in strength.\n- Higher VOT (e.g. 40ms) is a stronger cue to voicelessness than lower\nvalues (e.g. 20ms)\n- Typical values of VOT provide stronger cues to voicing than typical\nf0 differences\n(c) The Journal of the Acoustical Society of America. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\nSource: Whalen, Douglas H., Arthur S. Abramson, Leigh Lisker, and Maria Mody. \"F 0 gives voicing information even\nwith unambiguous voice onset times.\" The Journal of the Acoustical Society of America 93, no. 4 (1993): 2152-2159.\n\nReferences\n-\nDelattre, Pierre C., Alvin M. Liberman, Franklin S. Cooper, and Louis J. Gerstman\n(1952). An experimental study of the acoustic determinants of vowel color: observations\non one- and two-formant vowels synthesized from spectrographic patterns. Word 8,\n195-210.\n-\nHaggard, Mark P., Stephen Ambler, and Mo Callow (1970). Pitch as a voicing cue.\nJournal of the Acoustical Society of America 47, 613-17.\n-\nJun, Jongho (1995). Perceptual and Articulatory Factors in Place Assimilation: An\nOptimality-Theoretic Approach. PhD dissertation, UCLA.\n-\nKingston, John, and Randy L. Diehl (1995). Intermediate properties in the perception of\ndistinctive feature values. Bruce Connell and Amalia Arvaniti (eds) Papers in Laboratory\nPhonology IV , Cambridge University Press, Cambridge.\n-\nLisker, Leigh (1957). Closure duration and the intervocalic voiced-voiceless distinctions\nin English. Language 33, 42-49.\n-\nLisker, Leigh (1975). Is it VOT or a first formant transition detector?. Journal of the\nAcoustical Society of America 57, 1547-51.\n-\nLisker, Leigh (1986). \"Voicing\" in English: A catalogue of acoustic features signaling /b/\nversus /p/ in trochees. Language and Speech 29.3-11.\n\nReferences\n-\nMassaro, Dominic W., and Michael M. Cohen (1983). Consonant/vowel ratios: An\nimprobable cue in speech. Perception and Psychophysics 33, 501-5.\n-\nOhala, J.J. (1990) The phonetics and phonology of aspects of assimilation. M. Beckman\nand J. Kingston (eds) Papers in Laboratory Phonology I: Between the Grammar and\nPhysics of Speech. CUP, Cambridge.\n-\nOhde, Ralph (1984). Fundamental frequency as an acoustic correlate of stop consonant\nvoicing. Journal of the Acoustical Society of America 75(1), 224-230.\n-\nRepp, Bruno (1979). Relative amplitude of aspiration noise as a cue for syllable-initial\nstop consonants. Language and Speech 22, 947-950.\n-\nShepard, Roger N. (1972). Psychological representation of speech sounds. Edward David\nand Peter Denes (eds.) Human Communication: A Unified View. McGraw-Hill, New\nYork, 67-113.\n-\nSteriade, Donca (1997). Phonetics in phonology: the case of laryngeal neutralization. Ms,\nUCLA.\n-\nStevens, Kenneth N., and Sheila E. Blumstein (1981). The search for invariant acoustic\ncorrelates of phonetic features. Peter D. Eimas and Joanne L. Miller (eds.) Perspectives\non the study of speech. Lawrence Erlbaum, Hillsdale.\n-\nWright, R., Frisch, S., & Pisoni, D. B. (1999). Speech Perception. In J. G. Webster (Ed.),\nWiley Encyclopedia of Electrical and Electronics Engineering, Vol. 20 (pp. 175-195).\nNew York: John Wiley and Sons.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n24.915 / 24.963 Linguistic Phonetics\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 10",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-915-linguistic-phonetics-fall-2015/ce7a2f2591b079ab227e6d49d476245e_MIT24_915F15_lec10.pdf",
      "content": "24.915/24.963 Linguistic Phonetics\nPerception II:\nDistinctiveness and cue strength\n(c) The Journal of the Acoustical Society of America. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\nSource: Redford, Melissa A., and Randy L. Diehl. \"The relative perceptual distinctiveness of initial and final\nconsonants in CVC syllables.\" The Journal of the Acoustical Society of America 106, no. 3 (1999): 1555-1565.\n\nReadings for next week - Speech production:\n- Keating (1990)\n- Browman and Goldstein (1990)\nAssignment:\n- Recording and measurements for affricate voicing\nexperiment.\n- Talk to me about your final project\n- Sorry, no office hours tomorrow (Wed 10/4)\n\nPerceptual distinctiveness in phonology\n- Perceptual distinctiveness plays a central role in\nrecent phonological theory.\n- Related concept of cue strength: stronger cues to a\ncontrast imply that the contrast is more distinct.\n- There is hypothesized to be a general preference for\nmore distinct (less confusable) contrasts:\n- Theory of Adaptive Dispersion - vowel inventories\n- Distribution of retroflex vs. apical alveolar contrasts (1st\nlecture)\n- Distribution of major place contrasts\n\nDistribution of retroflexion contrasts in\nGooniyandi\nSummary:\n- Contrast between retroflex and apical alveolar after vowels\nV_#, V_V, V_C\n- No contrast elsewhere #_, C_\n- This pattern of distribution is common in Australian and\nDravidian languages.\n- Probable universal: If a language contrasts retroflexes and\napical alveolars in contexts with no preceding vowel, then it\nalso contrasts these sounds following vowels.\nWhy?\n\nDistribution of retroflexion contrasts\nOutline explanation (Steriade 1995, 2001 etc):\n- Contrasts preferentially appear in environments where they\nare more distinct perceptually.\n- Apical alveolars are more distinct from retroflexes when\nthey are preceded by a vowel.\n- Therefore some languages only allow the contrast in this\ncontext.\n- The primary cues to the contrast between retroflexes and\napical alveolars are located in the VC transitions\n- lowered F3 and/or F4 before retroflexes\n- Most retroflex stops are retroflexed at closure, but the\ntongue tip moves forward during closure.\n\nThe phonetics and phonology of retroflex\nconsonants\napical alveolar [t]\n\nretroflex [ʈ]\n\nMalayalam\nCourtesy of Ashtu Killimangalam. Used with permission.\n\nNeutralization of major place contrasts\n_V (_L)\n_#\n_(N) _T (_F)\nSpanish\nJapanese\nneutralization\nassimilation\nDiola Fogny\nassimilation\nRussian\nV = vowel; L= glides & liquids; N = nasals, T = stops, F = fricatives\n\nJun (1995), DeLacy (2002), Steriade (2001)\n\nNeutralization of major place contrasts\n- E.g. Spanish nasals\n- Place contrast prevocalically\nmata, nata, 1ata\n\nkama, kana, ka1a\n- Neutralization word-finally - pre-pausally, the only\nnasal is [n] in Castilian, [ŋ] in many other varieties.\nadan 'Adam'\nalbun 'album'\n- Neutralization before obstruents (assimilation)\nkampo'country'\n*kanpo, etc\nmanto 'cloak'\n*mamto, etc\nmaŋko'one-handed'*manko, etc\n\nMajor place neutralization\nDiola Fogny nasals (Sapir 1957)\n- Place contrasts before vowels [m, n, ɲ, ŋ]\n- Contrast word-finally (after a vowel):\n(r)um\n'bite'\nfamfan 'lots'\nbu(r)uN 'road'\n- Neutralization before consonants - nasal must be homorganic with a\nfollowing obstruent of nasal (medial or final)\n- Nasals delete before approximants.\nk gu...mp 'ashes'\nbunt\n'lie'\n\nkaNg 'be furthest away'\nma=O\n'know'\n/ni-gam-gam/\n→\nnigaNgam\n'I judge'\n/ku-bO=-bO=/\n→\nkubOmbO=\n'they sent'\n/na-ti...N-ti...N/\n→\nnati...nti...N\n'they sent'\n\nMajor place neutralization\n-\nPattern 3: E.g. Russian\nanglij 'England'\nmgla\n'fog'\ngbaronu 'the baron'\nkto\n'who\ntkanjja\n'weaving'\n\nNeutralization of major place contrasts\n_V (_L)\n_#\n_(N) _T (_F)\nSpanish\nneutralization\nassimilation\nJapanese\nDiola Fogny\nassimilation\nRussian\nV = vowel; L= glides & liquids; N = nasals, T = stops, F = fricatives\n\nJun (1995), DeLacy (2002), Steriade (2001)\n\nMajor place neutralization\nUnattested language type:\n- Place contrasts / _ V: ma - na\n- Neutralization /V_#: an, *am\n- Contrast / _ C: anta - amta\nAnother unattested language type:\n- Neutralization / _ V: na, *ma\n- Contrast /_C: anta - amta\n- NB specific place contrasts may be permitted finally but not\ninitially, e.g. English velar nasal [æm - æn - æŋ], but [mæ-næ- *ŋæ]\n\nMajor place neutralization\n- Preferred environments for major place contrasts are\ncontexts where the contrasting sounds are more distinct\n(Steriade 1999 etc).\n_V\npa - ka\nma - na\n>\n>\nV_#\nap - ak\nam - an\n>\n>\nV_T\nap}ta - ak}ta amta - anta\n- Evidence?\n\nMeasuring perceptual distinctiveness\n- Perceptual distinctiveness is related to confusability: less\ndistinct sounds are more confusable.\n- One way to measure confusability is via an identification\ntask:\n- Play a number of pre-vocalic consonants [pa, ta, ...] and post-vocalic\nconsonants [ap, at,...] that differ in place of articulation.\n- Ask subjects to label the stimuli (words, orthographic nonce words).\n- Observe rates of confusion (e.g. stimulus [ap] is identified as [at]).\n- Is place confused more often in the post-vocalic context?\n\nRedford & Diehl (1999)\n- Compares the confusability of a variety of consonants\n(including [p,t,k]) in prevocalic and post-vocalic contexts.\n- An identification experiment with natural stimuli.\n- Stimuli: CVC syllables\n- All combinations of C = [p, t, k, f, T, s, S], V = [i, a, u] (7×3×7).\n- Frame sentences 'Say CVC some more', 'Say CVC again'\n- 3 conditions: #CV, VC#C, VC#V\n- Read by two male and two female speakers of American English.\n- Presented in a low level of pink noise (15 dB SNR).\n- Noise is often added to stimuli in studies of confusability in order to\nencourage errors.\n\nAddition of noise\n- Varieties of noise:\n- White noise - flat spectrum\n- Pink noise - spectrum slopes down at 3dB/octave.\n- 'Cocktail party' noise, a.k.a. multi-talker babble\nwhite\nSound pressure level (dB/Hz)\n-20\npink\nSound pressure level (dB/Hz)\n-20\nFrequency (Hz)\nFrequency (Hz)\n- Level specified as Signal-to-Noise Ratio - difference between average\nintensity of speech and noise in dB.\n- Examples have 0dB SNR, Redford & Diehl used 15 dB SNR.\n\nSubjects & Procedure\n- 7 female, 7 male, native speakers of American English\n- Stimuli presented over headphones.\n- Subjects heard each stimulus once in random order at 3.5 s\nintervals.\n- Subjects asked to record the target words in orthography.\n\nResults\n- Confusion\nmatrices\n- #CV\n- VC#C\n(c) The Journal of the Acoustical Society of America. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\nSource: Redford, Melissa A., and Randy L. Diehl. \"The relative perceptual distinctiveness of initial and final\nconsonants in CVC syllables.\" The Journal of the Acoustical Society of America 106, no. 3 (1999): 1555-1565.\n\nResults\n- error rate - percentage of erroneous identifications.\n- only manner and place errors were counted, not voicing\nerrors.\n(c) The Journal of the Acoustical Society of America. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\nSource: Redford, Melissa A., and Randy L. Diehl. \"The relative perceptual distinctiveness of initial and final\nconsonants in CVC syllables.\" The Journal of the Acoustical Society of America 106, no. 3 (1999): 1555-1565.\n\nRedford & Diehl (1999)\n- Obstruent contrasts in place and manner are more distinct\nbefore vowels than before consonants.\n(c) The Journal of the Acoustical Society of America. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\nSource: Redford, Melissa A., and Randy L. Diehl. \"The relative perceptual distinctiveness of initial and final\nconsonants in CVC syllables.\" The Journal of the Acoustical Society of America 106, no. 3 (1999): 1555-1565.\n\nMajor place neutralization\n- What explains the differences in distinctiveness of place\ncontrasts across these contexts?\n_V\npa - ka\nburst, release transitions\n>\nV_#\nap -ak\nburst, closure transitions\n>\nV_T\nap}ta - ak}ta closure transitions\n- More cues in V_# compared to V_T (for stops)\n- stronger cues _V compared to V_#\n- Release transitions provide stronger cues than closure\ntransitions (Fujimura et al 1978)\n\nCue strength\n- Measuring cue strength\n- vary multiple cues, model contribution of each cue to\nperceptual judgments (cf. VOT and F0)\n- conflicting cue experiments: construct stimuli where\ndifferent properties cue different percepts (e.g. voiced,\nvoiceless).\n- The stronger cue is the one that dominates in\nperception.\n- Fujimura et al (1978) employed the 'conflicting cue'\nmethodology to investigate the relative strength of cues to\nstop place in VCV.\n- Closure transitions vs. Release burst+release transitions\n- E.g. cross-spliced [ab-] from [aba] and [-da] from [ada]\n- Do listeners perceive [aba] or [ada]? (Example)\n- Stimuli created from Japanese utterances.\n\nConflicting cue experiments - Fujimura et al\n- Results: Release cues dominate for English and Japanese\nlisteners\n- Is this simply because burst+transitions > transitions?\n- No: the same result was obtained when the stimuli were\nplayed backwards\nFigure removed due to copyright restrictions.\nSource: Tables 2 & 3, Fujimura, Osamu, Marian\nJ. Macchi, and Lynn A. Streeter. \"Perception of\nstop consonants with conflicting transitional cues:\nA cross-linguistic study.\" Language and speech 21,\nno. 4 (1978): 337-346.\nFigure removed due to copyright restrictions.\nSource: Tables 2 & 3, Fujimura, Osamu, Marian\nJ. Macchi, and Lynn A. Streeter. \"Perception of\nstop consonants with conflicting transitional cues:\nA cross-linguistic study.\" Language and speech 21,\nno. 4 (1978): 337-346.\n\nMajor place neutralization\n- What explains the differences in distinctiveness of place\ncontrasts across these contexts?\n_V\npa - ka\nburst, release transitions\n>\nV_#\nap - ak\nburst, closure transitions\n>\nV_T\nap}ta - ak}ta closure transitions\n- burst + release transitions > burst + closure transitions\nbecause release transitions provide stronger cues than\nclosure transitions.\n- Why is pre-obstruent context worse than word-final position\nfor nasal place contrasts?\n- Overlap with the following consonant?\n\nPerceptual space\n- Identification experiments based on synthetic/edited speech\ncan establish the perceptual significance of an acoustic\nproperty\n- But they do not reveal the nature of perceptual\nrepresentations\n- The dimensions of the perceptual space\n- E.g. VOT is a cue to stop voicing, but is there a perceptual\ndimension that corresponds directly to VOT, or just\nsomething that correlates with VOT?\n- E.g. integrated intensity of aspiration noise (cf. Repp 1979)\n- Multi-Dimensional Scaling is a method for investigating\nperceptual space directly.\n- But it does not reveal the mapping from acoustic signal\nto perceptual space.\n\nPerceptual space - vowel quality\n- The main dimensions of the perceptual space of vowel\nquality are related to the frequencies of the first two or three\nformants.\n- Acoustic analysis shows that contrasting vowel qualities\ndiffer in formant frequencies. Graph with data points (no line connecting them) in general shape of a V.\n26Graph with data points (no line connecting them) in general shape of a V.Graph with data points (no line connecting them) in general shape of a V.Graph with data points (no line connecting them) in general shape of a V.Graph with data points (no line connecting them) in general shape of a V.Graph with data points (no line connecting them) in general shape of a V.Graph with data points (no line connecting them) in general shape of a V.\ni\nu\nI\nε\nΩ\nc\nϪ\næ\nImage by MIT OCW.\nAdapted from Peter Ladefoged. A Course in Phonetics. 5th ed. Berlin, Germany: Heinle, 2005.\nISBN: 9781413006889. Available at: http://www.phonetics.ucla.edu/course/contents.html.\n\nPerceptual space - vowel quality\n- Perceived vowel quality is affected by formant frequencies.\n- A wide range of vowel qualities can be synthesized with two\nformants (Delattre, Liberman, Cooper, and Gerstman 1952).\n- Multi-Dimensional Scaling (MDS) analyses of vowel\nconfusions and similarity judgements yield spaces in which\nthe most significant dimensions correspond to F1 and F2.\n\nMulti-Dimensional Scaling\n- Techniques for constructing perceptual spaces from\nconfusion or similarity data (Shepard 1957, 1972).\n\nMulti-Dimensional Scaling\n- Input: a confusion matrix\n- e.g. Peterson & Barney 1952\nperceived\ni\nj\nintended i\npii\npij\nj\npji\npjj\ni\nI\nE\nœ\nA\nO\nU\nu\nø\n(r)\ni\nI\nE\nœ\nA\nO\nU\nu\nø\n(r)\nperceived\nintended\n\nMulti-Dimensional Scaling\n- Input: a confusion matrix\n- e.g. Peterson & Barney 1952\n- convert to probabilities\nperceived\nintended\nperceived\ni\nj\nintended i\npii\npij\nj\npji\npjj\ni\nI\nE\nœ\nA\nO\nU\nu\nø\n(r)\ni\n0.9987 0.0004 0.0006 0.0000 0.0000 0.0003 0.0000 0.0000 0.0000 0.0000\nI\n0.0006 0.9290 0.0675 0.0002 0.0001 0.0001 0.0000 0.0000 0.0000 0.0025\nE\n0.0000 0.0250 0.8771 0.0923 0.0001 0.0003 0.0000 0.0000 0.0002 0.0050\nœ\n0.0000 0.0001 0.0292 0.9651 0.0002 0.0002 0.0000 0.0000 0.0015 0.0038\nA\n0.0000 0.0001 0.0000 0.0018 0.8699 0.0986 0.0067 0.0000 0.0222 0.0007\nO\n0.0000 0.0000 0.0001 0.0002 0.0574 0.9275 0.0069 0.0005 0.0060 0.0014\nU\n0.0000 0.0000 0.0001 0.0001 0.0016 0.0050 0.9655 0.0093 0.0166 0.0018\nu\n0.0000 0.0000 0.0001 0.0000 0.0002 0.0000 0.0076 0.9919 0.0000 0.0002\nø\n0.0000 0.0001 0.0001 0.0008 0.0525 0.0124 0.0100 0.0000 0.9221 0.0020\n(r)\n0.0000 0.0000 0.0022 0.0006 0.0002 0.0003 0.0000 0.0000 0.0002 0.9965\n\nMulti-Dimensional Scaling\n- Input: a confusion matrix\n- e.g. Peterson & Barney 1952\n- convert to probabilities\n- distances are symmetrical (dij = dji) by definition.\n- Confusion matrices are usually not symmetrical.\n- Explanation is disputed. One possible source is bias.\n- Convert confusion probabilities to a symmetrical measure of\nsimilarity, sij.\n- sii = 1\nperceived\ni\nj\np\nSij =\nij + pji\nintended i\npii\nij\n\np\npii + pjj\nj\npji\njj\n\np\n\nMulti-Dimensional Scaling\n- Symmetrical similarity matrix\n- Similarity is related to distance in psychological space by an\nexponential decay function, where Dij is the perceptual\ndistance between i and j:\n-bDij\nSij = ae\n+ c\n- based on observation, derivation attempted in Shepard 19??.\ni\nI\nE\nœ\nA\nO\nU\nu\nø\n(r)\ni\n1.0000 0.0005 0.0003 0.0000 0.0000 0.0002 0.0000 0.0000 0.0000 0.0000\nI\n1.0000 0.0512 0.0002 0.0001 0.0001 0.0000 0.0000 0.0001 0.0013\nE\n1.0000 0.0660 0.0001 0.0002 0.0001 0.0001 0.0002 0.0038\nœ\n1.0000 0.0011 0.0002 0.0001 0.0000 0.0012 0.0022\nA\n1.0000 0.0868 0.0045 0.0001 0.0417 0.0005\nO\n1.0000 0.0063 0.0003 0.0099 0.0009\nU\n1.0000 0.0086 0.0141 0.0009\nu\n1.0000 0.0000 0.0001\nø\n1.0000 0.0012\n(r)\n1.0000\n\nMulti-Dimensional Scaling\n- Symmetrical similarity matrix\n- Similarity is related to distance in psychological space by an\nexponential decay function, where Dij is the perceptual\ndistance between i and j:\n-bDij\nSij = ae\n+ c\n- based on observation, derivation attempted in Shepard 19??.\n- MDS finds the best configuration of points for stimuli and\nthe values of parameters a, b, c that provide the best fit to the\nsimilarity data (Sij).\n- Solutions are for a space with a specified number of\ndimensions.\n- Usually select dimensions based on how goodness of fit increases as\nnumber of dimensions is increased.\n\nMDS analysis of vowel confusions\n- Shepard (1972) presents a 3-dimensional MDS analysis of\nPeterson & Barney's vowel confusion data.\n- MDS is based on confusions alone -\ncan be difficult to relate derived space\nto physical stimulus dimensions.\n- With vowel space, there are two nearly\northogonal dimensions that correlate\nwell with F1, F2.\n- dimension that best correlates with\nF3 is not orthogonal - close to F2.\n- relation between dimensions of\nperceptual space and Hz formant\nfrequencies are non-linear.\nFigure removed due to copyright restrictions.\nSource: Shepard, Roger N. \"Psychological\nrepresentation of speech sounds.\" Human\ncommunication: A unified view (1972): 67-113.\n\nReferences\n-\nDelattre, Pierre C., Alvin M. Liberman, Franklin S. Cooper, and Louis J. Gerstman\n(1952). An experimental study of the acoustic determinants of vowel color: observations\non one- and two-formant vowels synthesized from spectrographic patterns. Word 8,\n195-210.\n-\nHaggard, Mark P., Stephen Ambler, and Mo Callow (1970). Pitch as a voicing cue.\nJournal of the Acoustical Society of America 47, 613-17.\n-\nJun, Jongho (1995). Perceptual and Articulatory Factors in Place Assimilation: An\nOptimality-Theoretic Approach. PhD dissertation, UCLA.\n-\nKawasaki, Haruko (1982). An acoustical basis for universal constraints on sound\nsequences. Ph.D. dissertation, University of California, Berkeley.\n-\nKingston, John, and Randy L. Diehl (1995). Intermediate properties in the perception of\ndistinctive feature values. Bruce Connell and Amalia Arvaniti (eds) Papers in Laboratory\nPhonology IV , Cambridge University Press, Cambridge.\n-\nLindblom, Bjorn, and Michael Studdert-Kennedy (1967). On the role of formant\ntransitions in vowel recognition. Journal of the Acoustical Society of America 42,\n830-843.\n-\nLisker, Leigh (1957). Closure duration and the intervocalic voiced-voiceless distinctions\nin English. Language 33, 42-49.\n-\nLisker, Leigh (1975). Is it VOT or a first formant transition detector?. Journal of the\nAcoustical Society of America 57, 1547-51.\n\nReferences\n-\nLisker, Leigh (1986). Voicing in English: A catalogue of acoustic features signaling /b/ versus /p/ in\ntrochees. Language and Speech 29.3-11.\n-\nMann, V. A., & Repp, B. H. (1980).\nInfluence of vocalic context on the perception of [ ]-s] distinction: I. Temporal\nfactors. Perception & Psychophysics, 28, 213-228.\n-\nMassaro, Dominic W., and Michael M. Cohen (1983). Consonant/vowel ratios: An improbable cue in\nspeech. Perception and Psychophysics 33, 501-5.\n-\nOhala, J.J. (1990) The phonetics and phonology of aspects of assimilation. M. Beckman and J.\nKingston (eds) Papers in Laboratory Phonology I: Between the Grammar and Physics of Speech.\nCUP, Cambridge.\n-\nPlomp, Reinier (1975). Auditory analysis and timbre perception. Gunnar Fant and Michel Tatham\n(eds.) Auditory Analysis and Perception of Speech. Academic Press, New York, 7-22.\n-\nRepp, Bruno (1979). Relative amplitude of aspiration noise as a cue for syllable-initial stop\nconsonants. Language and Speech 22, 947-950.\n-\nShepard, Roger N. (1972). Psychological representation of speech sounds. Edward David and Peter\nDenes (eds.) Human Communication: A Unified View. McGraw-Hill, New York, 67-113.\n-\nSteriade, Donca (1997). Phonetics in phonology: the case of laryngeal neutralization. Ms, UCLA.\n-\nStevens, Kenneth N., and Sheila E. Blumstein (1981). The search for invariant acoustic correlates of\nphonetic features. Peter D. Eimas and Joanne L. Miller (eds.) Perspectives on the study of speech.\nLawrence Erlbaum, Hillsdale.\n-\nWright, R., Frisch, S., & Pisoni, D. B. (1999). Speech Perception. In J. G. Webster (Ed.), Wiley\nEncyclopedia of Electrical and Electronics Engineering, Vol. 20 (pp. 175-195). New York: John\nWiley and Sons.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n24.915 / 24.963 Linguistic Phonetics\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    }
  ]
}