{
  "course_name": "Communications and Information Policy",
  "course_description": "This course provides an introduction to the technology and policy context of public communications networks, through critical discussion of current issues in communications policy and their historical roots. The course focuses on underlying rationales and models for government involvement and the complex dynamics introduced by co-evolving technologies, industry structure, and public policy objectives. Cases drawn from cellular, fixed-line, and Internet applications include evolution of spectrum policy and current proposals for reform; the migration to broadband and implications for universal service policies; and property rights associated with digital content. The course lays a foundation for thesis research in this domain.",
  "topics": [
    "Engineering",
    "Electrical Engineering",
    "Telecommunications",
    "Social Science",
    "Communication",
    "Public Administration",
    "Science and Technology Policy",
    "Engineering",
    "Electrical Engineering",
    "Telecommunications",
    "Social Science",
    "Communication",
    "Public Administration",
    "Science and Technology Policy"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nSummary\n\nProductive life is ever more difficult without access to advanced telecommunications networks, both wireless and wired, and the information and services available through the Internet. As networking technologies pervade our lives, they engage public policy concerns ever more directly. Good engineering design increasingly must anticipate both public policy tussles and business strategy imperatives. At the same time, technical innovations are reshaping the possibility space for implementing effective public policies across many domains, including public safety, consumer privacy, media diversity, and economic development.\n\nThis team-taught, multi-disciplinary elective course focuses on the interplay of technology, policy, economics, and business strategy in public telecommunications and Internet networks. The course aims to equip students with techniques useful for exploring the social and economic impacts of design decisions and, conversely, for designing engineering systems consistent with social and economic requirements. It provides an essential foundation for student research (thesis or otherwise) in this domain.\n\nStudents will work in teams on design challenges drawn from pressing debates at the frontiers of communications networking and information policy. Class lectures, discussions and readings will develop the background necessary to support knowledgeable exploration of selected design challenges, as well as provide overviews of additional topics of interest.\n\nPrerequisites\n\nESD.10 (Introduction to Technology and Policy), or permission of instructor. Students who have not taken ESD.10 are encouraged to familiarize themselves with Stone, Deborah.\nPolicy Paradox: The Art of Political Decision Making\n. New York, NY: W.W. Norton, 2001. ISBN: 0393976254.\n\nTextbook\n\nNuechterlein, J., and P. Weiser.\nDigital Crossroads: American Telecommunications Policy in the Internet Age\n. Cambridge, MA: MIT Press, 2005. ISBN: 0262140918.\n\nGrading\n\nEvaluation will be based on following:\n\nACTIVITIES\n\nPERCENTAGES\n\nClass Participation\n\n20%\n\nA Short (5 page) Mid-term Paper\n\n20%\n\nA Final Team Project (comprised of a Proposal, Presentation, and Final (20 page) Paper)\n\n60%\n\nAssignments\n\nReadings: Readings are an integral part of this course. Students who indicate that they are prepared will be called on in class to explain the main ideas from assigned readings. Quality of explanation will be factored into the evaluation of class participation.\n\nMid-term Paper: The class will be given a written piece of policy advocacy on themes relevant to the course. Students will then be expected to write a paper that analyzes the piece's arguments and rhetorical techniques.\n\nFinal Project: Students will work in teams to develop a final project, based on their selection of one design challenge from several options to be provided by the instructors.\n\nCourse Layout\n\nModule 1: Technology (Clark)\n\nAn overview of technical topics underpinning the course, including the Internet's architecture, application design, and wired and wireless networking technologies.\n\nModule 2: Policy: Rationale and Methods (Gillett and Lehr)\n\nWhy have regulators been so involved in telecommunications?\n\nOverview of methods of technical and policy analysis applicable to the final project. Discussion of problem definition and issue framing for topics with interwoven technical, social, economic, and political dimensions.\n\nModule 3: Deep Dives (All)\n\nThis section of the course will provide the necessary background to support the topics offered as design challenges. It is broken into four submodules:\n\nModule 3a: Spectrum Policy (Lehr)\n\nModule 3b: Copyright and other Information-related Policies (Field)\n\nModule 3c: Interconnection of Internet Service Providers (Lehr)\n\nModule 3d: Broadband Access (Gillett and Guests)\n\nModule 4: Additional Lectures\n\nWhile students are preparing their final projects, additional lecturers will be invited to address the class on additional topics of interest.\n\nInternet Governance (Guest Scott Bradner, Harvard University)\n\nOpen Access, or Making Money Openly (Clark)\n\nOne Laptop per Child (aka $100 laptop); the Internet and Developing Countries (Michail Bletsas, MIT Media Lab)\n\nModule 5: Student Presentations\n\nClassroom presentation and discussion of final projects.",
  "files": [
    {
      "category": "Resource",
      "title": "midterm_question.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-68j-communications-and-information-policy-spring-2006/350487c08b5345e06a258b557f5db2a8_midterm_question.pdf",
      "content": "6.978J / ESD.68J Midterm Paper Assignment: Deconstructing a Policy Document\nHanded out: February 28, 2006\nDue: March 23, 2006\nExpected length: Maximum 5 pages\nIn 2004, in a proceeding that remains ongoing (i.e., the FCC has not yet issued an order), the\nFCC proposed allowing unlicensed radios to use unused broadcast TV channels - so-called\n\"white space\" spectrum. The FCC's Notice of Proposed Rulemaking (NPRM) that sets forth\nwhat the FCC is proposing to do is in docket ET 04-186. (FCC orders related to this proceeding\nare available at: http://wireless.fcc.gov/spectrum/proceeding_details.htm?proid=369.)\nIn the introduction to the NPRM, the FCC argues as follows:\n1. By this Notice, we propose to allow unlicensed radio transmitters to\noperate in the broadcast television spectrum at locations where that spectrum is not\nbeing used. We believe that the proposals set forth herein would provide for more\nefficient and effective use of the TV spectrum and would have significant benefits\nfor the public by allowing the development of new and innovative types of\nunlicensed broadband devices and services for businesses and consumers. Further,\nnew unlicensed broadband operations may provide synergy with traditional\nbroadcast operations and offer broadcasters the opportunity to provide new services.\nIn addition, because transmissions in the TV band are subject to less propagation\nattenuation than transmissions in the spectrum where existing broadband unlicensed\noperations are permitted, allowing unlicensed operation in the TV bands could\nbenefit wireless internet service providers (WISPs) by improving the service range\nof their existing operations, thereby allowing WISPs to reach new customers.\n2. We recognize that broadcasters are currently undergoing a transition to\ndigital operation, during which channel availability is likely to change more\nfrequently. Our approach will appropriately account for these changes. To ensure\nthat no harmful interference to authorized users of the spectrum will occur, we\npropose to define when a TV channel is \"unused\" and to require these unlicensed\ndevices comply with significant restrictions and technical protections. Unlicensed\ndevices would be required to incorporate \"smart radio\" features to identify the\nunused TV channels in the area where they are located. We intend to consider\nseveral alternative methods for identifying the unused TV channels, including\napproaches that would: 1) allow existing television and/or radio stations to transmit\ninformation on TV channel availability directly to an unlicensed device; 2) employ\ngeo-location technologies such as the Global Positioning Satellite (GPS) system; or\n3) employ spectrum sensing techniques that would determine if the signals of\nauthorized TV stations are present in an area.\nPage 1 of 2\n\nThis initiative, which was strongly supported by former FCC Chairman Michael Powell, has\nelicited strong reactions from industry participants. The 394 comments filed electronically to\ndate in association with this docket are available at http://gullfoss2.fcc.gov/cgi-\nbin/websql/prod/ecfs/comsrch_v2.hts?ws_mode=retrieve_list&id_proceeding=04-\n186&start=1&end=394&first_time=N.\nWe have selected comments from three parties as being reasonably representative of different\nindustry positions: the National Association of Broadcasters,1 the Consumer Electronics\nAssociation, and the Wi-Fi Alliance. Your assignment is to (1) review these comments and\n(2) write a paper of no more than 5 pages that compares and contrasts these comments, giving\nspecific consideration to the following questions:\n1. What position does the stakeholder take and why?\n2. What approach does the stakeholder take to evaluate the merits of the technical design\nalternatives (the \"methods\" in paragraph 2 above) that the FCC proposes for determining\nwhat spectrum is unused?\n3. Conclude by reflecting briefly on the implications of your answers to questions 1 & 2 for\nthe development and selection of technical design approaches within a politically\ncontested context.\n1 In addition to the comments provided, two attachments to the NAB submission are available at the FCC website,\nbut are not required reading.\nPage 2 of 2"
    },
    {
      "category": "Resource",
      "title": "team_interconnec.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-68j-communications-and-information-policy-spring-2006/600fc67baceb5bd5bd69b5742331c120_team_interconnec.pdf",
      "content": "End-to-end Quality of Service\nRobert Rudin, Chaki Ng,\nClifford Kahn\n5/16/2006\n\nConclusions\nMajor barrier to service-level\ninterconnection is coordination\nNeed a coordinator - an overlay\nNetwork Neutrality: justified\nGovernment could lead the way\n\nThree Levels of\nInterconnection\n\nStructure of Talk\nNarrowing the problem: video\nconferencing\nThe stakes\nHow stakeholders may solve the\nproblem\nGovernment's role\n\nHigh Quality Video Conferencing\nMay Help Drive QoS\n\nWidespread VC foreseeable\n\nNeeds considerable bandwidth\n{\nCould press existing network capacity\n\nHQVC has a money flow that helps\nanswer \"Who pays for the QoS\"?\n\nQoS = Lack of jitter, lack of loss, low\nlatency\n\nNon-Internet Video\nConferencing\nMulti-billion dollar industry\nHard-wired conference rooms\nPrivate IP network or ISDN\nDependable; good video quality\nMonthly costs are US$ thousands\nBut can't conference with everyone\nyou want\n\nInternet-Based Video\nConferencing\nWebEx, Skype, NetMeeting\nConnect from anywhere\n{ Another company, a laptop on the road\nMuch cheaper\nBut undependable\n\nNeeded: Best of Both\nWidely available\n{ Over the Internet\nHigh-quality & dependable\n{ Quality of HDTV\n\nInterconnection Is Lacking\nThere is no good QoS across ISP\nboundaries\nIt is not a technical problem\nIt is a problem of coordination of ISPs\n\nStakeholders' Interests\n\nCustomer\n{\nCannot sacrifice reliability, security\n\nAccess ISP\n{\nOffering profitable HQVC-related services\n\nVertical integration\n{\nOffering HQVC to many points\n\nBackbone ISP\n{\nProfiting from carrying high-QoS traffic\n\nStakeholders' Interests (2)\nApplication Provider\n{ Profit\n{ Having QoS among many points\nRegulator\n{ Avoiding inefficiencies we will discuss\n\nPossible Scenarios\n\nISPs self-organize\n\nApp providers deal individually with\nISPs\n\nOverlay coordinates\n\nISPs self-organize\nCurrently unorganized\n{ No industry-wide\nagreement on QoS\n{ No standards /\ncoordination initiatives\n{ Money is left on table\nNeed lots of\narrangements\n{ Each ISP negotiates\nwith all/most of its\nneighbors\nISP\nISP\nISP\nISP\nISP\nISP\nBusiness Arrangements\n\nISPs self-organize (cont'd)\nComplex task to coordinate\n{ Unclear compensation schemes\nPay by quantity? Pay by congestion?\n{ Conflicting internal policies to optimize\nEnd-to-end QoS unlikely\n{ More than agreeing to a standard -\nmanage complex money flows\n{ Possible fragmentation\n\nApp Providers Deal with ISPs\nISP\nISP\nISP\nISP\nISP\nAP\nAP\nAP\nHigh incentives\n{ \"Face\" to the customers\nTakes blame if low quality\nNo need to contact ISP for\nseparate QoS\n{ Possible strategic edge\nBetter service than\ncompetition\nCo-market \"bundles\" with\nselected access ISPs\n\nApp Providers: Packet Flow\n\nApp Providers: Money Flow\n\nApp Providers: Issues\nStill very high costs to coordinate\n{ Critical to partner with large ISPs\nApp providers want exclusivity\n{ Fragmentation possible\nSmall app providers may be left out\n{ High costs, no bulk discounts by ISPs\nDoubtful many app providers can\ncoordinate a majority of ISPs\n\nReality Check\nGetting ISPs to self-organize is hard\nGetting App Providers to each organize\nwith every ISP is hard\nPotential role for an overlay as a\ncoordinator\n\nOverlay Drives Coordination\nTrusted 3rd party\nOverlay manages:\n{ money flow\n{ traffic through\npreferred ISPs\nWho pays whom:\n{ Users pay APs\n{ APs pay overlay\n{ Overlay pays\nISPs\nISP\nAP\nOverlay\nAP\nAP\nISP\nISP\nISP\nISP Business Arrangements\n\nCase Study - Internap\nLease bandwidth from backbone ISPs\nProvide very high dependability by\navoiding ISPs with congestion\n\nInternap Congestion Routing\nBut Internap doesn't offer last-mile QoS\n\nOverlay Benefits\nFor ISPs:\n{ Can remain a \"cloud\" to other ISPs\n{ Coordinate with one overlay\nLower cost than self-organizing\nFor App Providers:\n{ Large/small providers can get SLA\n{ Deal only with overlay - no ISP\nFor consumers:\n{ Same way to sign up / get service\n{ Extra fees, if any, paid only to app provider\n{ Widely availability - can reach more users\n\nSummary of Scenarios\nISPs\nApp Providers\nOverlay\n# ISPs * # Aps # ISPs + # Aps\nFragmentation Medium\nHigh\nLow\nHigh\nMedium\nMedium\nHigh\nLow\nHigh\n# of\nCoordinations\n# ISPs * #\nNeighbors\nTrade Secret\nSensitivity\nScalability for\nNew Aps\n\nOverlay: A Natural Monopoly?\nHigh sunk cost: putting a system of\ncoordination in place\nLow marginal cost: operating, adding\nnew ISPs\nNetwork externalities; hard to start up\nBut after it is done once, others may\nlearn from example\n\nNetwork Neutrality\nQoS is new revenue opportunity for\nISPs\nIf monopoly, overlay should be neutral\nfor QoS traffic\n{ More enforceable\n\nNetwork Neutrality (cont'd)\nNew problem: pro-QoS discrimination\n{ ISPs degrade non-QoS traffic on purpose\n{ Requires regulation?\n\nGovernment Initiates Overlay\nEstablish functional guidelines for\noverlay\nOversee development of overlay\nProvide seed money\n\nConclusions\nMajor barrier to service-level\ninterconnection is coordination\nNeed a coordinator - an overlay\nNetwork Neutrality: justified\nGovernment could lead the way\n\nOverlay Definition\n(Clark et. al. 2005)\nAn Overlay is a set of servers deployed\nacross the Internet that:\na) provide some sort of infrastructure to one (or ideally\nseveral) applications,\nb) in some way take responsibility for the forwarding and\nhandling of application data in ways that are different from\nor in competition with what is part of the basic Internet,\nc) are operated in an organized and coherent way by third\nparties (which may include collections of end-users) to\nprovide a well-understood service that is infrastructure-\nlike, but,\nd) are not thought of as part of the basic Internet."
    },
    {
      "category": "Resource",
      "title": "team_neutrality.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-68j-communications-and-information-policy-spring-2006/0171f89d86d7369830836fa2a0594551_team_neutrality.pdf",
      "content": "Network Neutrality\nNetwork Neutrality\nand Harmful Discrimination\nand Harmful Discrimination\nRichard Hansen, Elisabeth Maida, Gladys Priso\nMIT 6.978J/ESD.68J\n2006-05-11\n\nNetwork Neutrality is a no\nNetwork Neutrality is a no--brainer,\nbrainer,\nright?\nright?\n-\n\"This is that rare bird, a black and white issue, with large companies on\none side and the vast majority of America on the other. Politicians will only\noppose network neutrality so long as it stays in the darkest corners of\ndebate.\"\nEvan Derkacz, http://alternet.org/blogs/peek/35728/\n-\n\"Predictably, the careerist politicians on the House Energy and Commerce\nCommittee rolled right over in their frantic desire to do the telecoms'\nbidding,\" said Craig Fields, director of Internet operations for Gun Owners\nof America.\n\"House Ignores Public, Sells Out the Internet\" press release on savetheinternet.com\n-\n\"We cannot allow telecommunications companies to hijack the Internet.\nAfter all, the beauty of the Internet is its open architecture.\"\nRep. Jay Inslee D-WA\n-\n\"But now, the cable and telco giants want to eliminate this open road in\nfavor of a tollway that protects their status quo while stifling innovation.\nIf they get their way, they'll shut down the free flow of information and\ndictate how you use the Internet forever.\"\nFree Press, http://www.freepress.net/netfreedom/=threat\n\nAgenda\nAgenda\n- Introduction and background\n- Brief history of network neutrality\n- The problem with codifying network neutrality\n- Our proposal\n\nThe problem\nThe problem\n- Can \"harmful discrimination\" be defined?\n- Can it be identified?\n- Is it OK that we accept current methods of\ndiscrimination?\n- Can network operators use current technical\nmechanisms to discriminate in other ways that\nare \"better\" or \"worse\"?\n- Is it possible to ensure network neutrality\nwithout heavy-duty Title II-esque\nregulation?\n\nSummary of conclusions\nSummary of conclusions\n-\nDifficult to distinguish between harmful and acceptable\ntypes of discrimination\n- Technological mechanisms and business policies can be used\nfor good or bad\n-\nHard to enforce good behavior\n- Almost any problem can be justified\n-\nHeavy regulation based on discrimination will likely fail to\nguarantee network neutrality\n- Operators will still get away with doing bad things\n- Operators will be limited in which good things they can do\n-\nThe best policy option (discussed in detail later):\n- go easy on legislation and regulation (for now)\n- credible threat of heavy regulation\n- watch network operators closely\n\nAgenda\nAgenda\n- Introduction and background\n- Brief history of network neutrality\n- The problem with codifying network neutrality\n- Our proposal\n\nThe Computer Inquiries and the\nThe Computer Inquiries and the\nCommunications Act of 1996\nCommunications Act of 1996\n- FCC began examining the relationship between communications and\ncomputer processing in the 1960s\n- Common carriers were offering services that were competitive with\nthose offered by non-regulated entities\n- Non-regulated entities were dependent on the common carriers\n- How should computers and data processing be handled by the\nCommission?\n- Tried to establish distinctions based on the market in which the\ntechnology was used\n1966: Computer I\n\"Communications\": regulated\n\"Data processing\": unregulated\n\"Hybrids\": case-by-case\n1976: Computer II\n\"Basic services\": Title II\n\"Enhanced services\": Title I\n1996: Communications Act\n\"Telecommunications service\": Title II\n\"Information service\": Title I\n\nClassifying Broadband Access\nClassifying Broadband Access\nProviders\nProviders\n-\nComputer II common carrier obligation did not apply to cable\nmodem service providers\n-\nNCTA v. Brand X (June 2005): Supreme Court upheld FCC's\nclassification of cable modem service as an \"information service\"\n-\nWireline Broadband Order (August 2005): FCC declines to impose\n\"any Computer Inquiry requirements on facilities-based carriers in\ntheir provision of wireline broadband Internet access service\"\nBroadband Internet access providers are no longer\nsubject to Title II and common carriage obligations.\n\nStakeholders\nStakeholders'' Concerns\nConcerns\n- Content and application providers\n- Academic community and advocacy groups\n- Network backbone\nproviders\n- Academic community\nNo legislation required\nLegislation required\n\nDefining Network Neutrality\nDefining Network Neutrality\n- Confusion between the end and the means\n- \"A principle of network operational architecture where the\nnetwork is operated under the three principles of neutrality: non-\ndiscrimination, interconnection, and access\"\n- Wu identifies multiple means to achieve this objective\n- Open access (structural remedy)\n- Network neutrality legislation (non-discrimination regime)\n- Is network neutrality legislation required?\n- Economic arguments (Farrell and Weiser, Van Schewick, Owens)\n- Do broadband providers have the incentive to discriminate\nagainst higher layer services?\n- How competitive is the market?\n- Should network operators be allowed to discriminate?\n- Can network neutrality be codified?\n\nAgenda\nAgenda\n- Introduction and background\n- Brief history of net neutrality\n- The problem with codifying network neutrality\n- Our proposal\n\nThe Internet is not neutral today\nThe Internet is not neutral today\n-\nTechnical limitations of\nusage\n- Asymmetric bandwidth\n- Real time applications\n- Locality makes a\ndifference (cf. Akamai)\n-\nContractual limitations of\nusage\n- No operating a server\n- No home networking\n- No commercial use\n- No overuse of bandwidth\n- No resale of bandwidth\nThe SavetheInternet.com\nCoalition\n'From its beginnings, the\nInternet has leveled the\nplaying field for all comers.\nEveryday people can have\ntheir voices heard by\nthousands, even millions\nof people.'\n\nIs it possible to classify discrimination?\nIs it possible to classify discrimination?\n\nDifficult to distinguish harmful\nDifficult to distinguish harmful\ndiscrimination from acceptable\ndiscrimination from acceptable\n- Technological mechanisms can be used for good\nor bad\n- Examples:\n- Prioritizing real-time applications\n- Collocation servers\n- Blocking port 25 (SMTP) in the name of spam\n- Peering with certain parties\n- Business policies may or may not be based on\nunderlying costs\n- Examples:\n- No servers allowed\n- No P2P allowed\n\nHard to enforce good behavior\nHard to enforce good behavior\n-\nProblems can have multiple causes\n- Example with H.R. 5273: Markey's Network Neutrality Act of 2006,\n4(a)(2)(A):\n\"Each broadband network provider has the duty to not block, impair,\ndegrade, discriminate against, or interfere with the ability of any\nperson to utilize their broadband service to access, use, send, receive,\nor offer lawful content, applications, or services over broadband\nnetworks, including the Internet\"\n- High jitter: Artificially introduced, or due to unavoidable congestion?\n- Certain web sites are slow: Did the ISP maliciously choose to delay the\nupgrade of a certain link, or is the upgrade currently impractical?\n- Slow upload speeds: Is the ISP trying to prevent users from publishing\ncontent that competes with their own, or is it technically difficult to provide\nhigh upload speeds to home users?\n-\nAlmost every problem can be justified by a legitimate\ntechnological excuse\n\nPolicy based on discrimination will not\nPolicy based on discrimination will not\nguarantee network neutrality\nguarantee network neutrality\n-\nOperators will still get away with doing bad things\n- Blame problems on finite resources\n- Blame problems on \"that's the way the Internet works\"\n-\nOperators will be limited in which good things they can do\n- Not allowed to take advantage of the network they built\n- e.g., no exclusive ability to place servers close to users\n- Not allowed to cater the network to a certain class of users (to\ndifferentiate from competitors)\n- Operators may be forced to devote attention to addressing\npetty complaints of discrimination at the expense of overall\nnetwork innovation\n- Environment of \"not allowed unless specifically permitted\"\ninstead of \"permitted unless specifically not allowed\"\n\nAgenda\nAgenda\n- Introduction and background\n- Brief history of net neutrality\n- The problem with codifying network neutrality\n- Our proposal\n\n- Go easy on legislation and regulation\n- Threaten heavy regulation\n- Watch network operators closely\nOur proposal (1):\nOur proposal (1):\n- Go easy on legislation and regulation (for now)\n- Leverage existing antitrust and fraud laws\n- Give the FCC limited authority to enforce general\nnetwork neutrality principles\n- FCC's Broadband Policy Statement is a good start (more\nabout this in a minute...)\n- FCC's authority limited to adjudicating complaints only\n(no creating rules or regulations)\n- Burden of proof on the network operators\n- Go case-by-case\n- This is similar to the structure of the COPE act\n(H.R.5252)\n\n- Go easy on legislation and regulation\n- Threaten heavy regulation\n- Watch network operators closely\nOur proposal (1):\nOur proposal (1):\n-\nNetwork neutrality principles\n- Consumers are entitled to:\n- access the lawful Internet content of their choice\n- run applications and use services of their choice, subject to the\nneeds of law enforcement\n- connect their choice of legal devices that do not harm the\nnetwork\n- competition among network providers, application and service\nproviders, and content providers\n- meaningful service plan information\n- Want ISPs to publish what they are doing (to keep them honest)\n- Granularity: application performance limits should be anticipatable\n- reasonable service plan choices\n- Let advanced users have a minimally invasive provider\n- Let casual users adopt \"value added\" services such as content filtering\nand security protection\n\n- Go easy on legislation and regulation\n- Threaten heavy regulation\n- Watch network operators closely\nOur proposal (2):\nOur proposal (2):\n- Threaten heavy regulation\n- Force Congress to revisit the net neutrality principles\nand the FCC's authority by sunsetting net neutrality laws\n- If the light regulation is effective, Congress can simply\nextend the sunset date\n- If light regulation is unsuccessful, Congress must write new\nlaws or face anarchy when the expiration date rolls around\n\n- Go easy on legislation and regulation\n- Threaten heavy regulation\n- Watch network operators closely\nOur proposal (3):\nOur proposal (3):\n- Watch network operators closely\n- Conduct regular subscriber surveys\n- FCC regularly reports the health of the Internet to\nCongress:\n- the state of investment and competition\n- the number and nature of complaints\n- significant technological developments\n- recommendations for change\n- etc.\n\nSummary of conclusions\nSummary of conclusions\n-\nDifficult to distinguish between harmful and acceptable types of\ndiscrimination\n- Technological mechanisms and business policies can be used for good\nor bad\n-\nHard to enforce good behavior\n- Almost any behavior can be justified\n-\nPolicy based on discrimination will likely fail to guarantee network\nneutrality\n- Operators will still get away with doing bad things\n- Operators will be limited in which good things they can do\n-\nThe best policy option (discussed in detail later):\n- go easy on legislation and regulation (for now)\n- threaten heavy regulation\n- watch network operators closely\nAny questions?"
    },
    {
      "category": "Resource",
      "title": "team_spectrum.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-68j-communications-and-information-policy-spring-2006/27967328150fd52d6c494be89e230439_team_spectrum.pdf",
      "content": "Spectrum Allocation for\nMunicipal Wireless\nMesh Networks\nM. Hassan-Ali\nH. Jones\nH. Matsunaga\n\nAgenda\nz Project topic\nz Introduction\nz Motivation/justification for Municipal WMN\nz Issues with current WiFi spectrum\nz Recommendations for spectrum\nz Conclusion\n\nProject topic\nz Issue:\nz Spectrum policy with Municipal Wireless Mesh\nNetwork\nz Main results:\nz FCC should allocate Low Frequency dedicated\nspectrum for Municipal Wireless Mesh Backbone\nz The soon-vacated analog TV channels (700MHz)\nwould be ideal for this purpose\n\n801.11a/g\nWiMax\nz Wireless broadband\nz Mesh type\nz Topologies\nz Mesh\nz Resiliency\nz Spectrum allocation\nz User side\nz Network side (Backbone)\nIntroduction\nLow Frequency\nMesh (WiMax)\nMunicipal\nlight pole\nLow Frequency\nMesh (WiMax)\n\nMotivation for MWN\nz Digital divide\nz Public applications\nz Increase competition\nz Baller's \"birch rod in the cupboard\"\nFDR, Baller notes, called municipal power systems \", to be\ntaken out and used only when the child gets beyond the\npoint where more scolding does any good.\"\n\nAll Other\n2.3%\nFiber\n2.0%\nADSL\n37.7%\nSDSL and Traditional\nWireline\n2.1%\nCable Modem\n55.8%\nJustification for WMN\nz Economically feasible\nz Currently less than 50% of\nUS households are\nconnected to BB.\nz Nomadic computing enabler\nz Who needs help urgently:\nz\nRural areas lack BB\nz\nImpoverished areas\nSource: FCC: HiSpdTables_0605_public\n\nImpact of Muni WMN on\neconomy (Philadelphia view WCA05)\nz Broadband availability allows local businesses to remain\ncompetitive, operate more efficiently, and access more\nconsumers more quickly and thus grow faster.\nz Information businesses can start and locate anywhere they want,\nand they tend to look for areas with educated workforces,\nadvanced infrastructures and high quality of life. Knowledge\nworkers expect and require advanced telecommunications\ninfrastructure\nz Broadband connections can improve education for students.\nz The Internet enables entrepreneurship, with wireless broadband\nempowering smaller players to compete against larger and more\nestablished companies.\nz The Internet enables government to deliver city and county\nservices at a lower cost.\n\nAnalysis Methodology\nSystem\nparameters\nNetwork\neffect\nEnd-user\neffect\n\nConstraints imposed by WiFi\nz Limitations of the current version of 802.11:\nz ISM spectrum\nz High operating frequency\nz Power limitation\nz No. users per router\nGraph removed for copyright reasons.\nhttp://www.belairnetworks.com/resources/pdfs/Athens_WAGZone_BDMD00020_A01.pdf\n\nLimitation of the current Mesh\nz Throughput\nz Power limitation\nz Attenuation\nz Noise (ISM)\nz Line-of-sight\nz High Operating\nFrequency\nz Range\nz Low bit-rate delivered\nto users.\nz Scalability\nz More MGRs needed\nz Latency\nz Rural area limitation\n\nSolutions\nz Lower frequency\nz Multi-radio\nz Dedicated\nz Low attenuation\nz\nMore coverage\nz\nMore bandwidth\nz\nLower cost\nz Low interference\nz\nBetter reliability\nz\nLow latency\nz Flexibility\nz\nPower setting\nz\nBetter performance\n\nRecommendation (source)\nz Allocate Mesh backbone from vacated\nanalogue TV\nz Based on the FCC's TV (700MHz) NPRM-\nCourtesy of J. H. Snider. Used with permission.\nhttp://www.newamerica.net/Download_Docs/pdfs/Doc_File_2898_1.pdf\n\nRecommendation (size)\nz For 100Mbps WiFi backbone\nz Hence, allocation of 8 channels @ 700MHz;\nz Or 4 channels with 2x2 MIMO\n\nRecommendation\n(management)\nz Dedicated spectrum model for municipal\nWMNs\nz Initially we recommend the franchised model\nz Reduce risk\nz Efficiency\n\nConclusion\nz FCC should allocate at least 8 channels @\n700MHz (unused TV spectrum) for municipal\nWMNs.\nz This spectrum should be dedicated to\nmunicipalities"
    },
    {
      "category": "Lecture Notes",
      "title": "mod1_lec1.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-68j-communications-and-information-policy-spring-2006/8cb9e616dccb84d7aa805d8d0bdf1386_mod1_lec1.pdf",
      "content": "A quick guide to the Internet\nDavid Clark\n6.978J/ESD.68J\nLecture 1 V1.0\nSpring 2006\n\nWhy should you care?\n\"People\" say: \"Why doesn't the Internet...\"\nProtect me from spam.\nControl porn\nKeep terrorists from plotting\nEtc.\nWe need to translate from a cry of pain to\nrealistic expectations.\nMust understand (in general terms) the\ntechnology to make realistic policy.\n\nDefining the Internet\nIt is not the applications:\nEmail\nWeb\nVoIP\nIt is not the technology\nEthernet\nWiFi\nFiber optics\nSo what is it?\n\nA nice picture\nA range of applications operating over\na range of technologies, by means of\na single interface -- the Internet\nProtocol IP.\nFigure removed for copyright reasons.\nFigure 2.1 in National Research Council. \"Realizing the Information\nFuture: The Internet and Beyond.\" National Academies Press, 1994.\nSee http://www.nap.edu/openbook/0309050448/html/53.html\n\nWhat is a network?\nOr...what is the problem we are solving?\nA shared medium of communications.\nWhy?\nTo share expensive resources\nCannot afford a wire between \"everywhere.\"\nTo facilitate general communication--\ninformation sharing.\n\nHow to share?\nComputer traffic is bursty.\nOlder sharing method (circuit switching)\nwas inefficient.\nAbout 30 years ago, the need for a new\nmode of sharing was felt.\nPACKETS!\n\nWhat is a packet?\nPacket:\n- Some data with an address on the front.\nSpecified maximum size\n- Sent serially across a link.\n- Use a computer (a \"router\" or \"packet switch\")\nto manage the link.\n- Statistical sharing.\nA neat idea that has stood the test of time.\n\nA simple view of the Internet\nUser\nUser\nUser\nUser\nUser\nUser\nUser\nUser\nRouter\nRouter\nRouter\nRouter\nRouter\nRouter\nRouter\nRouter\n\"The Internet\"\n\nAn (over) simple packet picture\nHeader\nData\nStuff...Destination/Source/Length...stuff\nA packet\nA packet header\nAddresses: written in the form 18.26.0.166\n\nWhat a router does\nWhen it gets a packet:\nCheck that it is not malformed.\nCheck that it is not going in circles.\nLook at its destination address.\nPick the best link over which to forward it.\nIn the background:\nComputes the best routes to all destinations.\n\nWhat was at the edge?\nThe slide said \"user\".\nIt is a \"host\", or a \"PC\", or a \"server\", or a\n\"computer\" or an \"end node\".\nThe place where application code runs.\nThere might be a person there.\nGet back to this later...\n\nImplications\nInside the network there are only packets.\nThere is no understanding of higher-level\nintentions.\nThere is nothing like a \"call\", or \"placing a\ncall\", in the router's design.\nThe routers have a limited view of what it\nmeans to \"operate correctly\".\n\nThe service model\nThe other half of the Internet specification:\nWhat is the commitment when I send a packet?\nAnswer: very little.\nThe Internet tries it best, but makes no\npromises.\nIt can lose, reorder, delay, or duplicate packets.\nUsually they arrive in good order.\nIf they don't--you have no complaint.\nCalled the \"best effort\" service.\n\nIs this such a good idea?\nWeak expectation means Internet can run\nover \"anything\".\nMakes the application's job harder, but not\nimpossible.\nSo, yes, it is a good idea.\nBut now under attack.\n\nCongestion\nMore than you want to know in one slide...\nWhat happens if too many packets get sent?\nIn the short run, queues form in routers.\nIn the longer run, senders (are supposed to) slow down.\nWhy does this work?\nApplication are expected to tolerate it.\nBut if senders do not slow down?\nOut of aggression, or because they cannot.\nA raging debate among designers.\n\nQuality of Service (QoS)\nFour options.\nDemand and expect them to slow down.\nBenign socialist\nPolice them and punish them if they don't\nslow down.\nPolice state\nLet them pay to keep going fast.\nCapitalist\nOver-provision so net is \"never\" congested.\nPragmatic\n\nWhat was at the edge?\nThe slide said \"user\".\nIt is a \"host\", or a \"PC\", or a \"server\", or a\n\"computer\" or an \"end node\".\nThe place where application code runs.\nThere might be a person there.\n\nWhat a \"host\" does\nRuns the application code\nWeb, email, voip, ssh, doom, etc.\nRuns software that helps cope with\npackets and the best effort service model\nExample: Transmission Control Protocol, or\nTCP.\n\nWhat is a protocol?\nProtocol: A specification of what can be sent\nwhen and in what format.\nA very general term, used to describe many\naspects of networking.\n- The voltage to represent a 1 or 0 on a link.\n- The bit sequence to represent characters (e.g. ASCII).\n- The format of the address on the front of the packet.\n- How one reports a lost packet.\nFrom the Greek: \"Glued on the front.\"\n\nWhat does TCP do?\nBreaks a chunk of data (what the\napplication wants to send) into packets at\nthe sender.\nNumbers the packets.\nKeeps sending them until it gets an\nacknowledgement.\nPuts them in order at the receiver.\nPasses the date to the right application.\nProvides a very simple failure model.\n\nHost vs. router\nInternet\nApplications\nTechnologies\nTCP\nHost\nknows\nabout\nRouter\nknows\nabout\nNTWT*\n*Not the whole truth\n\nA (less) simple packet picture\nHeader\nData\nStuff...Destination/Source/Length...stuff\nA packet\nLink Dest/Src/Length/NxtHdr SN/NxtHdr (app)\nIP header\nTCP header\n\nThe end-to-end arguments:\nThe lower layers of the network are not the right\nplace to implement application-specific\nfunctions. The lower layers of the network\nshould implement basic and general functions,\nand the applications should be built \"above\"\nthese functions, at the edges.\nE.g. move functions \"up and out\".\nThis causes function migration to the end-node.\nThe network should be \"as transparent as\ntechnology permits\".\n\nBenefits of end-to-end\nUser empowerment.\nRun what you please.\nFlexibility in the face of unknown applications.\nA network to hook computers together.\nLower cost in core of network.\nEliminate special \"features\".\nRely on edge-node equipment.\nMore robust applications.\nNo unexpected failures of third-party nodes.\nAn example of \"getting it wrong\": make the\nnetwork reliable.\n\nSummary\nWhat \"the Internet\" does is very simple:\nIf forwards packets.\nIt is oblivious to the purpose of the packets.\nPackets allow effective/efficient sharing.\nLots of applications run on the Internet\nAnd there will be more tomorrow.\nEach has its own design.\nThere is a tension/tradeoff as to where functions are\nplaced.\nThe Internet can exploit lots of technologies.\n\nHow about the phone system?\nHow does it different from the Internet?\nAnd why?\nWhat are the implications for policy?\n\nA simple view of the Internet\nUser\nUser\nUser\nUser\nUser\nUser\nUser\nUser\nRouter\nRouter\nRouter\nRouter\nRouter\nRouter\nRouter\nRouter\n\"The Internet\"\n\nA simple view of the phone system\nPhone\nPhone\nPhone\nPhone\nPhone\nPhone\nPhone\nSwitch\nSwitch\nSwitch\nSwitch\nSwitch\nSwitch\nSwitch\nSwitch\n\"The phone system\"\nPhone\n\nThe differences?\nSwitches are powerful, because phones\nare simple.\nThe knowledge of what the phone system is\nfor is embedded in the switches.\nIt \"knows\" that its purpose is to carry voice.\nRouters are simple, because end-points\nare powerful.\nThe knowledge of what the Internet is for is\nembedded in the end-points.\n\nAnd...?\nThe phone system has no open interface\nfor complementers.\nNo easy way to attach new applications.\nCompare the generality of a voice circuit and\npacket carriage.\nVery different view of layering. There is no\n\"voice\" layer.\n\nNext lecture\nHow we design applications.\nTechnical design issues.\nImplications for policy and for industry\nstructure.\nOptions for shaping tussle among\nstakeholders.\n\nMultiple views of system\nTopology view:\nRouters as expression of physical distribution.\nLayered view:\nWhat is the role of each \"box\".\nWhat does this imply about limits to action?\nAdministrative view.\nWho owns/operates each part?\nWho controls what talks to what?\n\nA more realistic picture\nBackbone\n(big ISP)\nBackbone\n(big ISP)\nBackbone\n(big ISP)\nLittle\nISP\nUser\nUser\nUser\nUser\nLittle\nISP\nCorp\nCampus\nLittle\nISP\nUser\nUser\nUser\nUser\nUser\nUser\nUser\nThe ISP lives here..\nThe ISP does not live\nat the end-points."
    },
    {
      "category": "Lecture Notes",
      "title": "mod1_lec2.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-68j-communications-and-information-policy-spring-2006/0ec49df5135ae42dac7960df6e4693a5_mod1_lec2.pdf",
      "content": "Application design on the\nInternet\nDavid Clark\n6.978J/ESD.68J\nLecture 2 v1.0\nSpring 2006\n\nApplication design\nRemember: applications run \"on\" the\nInternet. They are not the Internet.\nMany approaches to construction\nPatterns of communication.\nUse of end node software and server\nsoftware.\nDesign considerations such as:\nEase of use and deployment, robust\noperation, low cost, simplicity, lawsuit-\nproofing, easy management.\n\nWhere to start? Servers\nModern apps do not follow a simple end to\nend model.\n(End to end at application level)\nRemember the end to end argument?\nThey are full of servers and services run\nby third parties.\n\nSome examples:\nEmail:\nSender\nServer\nServer\nReceiver\nSMTP\nSMTP\nPOP\nWeb:\nHTTP\nBrowser\nProxy\nServer\n\nMore examples:\nNapster (early peer to peer)\nPeer\nPeer\nPeer\nPeer\nData\nData\nData\nCatalog\n\nMore examples:\nLater peer to peer\nPeer\nPeer\nPeer\nPeer\nData\nData\nData\nJust go feel around\nfor the data. It might\nbe there\nsomewhere.\n\nMore examples:\nGames (some), and IM (some)\nClient\nClient\nClient\nClient\nServer\n\nLots of reasons for servers\nStage content close\nPre-process content\nSpecialized device\nConstrain actions\nFilter content\nReplicate functions for robustness\nManage identity\nCentralize authentication\nControl release of attributes\nPreserve anonymity\nOutsource functions\nCope with NAT and addressing issues\nMake comms asynchronous\nMove between end-nodes\n\nWhat problems are we solving?\nEase of use\nEase of deployment\nPerformance\nEconomic (industry) structure\nRobustness\nSecurity\nWho is in control?\n\nBalance of power\nn\nWho can select the servers to be used?\nn\nUser: delegation (ease of use), filtering\n(security), pre-formatting, control anonymity,\nreplication and location, protection (applies\nto both ends)\nn\nISP: filtering (value strat, usage control,\nagent of state), revenue generation\nn\nThird party (state or \"other\"): filtering (law\nenforcement and censorship), monitoring\n(law enforcement, taxation)\n\nFinding a framework for analysis\nNeed to construct a list of stakeholders\nNeed to catalog their interests.\nTwo pictures:\nA value chain stakeholder diagram\nA broader societal stakeholder diagram\n\nValue chain assessment\nUser\nISP\nApp provider\nFacilities\nCustomer:\nchoice,\npayment,\ncapture\nDependency\nIntegration\nIndependence\nCustomer:\nchoice,\npayment,\ncapture\n\nA larger space of stakeholders\nCommunal\nconcerns\nPersonal\nconcerns\nShared\nconcerns\nConcerns of\nthe state\nConcerns of\nbig business\nConcerns of\nconsumer advocates and\ncivil liberties advocates\nUser empowerment\nGlobal\nconcerns\nLimits to\njurisdiction\nLocal\nvalues\n3rd party\nconcerns\n\nSome stakeholder concerns\nUsers want choice\nProvides competitive pressure\nProviders want stickiness\nProviders want value stratification\nProviders want to sell services\nISPs want to balance usage with revenues\nGovernments want taxation\nNations make money on settlement\nRights-holders want protection\n\nThis is very abstract...\nA server is a tangible element.\nIt may play many purposes\nThe design constrains which purposes it\ncan play.\nThe deployment determines what actually\nhappens.\n\nSome topics for consideration\nRelation of app design and addressing.\nThe importance of \"design for economics\"\nAn application-centered view of security\nHow do applications get deployed?\n\nTopic 1--global addressing\nThesis: proper design of applications can\nmitigate the \"NAT problem\", and allow us\nto architect private edge address spaces.\nUse host-specific ports (e.g. RFC 2782).\nRequires extensive tussle analysis.\nUse servers in global space for\nrendezvous.\n\nTussle analysis\nPorts would be random, not well-known.\nRequires host-specific knowledge to filter.\nISP filtering (value strat, traffic engineering) much harder.\nFirewall filtering much harder.\nPort scans less useful.\nName server can be anywhere. Per-service name.\nHard to launch location-based attack or scan on name server.\nBut: what names show in messages? What history?\nExample of interaction between application design and\nnetwork design.\nA real design question for today. Not hypothetical.\n\nTopic 2--economics\nShould applications be designed taking into\naccount the economic goals of the various\nstakeholders?\nUser choice of server and provider.\nDrives competition and controls prices\nPrevent ISP capture\nServer-based services are basis for revenue\ngeneration.\nAkamai as source-driven example.\nEmail as receiver-based example.\nShould we concern ourselves with advertising?\n\nEconomics of overlay networks\nOverlays are:\nA tool for sophisticated applications.\nA tussle tool with ISPs\nIf the latter, who pays for them?\nCannot scale for free. (Can they?)\nWhen overlays grow up, who will run them?\nOption 1: they will be run by the ISPs.\nThe major source of new ISP revenues.\nOption 2: third party providers\nWhat will make one option or another the answer?\n\nTopic 3: Security architecture\nDoes an application-centered view help sort out\nissues? (I vote yes...)\nRe-factor security using tussle analysis.\nFreedom from attack:\nUsers, end-servers,third-party infrastructure\nTrusting users who want privacy\nUntrusting users who want help\nThird parties that want to intervene\nWho trusts the servers, and how does app\nconstrain this (shared keys, revealed info, etc.)\n\nDesign rules for secure apps\nThink about:\nApp-level DOS attacks\nThe role of identity and attributes in the above\nDefense in depth and \"outsourcing\".\nDon't be an attack amplifier.\nWhat can be done cross-app? (support\nservice?)\nCommon services vs. app-specific services in\nthe net.\n\nTopic 4: Ease of deployment\nThe life cycle of an app, or how do apps\ngrow up?\nIn the beginning, must be end to end. No\nservers.\nIf successful, lots of folks get interested, and\njump in. Leads to servers.\nIn the middle? How about peer to peer?\nThe design of an app should take into\naccount how it is to grow up.\n\nA more realistic picture\nBackbone\n(big ISP)\nBackbone\n(big ISP)\nBackbone\n(big ISP)\nLittle\nISP\nUser\nUser\nUser\nUser\nLittle\nISP\nCorp\nCampus\nLittle\nISP\nUser\nUser\nUser\nUser\nUser\nUser\nUser\nThe ISP lives here..\nThe ISP does not live\nat the end-points.\n\nISPs and applications\nISPs do more than run routers and\nforward packets.\nThey run servers and participate in\napplications.\nEach application has its own architecture.\nThis is not the \"Internet\" design, it is an\n\"application\" design.\n\nQuestions about applications\nWho controls the servers?\nCan only the ISP provide them?\nCan the user select which server to use?\nIs there a topological limitation on the servers?\nCan my mail server be in China? (Yes...)\nWhat information has to be revealed to the\nservers? What is \"end to end\"?\nEmail--the contents can be encrypted.\n\nPeeking is irresistible\nWhat is revealed and who chooses?\nWhat:\nWhat can the servers count, see or change?\nEmail as example of rich design space.\nWho:\nSender (mechanically).\nReceiver (by agreement).\nISP (by contract or demand)\nState (by law)\n\nWhat has to \"show\" in the net?\nWhat transport edges are using?\nTCP, UDP, RT, etc.\nWhat application (port) edges are using?\nWhat Web page is being retrieved.\nWho the parties doing mail or IM are?\nWho the copyright holder on the content\nis?\nAnd so on, up the layers.\n\nHost vs. router\nInternet\nApplications\nTechnologies\nTCP\nISP\nwould\nlove to\nsee\nHost\nknows\nabout\nRouter\nknows\nabout\nPeeking is irresistible--so encrypt?"
    },
    {
      "category": "Lecture Notes",
      "title": "mod1_lec3.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-68j-communications-and-information-policy-spring-2006/bf760030db372bab28ce53734e7daf99_mod1_lec3.pdf",
      "content": "\"EE 101\"\nDavid D. Clark\n6.978J/ESD.68J\nLecture 3 V1.0\nSpring 2006\n\nWhat is the EE problem?\nGet some data across a link, or \"channel\".\nNot a network, just a link.\nCould be a wire, a fiber, radio, or something.\nThe space of design--multi-dimensional\noptimization:\nBandwidth and distance\nCost\nPower\nEfficiency (what does this mean?)\nRobustness and resilience\n\nWhat are we sending?\nComputer systems represent data as bits,\nso we send bits.\nOther systems send analog signals, or\ndigitized analog systems (bits, usually).\nSo no single answer.\nA brief digression into sampling.\n\nDo we always send bits?\nNo. That is a \"recent\" idea.\nTelevision, radio, etc are \"analog\" signals.\nAmplitude modulation (AM) : the amplitude\nof the signal at any moment represents\nthe amplitude of the data being sent.\n\nBut we can convert\nTo \"digitize\" an analog waveform.\nFind the highest frequency in the signal.\nOr filter to make it so.\nMeasure the amplitude at (at least) twice that\nfrequency (the Nyquist rate).\nThose two values are sufficient to recreate\nthe waveform.\nSubject to the precision of the measurement.\n\nExample:\n\nSample and digitize\nRepresent each sample as an integer of\nsome precision, send the numbers.\nExample: 4 kHz signal (telephone), 8 bits\nper sample (256 values) -> 64 kb/second.\nExample: 20 kHz, two channel (hi-fi stereo),\n16 bits per sample, 1.28 mb/second\nCD sample rate is 44.1 kHz, 1.4122 mb/s\n\nSo assume we are sending bits\nFirst question: what does a bit look like?\nLots of representations: low/high voltage,\non/off light, high/low tone, N/S magnetic spin.\nPicking the rep is part of the design.\n\nTry a simple idea to send a bit\nTake a wire.\nSend DC voltage for 1, no voltage for 0.\nReconsider: means sending average of 1/2\nvoltage, so net current flows.\nSend + DC voltage for 1, - DC voltage for 0.\nSimple, low cost, does not go very far,\nworks.\n10 mb/s ethernet (sort of)\n\nEarly ethernet\nSend either:\nor:\n(Sequence of 1's or 0's does not lead to\ncontinuous current. )\n\nHow can we evaluate this?\nCapacity C, bits/second.\nDistance\nCost\n\nLet's talk about distance\nFirst digression into EE:\nWhat happens to a signal as it goes down a\nwire?\nIt gets weaker.\nCrisp transitions get vague.\nHigh-frequency attenuation.\n\nCrude visualization\nWhat goes in:\nWhat comes out:\nAfter a while, cannot find the signal in the\nnoise. So the representation interacts with\ndistance to determine the region of utility.\n\nHow could we improve this?\nGo further, or send more bits, or something.\nOne option: improve the wire.\nCAT 3, CAT 4, CAT 5, CAT 6, etc.\nWhat are they doing?\nReducing loss.\nMake the signal at the receiver bigger.\nReduce high-frequency attenuation.\nMake the signal more well-defined.\n\nSo we have a clue to design\nWires can carry certain frequencies. This is\nthe \"bandwidth\" of the wire.\nBandwidth B (measured in Hz) is not Capacity\nC (measured in bits/second).\nHigher frequencies attenuate, and distance\nmakes it worse.\nHigher speed ethernet does not go as far.\n\nAnother idea--better representation\nA short history of dialup modem design:\nThe channel has a bandwidth of about 4 kHz.\nSo signal must have a frequency profile that\nfits inside that envelope.\nHow to do this?\nInstead of two voltages, send:\nTwo frequencies? FSK -> 110 b/s in 1960's\nOne frequency but shift the phase? PSK\nWhy just two? Aha!\n\nMultiple bits per symbol\n2 bits per symbol: 4 symbols\n3 bits per symbol: 8 symbols\nAnd so on...\nHow to create multiple symbols?\nAdjust the:\nfrequency\nphase\namplitude\nDef: Baud--symbols/second. Not bits/second\n\nAn example: QAM\nQuadrature Amplitude Modulation.\n\"Quadrature\" describes a way to talk about\nvariation in the phase.\nWith respect to a reference, a signal can be\n\"in phase\" or \"in quadrature\" which is 90\ndegrees off.\n\nFour phases, two amplitudes\nReference\nt\nt\nSignal\n\nA different representation\nPolar co-ordinates\nThis is a \"constellation\" diagram.\nI\nQ\n\nQAM state of the art:\n256 QAM\n16 values for I\n16 values for Q\n256 symbols, which means\n8 bits per symbol\n\nA figure of merit:\nA circuit has bandwidth B, measured in Hz.\nWe devise a scheme with some capacity C,\nmeasured in bits/second.\nExpress the efficiency as C/B, or\nbits/second/Hz (b/s/Hz)\nOriginal modem 110 b/s 4 KHz, .0275 b/s/Hz\nCurrent modem 56 kb/s, 14 b/s/Hz (this is\nimpossible in general, and requires magic)\nFactor of 509 improvement\n\nCan we just get better?\nShannon gave us the theoretical limit, in terms of\ncapacity C, bandwidth B, signal power S and\nnoise N:\nC/B = log2 (1+ S/N)\nThis is hard to derive but easy to think about.\nCase 1: high signal to noise:\nC/B = log2 (S/N) = 3.3 log10 (S/N) = .33 dB S/N\nSo 30 dB channel -> 10 b/s/Hz\n40 dB channel -> 13 b/s/Hz\n\nAnother design clue\nTurning up the power and \"blasting away\" is\nan inefficient way to go.\nThat \"log\" is a pain. 10x power means only +3\nimprovement in b/s/Hz.\nMuch better to increase the bandwidth.\nDouble the bandwidth, same power, double\nthe bits/second. (ignoring increase in noise.)\nSo go to the FCC and fight for spectrum.\n\nWhat about radio?\nAll this applies.\nDivide the spectrum up into frequency bands.\nThink TV, FM, AM, etc.\nUse some scheme like QAM in your band.\nCurrent schemes come close to the\nShannon limit.\nBut radio is noisy, so b/s/Hz tends to be\nworse than over a wire (Duh!)\n\nState of the art\nTDMA cellular, 48 kb/s over 30 kHz channel,\nor 1.6 b/s/Hz.\nPower limited (cell phone battery).\nSpectrum limited (want to carry lots of calls at\nsame time).\nNoise limited.\n\nTelevision: analog to digital\nOld way--analog\nDivide the spectrum into 6 mHz bands.\nFit one TV signal into each band.\nView the picture as a series of horizontal lines\nSweep across the lines in time\nSignal at each instant is the brightness of that\npoint.\n\nThe digital version of TV\nNew way--digital\nKeep the 6 mHz allocation\nCable: use 256 QAM, get about 6 b/s/Hz,\nor 36 mb/sec\nOver the air: more noise, so perhaps 3b/s/Hz.\nHow many bits to carry a TV picture?\n\"It all depends\", but about 1 mb/s\nGet 4 or 5 digitized channels in one band\n\nWhy is the phone so limited?\nWhere did that 4 kHz limit come from?\nThe wire?\nNope. The wire can do better than that?\nThe switches?\nNot the old ones. Relays have great bandwidth.\nIt is the digital backbone.\nThe insides of the phone system are all digital.\nNyquist sampling requires that you filter before you\nsample.\n\nThings can get complex\nThink about computer communication over\nthe phone system.\nEncode the digital stream into a 4 kHz limited\nanalog signal.\nSend that to central office, where...\nIt is digitized as 64 kb/s bit stream,\nWhich is then encoded and send over high-\nspeed circuits.\n\nSo how does DSL work?\nDSL: digital subscriber loop.\nJust use the wires, not the switches.\nPush the limits of the wires.\nVery dependent on distance and quality.\n1 or 2 mb/s over 15,000 feet.\nUse new switching equipment.\nDSLAM, or DSL access module.\nMust be in each central office.\n\nSo where to decode?\nUse DSL as example.\nWhen data goes to the central office, what\nthen?\nSample the DSL signal, digitize, encode and\nresend.\nDecode the DSL to extract the bits, then send\nin some other format.\nThat is the Internet way--at each forwarding point,\nextract the packet, then recode for the new\nmedium.\n\nDifferent ways to share?\nDividing spectrum up into frequency bands\nis not the only option.\nMade lots of sense with simple, pre-digital\nradios.\nGo back to Shannon. For given power, best\nC/B improvement is wider spectrum.\nSo perhaps we could all use the same\nspectrum and share in some other way?\n\nSpread spectrum\nGeneral idea:\nInstead of squishing my signal into a narrow\nfrequency band.\nIntentionally spread it out across a wide\nband.\nTwo questions:\nHow?\nIs it really a good idea?\n\nHistory\nThis idea is older than Shannon.\nOriginal idea was to hide the radio signal\nfrom enemy detection (assuming a\nnarrow-band receiver).\nWW2, patent by Hedy Lamarr and George\nAntheil, 6 years before Shannon's result.\n\nFrequency hopping\nModulate carrier, then shift it around during the symbol\ntime. The pattern of frequencies is the \"code\".\nf4\nf3\nf2\nf1\nf0\nt\nTsymbol\n\nThinking about spread spectrum\nThe receiver can follow the signal if it knows\nthe code. Otherwise, hard to find the\nsignal in the noise.\nCDMA--Code division multiple access.\nThere are other ways to spread the signal.\nIf the signal is spread out enough, then on\nthe average, S/N is less than 1.\nThe improvement from knowing the code is\nthe \"processing gain\", measured in dB.\n\nBack to Shannon\nC/B = log2 (1+ S/N)\nWhere total noise N = N0B\nIf S/N < 1, expansion of Log (1+S/N) S/N\nSo turn up the power?\nBut N is now the signal from the other senders.\nThis is not as efficient as frequency division.\nNoise proportional to signal: don't turn up power\nBut N is not Gaussian white noise.\nSo Shannon's limit does not apply.\nThat other \"noise\" is signal, so process it\n\nSo why do spread spectrum?\nDifficulty of interception and detection.\n\"Soft\" sharing.\nInstead of rigid frequency bands, more or\nfewer shares depending on current\nconditions.\nEasier to exploit the power of digital signal\nprocessing.\n\nThe ultimate...\nWhat is the spectrum of a pulse?\nIt is spread out across a wide band of\nfrequencies.\nThink about a lightning bolt.\nSo send a signal by emitting pulses.\nUltra-wide band (UWB)\nIs this cool, or stupid?\n\nAnd other ways to share\nShare over time--taking turns.\nStatic shares\nListen before sending\nListen while sending\nShare in space\nTV and radio in different cities\nCell towers\n802.11\n\nMany patterns of communication\nOne to one:\nA phone call\nOne to many:\nRadio and television\n802.11 (pattern of sharing, if not comms)\nMany to many:\n\nReview--what is the point\nGoal is to communicate\nOver a channel of some sort.\nWith various requirements and constraints\nDistance\nCapacity\nCost\nEfficiency: power, use of spectrum\nEngineers spend lots of time devising\nsolutions.\n\nSummary: \"EE\" rules of thumb\nCoding:\nOver a wire: 6 b/s/Hz is pretty good.\nOver the air: 2 b/s/Hz is pretty good.\nWith bad noise: 1 b/s/Hz is not bad.\nSampling:\n8 bits/sample x 2 samples/Hz = 16 b/s/Hz\nSo why digital?\nCompression, clever sampling, etc.\nUsually better in practice.\n\nWhy is this relevant to the class?\nA wire is a private affair (usually).\nSpectrum is more public.\nMost countries, as matter of policy, regulate its use.\nIn US, FCC and NTIA.\nRegulation centers on who can use, and how to\ndivide it up.\nIn other words, how to share.\nSo regulation constrains the technical options.\nBy tradition, allocate frequencies. See NTIA chart.\nBut this is not the only way, as we have learned.\n\nPropagation\nA final technical issue: what happens to radio\nsignals as they radiate.\nWe looked at propagation along a wire: signals get\nweaker and lose the high frequencies.\nRadio is like light (sort of).\nSignal strength falls off as 1/d2 (or worse)\nSignals reflect\nSignals interfere at the receiver (but not in free space)\nFade varies over time\nDifferent frequencies behave differently.\nLower frequencies refract more.\n\nAntenna design\nUse multiple antennas to deal with interference\n(curing \"deep fade\")\nUse multiple antennas to create multiple paths.\nThis seems like magic.\nAs frequencies go up, antennas get smaller.\nBut receive less power.\nThis is a golden age for electrical engineering.\nHigher frequencies, digital processing, cheap silicon,\nbetter theory.\nCreates lot of tension for regulators.\n\nWhen is an antenna...\nnot an antenna?\nWhen it is a wire.\nWhen we want the signal in the form of\nelectromagnetic radiation, we call the wire an\nantenna.\nWhen we don't want the radiation, we call it\nCross talk\nLeakage\nInterference.\nIn this respect, wires are not private.\n\nDesigning better wire\nKeep the signal inside when you want it\ninside.\nAvoid loss (attenuation).\nHave a high bandwidth.\nCo-axial cable\nA grounded sheath to keep the\nsignal from leaking out\nTwister pair\nReduces radiation, inexpensive\nShielding makes it worse.\n\nHow about fiber?\nWonderful signal to noise ratio.\nVery little signal loss, compared to copper.\nSo why try for spectral efficiency?\nTypical modulation: light on/off.\nFiber is a cost-constrained design space.\nHigh speed lasers are costly.\nLong distance (high power) lasers are costly.\nFor more efficient use of fiber, use simple\nfrequency (color) division.\nDense wavelength division multiplexing DWDM\nOnly now beginning to see more complex\nmodulation schemes."
    },
    {
      "category": "Lecture Notes",
      "title": "mod1_lec4.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-68j-communications-and-information-policy-spring-2006/38a26d32a1f1a5f8cb5e7f8b422c6bea_mod1_lec4.pdf",
      "content": "Internet Interconnection\nDavid D. Clark\n6.978J/ESD.68J\nLecture 4 V1.0\nSpring 2006\n\nThe fundamental problem\nOn what basis should competing ISPs\ninterconnect so that the global Internet can\nhappen?\nThey have to interconnect.\nThey are fierce competitors.\n\nThe traditional Internet picture\nBackbone\n(big ISP)\nBackbone\n(big ISP)\nBackbone\n(big ISP)\nLittle\nISP\nUser\nUser\nUser\nUser\nLittle\nISP\nLittle\nISP\nLittle\nISP\nLittle\nISP\nUser\nUser\nUser\nUser\nUser\n\nWhat constrains that picture?\nMoney routing.\nPackets are an excuse to make money...\nAnd old and possibly true story.\n\"I thought you were going to pay me money.\"\nOr: how not to trade in a car.\nThe result: revenue-neutral peering, or\n\"money insulators\".\n\nThe money picture\nBackbone\n(big ISP)\nBackbone\n(big ISP)\nBackbone\n(big ISP)\nLittle\nISP\nUser\nUser\nUser\nUser\nLittle\nISP\nLittle\nISP\nLittle\nISP\nLittle\nISP\nUser\nUser\nUser\nUser\nUser\nMoney flow\nNot packet flow\n\nThe two modes\nTransit: small ISP pays large ISP to deliver\npackets to/from anywhere.\nPeering: two ISP agree to exchange packets\nfor free.\nNormally, only packets destined for each ISP\nand its transit customers.\nNormally, no payment.\n\nDig deeper--why?\nInternet has no expression of value flow.\n\nNo \"800\" numbers.\n\nPacket flow not the same as value flow.\n\n(No concept of a \"call\".)\n\nWe were proud of that.\nSo, two rough arguments.\n1)\nYou were going to get the traffic anyway.\n2)\nSome sort of symmetry.\n\nNo payment = symmetric value\nMuch too simple analysis:\nValue to ISP1: N1*(V1-2*N2)\nValue to ISP2: N2*(V2-1*N1)\nIf V1-2 = V2-1, terms are equal. Relative size does\nnot matter.\nISP1\nISP2\nN1\nusers\nN2\nusers\n\nWhat actually happens\nEqual size\nNo relative market power.\nBalanced packet flows.\nAssume the value uncertainty balances out.\n\nWhat is wrong?\nPeering points are sometimes congested.\nHard to negotiate about upgrade.\nISPs cannot offered assured end to end\nservice.\nSmall players distort themselves to balance\npacket flow.\nPerhaps there is a real inefficiency.\nValue is not symmetric.\nRevenue neutrality is easy, but unjustified.\n\nEvidence\nInternap: giving Amazon (and others)\nassured access to their users.\nEmerged to serve a specific value flow.\nMakes it possible to find the valuable packets.\nLooks like \"paid peering\".\n\nInternap\nBackbone\n(big ISP)\nBackbone\n(big ISP)\nBackbone\n(big ISP)\nLittle\nISP\nUser\nUser\nUser\nUser\nLittle\nISP\nLittle\nISP\nLittle\nISP\nLittle\nISP\nUser\nUser\nUser\nUser\nUser\nInternap\nAmazon\n\nWhy don't ISPs fix the problem?\nStill have the fundamental problem.\nNo way to find direction of value flow.\nInternap does it with physical path.\nNegotiation might trigger antitrust concerns.\nNegotiation with competitors still hard.\nLook for \"cable alliance\" and \"telco aliance\".\n\nWhat is really wrong?\nIt is not just the inefficiency of peering.\nBut note the recent posturing from SBC\nIt is the inability to create and offer new\nservices.\nEvidence:\nThe (non-)history of Quality of Service.\nAkamai\n\nThe phone company story\nVery different history.\nInterconnection is regulated.\nSimple, well understood service.\nDifferent revenue model (sort of).\nAccess charges and settlements.\nQuestion for discussion: should we regulate\nInternet interconnection?"
    },
    {
      "category": "Lecture Notes",
      "title": "mod2_lec1.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-68j-communications-and-information-policy-spring-2006/7e457a58fb86c8914c2cc0bcbe5846ed_mod2_lec1.pdf",
      "content": "(c)Lehr, 2004\nPolicy Rationales:\nWhy Regulate Telecoms?\nMost slides from\nWilliam Lehr\nMassachusetts Institute of Technology\n\n(c)Lehr, 2004\nRegulatory Frameworks\nWhy regulate telecoms: the policy agenda\nHow regulate telecoms: from utility regulation to\ncompetition\nWho regulates telecoms: the institutions\nSome key issues/themes:\ny Convergence and challenge for legacy\nregulation\ny Jurisdiction: international v. national v. local\ny Models of regulatory enforcement\n- Agency v. standards v. courts (antitrust)\n\nPolicy Rationales\nDomain\nRationale\nTech Change?\nEconomic\nNetwork effects (interconnection)\n\"Natural monopoly\"\ncompetition\nMultiplier effect of infrastructure\nSocial\n\"Universal service\" (equity)\nPolitical\nAppeal to important constituencies\nNational security\nContent (many aspects)\nRevenue source for governments\n\"Coordi-\nnation\"\nStandardization\nManagement of \"scarcity\"\n\n(c)Lehr, 2004\nFrom \"Where the Money Comes From and Where It Goes,\" Mark A. Jamison, Public Utilities Research\nCenter, U. Florida, 1997.\n1895, 1902, 1912, 1920 -- Mueller, \"Universal Service.\"; 1940, 1950, 1955 -- Majority Staff of the Subcommittee on Telecommunications, Consumer Protection, and Finance of\nthe U.S. House Committee on Energy and Commerce, Telecommunications in Transition: The Status of Competition in the Telecommunications Industry, H.R. Doc. No. 86-058,\n97th Congress, 1st Session, November 3, 1981; 1960-1981 -- FCC, Common Carrier Statistics; 1983-1996 -- FCC, Trends in Telephone Service.\nCourtesy of Mark Jamison, PURC, University of Florida. Used with permission.\n\n(c)Lehr, 2004\nHow are telecoms regulated?\nTraditional model: Public utility regulation of monopoly carrier\ny Government owned Post Telephone and Telegraph (PTT), or\ninvestor-owned PTT with National Regulatory Authority\n(NRA)\n- US: FCC regulates AT&T Bell System\n- UK: Ofcom regulates British Telecom\n- France: ART regulates France Telecom\n- Japan: MPHPT regulates NTT\n- etc.\ny (Before PTT privatized, no need for NRA)\ny Rate of Return (RoR) regulation\n\n(c)Lehr, 2004\nRate of Return Regulation (RoR)\n\nRegulatory Compact\ny Carrier agrees to provide: Universal service\n- Carrier of Last Resort, Duty to Serve\ny Regulator agrees to allow: Cost recovery (+ fair return)\n- Prices = costs + allowed return = c+F/q + rK/q\n- Rate base (K), fair return (r) which risk-adjusted, depreciation\n\nRetail rate regulation\ny Prices set to achieve social goals\n- Low for consumers (US), high for carriers/equipment makers (Japan)\n- Recover costs and support employment or generate govt. revenues\ny Prices include implicit subsidies:\n- Toll->Local, Urban->Rural, Bus->Res, Usage->Fixed\n\nEntry restrictions (protection from competition)\ny Telecom out of computers, everyone else out of telecom\ny Structural separation or accounting separation (separate subsidiary)\n\n(c)Lehr, 2004\nTransition to Competition\n\nMarkets instead of \"Soviet-style\" central planning!\ny Regulatory capture/rent-seeking and overhead costs avoided\ny Competition => \"Survival of the Fittest\" => Efficiency\ny Prices driven to cost (no excess profits)\n\nPrivatization of PTTs and creation of NRAs (1980/1990s)\n\nLiberalization and Deregulation:\ny Equipment markets - 1960/1970s\ny International/Long distance (US) - 1980s\ny Mobile services (and auctions) - 1990s\ny Local (Loop unbundling) - 1990s\n\nFrom RoR to Price Cap: P(t+1) = P(t) - Productivity Adj.\ny If transition to competition, then eventually markets set prices\ny If no transition, then RoR with a regulatory lag.\n\nRules for Interconnection and Access\ny With competition, there will be multiple networks\ny Entrants need access to legacy network (at least initially)\ny Wholesale regulation (Interconnection, Resale)\n\n(c)Lehr, 2004\nTransition to Competition\nIn US...\ny 1959 Above 890 FCC decision (private line competition)\ny 1968 Carterfone FCC decision (CPE competition)\ny 1984 Divestiture Bell System (long distance competition)\n- Regulatory separation of local and long distance calling.\n- Structural separation of AT&T long distance (competitive) and Bell\nOperating Company local telephone monopolies (Verizon, SBC).\ny 1996 Telecommunications Act of 1996 (local competition)\n- Local network unbundling and interconnection\n- LD entry by local companies\nNo divestuture, but otherwise similar abroad...\ny Canada, UK, Japan, Korea, Mexico, etc., etc...\ny European Commission\n- Liberalization in EC mandatory in 1998\n- New regulatory framework since July 2003\n\n(c)Lehr, 2004\nInternational trend\nduring 1990s to\nprivatize/liberalize\ntelecommunications\nFigures removed for copyright reasons.\nSource: ITU Review of Regulatory Frameworks (1998), WTD98 - Doc. 32\n-\nFigure 1.1 \"New laws adopted 1992-1997 and separate regulators.\"\n-\nFigure 1.3 \"Going private: Telecom privatizations, by number of transactions\nand by value 1984-1996 and by region.\"\n\n(c)Lehr, 2004\nEuropean Regulatory Framework\nGoal: Transition from communications law to competition law.\ny Convergence => from silos to platform competition with symmetric\nobligations.\ny As competition emerges, roll back regulation\ny Mandatory access to \"monopoly\" facilities during transition\nThree stage effort:\ny Analyze state of competition: Is there market power (SMP)?\n- 18 Markets: 7 Retail (Universal Service), 11 Wholesale\n- If no, then deregulate\ny If yes, then craft remedies consistent with EC Framework\n- National findings subject to EC rules\n- Ex ante controls justified to support transition\ny Impose remedies\n- Unbundling, line of business restrictions (separate subsidiary)\n\n(c)Lehr, 2004\nEuropean Regulatory Framework: Markets for Assessing Power\n\nRetail Level (universal service)\ny\n(1) Access to public telephone network at fixed location for residential customers\ny\n(2) same as (1) for for non-residential customers\ny\n(3) Publicly available local and/or natl telephone services provided at a fixed location for resid. customers\ny\n(4) Publicly available international telephone services provided at a fixed location for resid. customers\ny\n(5) same as (3) for non-residential customers\ny\n(6) same as (4) for non-residential customers\ny\n(7) Minimum set of leased lines (which comprises the specified types leased lines up to and incl 2Mb/sec)\n\nWholesale Level (interconnection)\ny\n(8) Call origination on public telephone network provided at fixed location\ny\n(9) Call termination on individual public telephone networks provided at a fixed location\ny\n(10) Transit services in the fixed public telephone network\ny\n(11) Wholesale unbundled access (including shared access) to metallic loops and sub-loops for purposes\nof providing voice and broadband services\ny\n(12) Wholesale broadband access ('bit-stream' access that permit 2-way transmission of broadband data)\ny\n(13) Wholesale terminating segments of leased lines\ny\n(14) Wholesale trunk segments of leased lines\ny\n(15) Access and call origination on public mobile telephone networks\ny\n(16) Voice call termination on individual mobile networks\ny\n(17) Wholesale national market for international roaming on public mobile networks\ny\n(18) Broadcasting transmission services, to deliver broadcast content to end-users\nSource: European Commission Directive, 11 February 2003 (2003/311/EC)\n\n(c)Lehr, 2004\nConvergence & Legacy Regulation\n\nTraditional networks were single purpose. Tight integration of services\nand infrastructure.\n\nNew broadband platforms support multimedia apps.\n\nFrom silos to hourglass: what to regulate?\ny Layered regulation...\nNet\nwo\nrk\nSer\nvi\nc\ne\nNet\nwo\nrk\nSer\nvi\nc\ne\nN\net\nw\nor\nk\nS\nerv\nice\nNe\nt\nwo\nr\nk\nSer\nvic\ne\n64 Kbbs channel\nVertical integration\nApplications\nHorizontal integration\nBitways\nNetwork\nservices\nApplications do not share\nmuch with each other\nApplications share\nnetwork services with each other\nApplications\nFigure removed for copyright reasons.\nSee http://www.nap.edu/openbook/0309050448/html/53.html\nFigure 2.1 in National Research Council.\n\"Realizing the Information Future: The Internet and Beyond.\"\nNational Academies Press, 1994.\n_____________________________________________\n\n(c)Lehr, 2004\nConvergence: Broadcasting v. Telecom\nBroadcasting: content regulation\ny Local content (national public broadcasting)\ny Free speech/editorial responsibility (libel)\ny Decency/censorship\ny Is the \"Internet\" broadcasting?\nTelecom: conduit regulation\ny Common carriage: content not under control of carrier\ny Cable TV a broadcast or telecom service? or, something else?\ny Legacy incumbents v. Entrants: duty to serve? regulatory burden?\ny Fixed v. Mobile?\nFuture need regulatory symmetry.\ny Transition from legacy to future:\n- if competitive? then deregulate (goal of European/US frameworks)\n- but, what if not adequately competive?\ny From physical unbundling to service level/functional unbundling\n- \"Bit stream\" unbundling?\n\n(c)Lehr, 2004\nConvergence: Computers v. Telecom\n\nLegacy of separation: IBM v. AT&T\ny FCC Computer Inquiries and emergence of commercial networks\n\nInternet: U.S. government R&D funding (D/ARPA, NSF)\n\nComputers: regulation by standards and courts, but still regulation\ny Antitrust review (Microsoft, Worldcom/Sprint merger...)\ny Which interfaces are open?\n- Equipment v. Service providers?\n- OS v. Applications (Browser wars)\n- Hardware v. software (Software radio)\n\nWhere's the boundary? What's a telecom service?\ny Is Voice-over-IP a \"telephone service\"?\ny Should legacy regulation be imposed on emerging services?\ny Where is the network edge?\n- Unbundling customer premise equipment\n\n(c)Lehr, 2004\nWho are the regulators?\n\nNational Regulatory Authorities (NRAs): national telephone services\ny\nPost-privatization, so 1990s phenomenon in many countries.\ny\nHow independent are they? Whose interests do they protect?\n\nInternational Treaties: international interconnection\ny\nInternational Telecommunications Union (ITU)\ny\nWorld Trade Organization (WTO)\ny\nUnited Nations (UN)\n\nStandards Bodies and NGOs: industry standards and interfaces\ny\nProfessional: IEEE (P802)\ny\nNational: ANSI (US), JISC (Japan), AFNOR (France)\ny\nInternational: ISO, IEC, ITU-T, WIPO\ny\nRegional: CEN/CENELEC (European), ETSI\ny\nTrade Associations and NGOs: EIA, W3C, ATM Forum\n\nCourts: common law v. civil law countries\ny\nProperty rights (intellectual property)\ny\nContracts (negotiated interconnection)\ny\nAntitrust (mergers, anticompetitive behavior)\n\n(c)Lehr, 2004\nJurisdiction: who's in charge?\n\nProblems are inherently multi-domain.\ny\nUbiquitous connectivity and Death of distance\ny\nGlobal networks, global traffic, global eCommerce\ny\nNot just about communications anymore (Civil Society, International Trade)\ny\nComplexity is endemic in converged world\n\nJurisdiction: Local Autonomy v. Coordination\ny\nRegional (Lehr & Keissling, 1999)\n- Europe: European Commission (EC) vs. National Regulatory Authorities (NRAs)\n- US: FCC v. state PUCs (vs. local franchising authorities)\ny\nInternational\n- International Settlements for Telecom: WTO(1997) v. FCC\n- UN, ICANN, and Internet governance\n\nAmbiguity is costly\ny\nRegulatory uncertainty raises investment/participation costs.\ny\nEncourages venue shopping/rent-seeking\ny\nBut, political reality is that it is not going away.\n\n(c)Lehr, 2004\nStandardization as form of regulation\n\nStandards define markets\ny\nCompetitive advantage (whose technology is adopted?)\ny\nScale and scope economies (bigger markets, lower costs)\ny\nWholesale competition/unbundling opportunities at interfaces\n\nEconomics of standards setting: externalities & coordination failures\ny\nNetwork externality: value to each subscriber increases with total\nsubscribership (e.g., PCs, telephone networks, language)\ny\nRole for government to solve market failure:\n- \"Horses, Penguins, and Lemmings\" (Farrell & Saloner, 1985)\n- \"Narrow Windows, Blind Giants, and Angry Orphans\" (David, 1986)\ny\nMobile Standards:\n-\n2G in Europe (GSM) v. US (GSM, CDMA, TDMA, etc.)\n-\nWhat about 3G? CDMA2000 v. W-CDMA. What about WiFi?\n\nSDOs are political institutions\ny\nWho gets to participate, public access to debate\ny\nHow is \"consensus\" measured (voting?)\ny\nRules that protect access/prevent capture slow progress\n\n(c)Lehr, 2004\nCourts and Antitrust Enforcement\n\nUS: Department of Justice v. FCC; Europe: DG Competition v. DG Information Society\n\nAntitrust: prevent abuse of monopoly power\ny\nBlock mergers that create market power\ny\nPenalize behavior that abuses (predatory pricing, illegal tying)\ny\nMarket power not illegal per se, only its misuse.\n\nMeasuring market power is contentious\ny\nDefine markets\n-\nHorizontal markets: are goods substitutes?\n-\nVertical markets: complements? Essential?\ny\nAbility to sustain price above cost for significant time\n-\nPotential entry can constrain (entry barriers?)\n\nPredatory pricing/illegal tying or Efficient pricing? Ambiguous economics.\ny\nPricing below cost, but what is cost?\n-\nHard to measure when shared/common costs, rapid technical progress\n-\nDynamic pricing with externalities, learning\ny\nComplementary bundling of products or illegal tying\n-\ne.g., Microsoft browser and OS\n\nAntitrust regulation is ex post\ny\nPresumption that industry competitive\ny\nNo role (limited role) for industrial policy: encourage transition to competition, promote\ninfrastructure investment. (Varies by country)\n\nEnforcement via Courts presumes litigation is established business option\n\n(c)Lehr, 2004\nSumming Up\nWhy regulate telecoms: the policy agenda - not just telecom\ny More important & more complex relationship to economy.\ny Lots of historical legacies (for better or worse).\nHow regulate telecoms: from utility regulation to competition\ny Managing the transition difficult: how fast to liberalize?\ny Facilities-based competition needed to enable deregulation\ny Is competition viable everywhere? New \"bottlenecks\"?\nWho regulates telecoms: the institutions\ny Complex global array: NRAs, SDOs, Courts\ny Jurisdiction: tension between global coordination and local\nautonomy"
    },
    {
      "category": "Resource",
      "title": "mod3a_intro.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-68j-communications-and-information-policy-spring-2006/6dcba3f123fc5b94612f0c44224dabf9_mod3a_intro.pdf",
      "content": "ESD.68 Lecture Notes\nMarch 2, 7, 9 & 14 (Lehr) - Spectrum Policy\nThis module of four lectures will focus on the rationales for regulating radio frequency\n(RF) spectrum and current topics associated with the reform of the mechanisms.\nWe will begin by considering the history of spectrum regulation and the evolution of\nwireless services from command and control assignment to auctions to the current debate\nover spectrum commons versus property rights. This will include discussion of issues\npertaining to the economic and public polic y rationales for spectrum regulation and\nwhy/ how traditional mechanisms need to be modified in light of evolving technical and\nindustry trends for wireless services. We will then move on to an introduction to the\ncurrent debate over regulatory models to support licensed and unlicensed spectrum and\nproposals for spectrum management reform under consideration in the United States and\nEurope.\nAssigned Readings for this module include :\nHazlett, Thomas (2001), \"The Wireless Craze, The Unlimited Bandwidth Myth, The\nSpectrum Auction Faux Pas, and the Punchline to Ronald Coase's \"Big Joke\" An Essay\non Airwave Allocation Policy,\" AEI-Brookings Joint Center for Regulatory Studies,\nWorking Paper 01-01, January 2001.\nFaulhaber, Gerald and David Farber. 2002. \"Spectrum Management: Property Rights,\nMarkets and the Commons.\" Wharton School Working Paper, University of Pennsylvania\n(presented at TPRC October 2002).\nKolodzy, Paul, Spectrum Policy Task Force, Office of Engineering & Technology,\nFederal Communications Commission, November 2002.\nKwerel, Evan and John Williams, \"A Proposal for a Rapid Transition to Market\nAllocation of Spectrum,\" OPP Working Paper #38, Federal Communications\nCommission, November 2002.\nWilliam Lehr, \"Economic Case for Dedicated Unlicensed Below 3GHz,\" mimeo, 2004.\nSome questions to consider include:\n- Please comment on the benefits/problems associated with traditional spectrum\nmanagement policies.\n- What ought to be the appropriate goals (roles) for spectrum manageme nt policy?\n- What has changed in wireless technology, markets, and regulatory policy to make\nspectrum reform more likely today? What are the biggest challenges to achieving\nspectrum reform?\n\n- Do you agree with the FCC's Spectrum Policy Task Force's recommendations\nregarding how policy should be reformed? Is this applicable elsewhere around the\nglobe (e.g., in the developing world)?\n- What are the benefits/problems with:\n- Spectrum auctions\n- Property rights applied to spectrum\n- Unlicensed spectrum access\n- What are the benefits (costs) of allocating spectrum to unlicensed use instead of\nlicensed use? Which model has produced more benefits to date? Is likely to produce\nmore benefits in the future?\nAdditional (Optional) Readings (both lectures) Include:\n(of these, the Marcus/WIK report provides a good recent summary overview of reform\npolicies in a number of countries).\nBaumol, William and Dorothy Robyn, \"Toward an Evolutionary Regime for Spectrum\nGovernance: Licensing or Unrestricted Policy?\", AEI-Brookings Joint Center for\nRegulatory Studies, 2006.\nBenkler, Yochai, \"Some Economics of Wireless Communications,\" presented at TPRC\nOctober 2002.\nCarter, Kenneth, Ahmed Lahjouji, and Neal McNeil, \"Unlicensed and Unshackled: A\nJoint OSP-OET White Paper on Unlicensed Devices and Their Regulatory Issues,\" OSP\nWorking Paper 39, Federal Communications Commission, May 2003.\nCave, Martin, \"Reforming UK Spectrum Policy,\" White Paper prepared for UK Spectrum\nManagement Review, March 2002.\nFarquhar, Michele C. and Ari Q. Fitzgerald, \"Legal and regulatory issues regarding\nspectrum rights trading,\" Telecommunications Policy, Volume 27, Issue 7, August 2003,\nPages 527-532.\nLehr, William and Jon Crowcroft, \"Managing a Spectrum Commons,\" IEEE DySPAN\n2005, Baltimore, November 2005.\nLehr, William, Sharon Gillett, and Fuencisla Merino, \"Software Radio: Implications for\nWireless Services, Industry Structure, and Public Policy,\" Communications and\nStrategies, IDATE, Issue 49 (1st Quarter 2003) 15-42.\nLehr, William and Lee W. McKnight \"Wireless Internet access: 3G vs. WiFi?,\"\nTelecommunications Policy, Volume 27, Issues 5-6, June-July 2003, Pages 351-370\n\nMarcus, J., Lorenz Nett, Mark Scanlan, Ulrich Stumpf, Martin Cave, and Gerard Pogerel,\n\"Towards More Flexible Spectrum Regulation,\" WIK-Consult, Germany, December\n2005.\nNoam, Eli, \"Beyond spectrum auctions. Taking the next step to open spectrum access,\"\nTelecommunications Policy, Volume 21, Issue 5, June 1997, Pages 461-475.\nOwen, Bruce and Gregory Rosston, \"Spectrum Allocation and the Internet,\" in William\nLehr and Lorenzo Pupillo Cyber Policy and Economics in an Internet Age, Kluwer\nAcademic Publishing: Boston, MA, 2002.\nOftel, Strategy for the future use of the Radio Spectrum in the UK, UK Spectrum\nStrategy Report, March 2002.\nWerbach,\nKevin,\n\"Supercommons:\nToward\na\nUnified\nTheory\nof\nWireless\nCommunication,\" mimeo, 2003.\nWerbach, Kevin, \"Radio Revolution: The Coming Age of Unlicensed Wireless,\" New\nAmerica Foundation, 2003."
    },
    {
      "category": "Lecture Notes",
      "title": "mod3a_lec1.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-68j-communications-and-information-policy-spring-2006/28f4e4a0b6589971551de37ac07bdddd_mod3a_lec1.pdf",
      "content": "(c)Lehr, 2006\nSpectrum Policy Lecture #1:\nSpectrum Management Reform\nWilliam Lehr\nMassachusetts Institute of Technology\nESD 68 :\nCommunications and Information Policy\nMassachusetts Institute of Technology\nMarch 2, 2006\n\n(c)Lehr, 2006\nOutline\nWhy regulate spectrum?\ny What wireless used for?\ny History of wireless technology\ny Broadcasting regulation\nWireless industry trends and pressure for policy reform\ny Changing technology, industry and regulatory context\ny Spectrum management models\ny History of spectrum reform in US\nStakeholders and Issues\ny Who are the stakeholders?\ny What are some of the issues?\n\n(c)Lehr, 2006\nWhat wireless used for?\nBroadcast TV & radio (AM, FM, DBS, PAL; terrestrial & satellite)\nSensing, Imaging, Location (GPS, satellite photo, radar, x-ray)\nCommunications (distance/area coverage)\ny WAN: cellular telephony (AMPS, GSM, CDMA, Satellite)\ny MAN: fixed wireless data (Microwave, LMDS, 802.16 WiMAX)\ny LAN: local area data nets (802.11x WiFI)\ny PAN: cable substitutes (Bluetooth, IRDA, Zigbee)\nAll use RF Spectrum:\ny Who gets to use it, for what services, when?\ny Managing interference\n- Intentional v. Unintentional Radiators (microwave, computer CPUs, etc.)\n\n(c)Lehr, 2006\nRF Spectrum\n\nRadio spectrum (3Khz-300GHz): when Frequency , then\ny .. bandwidth (info carrying capacity)\ny .. wavelength (antenna )\ny .. propagation (rain fade , Power Law)\n\nLine of sight?\ny Below 3GHz: not needed\n- Communication services (cellular, pagers)\n- Broadcast services (radio, TV)\ny Above 3 GHZ: needed\n- Point-to-point (e.g., wireless fiber @ 70GHz)\n\nSpectrum at different RF imperfect substitutes\ny But, usable spectrum expanded over time\ny Technology increases substitutability & opportunity cost\n\n(c)Lehr, 2006\nNeed Multiple Wireless Networks\nBandwidth\ny Control: <10Kbps (monitoring, signaling)\ny Real-time communications: < 100Kbps (telephone)\ny Broadband: 10-100s Mbps (streaming video)\nCoverage (power)\ny PAN (few feet), LAN (on campus, in home), MAN (metro), WAN (satellite)\nArchitecture\ny Broadcast: one transmitter to many receivers\ny 2-way: point-to-point (fixed or mobile?)\ny Multipoint-to-multipoint (grid)\nHow integrated are different networks?\ny Lots of technology: incompatible standards, uses, etc.\n\n(c)Lehr, 2006\nHistory of Wireless Technology\nEarly technology\n\n1887: Hertz sends/receives radio waves\n\n1895: Marconi invents spark transmitter\n\n1912: Titanic and Ship radio\n\n1918: Armstrong invents superheterodyne receiver\nBroadcasting Age: AM radio  VHF TV  FM radio UHF TV\n\n1920: 100-watt KDKA starts broadcasting Pittsburgh\n\n1922: BBC formed. (1926/27 NBC and CBS formed)\n\n1928: Federal Radio Commission established\n\n1948: CATV for rural\n\n1951: CBS broadcasts in color\nWireless Communications: \"Push-to-talk\" AMPS  PCS  3G  WiFi\n\n1927: Wireless radiotelephone between Britain and US\n\n1946: \"Push-to-talk\" radio communications\n\n1983: Commercial AMPS (1G \"analog\") in Illinois\n\n1990/1: TDMA digital (2G \"digital\") overbuilds to AMPs. GSM in Europe.\n\n1994/5: PCS auctions in US\n\n1997: UMTS-Forum (3G \"wireless broadband\")\n\n1999: IEEE approves 802.11b (\"WiFi\")\n\n2000: WRC2000: UMTS/W-CDMA\n\n(c)Lehr, 2006\nWhy regulate spectrum?\n\nGovernment stewardship of public asset (airwaves)\n\nScarce resource => how to allocate when congested\ny Interference regulation\ny Regulation or markets (Ronald Coase)?\n- Market failure? e.g., International spectrum harmonization\n\nService/Industry structure regulation\ny Broadcast/Media Regulation (content/editorial)\ny Communications Regulation (common carrier)\n\nOther\ny Safety (harmful RF emissions)\ny Emergency services (policy access) & defense\ny Equipment licensing/certification (Trade policy)\ny Privacy, eCommerce, government revenues, etc.\n\n(c)Lehr, 2006\nHow spectrum regulated?\n\nGovernment owns spectrum --- \"national asset\"\ny\nDefense/government uses - major user\ny\nLicensed commercial applications - second (in US, about 6% spectrum below 3GHz)\ny\nUnlicensed - 2% of spectrum in use (amateur radio, science, WLANs)\ny\nUnregulated\n- \"What not forbidden is permitted\" or \"what not permitted is forbidden\"\n- e.g., Above 50GHz\n\nExpert federal agency: allocates and assigns spectrum, regulates services, general\ncompetition law\ny\nin US: NTIA (Government) & FCC (Commercial/Private); in UK: Ofcom\ny\ninternationally, ITU-T\ny\nrequires sophisticated engineering and technical oversight\n\nCommand & control (tight admin of freq bands) => flexibility\ny\nLicenses specify (1) service (content?); (2) technology; (3) Ownership (foreign,\ntransferability)\ny\nRenewal: Pro-forma or real review?\ny\nAllocation: assignment, fee, or auctions?\n\n(c)Lehr, 2006\nBroadcast/Media\n\nRadio & TV\ny\nBroadcast architecture: one-to-many\ny\nFree (advertiser supported) vs. Subscription (Pay-TV)\n\nAccess to media channels (scarcity)\ny\nPublic broadcasting\ny\nIn US: \"Free speech\" 1st Amendment\n\nContent diversity\ny\nIndustry structure? (Media cross-ownership rules, foreign ownership)\ny\nLocal content requirements\ny\nCensorship (filtering)\n\nCurrent Issues: Transition from analog PAL/NTSC => digital\ny\nHDTV?\ny\nOver-the-air vs. cable/satellite?\n\nContent (Media)/Conduit (Telecom) convergence\ny\nDoes Broadcast law apply to Telecoms or visa versa?\n\n(c)Lehr, 2006\nLegacy of Wireless Technology\nTransmitter & Dumb Receivers: frequency allocation\ny Armstrong: Superhet transceiver (1918).\n- Information modulated on carrier frequency.\n- Radio receiver demodulates signal and extracts information.\ny Multiple signals arriving at receiver, receiver cannot extract useful\ninformation (other signals are regarded as noise)\ny Assign a frequency band (channel) to specific use in each area\ny Range: S/N above floor at farthest receiver. Non-uniform signal\ndensity\nSpectrum coordination/management needed to limit\ndestructive interference\ny Exclusive frequency allocation/assignment in\ngeographic areas\n\n(c)Lehr, 2006\nLots of Wireless Technology\nAll along the RF spectrum (different RF not perfect substitutes)\ny Microwave\ny Satellite (geosync, LEO)\ny Mobile 2G => 3G (4G?)\ny WLANs (e.g., WiFi) => WISPs and MESH (Tropos)\ny BWFA: MMDS => Alvarion => WiMax (802.16)\ny Free Space Optics, UWB, etc.\nLots of complementary technology\ny Smart antennas, software radio, MUD, ad hoc routing, mesh\nnetworking, OFDM, etc.\n\n(c)Lehr, 2006\nTechnology => Spectrum Efficiency AA\n\nDigital signal processing: From analog to digital \"0s & 1s\"\ny Regenerate, not amplify\ny Moore's Law\ny Computation instead of digitization (spread spectrum)\ny Multimedia\n\nNetworking and Communications Theory\ny Mobile routing. Smaller cell sizes\ny Modulation and signal processing\n\nInformation Theory:\ny Capacity channel proportional to bandwidth (Shannon)\ny Multiuser theory => cooperation gain. Wireless grids.\n\nSmart antennas (spatial diversity, multipath can help)\n\nSoftware radios (cognitive radios: smart edge devices)\n\n(c)Lehr, 2006\nChanging industry/regulatory context\n\nMerging of computing & communications\ny WWII-1960s: Mainframes & dumb terminals\ny 1970s: Minicomputers & distributed processing\ny 1980s: PCs and LANs (edge-based computing)\ny 1990s: Internet (data services for masses) and Mobile Cellular (wireless\nservices for the masses)\ny 2000s: Wireless broadband (3G, WiFi, Satellite, etc.)\n\nMerging of wireless & wireline\ny Pervasive computing: always on, connected\ny Mobility: ubiquity, flexibility, portability (nomadicity)\n\n(c)Lehr, 2006\nChanging industry/regulatory context\n\nFrom regulation to markets\ny Global trend towards privatization, liberalization\ny Transport (airlines, RR), Gas/electric power, banking, and telecoms\ny Inefficiency of government:\n- Soviet-style central planning vs. Western Capitalism\n- Slow: non-responsive to innovation\n- Vulnerable to capture/rent-seeking\n- Coase & Chicago School: Property rights & markets\n\nTelecom Crash of 2000\ny dot-com bomb: collapse in demand\ny Spectrum auctions (3G)\ny Worldwide recession (telecom/IT capital intensive)\n\n(c)Lehr, 2006\nImplications of Wireless Technology\nIncreased performance\ny Spectral efficiency, NLOS, Improved reliability/security/QoS\nLower costs\ny Moore's Law, Scale/scope economies, Standardization.\ny New architectures.\nDistributed control\ny MESH networks, edge-based networking => toward cognitive radio\ny Towards smart radio systems (antennas, receivers)\nWireless everywhere..\ny WPANs, WLANs, MANs\ny Fixed & Mobile\n\n(c)Lehr, 2006\nWireless Industry Trends\n\nStandardization:\ny\nProprietary physical layers giving way to few industry standards (3G, 802.11,\n802.16). Driven by chip economics.\n\nTrade-off between bit rate and reach & cost deploy\ny\nRooftop antennas => high speed, long-reach\ny\nDesktop antennas => inexpensive deployment (and need to address mobility\n=> PC cards, PDAs, etc.)\n\nCompeting architectures: Large cell v. Small cell\ny\nLarge => long reach => few cells => wired backhaul (Alvarion)\ny\nSmall => short reach => lots of cells => wireless backhaul or mesh (Tropos)\ny New designs include QoS capability (VoIP)\n\nMerging of wireless & wireline\ny Pervasive computing: always on, connected\ny Mobility: ubiquity, flexibility, portability (nomadicity)\n\nMultiple models for spectrum mgmt: Unlicensed v. Licensed\ny\nUnlicensed => rapid, low-cost entry for WISPs\ny\nLicensed => better protection against congestion (QoS)\n\n(c)Lehr, 2006\nWhy spectrum reform now?\nLots of new technology and services that are being held back by\nlegacy regulations...\ny Insufficient spectrum for commercial use\ny What is available, is not used efficiently\ny License rules limit market flexibility\nProblem: Artificial spectrum scarcity!\ny Sharing opportunities missed\ny Innovation blockaded: services, devices, and business models\ny High marginal cost for spectrum (auctions bankrupt providers)\nSolution: Spectrum Reform...\n\n(c)Lehr, 2006\nGoals for Spectrum Policy Reform\n\nEliminate artificial scarcity: introduce market forces\ny Flexible use, secondary market trading\n\nAccelerate wireless broadband revolution\ny Convergence of Internet & wireless\ny Promote evolution from 2G to 3G\n\nPromote adoption of advanced technology\ny Refarm underused spectrum to high value uses\ny Enable new capabilities, promote investment (smart receivers)\n\nLast mile bottleneck: unleash 3rd mile competition\ny New, low cost infrastructure in developing world\n\nEnable new business models:\ny MVNOs and value-added service providers\ny Wireless grids and edge-based networks\n\n(c)Lehr, 2006\nSpectrum Management Models\nThree basic models:\ny Command & Control: (legacy model under attack)\n- Technology, provider, services specified by regulator\ny Exclusive license: \"Property rights\"\n- Flexible, transferable licenses to operate in area/band.\n- Licensee chooses technology, services\n- Secondary markets: licensee can trade rights to third parties\ny Unlicensed: \"Commons\"\n- Underlay: UWB, Part 15 devices (secondary use)\n- Opportunistic: interleaving, use white space (secondary use)\n- Dedicated: ISM 2.4 and 5 GHz bands used by WiFi\nPolicy recommendation: increased reliance on exclusive licensed\nfor scarce spectrum or commons otherwise\ny Especially for spectrum below 3GHz\n\n(c)Lehr, 2006\nSpectrum Mgmt in U.S.: a brief history\n\npre-1927: Priority in use, Commons model\ny\n(Radio Act 1912: spectrum use requires Federal license)\n\nRadio Act 1927, then Communications Act 1934: Exclusive use\ny\nFederal agency (FCC) manages commercial spectrum, NTIA manages government.\ny\n(1) Block Allocation; then, (2) Assignment\n-\nExclusive use, restrictive licenses: Technology/Service/Build-out/Transferability all limited by FCC\n-\nMinimum frequency allocation per license to deliver service.\n-\nInterference model based on capabilities of dumb receivers\ny\nUnlicensed for low power, not valuable spectrum\n\nSlow trend towards liberalization\ny\nWaivers, Private management interference, sharing, overlays\n\nAuctions authorized in 1993 for license assignment.\ny\nBeauty Pageant (1927-1981), then lotteries (1981-1993)\n\nTelecom Act 1996\ny\nEliminate cap for non-broadcast licenses; increased flex for broadcast spectrum use; and authorized\nspectrum fees\nA history of \"regulatory capture\" by broadcast industry (Hazlett, 2001)\ne.g., AM blocks FM (1930s), Du Mont fails (1950s), VHF blocks CATV (1960s), etc.\n\n(c)Lehr, 2006\nSpectrum Management and Wireless Markets\n\nBroadcasting Spectrum (exclusive, inflexible licenses) - example of problem\ny\nArchitecture for high power transmission for over-the-air broadcasters uses (low power)\nspectrum inefficiently\ny\nMove terrestrial TV to satellites or wires (cable)\ny\nEncourage development of smart receivers\ny\nLegacy of using \"interference\" threat to oppose competition (FM radio, UHF broadcasting)\nand slow to deploy new technology (digital TV conversion)\ny\nWhat about over-the-air digital TV?\n\nMobile Telephone Services (exclusive, (semi)-flexible licenses) - success!\ny\nPoster child for competition success: consumer choice, declining prices, service innovation.\ny\nUse spectrum very efficiently. Lots of sharing.\ny\nAllocated via auctions (but what about 3G auctions and telecom meltdown in 2000?)\ny\nBenefits of mandating a single standard? 2G in Europe v. US\ny\nFurther growth constrained by lack of access to available spectrum\n\nWiFi success (open access, unlicensed) - success!\ny\nPower limits on equipment. No exclusive right to interference protection.\ny\nCongestion emerging as problem.\ny\nIs this model generalizable?\n\n(c)Lehr, 2006\nStakeholders in Spectrum Debates: perspective?\n\nUsers: Commercial: consumers & businesses (small/large) v. Govt.\n\nProviders - Value chain...\ny Equipment: chips, software, edge and network hardware and\nsoftware\ny Network service providers: mobile, BWFA, DBS\ny Content/Application providers: Hollywood, music, games\n\nRegulators/governments\n\nIndustries: Broadcast v. Telecom (Internet) v. Users\n\nEntrants v. Incumbents\n\nNations (and w/in nations, cities v. states v. feds; member states v. EC)\n\n(c)Lehr, 2006\ne.g., Why is govt spectrum different from commercial?\n\nIn US and abroad: largest share of spectrum is government\n\nGovernment spectrum:\ny US: NTIA  government spectrum; FCC commercial\ny Government: Defense, Public safety, Aviation, NASA, Agriculture, etc.\n\nCommercial v. Government\ny Profit/Competition v. Mission/Bureaucracy\ny Trade and business law v. Constitution/treaties\n\nBut if spectrum is scarce, shouldn't all users bear opportunity cost?\ny Resources that have alternative uses have value.\ny Opportunity Cost = Value in next best use\ny WHAT IS VALUE? HOW TO ESTIMATE?\n\n(c)Lehr, 2006\nSumming Up\n\nWireless industry and technology: rapid growth and seismic changes\ny\nFrom analog  digital\ny\nFrom broadcast  communications  multimedia\ny\nFrom dedicated to shared use\n\nFrom regulation to markets: deregulation\ny\nPromote innovation, investment, and competition\ny\nKey issues:\n- (1) Markets v. Regulation\n- (2) Auctions v. Free Use\n- (3) Spectrum scarcity & transaction costs\n- (4) Defining interference\n- (5) Industry structure and models for management\n- Transition politics, Windfall Gains\n- (6) International Coordination\n- (7) Commercial v. government spectrum use\n\nBalancing stakeholder interests\n- Incumbents v. Entrants\n- Service providers v. equipment makers\n- Suppliers v. end-users (existing or new apps?)\nHow best to introduce market forces:\n* Managing the transition?\n* Licensed v. Unlicensed models?"
    },
    {
      "category": "Lecture Notes",
      "title": "mod3a_lec2.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-68j-communications-and-information-policy-spring-2006/ff21554a097a1aa8f342bb498a5753f9_mod3a_lec2.pdf",
      "content": "(c)Lehr, 2006\nSpectrum Policy Lecture #2:\nSpectrum Management Reform\nWilliam Lehr\nMassachusetts Institute of Technology\nESD 68 :\nCommunications and Information Policy\nMassachusetts Institute of Technology\nMarch 8, 2006\n\n(c)Lehr, 2006\nOutline\nWhy spectrum reform now: a recap..\nModels of spectrum regulation\nProperty Rights v. Commons\ny Simplistic view\ny More complicated view\n\n(c)Lehr, 2006\nWhy spectrum reform now?\nLots of new technology and services that are being held back by\nlegacy regulations...\ny Insufficient spectrum for commercial use\ny What is available, is not used efficiently\ny License rules limit market flexibility\nProblem: Artificial spectrum scarcity!\ny Sharing opportunities missed\ny Innovation blockaded: services, devices, and business models\ny High marginal cost for spectrum (auctions bankrupt providers)\nSolution: Spectrum Reform...\n\n(c)Lehr, 2006\nGoals for Spectrum Policy Reform\n\nEliminate artificial scarcity: introduce market forces\ny Flexible use, secondary market trading\n\nAccelerate wireless broadband revolution\ny Convergence of Internet & wireless\ny Promote evolution from 2G to 3G\n\nPromote adoption of advanced technology\ny Refarm underused spectrum to high value uses\ny Enable new capabilities, promote investment (smart receivers)\n\nLast mile bottleneck: unleash 3rd mile competition\ny New, low cost infrastructure in developing world\n\nEnable new business models:\ny MVNOs and value-added service providers\ny Wireless grids and edge-based networks\n\n(c)Lehr, 2006\nSpectrum Management Models\nThree basic models:\ny Command & Control: (legacy model under attack)\n- Technology, provider, services specified by regulator\ny Exclusive license: \"Property rights\"\n- Flexible, transferable licenses to operate in area/band.\n- Licensee chooses technology, services\n- Secondary markets: licensee can trade rights to third parties\ny Unlicensed: \"Commons\"\n- Underlay: UWB, Part 15 devices (secondary use)\n- Opportunistic: interleaving, use white space (secondary use)\n- Dedicated: ISM 2.4 and 5 GHz bands used by WiFi\nPolicy recommendation: increased reliance on exclusive licensed\nfor scarce spectrum or commons otherwise\ny Especially for spectrum below 3GHz\n\n(c)Lehr, 2006\nSpectrum Management and Wireless Markets\n\nBroadcasting Spectrum (exclusive, inflexible licenses) - example of problem\ny\nArchitecture for high power transmission for over-the-air broadcasters uses (low power)\nspectrum inefficiently\ny\nMove terrestrial TV to satellites or wires (cable)\ny\nEncourage development of smart receivers\ny\nLegacy of using \"interference\" threat to oppose competition (FM radio, UHF broadcasting)\nand slow to deploy new technology (digital TV conversion)\ny\nWhat about over-the-air digital TV?\n\nMobile Telephone Services (exclusive, (semi)-flexible licenses) - success!\ny\nPoster child for competition success: consumer choice, declining prices, service innovation.\ny\nUse spectrum very efficiently. Lots of sharing.\ny\nAllocated via auctions (but what about 3G auctions and telecom meltdown in 2000?)\ny\nBenefits of mandating a single standard? 2G in Europe v. US\ny\nFurther growth constrained by lack of access to available spectrum\n\nWiFi success (open access, unlicensed) - success!\ny\nPower limits on equipment. No exclusive right to interference protection.\ny\nCongestion emerging as problem.\ny\nIs this model generalizable?\n\n(c)Lehr, 2006\nFuture is shared spectrum:\ndecoupling spectrum frequencies from\ninfrastructure investment & applications\nTechnology\n(Capabilities)\nSmart radio systems, spread spectrum, transition to\nbroadband platform architectures \nfrequency agility, expanded capacity for sharing\nRevenue\n(Customer experience)\nHeterogeneous networks (3G/WiFi, wireless/wired, global\nroaming)  24/7 availability, simplicity of use, seemless\nmobility\nCosts\n(Network provisioning)\nBursty traffic, multimedia services, fat-tailed usage profiles\n lower costs, take advantage intermodal competition\nPolicy\n(Spectrum reform)\nTransition to expanded flexible market-based licensing and\nunlicensed spectrum mgmt regimes reduced artificial\nscarcity due to legacy regulations\n\n(c)Lehr, 2006\nProblem with Spectrum Mgmt: Artificial Scarcity\n\nStatus Quo regulation => Command & Control\ny\nBlocks efficient reallocation of spectrum\ny\nDistorts opportunity costs => innovation, investment, competition\n\nSolution: Transition to market forces\nLicensed\n(aka, \"Market Mechanism,\" \"Exclusive\nUse,\" or \"Property Rights\")\nUnlicensed\n(aka, \"License-exempt,\" \"Open,\" \"Free,\" or\n\"Commons\")\nExclusive use: \"right to exclude other\ntransmitters\"\nFlexible: choice of technology & rules\nused to manage spectrum\nTradable: transferable right, secondary\nmarkets\nNon-exclusive use: \"right to transmit\"\nFlexible: choice of technology\nconsistent with rules/etiquette\nCollective choice of rules:\nstandards/protocol (or government?)\nFlavors of Unlicensed:\n-Underlay: UWB, Part 15 devices (secondary use)\n-Opportunistic: interleaving, use white space (secondary use)\n-Dedicated: ISM 2.4 and 5 GHz bands used by WiFi (\"Part 15\")\n\n(c)Lehr, 2006\nCurrent Trajectory for Reform\n\nFrom status quo C&C => flexible, tradable, exclusive licenses\n\nUnlicensed for low-power, low-range uses (<100m)\ny\nLimited allocation below 3Ghz\ny\nUnderlays and Overlays (??), Dedicated @ 5GHz\nSource: Ofcom Spectrum Framework Review, Nov04.\nCourtesy of Ofcom.\n#1: Need exclusive licenses (and secondary markets) to\nmanage when scarce (if not scarce, then unlicensed best...)\n#2: Unlicensed (decentralized, commons) suitable only\nfor managing short distance, low cost of congestion\n\n(c)Lehr, 2006\nProperty Rights v. Commons, part I (naive view)\nProperty Rights\nCommons\nView?\nTransfer control to private\nsector via exclusive &\nflexible licenses defined over\nfrequency blocks\nGovernment-mandated\ncommunnal/\"open access\" use\nfor large frequency blocks\nSupporters?\nKwerel, Fahlhaber, Farber,\nHazlett, Cave -- economists\n& regulators\nLessig, Noam, Reed, Benkler,\nPeha -- engineers and lawyers\nSpectrum scarce?\nYes\nNo\nPay for spectrum?\nAuctions\nNo, \"free\" to be shared\nMarkets or regulation? Markets\nRegulation\nNetwork architecture\nNetwork-centric, centralized\ncontrol, service provider\nmodel\nEdge-centric, distributed\ncontrol, customer equipment\nmodel\nWhat to do with\nincumbents?\nLet them keep windfall. Cost\nof transition.\nA detail. Buy them off if\nnecessary.\nManagement? Use?\nCentralized, single\nDecentralized, communal\nFalse dichotomy and overly simplistic clustering of issues...\n\n(c)Lehr, 2006\nLicensed v. Unlicensed (simplistic view)\nMarkets\nGovernment\nAuctions\nFree\nScarce\nAbundant\n\nSpectrum scarce: use markets => exclusive licenses\ny\nEliminate command & control. Transition to market forces. Allocate initially with auctions.\ny\nDefine property rights that may be flexibly traded in secondary markets\n\nSpectrum abundant: conserve transaction costs => unlicensed\ny\nNo need to incur overhead of property rights regime to allocate\ny\nProvide open access.\n\nCoordination costs\ny\nSmall area (low power) (e.g., within home) => coordination costs without centralized\nenforcement are low => unlicensed fine\ny\nLarge area (high power) (e.g., metro mobile) => coordination costs high, spectrum and\nnetwork are co-specialized => use licensed\n\nConclusion: (1) Flexible licensed for scarce (low-frequency) spectrum; and (2)\nUnlicensed access via secondary use (underlays, overlays)\n\n(c)Lehr, 2006\nCommons v. Property Rights, part II\nSome common themes, falsely dichotomized...\ny Markets v. Regulation\ny Auctions v. Free Use\nReal differences that may be relevant...\ny Spectrum scarcity\ny Frequency bias v. other ways to define \"spectrum\"\ny Network v. Edge/ Service v. Equipment\n\n(c)Lehr, 2006\nMarkets vs. Regulation\nCommon themes, false dichomomy\n\nSimplistic: \"Markets vs. Collective/Central Planning\"\n\nMarkets could adopt commons-sharing protocol if efficient\ny Fahlhaber's \"Public Parks\"\n\nSpectrum Courts could replace administrative in either model\n\nRegulation in any case\ny By property rights or by administrator\ny Courts not cheaper than government necessarily\ny Government role does not disappear\n- Comm Act '34  cannot alienate public ownership. Periodic review built in.\n- Realpolitik concerns associated with transition\n- On-going need to manage/enforce interference management\n\nAnd, what if \"spectrum\" is a public good?\n\n(c)Lehr, 2006\nSpectrum a public good?\nPublic goods are (1) non-rival; (2) non-excludable\ny Technology: made more public-goods like?\n- Non-Rival: Ability to share \n- Excludability: GPS , Ubiquity of radios \ny Technology favors commons now?\nExcludable\nNon-excludable\nRival\nPrivate Property\nCommon Pool\nResource\nNon-rival\nClub Good\nPublic Good\n\n(c)Lehr, 2006\nAuctions vs. Free Use\nCommon themes, false dichomomy\n\nIf scarcity, need to allocate and opportunity cost is borne. How\nfinanced/paid for is separable matter.\n\nAuctions achieve efficient assignment\ny Not necessarily if (1) market power; (2) capital market\ninefficiencies; (3) irreversible investments & uncertainty (lock-in).\ny Only for first assignment (also need efficient secondary markets)\n\nCould use fee mechanism to charge for access. Could have admission\ncontrol for access to congested commons.\n\nIf spectrum revenue collected, who gets it?\ny General fund or keep in sector (e.g., auctions as general tax\nmechanism)? Is a \"spectrum tax\" efficient?\n\n(c)Lehr, 2006\nSpectrum scarcity?\nReal differences that may be important..\n\nWhat can technology do?\ny\nSmart receivers, MUD, etc. increase capacity\ny\nNeed to maintain innovation and adoption incentives.\n\nNo scarcity, then no need for property rights\ny\nReturn to pre-1912 world for RF.\n\nEven if scarcity, commons may be more efficient\ny\nOpen access/unlicensed instead of frequency-area licenses\n\nBut, can we be certain?\ny\nHow to protect sunk investment? (What is value of capital equipment?)\ny\nCannot have free resource that is substitute for other costly resources (computation v.\ntransport v. storage)\ny\nIs commons more easily reversible? (Interest group politics v. \"Takings\")\ny\nMarkets or regulation redux\n\n(c)Lehr, 2006\nSpectrum scarcity is matter of perspective\nC&C, subsidized licensed\nUnlicensed\nHigh\nLicensed\nLicensed/Unlicensed ??\nLow\nStrong\nWeak\nInterference Protection Needed\nTransaction\nCosts\n(relative to value)\nUser/Use ...\nSmart radio systems:\nGreater interference robustness\nMore sharing options\nMarket success:\nMore congestion\nFast innovation\nOff-diagonal cases more common? Weak/low or Strong/high\nDynamic shared spectrum options\nMultiple, complementary regulatory options\n\n(c)Lehr, 2006\nHow to define interference?\nReal differences that may be important..\n\nWho is causing the harm?\ny Legacy: Tx cause interference with Rx\ny New view: Dumb Rx impose externality on smart Rx\ny Ronald Coase: question of perspective, how you define property rights\n\nHow to regulate?\ny Legacy: Restrict inputs (power limits) to limit outcomes (interference)\ny New view: Specify outcome limits (spectrum temp, receiver standards)\n\nHow to implement?\ny Etiquettes (protocols) v. Prices v. Torts\ny Commons favors smart devices\n\n(c)Lehr, 2006\nNetwork/Service v. Edge/Equipment\nReal differences that may be important..\nWhich industry structure better?\ny Licensed/Property rights favors service providers.\ny Unlicensed/Commons favors equipment makers and end-users\nImplications for:\ny Competition & Market Power (foreclosure)\ny Innovation & Lock-in\ny Investment in infrastructure\ny Regulatory approach (mechanism design)\n\n(c)Lehr, 2006\nWLAN\n3G\nHow different...\nTechnology\nUMTS, CDMA-2000,\netc.\nWiFi (802.11b), etc.\nBandwidth\nLow (~100s Kbps)\nHigh (~10s Mbps)\nCoverage\nUbiquitous (Km)\nLocal (100m)\nDeploy Cost\nHigh (~$50k)\nLow (~$1k)\nSpectrum\nLicensed\nUnlicensed\nServices\nVoice adding data\nData adding voice\nRetail infrastructure\nYes, service model in\nplace\nNo, need to add\n\n(c)Lehr, 2006\nWireless Industry structure?\nWLAN\n3G\n\nTraditional Carrier Model\n\nTop Down\n\nVertically Integrated\n\nCentralized Control\n\nAccommodates Alternative\nPlayers\n\nBottom Up\n\nLess Vertically Integrated\n\nDistributed Control\nEnd-user Equipment Model\nEdge-centric\n(Internet vision)\nService Provider Model\nNetwork-centric\n(Bell system redux?)\nSubstitutes or Complements? WLANs Disruptive technology?\n\n(c)Lehr, 2006\nEquipment\nService\nExample?\nTelecom Services\nComputer\nBusiness model?\nInvest in capacity and\nlease access to\nconsumers for\nmonthly subscription\nservice\nSell boxes to\nconsumers who\nreplace when become\nobsolete\nWhere's network intelligence? Network\nEdge devices\nWhere's network CAPEX?\nService provider\nEnd-user\nInnovation adoption process?\nCentralized\nDecentralized\nWho controls services?\nService provider\nCustomers\nRegulatory?\nUtility regulation\nUnregulated,\nCertification, Industry\nStandards\nDifferent industry economics, institutional/regulatory history\n\n(c)Lehr, 2006\nPrivate Property v. Commons Debate\nPrivate\nProperty\nCommons\nResource is \"scarce\" (allocative efficiency)\n+\nFairness?\nAuctions?\nFees?\nTransaction costs high (relative to value)\n+\nCompactness : smaller community, reputation effects can work\n+\nProductivity : value of economic activity \n+\nComplexity : distance , need network with co-specialized\ninvestments\n+\nInnovation/investment incentives? (dynamic efficiency)\nNetwork\nproviders\nEquipment\nvendors\nSmart\nreceivers\nCompetition? (productive efficiency)\nIncumbents\nEntrants\n\n(c)Lehr, 2006\nLicensed v. Unlicensed (more complicated)\nMarkets\nGovernment\nAuctions\nFree\nScarce\nAbundant\n\nBoth consistent with markets, both still regulated\ny Unlicensed protocol can be chosen by SDO or markets\ny Enforcement via courts of license property rights is regulation by another\nmeans\n\nNo free lunch, but spectrum reform lowers opportunity cost\ny Transition, congestion, transaction costs must be borne\ny Auctions may be used to effect transition, but not to extract rents\nScarcity we observe is mostly \"artificial\"\ny Not driven by need to avoid \"interference\"\ny \"Exclusive licenses\" retain potential for artificial scarcity"
    },
    {
      "category": "Lecture Notes",
      "title": "mod3b_lec1.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-68j-communications-and-information-policy-spring-2006/e0657771f5fd2410e52b858055b06ca2_mod3b_lec1.pdf",
      "content": "5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nIntellectual Property:\nContent and Digital Telecommunication Policy\nFrank Field\nTechnology & Policy Program\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nIP as Policy Driver\nIncreasingly difficult to distinguish copyright policy\nand telecomm policy\n*Updates to the law of copyright - EUCD, DMCA\n*Updates to international treaties - TRIPS, WIPO\n*Subsidiary legislation and regulations\nSSSCA/CBDTPA & the \"Analog Hole\"\n\"Broadcast Flag\" and HDTV\n*Increased scrutiny of technologies & devices\n(CPRM; Trusted Computing; DVDCSS)\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nHow Did \"(c)\" Come To Be A Telecomm Issue?\nDerives from several sources\n*\nThe political economy of\ncopyright\n*\nThe nature of the legislative and\njudicial process\n*\nThe design of the digital\ncommunications network\nA complex interplay of interests ...\nLeading to a complicated set of\nhighly politicized problems\nFundamentally, a question of\ncontrol\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nCopyright - A Construct of the Law\nUSC, Title 17,  102. Subject matter of copyright: In\ngeneral\n(a) Copyright protection subsists, in accordance with this\ntitle, in\n*original works of authorship\n*fixed in any tangible medium of expression, now known or\nlater developed,\n*from which they can be perceived, reproduced, or otherwise\ncommunicated,\n*either directly or with the aid of a machine or device.\nWorks of authorship include the following categories:....\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nWhat An Odd Idea -- Why Does It Exist?\nCopyright is a So-Called \"Legislated Right\"\n*Exists Only as a Matter Of Law\n*Among the Most \"Strictly Constructed\" of Rights\n*Exception to Several Ideals of Enlightenment Polity\nAn Award of Monopoly Powers\nImposes Limits on Communication/Speech\nMoreover, the Limits are a \"Prior Restraint\"\nNot a Natural Right in most jurisdictions\n*Exception:\nContinental concept of \"droit d'auteur\" or \"moral rights\"\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nHistorical Context\n18th century\n17th century\n16th century\n15th century\n1445:\nGutenberg press\n1547:\nEdward VI grants\nmonopoly to King's\nprinter for certain works\n1707:\nScottish\npublishers act\nto break\nmonopoly\n1637:\nStar Chamber\ncodifies printing\n(registration, attribution, certification\nof content, copies to Bodley)\n1556:\nStationer's\nCompany\nestablished\n(powers to enforce monopoly, incl.\ninspection of content, customs, etc.)\n1694:\nMonopoly\ngrant expires\n(ongoing collusion among\nStationer's Council)\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nStatute of Anne - 1709/10\n\"An act for the encouragement of learning\"\nLegal protection for consumers of copyrighted works\n*Curtailment of the term of copyright\nStationer's Company Essentially Held Copyright In\nPerpetuity\nEffective Monopoly On What Would (and Could) Be\nPublished\n*Creation of a \"public domain\" for literature\nCopyright Only For New Works\nLimited Term\nLimited Copyright To Power To Print, Publish and Sell\n(i.e., control of the copy is relinquished once sold)\n*Copyright Belonged To The Author/Creator\nEssential Principles Maintained To Date\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nStatute of Anne Contentious Until 1774\n1769 - Millar v. Taylor\n*Publishers retain control over copyright \"forever\"\n1774 - Donaldson v. Beckett\n*Millar overturned\nMillar had sold his copyright to Beckett\n*Statute of Anne's limits on copyright terms upheld\n\"Modern\" copyright law established\n*Unanswered/unresolved:\n\"common law\" vs. \"statutory\" copyrights\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nIntellectual Property - Basis in US Constitution\nArticle I, Section 8, Clause 8:\nNote (arguable) parallelism\n*\"Author is to \"Science\" as \"Inventor\" is to \"useful Arts\"\nA notable Constitutional clause\n*Only enumerated power that also dictates how\nhow the power is\nto be exercised\nThe Congress shall have Power ...\nTo promote the Progress of Science and useful Arts,\nby securing for limited Times to Authors and\nInventors the exclusive Right to their respective\nWritings and Discoveries;\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nIntellectual Property - Basis in US Constitution\nArticle I, Section 8, Clause 8:\nNote (arguable) parallelism\n*\"Author is to \"Science\" as \"Inventor\" is to \"useful Arts\"\nA notable Constitutional clause\n*Only enumerated power that also dictates how\nhow the power is\nto be exercised\nThe Congress shall have Power ...\nTo promote the Progress of Science and useful Arts,\nby securing for limited Times to Authors and\nInventors the exclusive Right to their respective\nWritings and Discoveries;\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nControversial Monopoly Grant - T.Jefferson\nIf nature has made any one thing less susceptible than all others of\nexclusive property, it is the action of the thinking power called an\nidea, which an individual may exclusively possess as long as he keeps\nit to himself; but the moment it is divulged, it forces itself into the\npossession of every one, and the receiver cannot dispossess himself\nof it.\nIts peculiar character, too, is that no one possesses the less, because\nevery other possesses the whole of it. He who receives an idea from\nme, receives instruction himself without lessening mine; as he who\nlights his taper at mine, receives light without darkening me.\n... The exclusive right to invention [is] given not of natural right, but\nfor the benefit of society\nLetter to Isaac McPherson; August 13, 1813\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nCopyright: General Principle\nObjective:\n*Wide distribution of a diversity of creative expressions\nRecall: \"Learning\"\nDifficulty: Cannot sustain economic incentives to do so\n*High up-front costs in creation & setup for distribution\n*Negligible marginal costs in copying for distribution\n*Non-rivalrous good\nSolution: Award creators with monopoly powers\n*Marketable asset; Rents can be extracted\n*Use the power of the State to create/maintain scarcity\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nExclusive Rights Associated With (c)\n- Right to Copy\n- Right to Distribute\n1870 & 1909\n- Right to Make Derivative Works\n1856 & 1897\n- Right to Public Performance\n- Right to Public Display\n- Rights of Attribution and Integrity\n- Fixation and Trafficking in Sound\nRecordings and Music Videos\n- Right to Incorporate Technological\nProtection Measures\n- Right to Include Copyright Management\nInformation\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nWhat Is Covered?\nMovies\nBoat Hull Designs\nDrama, Paintings,\nDrawings & Sculpture\nArchitecture\nPhotographs\nDance\nMusic\nRecord & Tapes\nPrints\nComputer Programs\n1964,\nBooks, Maps & Charts\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nExceptions\nPractical exceptions\n*Monitoring exclusive rights excessive & intrusive\nCopying - \"Fair use\"\nCommerce - \"First sale doctrine\"\nPolitical exceptions\n*Mitigation of prior restraints on free speech\nCommentary and scholarship - \"Fair use\"\nPublic domain\n*Materials out of copyright usable by all\n*Raw material of new creations\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nExemptions to Copyright - Fair Use\nFigures removed for copyright reasons.\nBook cover: Weiner, Ellis, and Barbara Davilman.\nYiddish with Dick and Jane. New York, NY: Little,\nBrown & Co., 2004.\nNews coverage: Wyatt, Edward. \"Primer Spoof\nWith Yiddish Faces Suit (In English).\" New York\nTimes, 15 January 2005.\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\n\"Works of Utility\" -- Not Copyrightable\nMassachusetts Institute of Technology\nCambridge, Massachusetts\n\"Works of Utility\" -- Not Copyrightable\nFigures removed for copyright reasons.\nRecipes and cookbooks; clothing designs.\nFigures removed for copyright reasons.\nRecipes and cookbooks; clothing designs.\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nImplementation\nLegislature creates laws\n*\"Strict construction\" requires active development in\nthe face of changing circumstances\nAgencies develop regulations\n*Specifics of implementation\n*Institution for implementation\nConflicts among parties resolved by judiciary\n*Civil complaints - arguments about money\n*Criminal complaints - State intervention\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nJudicial Review - Key Implementation Issue\nCourts prefer NOT to make decision\n*Require an issue at conflict BEFORE taking a case\n*Moreover, will be \"strict constructionists\" wherever\npossible in IP\nA problem for the key exceptions to copyright\n*Even when obviously appropriate, fair use is\nfrequently challenged\nCosts of litigation\n\"Chilling effects\"\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nInternational Propagation\nMultilateral Treaties\n*TRIPS (trade-related aspects of intellectual\nproperty rights)\n*WIPO (World Intellectual Property\nOrganization)\nBilateral treaties, followed by calls for\n\"harmonization\"\nMassachusetts Institute of Technology\nCambridge, Massachusetts\n(c) Implicitly About Communication Technology\nChallenges to Notions of (Author's) Control\n*Printing Press\n*Player Piano\n*Music Boxes\n*Sound (Phonograph) Recordings\n*Radio\n*Videocassette Recorder\n*Audio Recording, Analog and Digital\nA Continuous Cycle of Development & Reaction\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\n(c) - A Technologically Sensitive Policy\nNew technologies routinely upset \"strictly constructed\"\nlegislated scarcity and exclusive distribution\n*New kinds of copying\nPlayer piano rolls\n*Reduced costs of copying\nPhotocopiers, tape recorders\n*Reduced costs of distribution\nRadio, CDs\nChallenge to maintain economic power\n(Engineered) Scarcity through control\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nClassical Control Elements in Copyright\nLegal limits: King's patent, copyright law\nEconomic limits:\n*Cost of printing press/orchestra/DVD plant\n*Cost to develop skills/know-how\nSocial responsibility\n*Concerns about stability of institutions:\nState, church, markets\n*Support of creators\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nControl - Lessig's \"New\" Chicago School\nArchitecture\nNorms/Culture\nLaw\nMarkets\nIndividual\nSee: Code and Other Laws of Cyberspace; Lawrence Lessig\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nArchitecture - Technology As Policy\nDeployment of technologies as a method to achieve\nparticular goals\nMany examples\n*Overt: turnstiles, airport terminals\n*Semi-overt: street widths, blue lights in restrooms\n*Latent: Jones Beach access\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nArchitecture/Technology As Element of Policy\nCan be minor, major or dominant element\nOpportunities in implementation\nBut, important limitations\n*Flexibility/Ease of refinement\n*Discretion?\n*Transparency - recognition it's happening\nKey issue:\nIncreasingly requires formal appreciation of the technology\nitself before the scope of architecture's influence on the\npolicy can be appreciated\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nArchitecture as Control\nPotent Combination\nEspecially When The Technology Gets \"Clarkian\"\n\"Any sufficiently advanced technology is indistinguishable\nfrom magic\"\n- Arthur C. Clarke, \"Technology and the Future\"\nThe Lessig Dilemma\n*Significant Effort Necessary To Appreciate The Threat\n*Without This Appreciation, The Threat Is Shadowy, At\nBest\nWake up, Neo...........\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nDigital Telecommunications\nThe current revolution in copyright\nSeveral key elements\n*Digitization of communication/information\n*Transition from circuit switched to packet switched\ncommunications networks\nSmart networks to dumb networks\n*Increasingly inexpensive computing power\nA revolution in distribution of information\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nArchitecture of Digital Telecomm\nA simplified summary\n(that should be familiar)\nThree \"layers\" of digital\ncommunication\n*Content - text, speech,\nmusic, ...\n*Logical (code) -\napplications, protocols, etc.\n*Physical - hardware\ninterfaces, wires, spectrum,\netc.\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nCommunication & the Layers Metaphor\nh'ware, wires,\nspectrum\napplication,\nprotocols\nvoice,\ntext, music\nContent\nLogical\nPhysical\nContent\nLogical\nPhysical\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nImplementation Issues\nAs a fundamental descriptive metaphor, no problem\nImplementation, however, leads into difficult regimes\nDigitization, in particular, troubles copyright\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nClaude Shannon; \"A mathematical\ntheory of communication;\" Bell System\nTechnical Journal; July and October, 1948\n(published in two parts)\n*Study of how to communicate in the face\nof limits of communication channel\n*Modeled information transmission as\none of symmetric encoding and decoding of information\nLed to key (then impractical) insight - benefits of encoding\n(digitization) of information in communications\nAvailable at\nhttp://cm.bell-labs.com/cm/ms/what/shannonday/paper.html\nDigitizing of Information\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nDigitization and Copyright\nEncoding offers key benefits in\ncommunications\n*\nValidation of transmitted content -\n\"Good copies\"\nUS Library of Congress\nStudies/Reports\n*\nThe CONTU Report - 1978\n*\nIntellectual Property and the\nNational Information Infrastructure -\nDeclared, as a matter of policy, that\nall copies generated by computers in\nthe course of their operation were\nsubject to the copyright laws (!!)\nPhoto of Claude Shannon\nremoved for copyright\nreasons.\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nKey Government Policy Reports:\nCONTU and the NII White Paper\nhttp://www.uspto.gov/web/offices/com/doc/ipnii/\nhttp://digital-law-online.info/CONTU/PDF/index.html\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nThe Concern\nCopies everywhere!\n\"Transport\" of content is not happening\nRather, copies are being made at each locus\nEngineers' reaction\n*\"I'm shocked, shocked that there's copying going on here!\"\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nCurrent Network Design is no help to (c)\nEnd-to-end design means the network, by design,\ndoes not know or care about what it's transmitting\n*\"Phone taps\" on the internet are hard\nThus, copyright owners could not, a priori\n*Monitor traffic\n*Identify participants\n*Control actions/copying/distribution\nHave asked for (demanded) new powers to do so\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nWhat kind of powers?\nExploiting digitization in another way\nAnother key consequence - alienation\n*a withdrawing or separation of a person or a person's\naffections from an object or position of former\nattachment\n\n- Merriam-Webster Collegiate Dictionary Online\nIn other words:\nEncoding of content converts it into a form inaccessible to\nEncoding of content converts it into a form inaccessible to\nindividuals without technological instruments\nindividuals without technological instruments\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nNot Always Something We Think About\n\"Let's play some music.\"\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nAlienation; Vocaloid Article, NYTimes\nPhotos of guitar, drumset, CD duplicator removed for copyright reasons.\nFigure removed for copyright reasons.\nSee Werde, Bill. \"Could I Get That Song in Elvis, Please?\"\nNew York Times, November 23, 2003.\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nA Reminder.........\nUS Code, Title 17,  102. Subject matter of copyright: In\ngeneral\n(a) Copyright protection subsists, in accordance with this\ntitle, in\n*original works of authorship\n*fixed in any tangible medium of expression, now known or\nlater developed,\n*from which they can be perceived, reproduced, or otherwise\ncommunicated,\n**either directly or with the aid of a machine or device.\neither directly or with the aid of a machine or device.\nWorks of authorship include the following categories:....\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nA Key Insight: Technological Alienation\nUnlike other domains for distribution, digitized\ndistribution forces content consumers to rely upon\ncomplex, technological artifacts\n*Contrast with books, sheet music\n*Reading ability is internal to consumers\nWith digitized content, consumers are alienated\nfrom the ability to read content as delivered\n*Also true for analog music, video, etc.\nAn opportunity for control via access\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nCopyright Now Speaks of Technology\nDigital Millenium Copyright Act - 1998\n*Made the addition of \"digital locks\" one of copyright's\nexclusive rights\nRight to Incorporate Technological Protection Measures\nRight to Include Copyright Management Information\n*Criminalized lock-picking -- \"anti-circumvention provisions\"\n*Established new subpoena procedures to enforce these\nstrictures\nEU Copyright Directive, others include many of these\nsame elements\nMassachusetts Institute of Technology\nCambridge, Massachusetts\n(c) == Intervention at the Logical Layer\nCopyright law protects\ncopyright owner's rights to\ninterfere with the\ntransparency of the logical\nlayer\n*The \"end-to-end\" network\nLessig's Code:\nChoices of architecture\ninfluence the opportunities\nthat the \"built space\" affords\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nFor Example:\nSony BMG's use of\nFirst4's CD copy\nprotection technology\n\"Analog hole\"\nlegislation\nBroadcast flag\nTrusted Computing /\nNext Generation\nSecure Computing\nBase\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nFor Example:\nSony BMG's use of\nFirst4's CD copy\nprotection technology\n\"Analog hole\"\nlegislation\nBroadcast flag\nTrusted Computing /\nNext Generation\nSecure Computing\nBase\nImages removed for copyright reasons.\nSee: KreIbs, Brian. \"Study of Sony Anti-Piracy\nSoftware Triggers Uproar.\" Washington Post,\nNovember 2, 2005.\nPogue, David. \"Sony BMG's Copy-Protecting\nWatchdog\". The New York Times, November 9,\n2005.\nImage removed for copyright reasons.\nBray, Hiawatha. \"Computer worm exploits\nsoftware on Sony's CDs.\" Boston Globe,\nNovember 11, 2005.\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nWhat Kind of \"Built Space?\"\nFundamental questions\nWhat is the network supposed to be?\n*A service or a tool?\nWhat goals should it serve?\n*Who gets to decide?\n*How?\nArchitecture\nNorms/Culture\nLaw\nMarkets\nIndividual\nArchitecture\nNorms/Culture\nLaw\nMarkets\nIndividual\nMassachusetts Institute of Technology\nCambridge, Massachusetts\n\"End-to-End\" - Creative Context\nFramework for innovation\n*In hardware\n*In applications\nUnlike previous communication networks\n*\"Smart\" versus \"dumb\" networks\nNo need to ask permission to try something new\n*Agreements among users, rather than between\nnetwork operator and innovator\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nFor Example\nHTML/WWW - the \"web\"\nICQ - messaging\nVoIP - voice over the Internet\nVPN - virtual private networks\nP2P - peer-to-peer networks\nInventions by \"non-adults\" and \"foreigners\"\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nDigitization - Argument for Control\nPerfect communication has become perfect copy\n*Fundamental (intentional?) misunderstanding of\nwhat happens\nDMCA and its related laws only a start\n*Alienation - end run on fair use via access\n*A Second Enclosure Movement\nSeveral key issues building upon this set of\nconcerns/initiatives\n\n5CMI2: IP and Telecomm.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nThe Views At Conflict\n- Only those willing to adapt to these\nchanging economics will survive\n- Then, and only then, will content\nproviders participate fully\n- Technology & law need not change\ndramatically\n- These economic benefits are a\nsufficient incentive to provide content\n- The law should protect those controls\n- And technology should be managed\nto maintain these controls\n- The economics of internet\ndistribution change the business of\ncontent distribution radically\n- Content providers need to retain\nclassical forms of control to support\nthe economics of creativity\n- Content drives the development of\nthe internet\n- Content drives the development of\nthe internet\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nWorking Metaphors for Policy\n\"End-to-end\" (Lessig) - Policies should be undertaken to ensure that\nthe network stays \"dumb\"\n*\nIntelligence at the edges, not in the middle\n\"Layers model\" (Solum) - Policies should be undertaken to ensure\nthat the integrity of the layers is maintained\n*\nNothing that requires regulation across layers"
    },
    {
      "category": "Lecture Notes",
      "title": "mod3b_lec2.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-68j-communications-and-information-policy-spring-2006/0ba4a5e385978b1b818eca990a879b9f_mod3b_lec2.pdf",
      "content": "Massachusetts Institute of Technology\nCambridge, Massachusetts\nArchitecture and Control\nESD.68, Spring 2006\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nThe Views At Conflict\n- Only those willing to adapt to these\nchanging economics will survive\n- Then, and only then, will content\nproviders participate fully\n- Technology & law need not change\ndramatically\n- These economic benefits are a\nsufficient incentive to provide content\n- The law should protect those controls\n- And technology should be managed\nto maintain these controls\n- The economics of internet\ndistribution change the business of\ncontent distribution radically\n- Content providers need to retain\nclassical forms of control to support\nthe economics of creativity\n- Content drives the development of\nthe internet\n- Content drives the development of\nthe internet\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nControl - Lessig's \"New\" Chicago School\nArchitecture\nNorms/Culture\nLaw\nMarkets\nIndividual\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nResponses To Loss Of Control\nLegal Initiatives\n*Lawsuits, Legislative & Regulatory Changes\nTechnological Initiatives\n*\"Digital Bottles\", Copy protections, New Formats\n(SACD, Audio DVD, etc.)\nEconomic Initiatives\n*Price reductions, Distribution channels with control\nBehavior/Norm Initiatives\n*Education programs\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\n14 or 28\nTerm\nYear\nCopyright Term:\nOne Initiative to Retain Control\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nCorporate Influences; Lobbying and Negotiation\n\n\"Steamboat Willie,\" Debut of Mickey\nMouse, 1928\n*\nNote Importance of ~25 Years In\nThese Trends\n*\nMay Have Been Latent At Outset\n*\nPattern Became Too Obvious To\nMiss\n\n1998 Statute: \"Sonny Bono Copyright\nTerm Extension Act\"\na/k/a\n\"Mickey Mouse Protection Act\"\nDiff\nMMouse\nTerm\nYear\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nFREE MICKEY\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nEldred v. Ashcroft\nArgument\n*\nCopyright quid pro quo does\nnot obtain when copyright\nterm is extended\nCreations have been made\nNo need to further\nincentivize\n*\nNot \"limited Times\"\nPerpetual extension\nRejected\n*\nCongress can do as they see fit\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nhttp://www.waxy.org/archive/2003/01/15/eldred_s.shtml\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nIce-T's Take on\nNapster, the Law and Morality (2000 Aug 7)\nThe recording companies, \"are tripping off the fact this\nstuff comes through the computer clean,\" he said.\n\"That's the thing. When it comes on the radio, you\ncan tape it, I can send it to my homeboy. But mail\nmoves slow and the Internet moves faster.\"\n[...]Why do so many people traffic in music they\nhaven't paid for? \"To me,\" Ice-T said, \"you got the\ncops and the robbers. And, to me, I think human\nbeings are naturally robbers. I think human beings\nwant it free. And that's just your nature. And, if there\nis a way around paying, that is what you are going to\ndo. None of you guys are moral enough to say I would\nrather pay $16 than get it free.\"\nComic strips removed for copyright reasons.\nMickey Mouse and Goofy, \"Eldred Verdict\" strip -\nsee http://www.waxy.org/archive/2003/01/15/eldred_s.shtml.\nBolling, Ruben. \"Tom the Dancing Bug\" #633 (January\n23, 2003).\nAvailable at http://dir.salon.com/story/comics/boll/2003/01/23/boll/index.html\n(accessed 18 September 2006).\n\nPhoto and text removed for\ncopyright reasons.\nSee: Holson, Laura. \"Ice-T's\nTake on Napster, the Law\nand Morality.\" New York\nTimes, August 7, 2000.\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nMusic: The Legal Context\nFirst Distinction\n*\nA \"Song\"\n*\nA \"Sound Recording\"\nSecond Distinction\n*\nReproduction Right\nMaking Copies\n*\nPublic Performance Right\nOwned By the \"Song\" Owner\nNot Owned By the \"Recording\" Owner\nChanged in 1995 to add \"digital audio transmission\"\nCompulsory License (Section 115)\n*\nIf a recording has been distributed, the owner of a song must license the\nuse of the song at a legislated rate\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nThe Actors\n\nRecord Companies\n*\nContracts with Recording Artists\n*\nFinancing, Promotion and\nDistribution of Recordings\n*\nRoyalty Payment To Artists\n\nMusic Publisher\n*\nContracts with Songwriters\n*\nCommercial Exploitation of\nSongs\n*\nLicensing for\nRecordings\nSheet Music Printing\nPublic Performances, Live\nand Recorded\n\nASCAP/BMI/SESAC\n*\n\"Performance Rights Societies\"\n*\nRepresentation of Publishers and\nSongwriters wrt Performance\nLicensing\n*\n\"Songs\" not \"Song Recordings\"\n\nHarry Fox Agency\n*\nLicensing Agency\n*\nSpecifically To Record\nCompanies for Music Publishers\n*\nFor Reproduction of \"Songs\" as\nPhonorecordings\n*\nCompulsory Licensing\nArrangements\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nThe Actors (continued)\nRecording Industry Association of America\n*Trade Association\n*Promotion of Record Company Interests\n*Aggressive Anti-Piracy and Intellectual Property Protection\nEfforts\nThe Recording Artists Themselves\n*Prince\n*Courtney Love\n*Janis Ian\n*Don Henley & The Recording Artists Coalition\n*Metallica\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nA Complex Structure of Relationships\nCreators of Intellectual Property\n*Composers\n*Performers\n*Arrangers\nDistributors of Intellectual Property\n*Music Publishers\n*Phonorecording Manufacturers\n*Performers\n*Broadcasters, etc.\nConsumers of Intellectual Property\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nSong\n(writer)\nRecord\nCompany\nASCAP/BMI\nHarry Fox\nAgency\nmechanical\nreproduction\n(CD, etc.)\nPerformer\npublic performance\n(analog)\nMusic\nPublisher\nrecording\ncontract\ncontract?\ncontract\nMusic Licensing Structures - Current Non-Digital\n\n(\"simplified\" - focus on music delivery & mechanical reproduction)\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nMusic Licensing Structures - Digital Phonorecord Issues\nSong\n(writer)\nRecord\nCompany\nASCAP/BMI\nHarry Fox\nAgency\nmechanical\nreproduction\n(CD, etc.)\nPerformer\nMusic\nPublisher\nrecording\ncontract\ncontract?\npublic performance\n(digital, not copyable)\n? ? ?\n? ? ?\n? ? ?\npublic performance\n(digital, permanent)\ncontract\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nWhy All The Extra Lines?\nRecord Companies\n*\nDigital Copies, Persistent Or Otherwise, Are As Good As The Original\n*\nCould Displace CD Sales - Added To The 1995 Law\nHarry Fox\n*\nDigital Copies, Persistent Or Otherwise, Are \"Mechanical\nReproductions\"\n*\nThus, Copying Licenses Must Be Paid\nASCAP/BMI/SESAC\n*\nDigital Distribution Is A \"Public Performance\"\n*\nThus Performance Licenses Must Be Paid\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nEnter - Napster\n\nShawn Fanning -\n*\nNortheastern U. Undergraduate\n*\n1st prerelease - mid-1999\n\nConcept\n*\nMP3 Search Engine\n*\nFile Sharing Protocol\n*\nIRC/Communication Tool Within\nA Community\n\nPeer-to-Peer Technology Rather\nThan Central File Store\n*\nCentral Indexing/Locating\nMechanisms\n\nExplosive Growth\n*\nFeb 2000; 1.1 million\n*\nAug 2000; 6.7 million\n*\nFeb 2001; 13.6 million US\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\n46%\n35%\nHispanics\n30%\n29%\nBlacks\n26%\n20%\nWhites\n23%\n20%\nWomen\n36%\n24%\nMen\n2/2001\n7-8/2000\n21%\n15%\nGrad Coll+\n32%\n25%\nSome Coll\n31%\n25%\nGrad HS\n55%\n48%\n<High Sch\n2/2001\n7-8/2000\n24%\n15%\n$75k+\n29%\n20%\n$50k-$75k\n31%\n24%\n$30k-$50k\n36%\n28%\n< $30k\n2/2001\n7-8/2000\n15%\n9%\n50+\n23%\n19%\n30-49\n51%\n37%\n18-29\n2/2001\n7-8/2000\nPew Study - Upward Trend\nPercent of Internet Users Who Download Music (+/- 3%)\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nRIAA Year-End Sales Statistics\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nRIAA Year-End Sales Statistics\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nSome Market Observations\nCDs prices rising; LPs\nmoving to parity\nCD single and cassette\nprices falling\nCDs and cassettes roughly\nequal shares in 1990\nBy 2000, over 90% of\nrevenue derives from CDs\nShare of Revenue\nUnit Revenue\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nDistribution Outlets Changing\nPrecipitous decline in\nrecord stores\nRise in \"other\" (i.e., \"big\nbox\") stores\nInternet distribution\nbeginning to appear on the\nradar\n*Has outstripped sales\nrates of singles in some\nmarkets already\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nImmediate Controversy\n\nTypical Positions - \"Napster...\"\n*\n\"Is Theft of Intellectual Property;\nAbuse of Artists\"\n*\n\"Lets Me Sample Before Buying\"\n*\n\"Lets Me Find Music\nUnavailable Otherwise\"\n*\n\"Lets Me\nAcquire Only\nThat Which\nI Like On A\nCD\"\n*\n\"Lets Me\nStick It To\nThe Record\nCompanies\"\n\nOther Points\n*\n\"MP3s Allow Me To 'Space Shift'\nJust Like Analog Cassettes\"\n*\n\"MP3s Are Infringing Copies\"\n*\n\"MP3s Are/Can Be Degraded\nCopies, Not Pure Digital Copies\"\nImage removed for copyright reasons.\n\"Boondocks\" comic strip, 22 Februray 2001.\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nRIAA Sues Napster For Copyright Infringement\nRIAA Positions\n*\nMaking Copies\nNo Right To Distribute\n*\nPlaying Phonorecords\nNo Licensing\n*\nEconomic Harm To Artists,\nIndustry\n*\nSecondary copyright liability\nContributory\nVicarious\n\nNapster Counterpositions\n*\nFair Use (\"space shifting\")\n*\nNoncommercial Use - Home\nRecording Act\n*\nDMCA - Safe Harbor Provision\n*\nTransitory digital network\nconnections\n*\nInformation location tools\n*\nLawful Sharing (uncopyrighted\nworks or copyrights not enforced\nby owners)\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nSony Decision\n(Sony v Universal City Studios, 464 U.S. 417, 1984)\nA manufacturer of a device that can (even\nfrequently is) used for infringement cannot be held\nliable for contributory infringement, so long as the\ndevice is capable of \"substantial noninfringing uses\"\nUse of a VCR to \"time shift\" is not infringement\n*Does violate exclusive right to copy, but\n*Is exempt under \"fair use\"\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nSecondary Liability in Copyright Infringement\nContributory copyright infringement\n*If one has knowledge of infringement;\n*And one \"induces, causes or materially contributes to\" the\ninfringement\n*One is liable for contributory infringement.\nVicarious copyright infringement\n*If one has an obvious financial interest in infringement;\n*And one has the right & ability to supervise the\ninfringement;\n*And fails to block the infringement;\n*One is liable for vicarious copyright infringement.\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nFactors in finding \"Fair Use\"\nPurpose and character of use\n*Noncommercial, private, more like it's fair use\nNature of the creative work\n*More unique/intense effort to create, less likely it's\nfair use\nAmount of the work in question\n*The more that is copied, the less likely it's fair use\nEffect of the use on the market or potential market\n*More the economic harm, the less likely it's fair use\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nNapster Loses - Immediate Consequences\nFebruary, 2001 - Peaked\n*\nTrailed Off Rapidly\nThereafter\n*\nUltimately, Complete\nShutdown\nStill Weak, Tried To Convert\nTo Subscription Service\n*\nPurchased By Bertelsmann\n*\nDeclared Bankruptcy\n*\nOnly Remaining Asset: Brand\nName\nSold to Roxio; Has resurfaced\nas subscription service\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nAlternatives Immediately Emerge\nVariants designed to attack legal\nlimits of Napster\n*\n\"Pure\" peer-to-peer - no central\nserver\n*\nBuddy-list based-sharing\nsystems (\"Darknets\")\n*\nEncrypted/Obfuscated clients\nSome substantially successful,\nalbeit with some issues\n*\nFile sharing surpasses Napster\nat its peak\n*\nEmergence of some odd business\nmodels (BigChampagne)\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nGrokster, KaZaA\nEvolution of the Sony Betamax\ndecision\n*\n\"Substantial noninfringing uses\"\nNapster lost this argument (one of\nseveral)\nGrokster also lost, but it took the\nSupreme Court\n*\nSony doctrine skirted, preserved\nConcurring opinions spar over\nextent of preservation\n*\nNotion of \"inducement\" for\neconomic gain\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nGrokster:\nA New Secondary Infringement Doctrine\nInducement\n*If there is an affirmative act to promote infringement;\n*And there was intent to do so as well;\n*Then one is liable for inducement infringement liability\nContrast with \"Brief Amici Curiae Of Computer Science\nProfessors Harold Abelson,... David Clark,... Edward\nFelten,... Brian Kernighan,... and David S. Touretzky\"\nhttp://www.eff.org/IP/P2P/MGM_v_Grokster/20050301_cs_profs.pdf\n*\n\"Amici have no knowledge of the particular motives of Respondents, but\ncaution against the inference that a particular design decision, such as a\ndecision to include encryption or not to use filtering technologies,\nnecessarily represents bad faith. It may simply represent good,\nconservative engineering.\"\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nAnd, Of Course, Suits Against Direct\nInfringers\nOver 15,000 lawsuits filed\nAlmost all settled, without litigation\n*Cecelia Gonzales v. RIAA -- not so lucky\n*Summary judgement against her ($22,500)\nPatricia Santangelo (Elektra v Santangelo)\n*\"an Internet-illiterate parent, who does not know\nKazaa from kazoo, and who can barely retrieve her\ne-mail.\"\n*Challenge on evidence -- show that *she* did it\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nArtists Split on the Subject\nDisdain for Record Companies\n*Outstanding FTC Consent Degree On Price\nCollusion in CD Market\n*High Profile Artist Controversies\nPrince, Courtney Love, Janis Ian\nRecording Artists' Coalition\nOthers Working With RIAA\n*Metallica, Dr. Dre\nIndependents On The Outside, In Many Respects\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nPew Study:\nArtists, Musicians and The Internet (12/2004)\nhttp://www.pewinternet.org/PPF/r/142/report_display.asp\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nComplicating Factor - Distribution As A Player\nInjuries To Artists - Generally Decried\nInjuries To Users - Generally Decried\nInjuries To Record Companies - Generally Applauded\nImages removed for copyright reasons.\n1) Griffith, Bill. \"Overthowing Royalties.\" Zippy the Pinhead,\nMay 23, 2001.\n2) Napster promotional image.\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nThe Recording Industry Business Model\n\"Courtney Love Does the Math\" - Courtney Love; Salon; June 14,\n*\nPresented While in Litigation With Her Record Company\n*\nSettled Out of Court\nIs Copyright Working?\n*\nConflict Between Artists and Industry\n*\nUtilitarian Arguments For Copyright\nArticle Objective: To Demonstrate The Unfairness Of The Industry\nTo The Basic Performer (vs the Superstars)\nPresents The Basic Elements Of A Modern Recording Contract\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nEconomics - Courtney Does the Math\n\nMonies Received By The Band\n*\nAdvance:..................................$1,000,000\n*\nRoyalties:................................$2,000,000\n\n20% of Assumed $10/unit\n\nMonies Expended By The Band\n\nNOT to Record Company\n*\nAgent:...........................................$100,000\n*\nLegal:..............................................$25,000\n*\nManager:.......................................$25,000\n*\nTaxes:...........................................$170,000\n\nTO Record Company\n*\nRecording Costs:......................$500,000\n*\nRecouped Video Costs:.........$500,000\n*\nRecouped Tour Support:......$200,000\n*\nRecouped Promotion:............$300,000\n*\nRecouped Advance:............$1,000,000\n\nNet: $180,000\nNet: $180,000\n\nMonies Expended By Record Company\n*\nAdvance:..................................$1,000,000\n*\nVideo Production:................$1,000,000\n*\nTour Support:...........................$200,000\n*\nRadio Promotion:....................$300,000\n*\nCD Manufacturing:................$500,000\n\nAssumed per 1,000,000 units\n*\nPublisher Royalty:..................$750,000\n\n$0.75/unit\n*\nMarketing:............................$2,200,000\n\nMonies Received By Record Company\n*\nSales Gross: $10,000,000\n*\nRecouped Video Costs:........$500,000\n*\nRecouped Tour Support:.....$200,000\n*\nRecouped Promotion:............$300,000\n*\nRecouped Advance:.............$1,000,000\n\nNet: $6,050,000\nNet: $6,050,000\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nProfits as a function of sales volume\nAssume \"recoupable\" costs come out of royalties/sales\nIf sales are not high enough, record company \"eats\" the loss\nAssume CD production costs constant with volume and\nproduced in million-unit lots\nAssume no profit to company on recording studio time\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nProfits as a function of sales volume - detail\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nProfits as a function of sales volume - detail\n$1,980,000\n$13,875,000\n1,900,000\n$1,780,000\n$12,950,000\n1,800,000\n$1,580,000\n$12,025,000\n1,700,000\n$1,380,000\n$11,100,000\n1,600,000\n$1,180,000\n$10,175,000\n1,500,000\n$980,000\n$9,250,000\n1,400,000\n$780,000\n$8,325,000\n1,300,000\n$580,000\n$7,400,000\n1,200,000\n$380,000\n$6,475,000\n1,100,000\n$180,000\n$6,050,000\n1,000,000\n$180,000\n$4,925,000\n900,000\n$180,000\n$3,800,000\n800,000\n$180,000\n$2,675,000\n700,000\n$180,000\n$1,550,000\n600,000\n$180,000\n$425,000\n500,000\n$180,000\n$(700,000)\n400,000\n$180,000\n$(1,825,000)\n300,000\n$180,000\n$(2,950,000)\n200,000\n$180,000\n$(4,075,000)\n100,000\nArtist\nCompany\nUnits\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nWhat about uncertainty?\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nProfits as a function of sales volume - detail\nCompany\nBand\n152,000 -$3,487,667\n$180,007\n179,000 -$3,189,757\n$180,098\n205,000 -$2,897,168\n$180,504\n230,000 -$2,613,884\n$181,540\n303,000 -$1,808,042\n$191,111\n347,000 -$1,337,304\n$203,153\n409,000\n-$675,804\n$229,755\n452,000\n-$233,656\n$254,075\n506,000\n$320,187\n$291,758\n551,000\n$774,200\n$328,314\n606,000\n$1,319,794\n$378,461\n638,000\n$1,635,874\n$410,374\n714,000\n$2,379,319\n$492,843\n760,000\n$2,819,892\n$546,116\n812,000\n$3,317,700\n$609,786\n940,000\n$4,531,722\n$778,260\n1,112,000\n$6,146,103 $1,025,178\n1,222,000\n$7,161,057 $1,190,667\n1,352,000\n$8,357,934 $1,393,770\n1,507,000\n$9,780,598 $1,644,246\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nComparison\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nConclusions?\nOf Course, the Shape of the Distribution Can Change a Lot\n*\nBut, What Does the Base Analysis Suggest?\n*\nAre the Companies That \"Unfair?\"\n*\nOr, Is There Something Else?\nNote:\n*\nAlso see Steve Albini's \"The Problem With Music\"\n*\nOther Artists With Perspectives Online\n(Links : IP Controversies : Digital Music : Record Industry\nPractices)\nPrince - http://www.npgmusicclub.com\nJanis Ian - http://www.janisian.com\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nSo, Maybe The Record Company Has A Case\nBut Digital Distribution Should Have Some\nEconomic Consequences\nThe Physical versus the Digital Product\n*Changes in delivery\n*Changes in retail\n*Changes in product\n*Changes in control\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nDifferent Economics?\nConsider this breakdown\nin costs for an $18 CD\n*39% retailer\n*8% distributor\n*14% record co. overhead\n*13% record co. marketing\n*8% CD manufacture\n*1% record co. profit\n*12% artist profit/royalty\n*4% song publisher royalty\nSource: Promises to Keep:\nTechnology, Law, and the\nFuture of Entertainment;\nWilliam W. Fisher, III;\nStanford Univ. Press; 2004\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nDifferent Economics?\nConsider this breakdown\nin costs for an $18 CD\n*39% retailer\n*8% distributor\n*14% record co. overhead\n*13% record co. marketing\n*8% CD manufacture\n*1% record co. profit\n*12% artist profit/royalty\n*4% song publisher royalty\nSource: Promises to Keep:\nTechnology, Law, and the\nFuture of Entertainment;\nWilliam W. Fisher, III;\nStanford Univ. Press; 2004\n\n\n\n\n\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nIt's Not Just About P2P/Music\nDigital technology has led\nto many new opportunities\nBut certain constructions\nof the law are turning\nthose opportunities into a\nstranglehold on freedom &\nculture\nHow far do we want to go\nto protect this construct?\nWhat do we get out of it?\nMassachusetts Institute of Technology\nCambridge, Massachusetts\nThe Views At Conflict\n- Only those willing to adapt to these\nchanging economics will survive\n- Then, and only then, will content\nproviders participate fully\n- Technology & law need not change\ndramatically\n- These economic benefits are a\nsufficient incentive to provide content\n- The law should protect those controls\n- And technology should be managed\nto maintain these controls\n- The economics of internet\ndistribution change the business of\ncontent distribution radically\n- Content providers need to retain\nclassical forms of control to support\nthe economics of creativity\n- Content drives the development of\nthe internet\n- Content drives the development of\nthe internet\nImage removed for copyright reasons.\nEditorial cartoon, with person labeled \"RIAA\"\nsaying \"Beware, YOU might be next.\""
    },
    {
      "category": "Resource",
      "title": "blogging_policy.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-68j-communications-and-information-policy-spring-2006/6e4666eeac2cb2509b068f596f26343d_blogging_policy.pdf",
      "content": "________________________________________________________________\nCompany\nLogo\nCompany Name\nABBREV Policy regarding Blogging\nJanuary __, 2006\n[1/5/06 DRAFT]\nThis memo sets forth the policies of ____________________, a division of\n______________ (\"ABBREV\" or the \"Company\") regarding the maintenance of\n\nblogs by employees.\nABBREV encourages its employees to make positive use of this powerful new\nmethod of communication and welcomes the dissemination and exchange of\nideas that the blogosphere makes possible. At the same time, the Company's\nlegitimate interests can, in rare circumstances, be compromised by inappropriate\nuses of this medium. Accordingly, this policy is intended to respect employees'\nrights to personal expression while limiting the Company's legal liability and\nprotecting the Company's proprietary information and business interests.\n1. General Limitations.\nThe following are never permitted:\n- Blogs which support a competitor of the Company or its affiliates or\notherwise conflict with an employee's duties to the Company; or\n- Blogs which adversely affects the interests or reputation of the\nCompany.\nThe following are permitted only with the express prior written permission\nof both an employee's manager and the legal department:\n- Blogs which imply sponsorship or support by the Company; or\n- Blogs which use the Company's time, facilities, resources, or supplies.\n2. Disclaimer of Company Responsibility. If a blog refers to the Company\nor its operations, personnel, products or services, the employee blogger\nmust (i) notify his or her manager and the legal department of the\nexistence of the blog, and (ii) include a statement in the blog that all views\nexpressed in connection with the Company are those of the blogger and\nhave not been reviewed or approved by the Company.\n A \"blog,\" short for \"weblog,\" is a personal web site maintained and regularly updated by an\nindividual. A blog typically contains opinions, links, text, images and other personal content.\n\n3. No Disclosure of Confidential Information. Blogs may not disclose any\ntrade secrets, \"insider information\" or other confidential or proprietary\ninformation of the Company or violate any privacy policies of the Company.\nMoreover, blogs may not violate any of the terms of the Employee\nConfidentiality and Proprietary Rights Agreement of ABBREV, which\nprovides that Company confidential information may only be used within\nthe scope of one's duties as an employee.\n4. Use of Trademarks. A blog may not use any logos or trademarks of the\nCompany or its affiliates without the prior express written approval of both\nthe blogger's manager and the legal department.\n5. Inappropriate Content. Blogs may not contain any content which: (i)\nviolates any laws, including laws pertaining to intellectual property, (ii)\ninfringes any third party rights (including intellectual property rights), (iii)\ncontains content which is defamatory or libelous or might be construed as\nharassment or disparagement on the basis of race, color, religion, sex,\nsexual orientation, national origin, age, disability or any other status\nprotected by law; (iv) violates any policies, rules, standards or\nrequirements applicable to the Company, including the COMPANY Code\nof Ethics and Business Conduct and the ABBREV sexual harassment\npolicy; or (v) is adverse to the reputation, interests or business\nrelationships of the Company. Management reserves the right to require\nan employee to stop posting any blog which contains content that it deems\ninappropriate.\n6. Scope of Policy; Penalties. This policy is a statement of legal and\nethical principles for individual and business conduct. It does not\nconstitute an employment contract between any employee and the\nCompany or vary any employee's status as an at-will employee. Failure to\ncomply with this policy may subject an employee to disciplinary action,\nincluding termination of employment.\n7. Questions. If you have any questions regarding this policy, please\ncontact the Legal Department."
    },
    {
      "category": "Resource",
      "title": "clark_insider.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-68j-communications-and-information-policy-spring-2006/9e1e8fea998228aa149b091ce19ae9e8_clark_insider.pdf",
      "content": "An Insider's Guide to the Internet\nDavid D. Clark\nM.I.T. Computer Science and Artificial Intelligence Laboratory\nVersion 2.0 7/25/04\nAlmost everyone has heard of the Internet. We cruise the web, we watch the valuation of Internet\ncompanies on the stock market, and we read the pundits' predictions about what will happen next. But not\nmany people actually understand what it is and how it works. Take away the hype, and the basic operation\nof the Internet is rather simple. Here, in a few pages, is an overview of how it works inside, and why it\nworks the way it does.\nDon't forget--the Internet is not the World Wide Web, or e-mail. The Internet is what is \"underneath\"\nthem, and makes them all happen. This paper describes what the Internet itself is, and also tells what\nactually happens, for example, when you click on a link in a Web page.\n1 .\nIntroduction to the Internet\nThe Internet is a communications facility designed to connect computers together so that they can exchange\ndigital information. For this purpose, the Internet provides a basic communication service that conveys\nunits of information, called packets, from a source computer attached to the Internet to one or more\ndestination computers attached to the Internet. Additionally, the Internet provides supporting services such\nas the naming of the attached computers. A number of high-level services or applications have been\ndesigned and implemented making use of this basic communication service, including the World Wide\nWeb, Internet e-mail, the Internet \"newsgroups\", distribution of audio and video information, and file\ntransfer and \"login\" between distant computers. The design of the Internet is such that new high-level\nservices can be designed and deployed in the future.\nThe Internet differs in important ways from the networks in other communications industries such as\ntelephone, radio or television. In those industries, the communications infrastructure--wires, fibers,\ntransmission towers and so on--has been put in place to serve a specific application. It may seem obvious\nthat the telephone system was designed to carry telephone calls, but the Internet had no such clear purpose.\nTo understand the role of the Internet, consider the personal computer, or PC. The PC was not designed for\none application, such as word processing or spreadsheets, but is instead a general-purpose device,\nspecialized to one use or another by the later addition of software. The Internet is a network designed to\nconnect computers together, and shares this same design goal of generality. The Internet is a network\ndesigned to support a range of applications, depending on what software is loaded into the attached\ncomputers, and what use that software makes of the Internet. Many communication patterns are possible:\nbetween pairs of computers, from a server to many clients, or among a group of co-operating computers.\nThe Internet is designed to support all these modes.\nThe Internet is not a specific communication \"technology\", such as fiber optics or radio. It makes use of\nthese and other technologies in order to get packets from place to place. It was intentionally designed to\nallow as many technologies as possible to be exploited as part of the Internet, and to incorporate new\ntechnologies as they are invented. In the early days of the Internet, it was deployed using technologies\n(e.g. telephone circuits) originally designed and installed for other purposes. As the Internet has matured,\nwe see the design of communication technologies such as Ethernet and 802.11 wireless that are tailored\nspecifically to the needs of the Internet--they were designed from the ground up to carry packets.\n2 .\nSeparation of function\nIf the Internet is not a specific communications technology, nor for a specific purpose, what is it?\nTechnically, its core is a very simple and minimal specification that describes its basic communication\nmodel. Figure 1 provides a framework that is helpful in understanding how the Internet is defined. At the\ntop of the figure, there is a wide range of applications. At the bottom is a wide range of technologies for\n\nwide area and local area communications. The design goal of the Internet was to allow this wide range of\napplications to take advantage of all these technologies.\nThe heart of the Internet is the definition of a very simple service model between the applications and the\ntechnologies. The designer of each application does not need to know the details of each technology, but\nonly this basic communication service. The designer of each technology must support this service, but\nneed not know about the individual applications. In this way, the details of the applications and the details\nof the technologies are separated, so that each can evolve independently.\n2 . 1 .\nThe basic communication model of the Internet\nThe basic service model for packet delivery is very simple. It contains two parts: the addresses and the\ndelivery contract. To implement addressing, the Internet has numbers that identify end points, similar to\nthe telephone system, and the sender identifies the destination of a communication using these numbers.\nThe delivery contract specifies what the sender can expect when it hands data over to the Internet for\ndelivery. The original delivery contract of the Internet is that the Internet will do its best to deliver all the\ndata given to it for carriage, but makes no commitment as to data rate, delivery delay, or loss rates. This\nservice is called the best effort delivery model.\nThis very indefinite and non-committal delivery contract has both benefit and risk. The benefit is that\nalmost any underlying technology can implement it. The risk of this vague contract is that applications\ncannot be successfully built on top of it. However, the demonstrated range of applications that have been\ndeployed over the Internet suggests that it is adequate in practice. As is discussed below, this simple\nservice model does have limits, and it is being extended to deal with new objectives such as real time\ndelivery of audio and video.\n2 . 2 .\nLayering, not integration.\nThe design approach of the Internet is a common one in Computer Science: provide a simplified view of\ncomplex technology by hiding that technology underneath an interface that provides an abstraction of the\nunderlying technology. This approach is often called layering. In contrast, networks such as the telephone\nsystem are more integrated. In the telephone system, designers of the low level technology, knowing that\nthe purpose is to carry telephone calls, make decisions that optimize that goal in all parts of the system.\nThe Internet is not optimized to any one application; rather the goal is generality, flexibility and\nevolvability. Innovation can occur at the technology level independent of innovation at the application\nlevel, and this is one of the means to insure that the Internet can evolve rapidly enough to keep pace with\nthe rate of innovation in the computer industry.\n2 . 3 .\nProtocols\nThe word protocol is used to refer to the conventions and standards that define how each layer of the\nInternet operates. The Internet layer discussed above is specified in a document that defines the format of\nthe packet headers, the control messages that can be sent, and so on. This set of definitions is called the\nInternet Protocol, or IP.\nDifferent bodies have created the protocols that specify the different parts of the Internet. The Internet\nEngineering Task Force, an open working group that has grown up along with the Internet, created the\nInternet Protocol and the other protocols that define the basic communication service of the Internet. This\ngroup also developed the protocols for early applications such as e-mail. Some protocols are defined by\nacademic and industry consortia; for example the protocols that specify the World Wide Web are mostly\ndeveloped by the World Wide Web Consortium (the W3C) hosted at the Computer Science and Artificial\nIntelligence laboratory at MIT. These protocols, once developed, are then used as the basis of products that\nare sold to the various entities involved in the deployment and operation of the Internet.\n\n3 .\nForwarding data--the Internet layer\n3 . 1 .\nThe packet model\nData carried across the Internet is organized into packets, which are independent units of data, no more than\nsome specified length (1000 to 2000 bytes is typical), complete with delivery information attached. An\napplication program on a computer that needs to deliver data to another computer invokes software that\nbreaks that data into some number of packets and transmits these packets one at a time into the Internet.\n(The most common version of the software that does this is called Transmission Control Protocol, or\nTCP; it is discussed below.)\nThe Internet consists of a series of communication links connected by relay points called routers. Figure 2\nillustrates this conceptual representation. As figure 3 illustrates, the communication links that connect\nrouters in the Internet can be of many sorts, as emphasized by the hourglass. They all share the basic\nfunction that they can transport a packet from one router to another. At each router, the delivery\ninformation in the packet, called the header, is examined, and based on the destination address, a\ndetermination is made as to where to send the packet next. This processing and forwarding of packets is\nthe basic communication service of the Internet.\nTypically, a router is a computer, either general purpose or specially designed for this role, running\nsoftware and hardware that implements the forwarding functions. A high-performance router used in the\ninterior of the Internet may be a very expensive and sophisticated device, while a router used in a small\nbusiness or at other points near the edge of the network may be a small unit costing less than a hundred\ndollars. Whatever the price and performance, all routers perform the same basic communication function of\nforwarding packets.\nA reasonable analogy to this process is the handling of mail by the post office or a commercial package\nhandler. Every piece of mail carries a destination address, and proceeds in a series of hops using different\ntechnologies (e.g. truck, plane, or letter carrier). After each hop, the address is examined to determine the\nnext hop to take. To emphasize this analogy, the delivery process in the Internet is called datagram\ndelivery. While the post-office analogy is imperfect in a number of ways, it illustrates a number of other\nfeatures of the Internet: the post office carries out other services to support the customer besides the simple\ntransport of letters, and the transport of letter requires that they sometimes cross jurisdictional boundaries,\nin particular between countries.\n3 . 2 .\nDetails of packet processing.\nThis section discusses in more detail the packet forwarding process introduced in the previous section.\nThe information relevant to packet forwarding by the router is contained in a part of the packet header\ncalled the Internet header. Each separate piece of the header is called a field of the header. The important\nfields in the Internet header are as follows:\nSource address: the Internet address of the origin of the packet.\nDestination address: the Internet address of the destination of the packet.\nLength: the number of bytes in the packet.\nFragmentation information: in some cases, a packet must be broken into smaller packets to complete its\nprogress across the Internet. Several fields are concerned with this function, which is not discussed here.\nHeader checksum: an error on the communications link might change the value of one of the bits in the\npacket, in particular in the Internet header itself. This could alter important information such as the\ndestination address. To detect this, a mathematical computation is performed by the source of the packet to\ncompute a checksum, which is a 16-bit value derived from all the other fields in the header. If any one of\nthe bits in the header is modified, the checksum computation will yield a different value with high\nprobability.\nHop count: (technically known as the \"time to live\" field.) In rare cases, a packet may not proceed directly\ntowards the destination, but may get caught in a loop, where it could travel repeatedly among a series of\n\nrouters. To detect this situation, the packet carries an integer, which is decremented at each router. If this\nvalue is decremented to zero, the packet is discarded.\nProcessing in the router\nThe processing of the packet by each router along the route from source to destination proceeds as follows,\neach step closely related to the fields discussed above.\n1) The packet is received by the router from one of the attached communications links, and stored in the\nmemory of the router until it can be processed. When it is this packet's turn to be processed, the router\nproceeds as follows.\n2) The router performs the checksum computation, and compares the resulting value with the value placed\nin the packet by the source. If the two values do not match, the router assumes that some bits in the\nInternet header of the packet have been damaged, and the packet is discarded. If the checksum is correct,\nthe router proceeds as follows.\n3) The router reads the hop count in the packet, and subtracts one from it. If this leads to a result of zero,\nthe packet is discarded. If not, this decremented value is put back in the packet, and the checksum is\nchanged to reflect this altered value.\n4) The router reads the destination address from the packet, and consults a table (the forwarding table) to\ndetermine on which of the communications links attached to the router the packet should next be sent. The\nrouter places the packet on the transmission queue for that link.\n5) When the packet reaches the head of the transmission queue, the router transmits the packet across the\nassociated communications link, towards either a next router, or towards the computer that is the final\ndestination of the packet.\nProcessing in the source and destination computers\nThe source and destination computers are also concerned with the fields in the Internet header of the packet,\nbut the operations are a little different.\nThe source computer creates the Internet header in the packet, filling in all the fields with the necessary\nvalues. The source must have determined the correct destination address to put in the packet (see the\ndiscussion on the Domain Name System, below), and, using rules that have been specified, must select a\nsuitable hop count to put in the packet.\nThe destination computer verifies the values in the header, including the checksum and the source address.\nIt then makes use of an additional field in the Internet header that is not relevant when the router forwards\nthe packet: the next-level protocol field.\nAs discussed above, packets carried across the Internet can be used for a number of purposes, and\ndepending on the intended use, one or another intermediate level protocol will be used to further process\nthe packet. The most common protocol is Transmission Control Protocol, or TCP, discussed below; other\nexamples include User Datagram Protocol, or UDP, and Real Time Protocol, or RTP. Depending on which\nprotocol is being used, the packet must be handed off to one or another piece of software in the destination\ncomputer, and the next-level protocol field in the Internet header is used to specify which such software is\nto be used.\nInternet control messages\nWhen some abnormal situation arises, a router along a path from a sender to a receiver may send a packet\nwith a control message back to the original sender of the packet. This can happen when the hop count goes\nto zero and the packet is discarded, and in certain other circumstances when an error occurs and a packet is\n\nlost. It is not the case that every lost packet generates a control message--the sender is supposed to use an\nerror recovery mechanism such as the one in TCP, discussed below, to deal with lost packets.\n3 . 3 .\nPacket headers and layers.\nThe Internet header is not the only sort of header information in the packet. The information in the packet\nheader is organized into several parts, which correspond to the layers, or protocols, in the Internet design.\nFirst comes information that is used by the low-level technology connecting the routers together. The\nformat of this will differ depending on what the technology is: local area network, telephone trunk, satellite\nlink and so on. Next in the packet is the information at the Internet layer we have just discussed. Next\ncomes information related to higher protocol levels in the overall design, as discussed below, and finally\nthe data of interest to the application.\n4 .\nTCP -- intermediate level services in the end-no d e\nThe delivery contract of the Internet is very simple: the best effort service tries its best to deliver all the\npackets given it by the sender, but makes no guarantees--it may lose packets, duplicate them, deliver them\nout of order, and delay them unpredictably. Many applications find this service difficult to deal with,\nbecause there are so many kinds of errors to detect and correct. For this reason, the Internet protocols\ninclude a transport service that runs \"on top of\" the basic Internet service, a service that tries to detect and\ncorrect all these errors, and give the application a much simpler model of network behavior. This transport\nservice is called Transmission Control Protocol, or TCP. TCP offers a service to the application in which a\nseries of bytes given to the TCP at the sending end-node emerge from the TCP software at the receiving\nend-node in order, exactly once. This service is called a virtual circuit service. The TCP takes the\nresponsibility of breaking the series of bytes into packets, numbering the packets to detect losses and\nreorderings, retransmitting lost packets until they eventually get through, and delivering the bytes in order\nto the application. This service is often much easier to utilize than the basic Internet communication\nservice.\n4 . 1 .\nDetailed operation of TCP\nTCP is a rather more complex protocol than IP. This discussion describes the important functions, but of\nnecessity omits some of the details. Normally, a full chapter or more of a textbook is required to discuss\nall of TCP.\nWhen TCP is in use, the packet carries a TCP header, which has information relevant to the functions of\nTCP. The TCP header follows the Internet header in the packet, and the higher-level protocol field in the\nInternet header indicates that the next header in the packet is the TCP header. The fields in the header are\ndiscussed in the context of the related function.\nLoss detection and recovery: Packets may be lost inside the network, because the routing computation has\ntemporarily failed and the packet has been delivered to the wrong destination or routed aimlessly until the\nhop count is decremented to zero, or because the header has been damaged due to bit errors on a\ncommunication link, or because a processing or transmission queue in a router is full, and there is no room\nto hold the packet within one of the routers. TCP must detect that a packet is lost, and correct this failure.\nIt does so as follows.\nConceptually each byte transmitted is assigned a sequence number that identifies it. In practice, since a\npacket can carry a number of bytes, only the sequence number of the first byte is explicitly carried in the\nsequence number field of the TCP header. When each packet is received by the destination end node, the\nTCP software looks at the sequence number, and computes whether the bytes in this packet are the next in\norder to be delivered. If so, they are passed on. If not the packet is either held for later use, or discarded, at\nthe discretion of the TCP software.\nThe TCP at the destination sends a message back to the TCP at the origin, indicating the highest sequence\nnumber that has been received in order. This information is carried in the acknowledgement field in the\n\nTCP header in a packet being transmitted back from destination of the data towards the source. If the\nsource does not receive the acknowledgment in reasonable time, it transmits the data again, and this repeats\nuntil either some copy of the packet finally makes it to the destination, or the application making use of\nthe TCP terminates the activity and reports an unrecoverable error.\nFlow and congestion control: The term flow control describes the mechanism that attempts to insure that\nthe sender of data does not transmit faster then the destination can receive. The term congestion control\ndescribes the mechanism that attempts to insure that the sender of data does not transmit faster than the\nrouters in the network can process and transmit the packets. A router that receives packets faster than it can\ntransmit them along the next communication link must hold those packets temporarily. A router that is\nholding a number of packets for transmission is called congested. Congestion control is a critical aspect of\nthe Internet; since any attached end-node can in principle transmit at will, it is possible for more packets to\narrive at a router than can be carried across the outgoing communications link. Both flow control and\ncongestion control are implemented in TCP.\nPackets flowing back from the destination of the data to the source carry, in addition to the\nacknowledgment field, the flow control field. This field conveys a count of the number of bytes that the\nsender can send that have not been acknowledged. In other words, at any instant, there are some number of\nbytes that the sender has transmitted to the destination, but for which the acknowledgment has not yet\narrived back. The sender must limit the number of such bytes to the value noted in the flow control field.\nThe assumption behind this mechanism is that the receiver will allocate a holding area, or buffer, large\nenough to contain this many bytes, and if the receiver falls behind in processing the incoming packets,\nthey can sit in this buffer. If the sender exceeds the flow control limit, the extra packets will usually just be\ndiscarded at the receiver.\nThe implementation of congestion control is rather more complex. Apart from the flow control limit\npassed back from the receiver, the sender maintains another estimate of the suitable sending limit called the\n\"congestion limit\". The congestion limit is never allowed to grow larger than the flow control limit from\nthe receiver, but is often smaller. When the sending TCP starts to transmit packets to the receiving TCP,\nit makes an initial guess as to a suitable congestion limit. The initial guess is small: only one or two\npackets. It sends only this many packets into the Internet, and then waits for an acknowledgement packet to\nreturn from the TCP at the receiver. As long as packets are successfully acknowledged, the congestion limit\nis adjusted upward, at first rapidly and then more slowly. If an acknowledgment fails to arrive, the sending\nTCP assumes that some packet was lost because a router along the path was sufficiently congested that it\nhad no further space in its transmission queue, and had to discard it. The sending TCP retransmits the\npacket, as was discussed above under loss detection and recovery, but additionally adjusts its congestion\nlimit. Depending on the details of the situation, the sending TCP will cut the congestion limit in half or,\nmore drastically, cut it to the small limit it used as its initial guess. Reducing the limit has the\napproximate result of cutting the average sending rate similarly, so the final consequence of this whole\nmechanism is that the rate at which the sending TCP transmits packets moves up and down in an attempt\nto find a rate that does not congest any router.\nError detection: a transmission error on a data link can damage a bit in a packet. The Internet protocol\nspecifies a checksum function that is used to detect if a bit in the Internet header is altered, but this only\napplies to that header. TCP employs a similar checksum function to validate the TCP header as well as all\nthe data bytes that follow it in the packet. The sending TCP computes the checksum and stores it in the\npacket; the receiving TCP recomputes it and compares this value with the one in the packet, discarding the\npacket if the two are different. A packet thus discarded is later retransmitted because of the loss detection\nand recovery mechanism discussed above.\nReliable open and close: The Internet service was described as a datagram service. At that level, the sender\ntransmits a packet to a destination address, and need not know whether that destination is prepared to\nreceive it, or indeed whether it even exists. Most high-level services need to know that the receiver is there\nand functioning. For this reason, before data is exchanged, the TCP software at the two ends of the\ncommunication exchange a sequence of packets with each other (containing no data but just TCP headers\nwith specific values in certain fields) to insure each end that the other is there. This is called \"making a\nconnection\". Similarly, when each end is done sending data, the TCP notifies the TCP at the other end\nthat this is so. When both ends are done sending data, and all such data has been acknowledged back to its\n\nsender, then the TCPs \"close the connection\" by a final exchange of packets and a delay to insure that all is\nwell.\nTCP can carry data in two directions at once. Each end can send and receive at the same time, with\nseparate flow and congestion limits in each direction. Packets carrying data in one direction can at the\nsame time acknowledge data flowing in the other direction.\nOverall, the resulting behavior of TCP is as follows. When some software at the sending end gives TCP a\nsequence of bytes to transfer to the receiver, the sending TCP opens a connection and starts to break these\nbytes into packets, attaching a TCP header to each and then handing them on to the Internet software for\nformatting and forwarding as described in section 3. TCP continues to transmit these packets so long as\nacknowledgments arrive. Based on the pattern of acknowledgments and losses, it may retransmit packets,\nand send at a faster or slower rate. If the flow control limit from the receiver goes to zero, it will\ntemporarily suspend transmission. It will continue this process so long as there is further data to send.\nData may or may not flow in both directions, based on the nature of the application.\n4 . 2 .\nOther intermediate protocols\nTCP is the most commonly used protocol to enhance the basic communication service of the Internet, but\nit is not the only one. In some cases, the high-level application works best if it is built directly on the\nbasic IP communication service. In this case, a simple interface to that service is used, called the User\nDatagram Protocol, or UDP. For real time services that are concerned more with delivery within a delay\nbound rather than completely reliable delivery, an alternative to TCP has been developed and standardized,\ncalled Real Time Protocol, or RTP. RTP carries timing information in the header, but does not\nimplement retransmission to deal with lost packets. RTP is now being deployed as part of some audio\nand video applications on the Internet.\nLayers and modularity--more about the organization of the Internet\nFigure 4 provides a different visualization of the layering in the Internet. It shows the different software\nmodules that implement the different layers, and illustrates the difference between a router and an end-node.\nA router has software specific to all of the lower level communications technologies in use (in the jargon of\nthe trade, \"device drivers\" or \"link-level software\"). Above these elements, it has the Internet forwarding\nsoftware that looks at the Internet level header and decides how to send the packet onward. The end-node\nmust also have some link-level software and some software at the Internet level, but here the function is\nnot forwarding but origination and termination. Above that is found TCP software (in those cases where\nthe application needs it), and then the application software itself.\n5.1.\nThe end to end arguments\nIn terms of division of responsibility, the router, which implements the relay point between two\ncommunication links, has a very different role than the computer or end-node attached to the Internet. In\nthe Internet design, the router is only concerned with forwarding the packets along the next hop towards the\ndestination. The end-node has a more complex set of responsibilities related to providing service to the\napplication. In particular, the end-node provides additional services such as TCP that make it easier for the\napplication (such as the World Wide Web) to make use of the basic packet transfer service of the Internet.\nTCP is implemented in the end-nodes, but not in the packet forwarding software of the routers. The\nrouters look only at the Internet information, such as the delivery addresses, when forwarding packets.\nOnly the end-nodes look at the TCP information in the packets. This is consistent with the design goals\nof the Internet, and is a very important example of layered design. While TCP provides a very simple\nservice that most high-level applications find easy to use, some applications cannot make use of TCP.\nTCP always delivers data in order, and insists on retransmitting lost packets until they get through. This\ncan, on occasion, cause delays of several round trips while losses are recovered. For applications such as\nreal time Internet telephony, these occasional delays disrupt the communication flow much more than a\n\nshort \"glitch\" in the data stream due to a missing packet. So most but not all high-level services use TCP.\nIf TCP were implemented in the routers, it would be much harder for the high-level service to bypass it\nand use some other sort of transport service. So the design principle of the Internet has been to push\nfunctions out of the network to the extent possible, and implement them only in the end-node. By doing\nso, the high-level service can easily modify them or replace them by adding new software to the end-node.\nThis is another means by which the Internet can evolve rapidly. For a broad base of high-level services,\ninstalling new services can be done without any need to modify the routers.\nThe above example illustrates a set of general design principles called the end to end arguments. The\ndesign approach of the Internet moves functions out of the network and onto the end-nodes where possible,\nso that those functions can be modified or replaced without changing the routers. Any set of users who\ninvent a new application can run that application by installing the code for it on their end-nodes. Were it\nnecessary to modify routers, or other network elements not under the control of the individual user, change\nwould not be as rapid, and would be under the control of the network operator, not the user.\nThis principle has many implications. One example is security. The Internet header is distinct from the\nTCP and higher level headers in the packet. Those parts of the packet only concerned with end-node\nfunctions can be encrypted before they are forwarded across the Internet without fear that this will disrupt\nthe forwarding processing in the routers. Using end to end encryption, the end-node can thus take\nresponsibility for insuring the integrity and privacy of its own data.\n5 . 2 .\nRouting and forwarding -- functions specific to routers\nThere are also functions that are implemented in the routers, but not the end-nodes. The router must make a\ndecision as to how to forward each packet as it arrives. In order to do this, it must have forwarding tables\nthat specify, for each destination address, what the preferred path is onward towards that point. The routers\ncompute the best routes to all the addresses in the network, in order to construct this table. This requires\nthat all the routers send messages to other routers describing what links in the Internet are currently in\noperation, and what routers these links connect. This results in a collective decision-making, the routing\ncomputation, to select the best overall routes. Routers perform this task in the background, at the same\ntime that they forward packets. If a low-level communications link fails or a new one is installed, this\nrouting computation will construct new routes as appropriate. This adaptation is part of making the Internet\nrobust in the face of failure.\nEnd-nodes do not participate in the routing computation. They know only the identity of the router or\nrouters closest to them, and send the packets to this first router. This division of responsibility makes it\npossible to replace the routing computation (which has happened several times in the life of the Internet)\nwithout having to change the software in the end-nodes, an almost impossible task if it had to be done in a\nco-ordinated way for all the millions of end-nodes on the Internet.\n6 .\nThe Domain Name System\nThere are a few Internet services on which the end-nodes depend, in addition to the basic packet forwarding\nperformed by the routers. The most important of these is the Domain Name System.\nPackets carry source and destination addresses, but users do not use addresses of this form when they\ninvoke services. Applications tend to use names that are a little more \"user-friendly\", composed of\ncharacters rather than integers. For example, the mail system uses names like \"ddc@lcs.mit.edu\", where\n\"ddc\" is a user name, and \"lcs.mit.edu\" is (more or less) the name of the mail server for that user. Before\nmail can be sent, the software on the sending end-node must first translate the string \"lcs.mit.edu\" into an\nInternet address, so it can format the packets.\nIn order to do this, it first sends a few packets to a service called the Domain Name System, or DNS,\nasking that this translation be done. This step is normally hidden from the user, unless it fails and an\nobscure error message results. But every time a piece of e-mail is sent, or a browser fetches a Web page, a\nname in character format is first translated into an Internet address.\n\nThe DNS names are organized in a hierarchy. For example, the name \"lcs.mit.edu\" is organized as follows.\nStarting from the right, the \"highest\" part of the name is \"edu\". That name is associated with educational\ninstitutions. There are other common \"top level domain\" names, or TLDs: the name \"com\" is associated\nwith businesses, \"gov\" with the US government, and the standard two-letter country abbreviations can be\nused to identify countries. Within the \"edu\" domain, the name \"mit\" is associated with the Massachusetts\nInstitute of Technology. Within \"mit\", the name \"lcs\" is a machine at the Laboratory for Computer\nScience. (Some people believe the names would make more sense the other way around, with the \"edu\"\nfirst, but it is too late to switch now).\nThe mechanics of translating a DNS name into an Internet address is achieved using DNS name servers,\nwhich are simply computers located throughout the Internet that are programmed for this purpose. The\nservers are organized into a hierarchy that matches the hierarchy of the names. There are a set of servers\ncalled the \"root servers\" that are prepared to receive a request to translate the top level names. Given the\nname \"edu\", they return the Internet address of a server that knows about names inside the \"edu\" domain. A\nquery to that server with the name \"mit\" returns the Internet address of a server that knows names inside\nMIT. Next, a query to that server with the name \"lcs\" returns the Internet address of a machine inside\nLCS. In the case of LCS, that machine is prepared to receive mail for ddc@lcs.mit.edu, and the translation\nof a name into an address is done.\nThere is only one further step to make this all work right. All end-nodes, in order to translate a name to an\naddress, must be able to find a root server to start the process. But this fact is easy to get. Any DNS server\nanywhere in the Internet knows the Internet address of a root server. So if the end-node can find any DNS\nserver, it can then find the root, and start the search down the hierarchy. So how can an end-node find any\nDNS server? When a host is first configured to operate on the Internet, there are a few facts that have to be\nsupplied. Either the user must type them in manually, or they are downloaded by a special trick into the\nhost over its network interface before it starts sending real Internet packets. The host must know its own\nInternet address, the address of a nearby router (so that it can send packets out into the Internet) and the\naddress of a nearby DNS server. Those are the facts that have to be supplied when a new machine is\nattached to the Internet for the first time. Normally, with these three pieces of information, the software on\nthe end-node can send packets to figure out everything else that it needs to know.\n7 .\nThe design of high level services\nThe Internet itself, as an entity built of links and routers, is concerned with the delivery of packets.\nApplications such as the World Wide Web exist at a higher level. While to the consumer applications may\nbe viewed as a part of the Internet, technically they run \"on top of\" the basic communication service of the\nInternet, specifically on top of TCP.\n7 . 1 .\nThe World Wide Web as an example\nA case study of a World Wide Web interaction illustrates some of the complexity of the overall design.\nA Web server (an end-node attached to the Internet) stores \"Web pages\", and makes them available for\nretrieval on request. The pages have names, called URLs (Universal Resource Locators). These names,\nwhich have a rather ugly form, have become quite familiar over the few years; an example would be\n\"http://www.ana.lcs.mit.edu/papers/this-document.html\". These names are advertised so that potential\nreaders can discover them; they also form the basis of cross-references or \" links\" from one Web page to\nanother; when a user positions the mouse over a link and \"clicks\" it, the matching URL is used to move to\nthe associated page.\nWhen a user wants to retrieve a web page, the software must first consult the Domain Name System\n(discussed above) to translate the string (for example) \"www.ana.lcs.mit.edu\" into an Internet address,\nwhich will be the Web server storing the page \"papers/this-document.html\". The software at the user's\ncomputer (the so-called \"browser\") then opens a TCP connection to the server machine, and sends a\nretrieval request that contains, among other things, the string \"papers/this-document.html\". There is a\nprotocol called HyperText Transfer Protocol, or HTTP, that provides the rules and format for messages\nrequesting a Web page. The server, on receiving the HTTP request with the name \"papers/this-\ndocument.html\", finds the matching file on its disk, and passes that file through the software that\n\nimplements HTTP and down to the software that implements TCP. The TCP software breaks the file into\npackets, as described above, and sends these packets across the Internet. These packets are then re-\nassembled at the receiving end-node, and the resulting file is handed to the browser software for processing.\nThis somewhat complex story illustrates the layered nature of the Internet design. The transfer of a Web\npage involves actions at several different layers at the same time:\nIP: At the Internet level, packets are received and transmitted when a Web page is requested. At this layer,\nthe only relevant factors are the Internet addresses in the packets.\nTCP: The TCP software takes a unit of data (a file, a request for a Web page or whatever) and moves it\nacross the Internet as a series of packets. It does not examine these bytes to determine their \"meaning\"; in\nfact, the bytes might be encrypted.\nHTTP: HTTP makes use of TCP to move requests and replies. In contrast to TCP, it looks at the contents\nof requests, understands the format and \"meaning\" of these requests, and thus retrieves the correct Web\npage. It then transfers the Web page in question. However, it does not know the format or \"meaning\" of the\npage itself. The page could be a traditional Web page, an image, music, and so on. The HTTP standard\ndoes not define how pages are represented. The HTTP standard only specifies how the format of the page\nis indicated, so that HTTP can find the right interpreter for the page.\nHTML: the most common representation of a Web page is HTML, which stands for HyperText Markup\nLanguage. A Web page, as stored on the server, is not the literal representation of what the user sees on the\nscreen of the browser. Rather, a Web page is a series of instructions as to how that image on the screen is\nto be constructed. These instructions include text and images, information about relative location, size, and\nfont, the specification of links to other pages, layout information about background, colors, and so on.\nDepending on the size (for example) of the screen of the browser, these instructions will cause the page to\nbe presented in somewhat different ways. HTML is the \"language\" in which Web pages are specified.\nAll browsers include software that understands HTML, so that arriving Web pages can be interpreted and\ndisplayed on the screen. HTML is not the only page format. Images, for example, are encoded in a number\nof different ways, indicated by the name of the standard: GIF, JPEG etc. These are alternative formats that\ncan be found inside a Web page. Any format is acceptable, so long as the browser includes software that\nknows how to interpret it.\nReprogramming the browser: There are means to modify the behavior of the browser as it is being used.\nOne that has received a lot of publicity recently is JAVA. JAVA is a programming language that is used\n(among other purposes) as part of the Web. JAVA provides a means to transfer new software from a server\nto a browser that can interpret Web pages. JAVA eliminates the need for pre-agreement as to the format of a\nWeb page. The creator of a page can invent a new format if it suits his need, and transfer the interpreter to\nthe browser just before transferring the page itself. This innovation is intended to provide greater creative\nfreedom to the designer of the Web page. It has the implication that HTTP cannot know, in all cases, the\nformat and \"meaning\" of the bytes being transferred across the Internet, because the \"meaning\" may not be\ndefined in any standards document, but only by the \"behavior\" of the matching JAVA code. If running the\nJAVA code has the consequence that the receiving bytes are converted and played through the audio system\nof the computer, then it is possible to presume that the \"meaning\" of the bytes was to be \"sounds\", but\nthis is not knowable by any of the other layers of the software: HTTP, TCP and so on. This flexibility is\npart of what allows the Internet to evolve to support new sorts of applications.\n7 . 2 .\nDelivery modes: Unicast, multicast and streaming\nThe preceding discussion of Web retrieval illustrates one possible pattern of data delivery. The designers of\nthe Web categorize this as \"unicast pull\" mode: \"pull\" because the user initiates the request for the page, or\n\"pulls\" it at the time it is desired, and \"unicast\" because the packets crossing the network go to only one\nrecipient. There are other alternatives.\n\nMulticast\nThe term \"multicast\" is used to describe a pattern of packet distribution in which several destinations\nreceive copies of the packets coming from a source. Multicast is an Internet-level service, implemented in\nthe routers. It is intended to be more efficient than unicast for a number of cases. One example is multi-\nway teleconferencing, where multicasting is used to implement the equivalent of a conference call. Another\nexample is the delivery of audio and video to multiple recipients. What the radio and television industry\nwould call \"broadcast\" fits into this model.\nThe Internet design community reserves the word \"broadcast\" for a circumstance in which a packet is\ndelivered to all end-nodes within some scope. Broadcast is used across local area networks to transmit low\nlevel control information, but broadcast to all the millions of end-nodes on the Internet is not a useful\nconcept. It would lead to uncontrolled overload, jamming of end-node, and collapse of the Internet. Wide-\narea replication of packets only makes sense if receivers have expressed interest in getting the packets. This\nconcept of sending to a group of receivers who have requested the packets (a so-called \"multicast group\") is\nimportant enough that the term \"multicast\" was coined to capture it. Joining a multicast group is similar to\ntuning a radio to a particular station, except that on the Internet, an end-node can receive from multiple\nmulticast groups at once.\nStreaming\nThe basic communication service of the Internet today is the simple \"best effort\" service that makes no\nassurance about transmission rate or loss rates. For some emerging uses that involve the transmission of\naudio and video in real time, this service is insufficient. The term real time describes the circumstance in\nwhich data is being transferred across the network within a bounded delay, and \"played back\" or presented\nto the user as it is being transferred. Audio and video streams have a specific data-rate requirement, and\nunless the Internet can offer some assurance that it can sustain that rate from sender to receiver, the audio or\nvideo stream cannot be delivered. Using TCP, the sender would slow down if congestion were to occur,\nwhich would disrupt the real time delivery of the data. (Note that just because the data is audio or video,\nit does not necessarily follow that the data need be transmitted in \"real time\". The data can be transferred\n\"in bulk\" and stored on a disk at the receiver, to be \"played back\" from the disk once it has been received\ncorrectly. In this case, TCP could be used to move the data across the Internet.)\nThe forwarding of real time packets is sometimes called streaming. The Internet is now being augmented\nto support real time service as well as best effort service as part of the basic communication service in the\nrouter.\n7 . 3 .\nEnhancing the Web\nThe Web, as described, is strictly a transfer between two end-nodes: a server and a client. There are\napproaches to augment this simple model for a number of reasons.\nOne approach is the so-called \"Web proxy\". This is illustrated in figures 5 and 6. The concept here is that\na Web user will redirect all his Web retrieval requests to a \"Web proxy server\", also called a \"Web cache\nserver\". This server keeps a copy of any page recently retrieved by a customer, so that if a second customer\nasks for the same page, this request can be satisfied from the local copy on the cache. This improves the\nservice seen by the customer, since the page returns (hopefully) sooner. It also helps the Internet Access\nprovider (IAP) supporting the customer, because the wide area capacity that the IAP purchases from an ISP\nis not used up moving the same file more than once. In some cases, the IAP may interpose a Web proxy\nin the path from the user to the Internet, so that the user does not even know that his requests are being\nredirected to the proxy.\nThe consequence of a proxy server is that the IAP serving the consumer will intercept the request for the\nWeb page and originate the transmission of the page back to the consumer, using the locally remembered\ncopy. Many providers of Web pages want the queries to come to their own server, so they can insert\nadvertising, gather information on the user, and so on. For this reason, many Web pages are marked as\n\"non-cacheable\", which means that the proxy is not supposed to keep a copy, but to retrieve the page from\nthe original source each time it is requested.\n\nA related activity is the creation of servers that store long-term copies of popular Web sites as a service for\nthe provider of the page. These servers are sometimes called \"mirror\" servers, since they provide an\nidentical copy of what is stored on the master server. The intention here is similar: to reduce the delay of\nretrieving the page by having a copy of it located close to the consumer. In this case, the page is stored\nthere because of a contract between the provider of the page and the operator of the Web storage server.\nThe Web cache and the Web mirror illustrate that there are multiple reasons to put Web servers at points\n\"inside\" the network -- it can be a case of performance improvement and a business opportunity, perhaps at\nthe same time.\n7.4.\nE-mail\nThe description of the Internet given above was of high level transfers between two end-nodes, with the\nInternet itself providing only simple packet forwarding. Not all applications work this way. An important\nexample is electronic mail, or e-mail. Since many users are not connected full time, if mail was transferred\nin one step from origin to destination, the transfer could only be successful during those occasional periods\nwhen both parties just happened to be connected at the same time. To avoid this problem, almost all mail\nrecipients make use of a server (called a mail server or a \"POP server\") to receive their mail and hold it\nuntil they connect. They then collect all their mail from their server. The concept is that the mail server is\nalways attached and available, so anyone can send mail to it at any time, and the receiver can retrieve mail\nfrom it at any time. This eliminates the necessity for the sender and the receiver to be attached at the same\ntime. Most mail is actually transferred in three steps, from sending end-node to the mail server serving that\nsender, then to the mail server serving the recipient, and then to the final end-node. This is illustrated in\nfigure 7.\n7 . 5 .\nDifferent applications are different\nDifferent high-level services have different designs. The pattern of mail distribution does not resemble the\npattern of Web page retrieval. As new services are invented, there will be new patterns of distribution and\nstorage. For example, some emerging proposals for the distribution of \"TV\" programming across the\nInternet contemplate a two-stage pattern in which the first part is non-real time reliable (e.g. TCP) pushing\nof the content out to \"TV caches\", and the second part is a real-time \"pull\" of the information based on a\nstreaming protocol. The proposal is such that the cache can be located at any point in the system, from the\nISP or IAP to the disk on an end-node of the user.\n8 .\nWhy is the Internet the way it is?\nThe previous discussion is rather mechanical--it describes how the Internet works, but not why it works\nthat way. The why is as important as the how. Here is a short analysis of a few of the important design\nfeatures of the Internet.\n8.1\nThe why of packets\nPackets are not the only way to organize a network. The telephone system works differently--at the\nbeginning of a telephone call some transport capacity is dedicated to that call, enough to carry the voice\ninformation, and these resources are dedicated for the duration of the call. This is called a circuit network,\nin contrast to a packet network.\nOne advantage of packets is that no transport capacity is used unless there is data to send. In a circuit\nnetwork, capacity is reserved for the circuit even if the end points have nothing to send at the moment.\nMany computer applications are bursty: they send their data in bursts separated by quiet periods. For\nexample, when a user is cruising the Web, the transfer of each page is a burst of data, and nothing is sent\nwhile the user looks at the page and decides what to do next. With packets, the bursts of data for lots of\nusers can be interleaved, which leads to more efficient use of the transport capacity.\n\nSince packets can accommodate a range of data communication patterns, they can better accommodate the\nnew application with a different pattern. So packets are part of the objective of designing for change, and\nsupporting the unknown application yet to come.\n8.2\nThe why of end-to-end\nWe discussed above one of the central design tenets of the Internet, the end to end argument. This line of\nreasoning says that if some function (e.g. application-level processing) can be implemented at the edge of\nthe network, in an end-node, rather than in the routers in the network, edge placement is preferable. The\nbenefit of this approach is that the network itself remains simpler and not constrained to only certain\napplications. While this may mean that any specific application is less efficient, it improves the chance that\na new application can be added to the network without needing to modify the routers. So again, this is a\ntradeoff in which the ability to evolve is preferred over the optimization of the applications of today.\n8.3\nThe why of stateless design\nIn the Internet, there is no concept of a \"call\". Unlike the telephone system, where there is a \"setup phase\"\nat the beginning of a call where resources are reserved for that call along the path from source to\ndestination, there are no reservations in the Internet. The router forwards each packet as it gets it, but does\nnot have any advance knowledge that the packet is coming, or any log that it came. We call this a stateless\ndesign, since in the language of Computer Science, such stored information is often called state. (For a\nsystem to be in on or another state, there must be some information to distinguish the various states. If\nthere is no stored information, there are no distinct states.)\nThe advantage of the stateless design is, again, simplicity. If there was a setup phase before sending a\nbunch of packets, the router could establish some state information for the packets, perhaps precomputing\nthe forwarding decision or reserving some resources. This might be more efficient in specific cases, but\nalso more constraining and more complex. For example, if state describing a flow of packets is set up\nalong a path from source to destination, and then some link in the path fails, the state information in some\nof the routers would have to be removed, and state would have to be installed in some new routers. This is\nactually quite hard to do in a reliable and quick way. The design of the Internet went for simplicity.\n8.4\nThe why of loose specification.\nThe Internet makes few commitments to the user about the quality or consistency of service. The best\neffort service commitment is that the Internet will do the best it can, but there is no specification of how\ngood that is. The network may lose packets, deliver them out of order, delay them, and so on if conditions\nrequire. Why is this a good idea? This approach puts an extra burden on the application designer, who\nmust design the application to cope with these variations. But tolerating these variations has a benefit. A\nwide range of technologies can be put to use to carry Internet packets--fast and slow, reliable and lossy,\nand so on. If the Internet specified a more constrained and pre-determined level of service, then some of\nthese technologies might be excluded all together, which would mean that there would be situations where\nthe Internet was not available at all. The view of the designers is that \"poor\" service is better than no\nservice at all, and that the application and the user (the human) should determine what is \"too poor\", not a\nInternet-wide specification.\n8.5\nA preference for flexibility and change.\nThere is a common theme through much of the above discussion. The Internet designers, when making\ndesign choices, preferred to optimize for change, not to optimize any single application. The telephone\nnetwork is optimized for telephone calls. The Internet is optimized to adapt to the application that might\nhappen tomorrow.\n\n9 .\nConclusions -- implications\n9 . 1 .\nImplications of the layered structure\nBecause of the layered structure of the Internet design, the different sorts of service providers cannot always\nsee the parts of the information that is not relevant to them. The ISP cannot always see the higher level\ninformation in the packets (for example, it may be encrypted.) The higher-level service provider (a Web\nserver, for example) cannot see the routing information in the routers, and cannot determine what the\ntopology and capacity of the Internet is. These limitations have policy implications--for example it is\ndifficult for the IAPs to control access to objectionable material over the Internet, or to meter the delivery\nof content for which fees must be paid.\n9 . 2 .\nContent can have multiple representations.\nIn a digital system, a piece of material of one \"type\", e.g. a piece of music, can be stored and transmitted\nin multiple representations. Different encodings can be used to achieve different fidelity, different tolerance\nfor bit errors, and different transmission efficiency (\"compressed\" representations must be \"expanded\"\nbefore being used, so they require more processing power but less transmission capacity.)\n9 . 3 .\nDelivery modes are not tied to type of content.\nThe way in which material is encoded or represented in digital format is not linked in any way to the mode\nof transport across the Internet. A given file can be (at the Internet level) unicast or multicast, and can be (at\nthe end-to-end transport level) delivered reliably by TCP or in real time.\n9 . 4 .\nMany controls cannot be implemented \"in\" the net\nHigher level concerns such as limiting the access to objectionable material or preservation of intellectual\nproperty rights have often been implemented in the end-node. This follows from several considerations.\nFirst, the Internet level mechanisms, the routers, and thus the ISPs, cannot always tell what is being\ntransported at the higher levels, since it may be in an unknown representation or encrypted. Second, new\napplications can come into operation quickly, and the ISPs will not necessarily know what the nature of\nthat application is. The end-node is where that application runs, and thus the end node is a natural locus of\ncontrol.\n9 . 5 .\nThe Internet evolves rapidly\nAs has been illustrated above by several examples, the Internet is designed to evolve rapidly. The goal is to\nsupport new high-level services without requiring changes to the routers, to allow individual end-nodes to\ninstall and operate new software without negotiation without other parties, and to change the routers as\nnecessary when there are new service demands. As much of the router as possible is usually implemented\nin software, so that it can be changed without a hardware upgrade.\nThe modes in which the Internet operates today are not necessarily what we will see in a small number of\nyears. New applications, new delivery modes, new Internet level services, and new data representations can\nall be anticipated. We can also anticipate new billing and cost-allocation mechanisms.\nGlossary\nAddress (Internet): Packets crossing the Internet carry a destination address to indicate where the packet is\ngoing, and a source address to indicate where it is coming from. Current Internet addresses are 4 bytes (32\nbits) long. (See the definition of bit.) They are by custom written down by taking each byte of the\naddress, and writing it as an integer in the range of 0 to 255, separated by periods (or, in the terminology\n\nof the field, dots). Thus, an Internet address might be written as 18.26.0.120. There is a proposal for a\nnew generation of Internet packet header, called IPv6, with much larger addresses. This expansion may be\nnecessary to deal with all the computers that will be connected to the Internet over the next decade.\nApplication: a user-visible high-level service. Applications are normally implemented as software that runs\non end-nodes attached to the Internet.\nBit: the smallest unit of information stored and transmitted in a computer system. A bit can take on only\none of two values, normally expressed as 0 or 1. A number of bits can be used in sequence to store an\ninteger, a character, and so on. For example, in eight successive bits (called a byte) a total of 256 different\npatterns of 0's and 1's can occur. So a byte could be used to store an integer in the range of 0 to 255, or\none of 256 characters. Since there are less than 256 characters in normal English text, including lower and\nupper case letters, punctuation and numbers, it is traditional to store a text document in a computer by\norganizing the memory of the computer into bytes, and putting one character in each successive byte.\nByte: see bit.\nChecksum: a mathematical computation performed on data (a sequence of bytes) to yield a small numerical\nvalue. The outcome of this computation depends on all the data, so changing any one bit of the data will\nchange the computed value. The checksum can thus be used to detect if any part of a message has been\ndamaged as it is transmitted across the network.\nCongestion: the condition where a router has received more packets than the outgoing link can carry away,\nso that the memory of the router is forced to store these packets until the condition passes. If the\ncongestion persists, the router may have to discard some of the stored packets.\nDatagram: a term used to describe a packet in one particular sort of network, in which the routers in the\nnetwork make a separate forwarding decision for each packet as it is received. The alternative would be to\nrequire that the sender notify the network before sending a stream of packets, so that the network could pre-\ncompute how all of these packets are to be processed.\nEncryption: the act of disguising data before sending it across the network, so that it is meaningless to\nanyone who does not have the means (the encryption key) to reverse the encryption process.\nEnd-node: a computer or other device that is attached to the Internet for the purpose of transmitting and\nreceiving packets and participating in the high-level services of the Internet. A personal computer (PC) is\nan example of an end-node, as is a Web server.\nField: term used to describe each separate part of a packet header, such as a destination address. A field will\ntypically be some specified number of bytes in length.\nHeader: control information such as a destination address that is placed at the beginning of a packet to\npermits its proper processing by the various protocols that deal with it.\nInterface: a term used in Computer Science to describe what parts of a facility or system are externally\nvisible. The usual goal is to make a complex system easy to understand and use by creating a simple\ninterface to that system. A well-designed interface will preserve most of the useful features of the system\nwhile hiding the irrelevant ones.\nMulticast: the process by which a packet sent from a source is delivered to multiple recipients. The routers\nimplement this process by forwarding the incoming packet along multiple outgoing links as appropriate to\nfan out to all the intended destinations.\nProtocol: the term used to describe the various technical specifications of the Internet. A protocol is a\nspecification of permitted behavior by the various components of the Internet such that the resulting overall\noperation of the network is correct, and the participants can accomplish their intent.\n\nPacket: a unit of information, typically no more than 1000 to 2000 bytes, with a series of headers at the\nfront, that is transmitted across the Internet from a source to one or more destination.\nQueue: a part of the memory of a computer (for example a router) where packets can be held until they can\nbe processed or transmitted. Packets are held in a queue if they cannot be sent at once due to congestion.\nRouter: the physical device (typically a computer with special software) that connects communication links\ntogether to form the Internet, and forwards packets from one link to the next.\n\nInternet\nemail\nm'cast\nTV\ne-\ncomm\nLAN\ntelco\nTCP, UDP, RTP, etc.\nProtocol\nWWW\ntele-\nconf\nphone\naudio\nlinks\ncable\nradio\nmodem\nRouters are concerned with\nfunctions below this line.\nFigure 1: The \"hour-glass\" model of the Internet\nAn illustration of the organization of the Internet protocols.\nThere are a number of high-level services shown at the top,\nwhich are to be implemented using the various network\ntechnologies at the bottom. The Internet protocol, illustrated\nat the narrow point in the figure, specifies a set of basic\ncommunication services. The high level services make use\nof this basic service, and the network technologies support\nthis service. By this specification, the details of each part are\nhidden from the other.\n\nISP A\nR\nR\nR\nR\nR\nR\nR\nR\nR\nR\nR\nR\nR\nR\nR\nR\nIAP 1\nIAP 2\nISP B\nIAP 3\nIAP 4\nIAP 5\nFigure 2: The Internet as a mesh of links and routers\nAn illustration showing that the Internet is composed of links\nconnected by routers. The links are shown here conceptually as\npoint-to-point connections such as a line provided by a telephone\ncompany.\nDifferent parts of the Internet are operated by different entities: Internet\nService Providers (ISPs) and Internet Access Providers (IAPs), which provide\nconnections to the end-node computers that attach to the Internet. Although\nnot illustrated here, other entities such as institutional users can also operate\nparts of the Internet\nIAPs attach to ISPs to carry their traffic. IAPs can attach to more than one\nISP, and ISPs can interconnect in more that one point. Traffic between 2 IAPs\n(e.g. IAP 1 and 3) may have to cross more than one ISP.\n\nH\nR\nAn end node or host\nAn IP router\nR\nLAN\nH\nH\nH\nH\nLAN\nH\nS Switch\nH\nS\nR\nR\nR\nS\nH\nH\nS\nATM\nnetwork\nH\nH\nPOTS\nR\nHead end\nnetwork\nfacility\nC\nCable network\nH\nH\nH\nH\nFigure 3: The Internet is built out of different sorts of communication technology\nAn illustration of several different sorts of networks connected by routers.\nThe networks include a local area network (LAN), a switched network based\non the ATM technology, a dialup access network and a cable television\ndistribution facility.\n\nInternet end-node\nEthernet\nEthernet\nEthernet\nS/W\nT1\nH/W\nrouting etc\nS/W\nHi\nlevel\nservi\nS/W\nH/W\nH/W\nIP forwarding\nPPP S/W\nT1 S/W\nSNMP\nEthernet\nIP end-node\nTCP, UDP, etc.\ngh\nces,\nsupporting\nInternet router\nInternet router\nT1\nH/W\nrouti\netc\nIP forwarding\nPPP S/W\nT1 S/W\nSNMP\nng\nModem S/W\nPPP S/W\nEthernet link\nT1 link\nFigure 4: Implementing the protocol layers of the Internet\nIllustration of the hardware and software modules found in end-nodes and\nrouters. The illustrated end-node is attached to an Ethernet Local Area\nNetwork, and has software to operate this Ethernet. The IP (Internet Protocol)\nsoftware uses this Ethernet software to transmit and receive packets\nacross the LAN. The intermediate protocol software (TCP, UDP, etc.)\nuses the IP software to send packets. The high level service software\nuses the intermediate software.\nInside the router, there is no high-level software, and no intermediate\nprotocol software to support it. Depending on which networks are\nconnected to the routers (Ethernet, T1 links and modems are illustrated\nhere) there is matching software. The IP forwarding software uses that\nnetwork-specific software to receive and transmit packets. There is also\nrouting software to perform the routing computation, SNMP (Simple\nNetwork Management Protocol) to allow human operators to control\nthe router, and so on.\n\nWeb\nServer\nWeb\nProxy\nIAP 1\nISP 2\nIAP 4\nISP 3\nDISK\nDISK\nUser 1\nUser 2\nTransfer C\nRequest B\nRequest A\nFigure 5: Retrieval of a Web page from a server via a proxy\nThis figure illustrates the transfer of a Web page from a Web server\nto a user (User 1) making use of a Web proxy operated by the IAP\nthat serves the user (IAP 4). If there were no Web proxy in place, the\nrequest would go directly from the user to the Web server, and the Web\npage would be transmitted back directly to the user. Using the Web proxy,\nUser 1 requests the page from the proxy (Request A). In this case, the page\nis assumed not to be on the proxy, so it is requested from the original\nserver by the proxy (Request B). The required page is transmitted back\nto the proxy, where it is stored on disk, and also sent on to User 1.\nFigure 6 illustrates the case when User 2 subsequently requests the same\nWeb page.\n\nWeb\nWeb\nIAP 1\nISP 2\nIAP 4\nISP 3\nDISK\nServer\nDISK\nProxy\nUser 1\nUser 2\nRequest A\nTransfer B\nFigure 6: Retrieval of a Web page located on a proxy server\nThis figure illustrates the case of a Web retrieval in which the needed page\nis located on the proxy, because some user has previously requested it. In\nthis case, User 2 requests a page from the proxy, and since a copy of the page\nis currently stored on the proxy, no transfer occurs from the server, but the\npage is transferred from the proxy to the user.\n\nMail\nServer\nB\nDISK\nA\nDISK\nIAP 1\nISP 2\nIAP 4\nISP 3\nMail\nServer\nUser 1\nUser 2\nTransfer C\nTransfer B\nTransfer A\nFigure 7: Typical pattern of mail transmission\nThis figure issustrates the typical sequence of transmission that constitute\nthe sending of mail. In principle, User 1 could transfer the mail directly to\nUser 2. In practice, the users will take advantage of mail servers that are\noperated by their respective IAPs, IAP 1 and IAP 4. The mail is transmitted\nto Mail Server A, after which User 1 can disconnect from the Internet.\nServer A will attempt to transmit the mail to server B. When this succeeds,\nthe mail will be stored in Mail server B until User 2 connects to the Internet\nand requests it. In response to this request, server B will transmit the mail to\nUser 2. In this sequence, the transfers A and B are initiated by the sender,\nwhile transfer C is initiated by the receiver."
    },
    {
      "category": "Resource",
      "title": "future_internet.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-68j-communications-and-information-policy-spring-2006/bbd39e327e3244b20a3f6d467bd32b9e_future_internet.pdf",
      "content": "Readings on alternative futures for the Internet\nFeb 15, 2006\nWe have discussed in class the fact that the Internet seems so well-established, that it is\nhard to conceive of alternative structures for the Internet--different technical designs\nwith different implications for the larger social and economic context.\nHere are two readings that might help stimulate the imagination.\nThe first is a list of discussion topics that will define the working agenda of an upcoming\nmulti-disciplinary workshop on the future of the Internet. The topics were picked because\nthey emphasize the need for cross-discipline assessment and discussion.\nThe second was prepared to illustrate to the National Science Foundation what sort of\nresearch might be undertaken as part of the recently-announced Future Internet Design\n(FIND) project. This document was prepared for a more technical audience, and the list\nof issues will vary as to what their impact would be in the larger context. It might be an\ninteresting exercise to go through this list and look for policy issues that would arise as a\npart of these projects.\n\nDiscussion topics for a workshop on Future Internet Design\nThe goal of this workshop is to explore a new space of multi-disciplinary design, and the\nrelated question of process--how can a multi-disciplinary team function effectively to\ncontemplate design alternatives for a future Internet?\nThe workshop will consider several case studies, which will be the basis for a series of\nmini-design sessions. Each case study will describe a set of design alternatives, which\nwe will consider in terms of both the technical options and the social or economic\nimplications. Below is a list of possible questions that this workshop might consider.\nIdentity \"in the network\"\nIn the future, to what extent should an observer \"in the network\" be able to identify the\nsender of a packet? What are the social and economic implications of different degrees of\nidentity and anonymity in the network? How would the presence of identity information\nchange current uses of and interactions on the Internet? Should this ability be used to\ndevelop a policing system or \"surveillance cameras\" for cyberspace?\nToday, the source IP address in the packet gives some hint as to the identity of the sender.\nPrecisely, it indicates only the network location (not the physical location) of the sender;\nhowever, this information can often be translated into some better signal of identity. This\nlink to identity may get much weaker. With increasing mobility of end-nodes, the IP\naddress will become more of a transient indicator of location. The location may change\nrapidly over time, even for an ongoing connection. Given this trend, there is essentially\nnothing visible in a packet that can link it back to the identity of the sender.\nThere will, of course, be identifying information handed back and forth between the end\npoints of a connection. At a minimum, there will need to be some sort of identifier that\nthe end points use to keep track of each other as their location changes. Some end-points\nmay demand very robust identification from the other end-points. But while this\ninformation is carried among the end-points inside packets, it may not be visible--it may\nnot be in a standard recognized format and it may be encrypted. Further, it may not be in\nall the packets of the connection. So while the end-nodes may know each other's\nidentity, observers in the network may not. Given this fact, a \"surveillance camera\" in\ncyberspace may be able to see nothing except encrypted packets going between transient\nlocations. We could choose to include explicit identity information in packets, but how\nmight we minimize the chilling effect that is associated with loss of anonymity and\nanalogs such as identity cards and travel papers?\nHence the question: are there significant reasons for packets to carry some sort of identity\nthat is visible \"in the network\".\n\nTechnical form of the question: Should there be a field in the packet header that\nidentifies the sender of a packet? If ISPs want to give different users different services,\nwhat information in the packet should be used to signal that discrimination--session\nsetup or packet state? If the packet had an identity field in the header, do we need to fully\nspecify its semantics, or would it make sense to use the field in different ways at different\ntimes and places?\nIdentity in e-mail\nIn the Future Internet, when person A sends an email to person B, what level of\ninformation should B expect to have about A? With what level of certainty? How would\nacting to strengthen confidence/knowledge of identity in the Future Internet affect users?\nWould the benefits of stronger identity outweigh the possible negative consequences?\nToday, users of email identify themselves to each other using their email addresses,\nstrings such as user@example.net. Between cooperating users, these work well, but they\ncan be forged. So a certain amount of spam is sent using a forged sender email address,\nand the mail classified as \"phishing\" has false sender email addresses. There have been\ncalls to \"improve\" this situation, and give person B a higher level of confidence that\nperson A is actually person A, and a higher level of knowledge as to who person A\nactually is.\nIf it is generally agreed that identity needs to be strengthened, further questions remain as\nto how this would be accomplished. One option is that all users should be issued a \"top\ndown\" identity--that is, an identifier issued by some trusted party, who is in turn\nvalidated by some higher-level trusted party, perhaps leading to a chain of trustworthy\nidentities that can be traced back to a nation-state. This identity could be used to identify\nthe sender to the receiver. In a system like this, the question is: What attributes of identity\nare included (and verified) by this issued identity? Would it be just the given name of the\nperson? Name, address and years at that address? Age? Gender?\nAnother view is that we use \"bottom-up\" identities. In a system like this, users issue\nthemselves identifiers. If properly designed, these cannot be forged, but of course since\nthey are self-issued, they do not tell the receiver anything about the sender. All they allow\nis a sender to prove that he is the same sender as in the last message. They allow a user to\nconnect a series of interactions, and \"get to know\" someone by that means.\nTechnical form of the questions: Should we move toward a regime of mail signed with\npublic/private key pairs? If so, should we presume a single PKI, several unrelated PKIs,\nor self-signed certificates. How can we present identity information in the user interface\nof the mail system so that the user can make sensible decisions based on the information?\n\nPorts and application visibility\nToday, the Internet names services (such as Web or email) using \"well-known ports\"--\nnumerical indices that are statically assigned to each application and service at design\ntime. Since these port numbers are included in each packet, this permits any observer in\nthe network to determine what application is being used. And since these numbers are\nstatically assigned, an attacker can easily launch an attack against an application on a\ngiven host. It need not be this way--an alternative would be to design a new mechanism\nfor \"service rendezvous\", and to use random port numbers to identify connections. What\nwould the implications be if packets did not reveal what applications they were\nassociated with, and security tools could not associate applications with ports.\nThere are implications for economics and security if it is not possible to tell what\napplication the users are running by looking at the packets \"in the network\"? ISPs\nobserve port numbers to build models of what their users are doing. This information\nmay help with capacity planning, and is the basis of discrimination among different\nclasses of users that wish to use different services.\nFrom a security perspective, well-known ports are a fundamental component of both\nattack and defense. Attackers combine host addresses and well-know ports to explore\nwhether a host is running a version of the service with a known vulnerability. Firewalls\nrespond by blocking access to specified port numbers. If port numbers were random, this\ncould essentially eliminate the value of the attack known as port-scanning, but it would\nchange the whole security landscape by limiting what firewalls can do based on packet\ninspection.\nSo the question: should a future Internet employ a different scheme for session\nrendezvous and connection identification.\nTechnical form of the question: Should the Internet move to a mechanism such as\nDNS-SERV to assign port numbers to services on hosts? Should the port field be\nincreased, perhaps to 32 bits? Should we move to an application-specific mechanism for\nrendezvous and connection management? Should the port number be encrypted in some\nway?\nValidating the authorship of web pages and other\ndocuments.\nToday, we establish the authorship (or authority) of a piece of information indirectly. The\nway we confirm that a web page is (for example) created by CNN is that we download it\nfrom CNN. The confirmation of the authorship is associated with how we got it, not with\nthe object itself. If A downloads a web page and then send it to B, there nothing about the\nweb page itself that confirms to B that it is legitimate. Should the Internet include a way\nfor authors to sign Web pages and other net documents, and how should this namespace\nbe controlled?\n\nThere are lots of reasons why it would be important to validate the authorship of a piece\nof information independently of how one gets it. Today, bits of information are sent\naround from person to person as email attachments. The research community has\nproposed a number of creative schemes, such as peer-to-peer retrieval system, to support\nefficient and robust information dissemination. And as we more and more depend on\nsearch engines such as Google to find things, we have less and less confidence about the\norigin of anything we download. But today, none of these schemes can confirm the\nvalidity of the information they propagate. To mitigate these problems, what Is needed is\na scheme that associates the authority with the object, not how it is fetched.\nIt is not difficult to conceive a scheme to sign documents with some sort of encryption\nscheme. The hard part of this problem is to devise the namespace in which the authors are\nnamed. Such a system has to resist forgery, be easy to manage, and easy for users to\nunderstand. Today we use DNS names and public key certificates to verify the source of\ndata, and at first blush, we could just use those same names as names of authors.\nHowever, the ongoing debate about governance of the DNS suggests that we might\nconsider designing a name space that sidesteps some of the tough political tangles that\nhave snared the DNS.\nOne choice for naming is that there is some sort of registry of author names, similar to the\nregistry of domain names. Provided the registry is trustworthy, this approach gives the\nreceiver of an object some confidence about a page from a previously unknown author,\nbut raises all the issues we have today with control and governance of the registry.\nAnother approach is that names are not registered at all, but are just validated pairwise\nbetween sender and receiver. That is, a receiver comes to trust a sender by developing a\nrelationship with that sender. The names provide continuity, but not the trust in the\nrelationship. This concept is similar to the discussion about \"bottom-up\" signing of email.\nGated communities and virtual networks\nThe current Internet started out as \"one big network\", where everyone could send to\nanyone. Today, most of the Internet technology is not in the public Internet, but in private\nversions of the Internet, such as corporate networks, which are connected to the public\nInternet only in very constrained ways. The public Internet itself might go in this\ndirection, fracturing into groups that self-define in some way, and which link to each\nother only in very constrained ways. In balance, would this be a good idea or a bad idea?\nToday, the public Internet is \"open\", in that anyone can send to anyone. But different\napplications use this open basis in different ways. Email is fairly open, instant messaging\nis less so, and applications can impose very complex restrictions on which parties can\ncommunicate with each other. There is no reason to think that the \"open by default\"\nmodel is the one toward which the Internet will gravitate.\nThe question of \"how open?\" can be raised at several levels--at the packet level, at the\napplication level, and at the \"social\" level. The Web and its possible futures may be a\n\ncase study that can stand for all the Internet. The original idea of the Web was that any\npage could link to any other page, that any user could be a producer and make fresh\nlinkages in the Web, and that the power of the Web was its open nature. Of course, this\nsimple picture is imperfect. Corporate information (which may be proprietary) is not\nopen to this sort of linkage. Some ISPs are exploring the business opportunities that\nmight arise from providing selective access to some content over other. There seems to\nbe a trend for users to seek information from sources that they prefer. And some countries\nare demanding that their citizens be protected from seeing forbidden content.\nGiven that users only interact with the Internet through that applications that run on it, if\napplications control the degree to which the Internet is open or closed, has there been a\nloss of social value? Should application designers include features that can be used to\ncontrol the reach of openness? Perhaps the loss of social value is related to which parties\ncan control the degree of openness, and the issue is that if these controls are added at all,\nit is difficult to control which parties can control them. Should application designers\nconcern themselves with the question of how their design influences which parties have\ncontrol over the degree of openness. Should we be concerned with the design of search\ntools, and how they lead users to one or another answer to their queries?\nManaging location information\nThere is no notion of physical location in the design of today's Internet. But with the\nincreasing use of mobile and wireless devices, physical location will become of\nincreasing importance. Today, the cellular system has been required to determine the\nlocation of every cell phone so they can respond properly to a 911 emergency call.\nPhysical location is integral to some emerging on-line socialization, flirting and game-\nplaying. It seems inevitable that physical location will be central to many future Internet\napplications. So now is the time to consider how a system for managing physical location\nshould be designed.\nHow is location derived? Today, in the Internet, addresses are used as the starting point.\nAddresses are given out to Internet Service Providers, who give them in turn to\ncustomers. Most ISPs operate within a physical locale (which may be large in the case of\na national ISP), and most ISPs know where their physical circuits go. If they know that a\ncustomer is at the end of a physical circuit, they can make a reasonable guess as to where\nthat customer is. This sort of inference is used to prevent auction services from displaying\nNazi memorabilia to citizens of France, for example. Services such as Google give\ndifferent answers depending on what country you are in, and this requires some sort of\nguess as to physical location based on IP address.\nIn the future, there will be many more ways to determine location. More and more end-\nnode devices have GPS receivers, so if they are outside (in view of the open sky and the\nGPS satellites) they can compute their own location. The question then is whether (and to\nwhat parties) they will pass on that information. GPS information is under the control of\nthe end-node, not the ISP. But the wireless service providers are also getting better at\n\nlocating their end nodes. Wireless systems can attempt to geo-locate end-nodes using the\nradio signals, and triangulating.\nThe question, then, is what will operators do with this information? One obvious answer\nis to sell it. This may trigger calls for regulation of the use of this information. This will\nin turn raise question about what third-party players who attempt to guess a location will\nbe allowed to do with their information. To help visualize what the issues might be, here\nare some possible scenarios of usage:\nCase 1: Use of location in an ongoing interaction. In this situation, some number of\nparties are already in communication, and one of them attempts to determine the location\nof another. Since they are in communication, each end knows something about the\nother--at a minimum an IP address. There may be other information available. This is the\nsituation with country-specific modification of services like Google or E-bay. In these\ncases, the question about location is asked about a specific node that is already known.\nCase 2: Use of location to find possible candidates for interaction. In this case, the\ninteraction starts with a request to determine a set of nodes that are within some locale,\nafter which an attempt is made to communicate with them. Examples of this include\nsending a message to anyone on a beach that a tsunami is coming, or sending an\nadvertisement to anyone nearby about a sale going on. The social value may vary widely,\nand there may be calls to allow this sort of location-based search only under certain\ncircumstances, which will have to be debated.\n\nDesigning a new Internet--why FIND and GENI matters\nDraft version 2.1 of Wednesday, February 15th 2006\nThe NSF FIND project pursues a bold vision, the vision of creating a new Internet suited\nfor the needs of tomorrow. GENI is a research platform that will support experiments\nacross a wide range of computer science, including the NSF FIND project. This\ndocument illustrates what the FIND research entails, what it will mean to create and\nevaluate a new Internet, the range of concepts and innovations that will go into this\nproject, and how GENI will support the FIND program.\nThe nature of the contemplated research\nWe envision a program of research that combines scientific discovery, invention of new\nmechanism, and the integration of new concepts into coherent overarching proposals for\nan Internet of tomorrow. We call these integrated proposals architecture, and the\nintended outcome of the FIND research agenda is the creation and validation of candidate\narchitectures for an Internet of tomorrow. These will be tested on GENI.\nThe Internet has been with us long enough that it is easy to forget how recently its basic\nideas were conceived, and how novel they were at the time. The central concept of the\nInternet, that data is broken into small units called packets that are statistically\nmultiplexed over circuits, is less than 50 years old, and when it was first proposed it was\nviewed as a radical and unworkable idea. There were fears of instability and of\nuncontrolled queuing. The validity of the idea had to be proven by a combination of\nmathematics, simulation and real-world trials. In fact, the first workable approach to\ncontrolling queue length took over 10 years to conceive from the start of the Internet, and\nonly with real world experience did the designers come to understand that part of the\nproblem was system-wide oscillation caused by the network being driven at the\nfundamental frequency of the flow-control window size. Simpler models had simply\nfailed to capture this effect.\nDesigning a new Internet is not just the discovery of one or two new, breakthrough ideas.\nEven the singular idea of packet switching is only part of what defines the Internet.\nCreation of an architecture for a system is different from scientific discovery, and fits\nwithin the general domain of systems engineering. Systems engineering is a process that\nincludes specification of requirements, invention of new approaches, and a complex\nprocess of trade-off and balance among different functional objectives, and as well\namong different stake-holders and constituents. Validation involves a process that first\ntests specific proposals for new mechanisms to better understand their limitations and\nrelative advantages, and second tests more complete architectures to determine fitness of\npurpose within the multi-dimensional space of requirements.\nDesigning a new Internet is perhaps like designing a new airplane. Lots of new\ninnovations may be proposed, and the process of design must validate these innovations.\n\nBut the success of the overall design is the integration of concepts to produce a design\nthat balances a number of disparate considerations that include fuel efficiency, noise\nabatement, minimum required runway length, capacity, air safety and cost. In aircraft\ndesign, individual innovations become useful when a new plane is designed. The airframe\nmarket sees a steady introduction of new planes, which provides a platform for new ideas\nto enter the market. Similarly, there are some innovations in networking that can only\nenter the market if we contemplate a new Internet.\nSome examples: a critique of the current Internet\nOne way to contemplate what a new Internet might look like is to catalog some of the key\ncomponents of the current Internet, note what is wrong with each part, and list some of\nthe proposals that have been put forward to improve them. This approach has the risk that\nit can lock us too much into the current set of parts, but it has the merit that it permits a\nconcrete example of what the experiments on GENI might look like. So with that\nwarning, we can look at the current Internet.\nPackets and multiplexing\nA basic assumption of the Internet is that data is broken into packets, which are then\nmultiplexed statistically along communications paths. Most (though not all) researchers\nconclude that the concept of packets is a good one that should be a part of a future\nInternet. But in the center of the network, there is an increasing view that individual\npackets are too small to be handled individually. Instead, we need a design that can\nprocess aggregates of packets. Today, this is done outside the architecture, using a\nseparate mechanism (such as MPLS). If routing and management of aggregates were\nincluded into the architecture of the Internet, it would allow both packets and aggregates\nof packets to be handled in a unified way. In particular, the concepts of routing, traffic\nengineering and topology management should be unified in a future Internet. Fault\nrecovery should be unified across layers. The inclusion of switched optical components\nin GENI will allow researchers to experiment with algorithms for rapid reconfiguration of\naggregates.\nWhile statistical multiplexing of paths leads to good link utilization and cost-effective\ndesign, it is also a security risk, in that an attacker may be able to flood certain links to\nthe point where good users are squeezed out. There are several approaches that have been\nproposed to solve this problem. One is Quality of Service, which is now being used in\nprivate networks, but only partially in the public Internet. Another approach is\nvirtualized resources, in which simple statistical multiplexing is replaced with a more\ncomplex layered approach to sharing in which classes of users or activities are given\nstatic shares, and only within these classes is there dynamic sharing. GENI will be used\nto test the concept of virtualization. Another approach to controlling abuse is diffusion\nrouting, discussed below\n\nAddressing and forwarding\nOnce we agree that the network will carry packets, the next step is to design the\nmechanism that allows packets to be forwarded across the network. The Internet contains\nelements called routers, which look at the address in packets to determine how to forward\nthem. The original Internet assigned a global address to every destination, and allowed\nany computer to send a packet to any place. This open pattern of communication was\ncritical to the early success of the Internet, but has caused a number of serious problems,\nwhich only became apparent over time. For this one topic of packet addressing and\nforwarding, we have cataloged over 24 proposals for alternative addressing and\nforwarding schemes, most of which have gone nowhere, because there is no way to\nvalidate them. GENI will allow us to try out alternatives to today's scheme that might\nprovide better security, better management, and better functionality.\nOne problem with global addressing is that it allowed the Internet to be a vector to deliver\nsecurity attacks, since any machine, including a malicious one, can send traffic to a\nsecurity target. A future Internet must provide what has been called trust-modulated\ntransparency: trusting nodes should be able to communicate at will, as in the original\nconception of the Internet, but nodes should be protected from nodes they do not want to\ncommunicate with. There are several approaches to achieving this balance, which we\nexpect to validate using GENI. One is address indirection, in which senders do not\nknow the address of the receiver, but only a name. A protected element in the network\n(which would have to be invented for the purpose) would check the identity of the sender,\nand decide whether to forward the packet to the address of the named recipient. A second\napproach is the permit approach, in which the receiver gives to the sender a special\ntoken, which is then included in the packets from the sender. Again, a protected node in\nthe network would check the token to decide whether to forward the packet. These\nschemes, in general, are examples of taking the concept of a firewall, which is an\nafterthought in the current design, and considering from scratch how to integrate this\ncomponent into the Internet as a first-class element.\nA second problem with the original addressing scheme is that it did not take into account\nmobile devices, which are becoming the norm, and may dominate the Internet in 10\nyears. Today, Internet addresses are used to convey a weak form of identity as well as\nlocation on the net. Since the IP address captures the notion of identity, it is not possible\nto change the IP address in an ongoing conversation, which means that a node that is\nmobile cannot change its address as it changes it location. A future Internet must have a\nscheme for dynamic address reassignment and a scheme for automatic connection\npersistence for mobile end nodes.\nOn the other hand, as we better deal with mobility, the value of an address as a signal of\nidentity may erode. This raises the question of whether there needs to be some explicit\nform of identity that is visible to an observer of packets in the network. Different answers\nhave very different implications for privacy, for accountability and for policing. One\nresponse to this question is that there will be different needs for identity in different parts\n\nof the network, so the packet header should include an identity field, but not a rigid\nspecification of what that field should contain. One proposition for an experiment on\nGENI is a semantics-free identity field in the packet header.\nA final example of a problem with the current Internet addressing scheme is that IP\naddresses are normally bound to specific physical machines, but in many cases a message\nneeds to be sent to a more abstract entity--a service rather than a machine. A scheme\ncalled anycast has been proposed to solve this problem; this scheme allows the same\naddress to be assigned to multiple machines, and the particular machine to receive the\npacket is determined by the routing protocol at run time. Anycasting may solve a number\nof security problems as well as problems of service location and session initiation, but it\nhas never been fully elaborated or tested. A new Internet may contain a mechanism like\nthis, which will have to be evaluated on GENI.\nRouting\nRouting is the process of computing the best path from sources to destinations. Routing is\nnot the same as forwarding--routing computes the best paths, forwarding uses the results\ncomputed by routing to take the correct action as each packet arrives at the router.\nToday, the Internet uses a two-level routing scheme, with a top-level mechanism called\nBorder Gateway Protocol, or BGP, to connect different administrative regions, and a\nsecond level of protocol inside each region. The region structure of the Internet seems\nlike a fundamental, and in fact may be more explicitly expressed in a future Internet\ndesign. This means that we will have to set up experiments on GENI to capture the idea\nthat different parts of the Internet are run by different organizations.\nThe BGP of today is flawed: it limits the business relationships that ISPs can negotiate, it\nrecovers from some failures much too slowly, it is not sufficiently secure, and under\nsome circumstances it can be unstable and lead to routing oscillations. None of these\nissues were fully understood until the protocol was put into use on a large scale Internet.\nAlternatives to BGP are being developed that provide better convergence after\nequipment failures. A platform such as GENI is critical to testing these schemes.\nEvaluating a route-computation service in GENI would enable experiments that measure\nrouting-protocol convergence delay and the effects on end-to-end performance when\ntopology changes occur. This would involve \"injecting\" link failures under today's\nInternet routing architecture and under the new design. This experiment would be\ndifficult to conduct without GENI because simulations do not accurately capture the\noverheads and delays on the routing software, and operational networks would not permit\nresearchers to intentionally inject failures.\nOne of the concerns with BGP is that it does not provide adequate levels of security.\nGENI can be used to evaluate the route-computation service of a security-enhanced\nalternative to BGP. For example, upon learning a BGP route announcement from a\nneighboring domain, the service can classify the route as \"suspicious\" if the Autonomous\nSystem originating the route does not agree with past history. The service can prefer\n\nnon-suspect routes over suspect routes. The experiment could evaluate this new variant\nof the BGP path-selection process and see if it effectively protects the experimental\nnetwork from attackers injecting false routing information.\nToday, the user has little choice over the route his packets take. There is no equivalent of\n\"picking your long-distance provider\" in the Internet, and little support for a host or edge\nnetwork that wants to have multiple paths into the network. This lack of support for\nmulti-homing is a major contributor to poor availability. It has been proposed that\nInternet routing should be redone to support end-node route selection so that the user\nhas more control over how his packets are carried, both to support multi-homing and to\nimpose the discipline of competition on the service providers. We need to experiment\nwith this to see if we can design tools that make end-node route selection practical and\nusable, and to see if this approach actually improves availability, since the approach\nsolves some problems and raises others.\nRouting algorithms today attempt to find the optimal path for traffic, given the overall\ntraffic pattern. As the traffic pattern changes, routes must be constantly recomputed. An\nalternate idea is to take traffic and diffuse it across all possible paths from source to\ndestination. It can be shown that traffic diffusion provides stable traffic allocation to\nlinks for all feasible traffic patterns. In other words, it eliminates the need for traffic\nengineering. It also may improve security by eliminating the ability of an attacker to\nconcentrate his traffic onto one circuit in order to overload it. In order to test this idea,\nwhat is needed is a network with a high degree of route diversity, which GENI can\nprovide by means of virtualization.\nIn today's Internet, the route computation is performed in the same physical devices (the\nrouters) that also forward packets. One proposal for a future Internet moves the route\ncomputation out of the individual routers, and into a separate route computation service.\nThis approach offers great advantages in consistency, manageability, and scale. It allows\ncompeting route computation services to offer alternative algorithms for different\ncustomers. However, it raises new challenges for robustness and resilience in the face of\narbitrary failure. This breaking up of the router function will also shift the industry\nlandscape and create new opportunities for innovation and competition. We need to\nexperiment with this sort of scheme in a real network with rich connectivity and real-\nworld failure modes. In particular, since GENI provides the option of interconnection\nwith operational ISPs, it can be used to test new routing regimes in the real world.\nToday's routing protocols have some severe flaws with respect to management. One\nexample is that they are not designed to take a component out of service gracefully. They\ncan deal with a failed component, but there is always a transient glitch as they compute\nnew routes. If network operators know they are going to take a component out of service,\nit should be possible for the routing algorithm to plan for this so the users never see a\nmomentary outage. A demonstration on GENI could evaluate the effects on end-to-end\nperformance of a graceful maintenance protocol, which would make step-by-step\nchanges in the routing tables to prepare for removing equipment from the network.\n\nPutting it all together--architecture\nThe list of issues above, and the examples of approaches to deal with them, are only a\nvery partial catalog of what the research community is preparing do using the GENI test\nfacility. It is important, as we consider this list, to look at the whole and not the parts.\nEach one of the ideas above, and the many others that have been suggested by the\nresearch community, may be interesting in their own right, but it is when they are put\ntogether, their interactions explored, their joint implications worked out, that the real\npayoff occurs. It is through the combination and harmonization of many ideas like this\nthat new architecture emerges. GENI can be used to support initial experiments to\nexplore individual ideas, but the most important experiments on GENI will support the\ntesting of these new architectures--combinations of these new ideas that greatly improve\nthe fitness for purpose of the Internet.\nIt would be nice if we could discover simple, independent fixes that each improved one\nproblem with the current Internet. It would be much simpler if we could find \"the security\nfix\", \"the management fix\", \"the availability fix\", and so on. But in fact, most of the new\nideas cataloged above shift the landscape in all of these areas. This is why \"putting the\nparts together\" is such an important part of the project. As a further illustration of how\ncomplex the relationship is between mechanism and requirement, here is one final\nexample about new Internet design. The proposed change seems small, but it affects\nalmost every requirement we have posed for a future Internet.\nWell-known ports and service initiation\nToday, the Internet names services (such as Web or email) using \"well-known ports\"--\nnumerical indices that are statically assigned to each application at design time. Since\nthese port numbers are included in each packet, this permits any observer in the network\nto determine what application is being used. And since these numbers are statically\nassigned, an attacker can easily launch an attack against an application on a given host,\njust by combining a host address with the port number, and using that destination as the\ntarget of an attack. An alternative would be to design a new mechanism for \"service\nrendezvous\", and to use random port numbers to identify connections. This change,\nperhaps combined with an increase in the range of port numbers, would essentially\neliminate the value of the attack known as port-scanning, and would provide more\nprivacy from observers in the network. However, a sparse port-space would change the\nwhole security landscape by changing what firewalls can do based on packet inspection.\nIn fact, this change would force a complete re-conception of what a firewall does and the\nbalance of power in the space of attack and defense. The alternative would also change\nthe economic landscape by making it harder for Internet Service Providers to discriminate\namong customers based on what applications they want to run. Presumably, they would\nrespond by inventing some other form of discrimination. The change would make the\nnetwork more useful to consumers, by eliminating some of the restrictions that are\nimposed by the invention of Network Address Translation units as network attachment\ndevices.\n\nA broader set of experiments on GENI\nGENI is not just about experiments to support FIND and the creation of Future Internet\narchitectures. It will be used as well to support a broad set of experiments that range from\nevaluation of new technology options to new designs for distributed systems and\napplications. Here are some further examples of experiments to be run on GENI, which\nillustrate the range of experiments that it can support.\n1. A new end-to-end protocol model for mobile data: The ubiquitous TCP/IP protocol\nused for most Internet services has several known weaknesses when applied to mobile\ndata scenarios. In particular, the IP network layer framework does not support\ndisconnected operation or caching/storage within the network while the window flow-\ncontrol mechanism in the TCP transport layer performs poorly over wireless access links\nwith high error rate. Numerous solutions to these problems have been investigated by the\nwireless networking research community, including mobility service overlays and\nmodified TCP or all-new transport layer protocols, but none of these solutions have\nmigrated to general use due to legacy staying power and the difficulty faced by\ninnovators in deploying their protocols on a a large-scale network to test performance and\nend-user acceptance.\nA GENI experiment of near-term interest to the mobile networking community would be\nto deploy one or more alternative protocol solutions on an end-to-end basis with a\nsignificant user population. Experimental measurements of interest include short-term\nnumerical performance measures such as packet delay, packet loss rate and user\nthroughput for specified applications and mobility patterns. In addition, longer-term\nservice quality measures such as % dropped connections and availability will be\nmeasured.\n2. Delay Tolerant Networking (DTN): DTN is a very different model for an Internet\narchitecture, which is suited to disconnected operation; this can include wireless devices\nthat go in and out of range, as well as communication among planets. This concept has\nbeen under development for a number of years, and is an obvious candidate to deploy and\ntest on GENI. (The current design of GENI does not include inter-planetary links,\nhowever.)\n3. Evaluation of location-aware networking techniques for mobile and sensor\napplications: Location (defined in terms of geographic coordinates) is being recognized\nas an increasingly important aspect that needs to be integrated into mobile and sensor\nnetwork applications. For example, mobile users seek geographically relevant\ninformation about people, products and services in the immediate vicinity. Sensor\napplications require addressing of sensors by location rather than by network or MAC\naddress. Vehicular safety applications require multicasting to nearby cars within a certain\nbounded region. In all these instances, techniques for naming, addressing and routing in\nthe network need to be extended to account for geographic location. Techniques such as\nlocation service overlays and geographic routing have been proposed but never validated\nat sufficient scale or realism.\n\nA location-aware network experiment to be run on GENI involves instrumenting one or\nmore wireless subnetwork with location determination services based on signal\ntriangulation or other methods, along with implementations of overall or new network\nlayer protocols for location service, georouting, etc. This experiment would start with a\nbottom-up validation of the accuracy with which location can be tracked by the network\nalong with an estimate of protocol overheads and latencies associated with providing\nlocation information to higher layer protocols or applications. Once the protocol is\nvalidated and performance/overhead measured, it is anticipated that GENI would be used\nto offer long-running location services to new mobile and sensor applications with real\nend-users, leading to identification of one or more viable protocol designs.\nLocation management is an excellent example of a design problem that will benefit from\na multi-discipline approach, since an architecture for location management must take into\naccount issues of privacy, ownership of personal location information, and rights of third\nparties and the state to gain access to this information.\n4. Integrating adaptive cognitive radio networks with the global Internet: Cognitive\nradio technology is expected to emerge in the next 5-10 years and offers the promise of\nprogrammable radios which can adapt to their environment, share spectrum efficiently\nand organize themselves into collaborative multi-hop networks. The wireless research\ncommunity has several hardware and protocol design projects in this area, and would like\nto validate these designs further and study issues involved with integrating these\nnetworks with the global Internet. Protocol design topics of particular interest include\nnaming and addressing for dynamically changing constellations of radios, as well as\nrouting between ad-hoc radio networks and the wired Internet infrastructure. Of particular\ninterest is the level of cross-layer protocol support required on an end-to-end basis.\nThe wireless research community plans to conduct several experiments with cognitive\nradio networks using the GENI system. In particular, the cognitive radio subnetwork\nplanned for GENI will be instrumented to support dynamic spectrum measurements\nneeded to evaluate the benefits of shared spectrum, agility and etiquettes. In addition, the\ntestbed will be used to conduct large-scale validation of discovery, ad hoc collaborative\nnetwork formation and routing in cognitive networks. Both short-term network\nperformance (throughput, delay) and longer-term system behavior (spectrum utilization,\navailability) will be measured using GENI. Once a cognitive radio network is validated at\nthe subnetwork level, end-to-end experiments will be carried out to investigate issues\nsuch as naming, addressing and cross-layer routing support.\nThe importance of building\nHere is a final example of a specific experimental program. It is a story based on work\nthat was carried out on Planet Lab, which does not support the range of experiments that\nGENI will. But this example illustrates the power of experimentation, innovation and\n\ndiscovery when the community is able to carry out large scale experiments with real\nusers.\nA researcher designed a new system for Content Distribution that he believed scales\nbetter under load, yet has response time that's comparable to the best-known techniques.\nUsing the best methodology of the day, he simulated the system and quantified the\npotential improvement in aggregate throughput. He published a paper that reports 60\n91% improvement over the state-of-the-art.\nThen Planet Lab became available, which allowed the researcher to deploy the system in\na realistic setting, at scale, with real user traffic. The researcher took advantage of the\nfacility, and within days of deploying the system (v1), learned an important lesson:\nunanticipated traffic compromises the security of the system, making it unusable. The\nresearcher designed and deployed a redesigned system (v2) that took this lesson into\naccount.\nWithin weeks of deploying the new system, the researcher discovered that performance is\ncompromised by failures of the Domain Name System. Based on additional observations,\nthe researchers discovered the root cause, and in response, demonstrateed how the\nContent Distribution Network (which was designed to make web content more available)\ncould be adapted to also make DNS resolution more robust. The researcher modifiee his\nsystem (v3) and deployed it on Planet Lab.\nBased on instrumentation of this system, the researcher discovered that the best known\nmodels of DNS behavior were all wrong, and produced a new model that others can use\nby other researchers.\nBased on other data collected by instrumenting the system, the researcher discovered that\nhe is able to observe two orders of magnitude more Internet failures than any existing\nobservation platform has yielded. This results in a more accurate model of Internet\nbehavior that other researchers are able to incorporate into their research.\nThe researcher also recognized that he can augment his original system (v4) to also\ndiagnose Internet failures in real-time, and use this system to build adaptive applications\nthat are able to route around failures, resulting in an even more robust service.\nAfter gaining further experience, the researcher discoverd that his system performs\npoorly when distributing big files, especially to a large set of clients, but that by including\nnew mechanisms, he was able to redesign the system (v5) to yield large-object\nthroughput that scaled with the number of clients that request the object. One of the more\ninteresting lessons of this exercise is that the algorithms proposed by others to solve this\nproblem do not work well in practice, and it is only by a thorough evaluation of various\nengineering tradeoffs that he was able to design a system (v6) with robust performance\nunder a wide-range of conditions.\nEpilogue 1: Researcher never bothers to return to the issue of the specific algorithms used\n\nin his original system, as they are in the noise relative to the other factors that influence\nan Internet service.\nEpilogue 2: Researcher understands factors that influence network robustness at a deep\nlevel, and sets out to create a clean-slate network architecture that incorporates these\nlessons in the core of the design. The new architecture is dissemination-oriented rather\nthan client/server oriented, but must include completely new approaches to security\nbecause content is now decoupled from specific points (servers) in the network.\nGENI will be the test platform to evaluate this new architecture."
    },
    {
      "category": "Resource",
      "title": "mgm_v_grokster.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-68j-communications-and-information-policy-spring-2006/07d09c0d1acbda284b3c692cd8584d78_mgm_v_grokster.pdf",
      "content": "(Slip Opinion)\nOCTOBER TERM, 2004\nSyllabus\nNOTE: Where it is feasible, a syllabus (headnote) will be released, as is\nbeing done in connection with this case, at the time the opinion is issued.\nThe syllabus constitutes no part of the opinion of the Court but has been\nprepared by the Reporter of Decisions for the convenience of the reader.\nSee United States v. Detroit Timber & Lumber Co., 200 U. S. 321, 337.\nSUPREME COURT OF THE UNITED STATES\nSyllabus\nMETRO-GOLDWYN-MAYER STUDIOS INC. ET AL. v.\nGROKSTER, LTD., ET AL.\nCERTIORARI TO THE UNITED STATES COURT OF APPEALS FOR\nTHE NINTH CIRCUIT\nNo. 04-480. Argued March 29, 2005--Decided June 27, 2005\nRespondent companies distribute free software that allows computer\nusers to share electronic files through peer-to-peer networks, so\ncalled because the computers communicate directly with each other,\nnot through central servers. Although such networks can be used to\nshare any type of digital file, recipients of respondents' software have\nmostly used them to share copyrighted music and video files without\nauthorization. Seeking damages and an injunction, a group of movie\nstudios and other copyright holders (hereinafter MGM) sued respon\ndents for their users' copyright infringements, alleging that respon\ndents knowingly and intentionally distributed their software to en\nable users to infringe copyrighted works in violation of the Copyright\nAct.\nDiscovery revealed that billions of files are shared across peer-to-\npeer networks each month. Respondents are aware that users em\nploy their software primarily to download copyrighted files, although\nthe decentralized networks do not reveal which files are copied, and\nwhen. Respondents have sometimes learned about the infringement\ndirectly when users have e-mailed questions regarding copyrighted\nworks, and respondents have replied with guidance. Respondents\nare not merely passive recipients of information about infringement.\nThe record is replete with evidence that when they began to distrib\nute their free software, each of them clearly voiced the objective that\nrecipients use the software to download copyrighted works and took\nactive steps to encourage infringement. After the notorious file-\nsharing service, Napster, was sued by copyright holders for facilitat\ning copyright infringement, both respondents promoted and mar\nketed themselves as Napster alternatives. They receive no revenue\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\nSyllabus\nfrom users, but, instead, generate income by selling advertising\nspace, then streaming the advertising to their users. As the number\nof users increases, advertising opportunities are worth more. There\nis no evidence that either respondent made an effort to filter copy\nrighted material from users' downloads or otherwise to impede the\nsharing of copyrighted files.\nWhile acknowledging that respondents' users had directly in\nfringed MGM's copyrights, the District Court nonetheless granted re\nspondents summary judgment as to liability arising from distribution\nof their software. The Ninth Circuit affirmed. It read Sony Corp. of\nAmerica v. Universal City Studios, Inc., 464 U. S. 417, as holding that\nthe distribution of a commercial product capable of substantial nonin\nfringing uses could not give rise to contributory liability for infringe\nment unless the distributor had actual knowledge of specific in\nstances of infringement and failed to act on that knowledge. Because\nthe appeals court found respondents' software to be capable of sub\nstantial noninfringing uses and because respondents had no actual\nknowledge of infringement owing to the software's decentralized ar\nchitecture, the court held that they were not liable. It also held that\nthey did not materially contribute to their users' infringement be\ncause the users themselves searched for, retrieved, and stored the in\nfringing files, with no involvement by respondents beyond providing\nthe software in the first place. Finally, the court held that respon\ndents could not be held liable under a vicarious infringement theory\nbecause they did not monitor or control the software's use, had no\nagreed-upon right or current ability to supervise its use, and had no\nindependent duty to police infringement.\nHeld: One who distributes a device with the object of promoting its use\nto infringe copyright, as shown by clear expression or other affirma\ntive steps taken to foster infringement, going beyond mere distribu\ntion with knowledge of third-party action, is liable for the resulting\nacts of infringement by third parties using the device, regardless of\nthe device's lawful uses. Pp. 10-24.\n(a) The tension between the competing values of supporting crea\ntivity through copyright protection and promoting technological inno\nvation by limiting infringement liability is the subject of this case.\nDespite offsetting considerations, the argument for imposing indirect\nliability here is powerful, given the number of infringing downloads\nthat occur daily using respondents' software. When a widely shared\nproduct is used to commit infringement, it may be impossible to en\nforce rights in the protected work effectively against all direct in\nfringers, so that the only practical alternative is to go against the de-\nvice's distributor for secondary liability on a theory of contributory or\nvicarious infringement. One infringes contributorily by intentionally\n\nCite as: 545 U. S. ____ (2005)\nSyllabus\ninducing or encouraging direct infringement, and infringes vicari\nously by profiting from direct infringement while declining to exercise\nthe right to stop or limit it. Although \"[t]he Copyright Act does not\nexpressly render anyone liable for [another's] infringement,\" Sony,\n464 U. S., at 434, these secondary liability doctrines emerged from\ncommon law principles and are well established in the law, e.g., id.,\nat 486. Pp. 10-13.\n(b) Sony addressed a claim that secondary liability for infringement\ncan arise from the very distribution of a commercial product. There,\ncopyright holders sued Sony, the manufacturer of videocassette re\ncorders, claiming that it was contributorily liable for the infringe\nment that occurred when VCR owners taped copyrighted programs.\nThe evidence showed that the VCR's principal use was \"time-\nshifting,\" i.e., taping a program for later viewing at a more conven\nient time, which the Court found to be a fair, noninfringing use. 464\nU. S., at 423-424. Moreover, there was no evidence that Sony had\ndesired to bring about taping in violation of copyright or taken active\nsteps to increase its profits from unlawful taping. Id., at 438. On\nthose facts, the only conceivable basis for liability was on a theory of\ncontributory infringement through distribution of a product. Id., at\n439. Because the VCR was \"capable of commercially significant non-\ninfringing uses,\" the Court held that Sony was not liable. Id., at 442.\nThis theory reflected patent law's traditional staple article of com\nmerce doctrine that distribution of a component of a patented device\nwill not violate the patent if it is suitable for use in other ways. 35\nU. S. C 271(c). The doctrine absolves the equivocal conduct of sell\ning an item with lawful and unlawful uses and limits liability to in\nstances of more acute fault. In this case, the Ninth Circuit misread\nSony to mean that when a product is capable of substantial lawful\nuse, the producer cannot be held contributorily liable for third par\nties' infringing use of it, even when an actual purpose to cause in\nfringing use is shown, unless the distributors had specific knowledge\nof infringement at a time when they contributed to the infringement\nand failed to act upon that information. Sony did not displace other\nsecondary liability theories. Pp. 13-17.\n(c) Nothing in Sony requires courts to ignore evidence of intent to\npromote infringement if such evidence exists. It was never meant to\nforeclose rules of fault-based liability derived from the common law.\n464 U. S., at 439. Where evidence goes beyond a product's character\nistics or the knowledge that it may be put to infringing uses, and\nshows statements or actions directed to promoting infringement,\nSony's staple-article rule will not preclude liability. At common law a\ncopyright or patent defendant who \"not only expected but invoked\n[infringing use] by advertisement\" was liable for infringement.\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\nSyllabus\nKalem Co. v. Harper Brothers, 222 U. S. 55, 62-63. The rule on in\nducement of infringement as developed in the early cases is no differ\nent today. Evidence of active steps taken to encourage direct in\nfringement, such as advertising an infringing use or instructing how\nto engage in an infringing use, shows an affirmative intent that the\nproduct be used to infringe, and overcomes the law's reluctance to\nfind liability when a defendant merely sells a commercial product\nsuitable for some lawful use. A rule that premises liability on pur\nposeful, culpable expression and conduct does nothing to compromise\nlegitimate commerce or discourage innovation having a lawful prom\nise. Pp. 17-20.\n(d) On the record presented, respondents' unlawful objective is un\nmistakable. The classic instance of inducement is by advertisement\nor solicitation that broadcasts a message designed to stimulate others\nto commit violations. MGM argues persuasively that such a message\nis shown here. Three features of the evidence of intent are particu\nlarly notable. First, each of the respondents showed itself to be aim\ning to satisfy a known source of demand for copyright infringement,\nthe market comprising former Napster users. Respondents' efforts to\nsupply services to former Napster users indicate a principal, if not\nexclusive, intent to bring about infringement. Second, neither re\nspondent attempted to develop filtering tools or other mechanisms to\ndiminish the infringing activity using their software. While the\nNinth Circuit treated that failure as irrelevant because respondents\nlacked an independent duty to monitor their users' activity, this evi\ndence underscores their intentional facilitation of their users' in\nfringement. Third, respondents make money by selling advertising\nspace, then by directing ads to the screens of computers employing\ntheir software. The more their software is used, the more ads are\nsent out and the greater the advertising revenue. Since the extent of\nthe software's use determines the gain to the distributors, the com\nmercial sense of their enterprise turns on high-volume use, which the\nrecord shows is infringing. This evidence alone would not justify an\ninference of unlawful intent, but its import is clear in the entire re-\ncord's context. Pp. 20-23.\n(e) In addition to intent to bring about infringement and distribu\ntion of a device suitable for infringing use, the inducement theory re\nquires evidence of actual infringement by recipients of the device, the\nsoftware in this case. There is evidence of such infringement on a gi\ngantic scale. Because substantial evidence supports MGM on all\nelements, summary judgment for respondents was error. On re\nmand, reconsideration of MGM's summary judgment motion will be\nin order. Pp. 23-24.\n380 F. 3d 1154, vacated and remanded.\n\nCite as: 545 U. S. ____ (2005)\nSyllabus\nSOUTER, J., delivered the opinion for a unanimous Court. GINSBURG,\nJ., filed a concurring opinion, in which REHNQUIST, C. J., and KENNEDY,\nJ., joined. BREYER, J., filed a concurring opinion, in which STEVENS and\nO'CONNOR, JJ., joined.\n\n_________________\n_________________\nCite as: 545 U. S. ____ (2005)\nOpinion of the Court\nNOTICE: This opinion is subject to formal revision before publication in the\npreliminary print of the United States Reports. Readers are requested to\nnotify the Reporter of Decisions, Supreme Court of the United States, Wash\nington, D. C. 20543, of any typographical or other formal errors, in order\nthat corrections may be made before the preliminary print goes to press.\nSUPREME COURT OF THE UNITED STATES\nNo. 04-480\nMETRO-GOLDWYN-MAYER STUDIOS INC., ET AL.,\nPETITIONERS v. GROKSTER, LTD., ET AL.\nON WRIT OF CERTIORARI TO THE UNITED STATES COURT OF\nAPPEALS FOR THE NINTH CIRCUIT\n[June 27, 2005]\nJUSTICE SOUTER delivered the opinion of the Court.\nThe question is under what circumstances the distribu\ntor of a product capable of both lawful and unlawful use is\nliable for acts of copyright infringement by third parties\nusing the product. We hold that one who distributes a\ndevice with the object of promoting its use to infringe\ncopyright, as shown by clear expression or other affirma\ntive steps taken to foster infringement, is liable for the\nresulting acts of infringement by third parties.\nI\nA\nRespondents, Grokster, Ltd., and StreamCast Networks,\nInc., defendants in the trial court, distribute free software\nproducts that allow computer users to share electronic\nfiles through peer-to-peer networks, so called because\nusers' computers communicate directly with each other,\nnot through central servers. The advantage of peer-to-\npeer networks over information networks of other types\nshows up in their substantial and growing popularity.\nBecause they need no central computer server to mediate\nthe exchange of information or files among users, the high\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\nOpinion of the Court\nbandwidth communications capacity for a server may be\ndispensed with, and the need for costly server storage\nspace is eliminated. Since copies of a file (particularly a\npopular one) are available on many users' computers, file\nrequests and retrievals may be faster than on other types\nof networks, and since file exchanges do not travel through\na server, communications can take place between any\ncomputers that remain connected to the network without\nrisk that a glitch in the server will disable the network in\nits entirety. Given these benefits in security, cost, and\nefficiency, peer-to-peer networks are employed to store\nand distribute electronic files by universities, government\nagencies, corporations, and libraries, among others.1\nOther users of peer-to-peer networks include individual\nrecipients of Grokster's and StreamCast's software, and\nalthough the networks that they enjoy through using the\nsoftware can be used to share any type of digital file, they\nhave prominently employed those networks in sharing\ncopyrighted music and video files without authorization.\nA group of copyright holders (MGM for short, but includ\ning motion picture studios, recording companies, song\nwriters, and music publishers) sued Grokster and\nStreamCast for their users' copyright infringements,\nalleging that they knowingly and intentionally distributed\ntheir software to enable users to reproduce and distribute\nthe copyrighted works in violation of the Copyright Act, 17\nU. S. C. 101 et seq. (2000 ed. and Supp. II).2 MGM sought\n------------\n1Peer-to-peer networks have disadvantages as well. Searches on\npeer-to-peer networks may not reach and uncover all available files\nbecause search requests may not be transmitted to every computer on\nthe network. There may be redundant copies of popular files. The\ncreator of the software has no incentive to minimize storage or band\nwidth consumption, the costs of which are borne by every user of the\nnetwork. Most relevant here, it is more difficult to control the content\nof files available for retrieval and the behavior of users.\n2The studios and recording companies and the songwriters and music\npublishers filed separate suits against the defendants that were con\n\nCite as: 545 U. S. ____ (2005)\nOpinion of the Court\ndamages and an injunction.\nDiscovery during the litigation revealed the way the\nsoftware worked, the business aims of each defendant\ncompany, and the predilections of the users. Grokster's\neponymous software employs what is known as FastTrack\ntechnology, a protocol developed by others and licensed to\nGrokster. StreamCast distributes a very similar product\nexcept that its software, called Morpheus, relies on what is\nknown as Gnutella technology.3 A user who downloads\nand installs either software possesses the protocol to send\nrequests for files directly to the computers of others using\nsoftware compatible with FastTrack or Gnutella. On the\nFastTrack network opened by the Grokster software, the\nuser's request goes to a computer given an indexing capac\nity by the software and designated a supernode, or to some\nother computer with comparable power and capacity to\ncollect temporary indexes of the files available on the\ncomputers of users connected to it. The supernode (or\nindexing computer) searches its own index and may com\nmunicate the search request to other supernodes. If the\nfile is found, the supernode discloses its location to the\ncomputer requesting it, and the requesting user can\ndownload the file directly from the computer located. The\ncopied file is placed in a designated sharing folder on the\nrequesting user's computer, where it is available for other\nusers to download in turn, along with any other file in that\nfolder.\nIn the Gnutella network made available by Morpheus,\nthe process is mostly the same, except that in some ver\nsions of the Gnutella protocol there are no supernodes. In\nthese versions, peer computers using the protocol commu\n------------\nsolidated by the District Court.\n3Subsequent versions of Morpheus, released after the record was\nmade in this case, apparently rely not on Gnutella but on a technology\ncalled Neonet. These developments are not before us.\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\n\nOpinion of the Court\nnicate directly with each other. When a user enters a\nsearch request into the Morpheus software, it sends the\nrequest to computers connected with it, which in turn pass\nthe request along to other connected peers. The search\nresults are communicated to the requesting computer, and\nthe user can download desired files directly from peers'\ncomputers. As this description indicates, Grokster and\nStreamCast use no servers to intercept the content of the\nsearch requests or to mediate the file transfers conducted\nby users of the software, there being no central point\nthrough which the substance of the communications\npasses in either direction.4\nAlthough Grokster and StreamCast do not therefore\nknow when particular files are copied, a few searches\nusing their software would show what is available on the\nnetworks the software reaches. MGM commissioned a\nstatistician to conduct a systematic search, and his study\nshowed that nearly 90% of the files available for download\non the FastTrack system were copyrighted works.5 Grok\nster and StreamCast dispute this figure, raising methodo\nlogical problems and arguing that free copying even of\ncopyrighted works may be authorized by the rightholders.\nThey also argue that potential noninfringing uses of their\nsoftware are significant in kind, even if infrequent in\npractice.\nSome musical performers, for example, have\ngained new audiences by distributing their copyrighted\nworks for free across peer-to-peer networks, and some\n------------\n4There is some evidence that both Grokster and StreamCast previ\nously operated supernodes, which compiled indexes of files available on\nall of the nodes connected to them. This evidence, pertaining to previ\nous versions of the defendants' software, is not before us and would not\naffect our conclusions in any event.\n5By comparison, evidence introduced by the plaintiffs in A & M Re\ncords, Inc. v. Napster, Inc., 239 F. 3d 1004 (CA9 2001), showed that\n87% of files available on the Napster filesharing network were copy\nrighted, id., at 1013.\n\nCite as: 545 U. S. ____ (2005)\nOpinion of the Court\ndistributors of unprotected content have used peer-to-peer\nnetworks to disseminate files, Shakespeare being an\nexample. Indeed, StreamCast has given Morpheus users\nthe opportunity to download the briefs in this very case,\nthough their popularity has not been quantified.\nAs for quantification, the parties' anecdotal and statisti\ncal evidence entered thus far to show the content available\non the FastTrack and Gnutella networks does not say\nmuch about which files are actually downloaded by users,\nand no one can say how often the software is used to ob\ntain copies of unprotected material. But MGM's evidence\ngives reason to think that the vast majority of users'\ndownloads are acts of infringement, and because well over\n100 million copies of the software in question are known to\nhave been downloaded, and billions of files are shared\nacross the FastTrack and Gnutella networks each month,\nthe probable scope of copyright infringement is staggering.\nGrokster and StreamCast concede the infringement in\nmost downloads, Brief for Respondents 10, n. 6, and it is\nuncontested that they are aware that users employ their\nsoftware primarily to download copyrighted files, even if\nthe decentralized FastTrack and Gnutella networks fail to\nreveal which files are being copied, and when. From time\nto time, moreover, the companies have learned about their\nusers' infringement directly, as from users who have sent\ne-mail to each company with questions about playing\ncopyrighted movies they had downloaded, to whom the\ncompanies have responded with guidance.6 App. 559-563,\n808-816, 939-954. And MGM notified the companies of 8\nmillion copyrighted files that could be obtained using their\nsoftware.\nGrokster and StreamCast are not, however, merely\npassive recipients of information about infringing use.\n------------\n6The Grokster founder contends that in answering these e-mails he\noften did not read them fully. App. 77, 769.\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\n\nOpinion of the Court\nThe record is replete with evidence that from the moment\nGrokster and StreamCast began to distribute their free\nsoftware, each one clearly voiced the objective that recipi\nents use it to download copyrighted works, and each took\nactive steps to encourage infringement.\nAfter the notorious file-sharing service, Napster, was\nsued by copyright holders for facilitation of copyright\ninfringement, A & M Records, Inc. v. Napster, Inc., 114\nF. Supp. 2d 896 (ND Cal. 2000), aff'd in part, rev'd in part,\n239 F. 3d 1004 (CA9 2001), StreamCast gave away a\nsoftware program of a kind known as OpenNap, designed\nas compatible with the Napster program and open to\nNapster users for downloading files from other Napster\nand OpenNap users' computers. Evidence indicates that\n\"[i]t was always [StreamCast's] intent to use [its OpenNap\nnetwork] to be able to capture email addresses of [its]\ninitial target market so that [it] could promote [its]\nStreamCast Morpheus interface to them,\" App. 861; in\ndeed, the OpenNap program was engineered \" 'to leverage\nNapster's 50 million user base,' \" id., at 746.\nStreamCast monitored both the number of users\ndownloading its OpenNap program and the number of\nmusic files they downloaded. Id., at 859, 863, 866. It also\nused the resulting OpenNap network to distribute copies\nof the Morpheus software and to encourage users to adopt\nit. Id., at 861, 867, 1039. Internal company documents\nindicate that StreamCast hoped to attract large numbers\nof former Napster users if that company was shut down by\ncourt order or otherwise, and that StreamCast planned to\nbe the next Napster.\nId., at 861. A kit developed by\nStreamCast to be delivered to advertisers, for example,\ncontained press articles about StreamCast's potential to\ncapture former Napster users, id., at 568-572, and it\nintroduced itself to some potential advertisers as a com\npany \"which is similar to what Napster was,\" id., at 884.\nIt broadcast banner advertisements to users of other\n\nCite as: 545 U. S. ____ (2005)\nOpinion of the Court\nNapster-compatible software, urging them to adopt its\nOpenNap. Id., at 586. An internal e-mail from a company\nexecutive stated: \" 'We have put this network in place so\nthat when Napster pulls the plug on their free service . . .\nor if the Court orders them shut down prior to that . . . we\nwill be positioned to capture the flood of their 32 million\nusers that will be actively looking for an alternative.' \" Id.,\nat 588-589, 861.\nThus, StreamCast developed promotional materials to\nmarket its service as the best Napster alternative. One\nproposed advertisement read: \"Napster Inc. has an\nnounced that it will soon begin charging you a fee. That's\nif the courts don't order it shut down first. What will you\ndo to get around it?\" Id., at 897. Another proposed ad\ntouted StreamCast's software as the \"#1 alternative to\nNapster\" and asked \"[w]hen the lights went off at Napster\n. . . where did the users go?\" Id., at 836 (ellipsis in origi-\nnal).7 StreamCast even planned to flaunt the illegal uses\nof its software; when it launched the OpenNap network,\nthe chief technology officer of the company averred that\n\"[t]he goal is to get in trouble with the law and get sued.\nIt's the best way to get in the new[s].\" Id., at 916.\nThe evidence that Grokster sought to capture the mar\nket of former Napster users is sparser but revealing, for\nGrokster launched its own OpenNap system called Swap-\ntor and inserted digital codes into its Web site so that\ncomputer users using Web search engines to look for\n\"Napster\" or \"[f]ree filesharing\" would be directed to the\nGrokster Web site, where they could download the Grok\nster software. Id., at 992-993. And Grokster's name is an\napparent derivative of Napster.\n------------\n7The record makes clear that StreamCast developed these promo\ntional materials but not whether it released them to the public. Even if\nthese advertisements were not released to the public and do not show\nencouragement to infringe, they illuminate StreamCast's purposes.\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\n\nOpinion of the Court\nStreamCast's executives monitored the number of songs\nby certain commercial artists available on their networks,\nand an internal communication indicates they aimed to\nhave a larger number of copyrighted songs available on\ntheir networks than other file-sharing networks. Id., at\n868. The point, of course, would be to attract users of a\nmind to infringe, just as it would be with their promo\ntional materials developed showing copyrighted songs as\nexamples of the kinds of files available through Morpheus.\nId., at 848. Morpheus in fact allowed users to search\nspecifically for \"Top 40\" songs, id., at 735, which were\ninevitably copyrighted. Similarly, Grokster sent users a\nnewsletter promoting its ability to provide particular,\npopular copyrighted materials. Brief for Motion Picture\nStudio and Recording Company Petitioners 7-8.\nIn addition to this evidence of express promotion, mar\nketing, and intent to promote further, the business models\nemployed by Grokster and StreamCast confirm that their\nprincipal object was use of their software to download\ncopyrighted works. Grokster and StreamCast receive no\nrevenue from users, who obtain the software itself for\nnothing.\nInstead, both companies generate income by\nselling advertising space, and they stream the advertising\nto Grokster and Morpheus users while they are employing\nthe programs. As the number of users of each program\nincreases, advertising opportunities become worth more.\nCf. App. 539, 804. While there is doubtless some demand\nfor free Shakespeare, the evidence shows that substantive\nvolume is a function of free access to copyrighted work.\nUsers seeking Top 40 songs, for example, or the latest\nrelease by Modest Mouse, are certain to be far more nu\nmerous than those seeking a free Decameron, and Grok\nster and StreamCast translated that demand into dollars.\nFinally, there is no evidence that either company made\nan effort to filter copyrighted material from users'\ndownloads or otherwise impede the sharing of copyrighted\n\nCite as: 545 U. S. ____ (2005)\nOpinion of the Court\nfiles. Although Grokster appears to have sent e-mails\nwarning users about infringing content when it received\nthreatening notice from the copyright holders, it never\nblocked anyone from continuing to use its software to\nshare copyrighted files. Id., at 75-76. StreamCast not\nonly rejected another company's offer of help to monitor\ninfringement, id., at 928-929, but blocked the Internet\nProtocol addresses of entities it believed were trying to\nengage in such monitoring on its networks, id., at 917-\n922.\nB\nAfter discovery, the parties on each side of the case\ncross-moved for summary judgment. The District Court\nlimited its consideration to the asserted liability of Grok\nster and StreamCast for distributing the current versions\nof their software, leaving aside whether either was liable\n\"for damages arising from past versions of their software,\nor from other past activities.\" 259 F. Supp. 2d 1029, 1033\n(CD Cal. 2003). The District Court held that those who\nused the Grokster and Morpheus software to download\ncopyrighted media files directly infringed MGM's copy\nrights, a conclusion not contested on appeal, but the court\nnonetheless granted summary judgment in favor of Grok\nster and StreamCast as to any liability arising from dis\ntribution of the then current versions of their software.\nDistributing that software gave rise to no liability in the\ncourt's view, because its use did not provide the distribu\ntors with actual knowledge of specific acts of infringement.\nCase No. CV 01 08541 SVW (PJWx) (CD Cal., June 18,\n2003), App. 1213.\nThe Court of Appeals affirmed. 380 F. 3d 1154 (CA9\n2004). In the court's analysis, a defendant was liable as a\ncontributory infringer when it had knowledge of direct\ninfringement and materially contributed to the infringe\nment. But the court read Sony Corp. of America v. Uni\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\n\nOpinion of the Court\nversal City Studios, Inc., 464 U. S. 417 (1984), as holding\nthat distribution of a commercial product capable of sub\nstantial noninfringing uses could not give rise to contribu\ntory liability for infringement unless the distributor had\nactual knowledge of specific instances of infringement and\nfailed to act on that knowledge. The fact that the software\nwas capable of substantial noninfringing uses in the Ninth\nCircuit's view meant that Grokster and StreamCast were\nnot liable, because they had no such actual knowledge,\nowing to the decentralized architecture of their software.\nThe court also held that Grokster and StreamCast did not\nmaterially contribute to their users' infringement because\nit was the users themselves who searched for, retrieved,\nand stored the infringing files, with no involvement by the\ndefendants beyond providing the software in the first\nplace.\nThe Ninth Circuit also considered whether Grokster and\nStreamCast could be liable under a theory of vicarious\ninfringement. The court held against liability because the\ndefendants did not monitor or control the use of the soft\nware, had no agreed-upon right or current ability to su\npervise its use, and had no independent duty to police\ninfringement. We granted certiorari. 543 U. S. ___ (2004).\nII\nA\nMGM and many of the amici fault the Court of Ap-\npeals's holding for upsetting a sound balance between the\nrespective values of supporting creative pursuits through\ncopyright protection and promoting innovation in new\ncommunication technologies by limiting the incidence of\nliability for copyright infringement. The more artistic\nprotection is favored, the more technological innovation\nmay be discouraged; the administration of copyright law is\nan exercise in managing the trade-off. See Sony Corp. v.\nUniversal City Studios, supra, at 442; see generally Gins\n\nCite as: 545 U. S. ____ (2005)\nOpinion of the Court\nburg, Copyright and Control Over New Technologies of\nDissemination, 101 Colum. L. Rev. 1613 (2001); Lichtman\n& Landes, Indirect Liability for Copyright Infringement:\nAn Economic Perspective, 16 Harv. J. L. & Tech. 395\n(2003).\nThe tension between the two values is the subject of this\ncase, with its claim that digital distribution of copyrighted\nmaterial threatens copyright holders as never before,\nbecause every copy is identical to the original, copying is\neasy, and many people (especially the young) use file-\nsharing software to download copyrighted works. This\nvery breadth of the software's use may well draw the\npublic directly into the debate over copyright policy, Pe\nters, Brace Memorial Lecture: Copyright Enters the Public\nDomain, 51 J. Copyright Soc. 701, 705-717 (2004) (address\nby Register of Copyrights), and the indications are that\nthe ease of copying songs or movies using software like\nGrokster's and Napster's is fostering disdain for copyright\nprotection, Wu, When Code Isn't Law, 89 Va. L. Rev. 679,\n724-726 (2003). As the case has been presented to us,\nthese fears are said to be offset by the different concern\nthat imposing liability, not only on infringers but on dis\ntributors of software based on its potential for unlawful\nuse, could limit further development of beneficial tech\nnologies.\nSee, e.g., Lemley & Reese, Reducing Digital\nCopyright Infringement Without Restricting Innovation,\n56 Stan. L. Rev. 1345, 1386-1390 (2004); Brief for Innova\ntion Scholars and Economists as Amici Curiae 15-20;\nBrief for Emerging Technology Companies as Amici Cu\nriae 19-25; Brief for Intel Corporation as Amicus Curiae\n20-22.8\n------------\n8The mutual exclusivity of these values should not be overstated,\nhowever. On the one hand technological innovators, including those\nwriting filesharing computer programs, may wish for effective copyright\nprotections for their work. See, e.g., Wu, When Code Isn't Law, 89 Va.\nL. Rev. 679, 750 (2003). (StreamCast itself was urged by an associate\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\nOpinion of the Court\nThe argument for imposing indirect liability in this case\nis, however, a powerful one, given the number of infring\ning downloads that occur every day using StreamCast's\nand Grokster's software. When a widely shared service or\nproduct is used to commit infringement, it may be impos\nsible to enforce rights in the protected work effectively\nagainst all direct infringers, the only practical alternative\nbeing to go against the distributor of the copying device for\nsecondary liability on a theory of contributory or vicarious\ninfringement. See In re Aimster Copyright Litigation, 334\nF. 3d 643, 645-646 (CA7 2003).\nOne infringes contributorily by intentionally inducing or\nencouraging direct infringement, see Gershwin Pub. Corp.\nv. Columbia Artists Management, Inc., 443 F. 2d 1159,\n1162 (CA2 1971), and infringes vicariously by profiting\nfrom direct infringement while declining to exercise a\nright to stop or limit it, Shapiro, Bernstein & Co. v. H. L.\nGreen Co., 316 F. 2d 304, 307 (CA2 1963).9 Although\n------------\nto \"get [its] technology written down and [its intellectual property]\nprotected.\" App. 866.) On the other hand the widespread distribution\nof creative works through improved technologies may enable the\nsynthesis of new works or generate audiences for emerging artists. See\nEldred v. Ashcroft, 537 U. S. 186, 223-226 (2003) (STEVENS, J., dissent\ning); Van Houweling, Distributive Values in Copyright, 83 Texas\nL. Rev. 1535, 1539-1540, 1562-1564 (2005); Brief for Sovereign Artists\net al. as Amici Curiae 11.\n9We stated in Sony Corp. of America v. Universal City Studios, Inc.,\n464 U. S. 417 (1984), that \" 'the lines between direct infringement,\ncontributory infringement and vicarious liability are not clearly drawn'\n. . . . [R]easoned analysis of [the Sony plaintiffs' contributory infringe\nment claim] necessarily entails consideration of arguments and case\nlaw which may also be forwarded under the other labels, and indeed\nthe parties . . . rely upon such arguments and authority in support of\ntheir respective positions on the issue of contributory infringement,\"\nid., at 435, n. 17 (quoting Universal City Studios, Inc. v. Sony Corp.,\n480 F. Supp. 429, 457-458 (CD Cal. 1979)). In the present case MGM\nhas argued a vicarious liability theory, which allows imposition of\nliability when the defendant profits directly from the infringement and\nhas a right and ability to supervise the direct infringer, even if the\n\nCite as: 545 U. S. ____ (2005)\nOpinion of the Court\n\"[t]he Copyright Act does not expressly render anyone\nliable for infringement committed by another,\" Sony Corp.\nv. Universal City Studios, 464 U. S., at 434, these doc\ntrines of secondary liability emerged from common law\nprinciples and are well established in the law, id., at 486\n(Blackmun, J., dissenting); Kalem Co. v. Harper Brothers,\n222 U. S. 55, 62-63 (1911); Gershwin Pub. Corp. v. Co\nlumbia Artists Management, supra, at 1162; 3 M. Nimmer\n& D. Nimmer, Copyright, 12.04[A] (2005).\nB\nDespite the currency of these principles of secondary\nliability, this Court has dealt with secondary copyright\ninfringement in only one recent case, and because MGM\nhas tailored its principal claim to our opinion there, a look\nat our earlier holding is in order. In Sony Corp. v. Univer\nsal City Studios, supra, this Court addressed a claim that\nsecondary liability for infringement can arise from the\nvery distribution of a commercial product. There, the\nproduct, novel at the time, was what we know today as the\nvideocassette recorder or VCR. Copyright holders sued\nSony as the manufacturer, claiming it was contributorily\nliable for infringement that occurred when VCR owners\ntaped copyrighted programs because it supplied the means\nused to infringe, and it had constructive knowledge that\ninfringement would occur. At the trial on the merits, the\nevidence showed that the principal use of the VCR was for\n\" 'time-shifting,' \" or taping a program for later viewing at a\nmore convenient time, which the Court found to be a fair,\nnot an infringing, use. Id., at 423-424. There was no\n------------\ndefendant initially lacks knowledge of the infringement. See, e.g.,\nShapiro, Bernstein & Co. v. H. L. Green Co., 316 F. 2d 304, 308 (CA2\n1963); Dreamland Ball Room, Inc. v. Shapiro, Bernstein & Co., 36 F. 2d\n354, 355 (CA7 1929). Because we resolve the case based on an induce\nment theory, there is no need to analyze separately MGM's vicarious\nliability theory.\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\n\nOpinion of the Court\nevidence that Sony had expressed an object of bringing\nabout taping in violation of copyright or had taken active\nsteps to increase its profits from unlawful taping. Id., at\n438. Although Sony's advertisements urged consumers to\nbuy the VCR to \" 'record favorite shows' \" or \" 'build a li\nbrary' \" of recorded programs, id., at 459 (Blackmun, J.,\ndissenting), neither of these uses was necessarily infring\ning, id., at 424, 454-455.\nOn those facts, with no evidence of stated or indicated\nintent to promote infringing uses, the only conceivable\nbasis for imposing liability was on a theory of contributory\ninfringement arising from its sale of VCRs to consumers\nwith knowledge that some would use them to infringe. Id.,\nat 439. But because the VCR was \"capable of commer\ncially significant noninfringing uses,\" we held the manu\nfacturer could not be faulted solely on the basis of its\ndistribution. Id., at 442.\nThis analysis reflected patent law's traditional staple\narticle of commerce doctrine, now codified, that distribu\ntion of a component of a patented device will not violate\nthe patent if it is suitable for use in other ways. 35\nU. S. C. 271(c); Aro Mfg. Co. v. Convertible Top Replace\nment Co., 377 U. S. 476, 485 (1964) (noting codification of\ncases); id., at 486, n. 6 (same). The doctrine was devised\nto identify instances in which it may be presumed from\ndistribution of an article in commerce that the distributor\nintended the article to be used to infringe another's pat\nent, and so may justly be held liable for that infringement.\n\"One who makes and sells articles which are only adapted\nto be used in a patented combination will be presumed to\nintend the natural consequences of his acts; he will be\npresumed to intend that they shall be used in the combi\nnation of the patent.\" New York Scaffolding Co. v. Whit\nney, 224 F. 452, 459 (CA8 1915); see also James Heekin\nCo. v. Baker, 138 F. 63, 66 (CA8 1905); Canda v. Michigan\nMalleable Iron Co., 124 F. 486, 489 (CA6 1903); Thomson\n\nCite as: 545 U. S. ____ (2005)\nOpinion of the Court\nHouston Electric Co. v. Ohio Brass Co., 80 F. 712, 720-721\n(CA6 1897); Red Jacket Mfg. Co. v. Davis, 82 F. 432, 439\n(CA7 1897); Holly v. Vergennes Machine Co., 4 F. 74, 82\n(CC Vt. 1880); Renwick v. Pond, 20 F. Cas. 536, 541 (No.\n11,702) (CC SDNY 1872).\nIn sum, where an article is \"good for nothing else\" but\ninfringement, Canda v. Michigan Malleable Iron Co.,\nsupra, at 489, there is no legitimate public interest in its\nunlicensed availability, and there is no injustice in pre\nsuming or imputing an intent to infringe, see Henry v.\nA. B. Dick Co., 224 U. S. 1, 48 (1912), overruled on other\ngrounds, Motion Picture Patents Co. v. Universal Film\nMfg. Co., 243 U. S. 502 (1917). Conversely, the doctrine\nabsolves the equivocal conduct of selling an item with\nsubstantial lawful as well as unlawful uses, and limits\nliability to instances of more acute fault than the mere\nunderstanding that some of one's products will be mis\nused. It leaves breathing room for innovation and a vigor\nous commerce. See Sony Corp. v. Universal City Studios,\nsupra, at 442; Dawson Chemical Co. v. Rohm & Haas Co.,\n448 U. S. 176, 221 (1980); Henry v. A. B. Dick Co., supra,\nat 48.\nThe parties and many of the amici in this case think the\nkey to resolving it is the Sony rule and, in particular, what\nit means for a product to be \"capable of commercially\nsignificant noninfringing uses.\" Sony Corp. v. Universal\nCity Studios, supra, at 442. MGM advances the argument\nthat granting summary judgment to Grokster and\nStreamCast as to their current activities gave too much\nweight to the value of innovative technology, and too little\nto the copyrights infringed by users of their software,\ngiven that 90% of works available on one of the networks\nwas shown to be copyrighted. Assuming the remaining\n10% to be its noninfringing use, MGM says this should not\nqualify as \"substantial,\" and the Court should quantify\nSony to the extent of holding that a product used \"princi\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\n\nOpinion of the Court\npally\" for infringement does not qualify. See Brief for\nMotion Picture Studio and Recording Company Petitioners\n31. As mentioned before, Grokster and StreamCast reply\nby citing evidence that their software can be used to re\nproduce public domain works, and they point to copyright\nholders who actually encourage copying. Even if in\nfringement is the principal practice with their software\ntoday, they argue, the noninfringing uses are significant\nand will grow.\nWe agree with MGM that the Court of Appeals misap\nplied Sony, which it read as limiting secondary liability\nquite beyond the circumstances to which the case applied.\nSony barred secondary liability based on presuming or\nimputing intent to cause infringement solely from the\ndesign or distribution of a product capable of substantial\nlawful use, which the distributor knows is in fact used for\ninfringement. The Ninth Circuit has read Sony's limita\ntion to mean that whenever a product is capable of sub\nstantial lawful use, the producer can never be held con\ntributorily liable for third parties' infringing use of it; it\nread the rule as being this broad, even when an actual\npurpose to cause infringing use is shown by evidence\nindependent of design and distribution of the product,\nunless the distributors had \"specific knowledge of in\nfringement at a time at which they contributed to the\ninfringement, and failed to act upon that information.\"\n380 F. 3d, at 1162 (internal quotation marks and altera\ntions omitted). Because the Circuit found the StreamCast\nand Grokster software capable of substantial lawful use, it\nconcluded on the basis of its reading of Sony that neither\ncompany could be held liable, since there was no showing\nthat their software, being without any central server,\nafforded them knowledge of specific unlawful uses.\nThis view of Sony, however, was error, converting the\ncase from one about liability resting on imputed intent to\none about liability on any theory. Because Sony did not\n\nCite as: 545 U. S. ____ (2005)\nOpinion of the Court\ndisplace other theories of secondary liability, and because\nwe find below that it was error to grant summary judg\nment to the companies on MGM's inducement claim, we\ndo not revisit Sony further, as MGM requests, to add a\nmore quantified description of the point of balance be\ntween protection and commerce when liability rests solely\non distribution with knowledge that unlawful use will\noccur. It is enough to note that the Ninth Circuit's judg\nment rested on an erroneous understanding of Sony and to\nleave further consideration of the Sony rule for a day when\nthat may be required.\nC\nSony's rule limits imputing culpable intent as a matter\nof law from the characteristics or uses of a distributed\nproduct. But nothing in Sony requires courts to ignore\nevidence of intent if there is such evidence, and the case\nwas never meant to foreclose rules of fault-based liability\nderived from the common law.10 Sony Corp. v. Universal\nCity Studios, 464 U. S., at 439 (\"If vicarious liability is to\nbe imposed on Sony in this case, it must rest on the fact\nthat it has sold equipment with constructive knowledge\" of\nthe potential for infringement). Thus, where evidence\ngoes beyond a product's characteristics or the knowledge\nthat it may be put to infringing uses, and shows state\nments or actions directed to promoting infringement,\nSony's staple-article rule will not preclude liability.\nThe classic case of direct evidence of unlawful purpose\noccurs when one induces commission of infringement by\nanother, or \"entic[es] or persuad[es] another\" to infringe,\nBlack's Law Dictionary 790 (8th ed. 2004), as by advertis\ning. Thus at common law a copyright or patent defendant\n------------\n10Nor does the Patent Act's exemption from liability for those who\ndistribute a staple article of commerce, 35 U. S. C. 271(c), extend to\nthose who induce patent infringement, 271(b).\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\n\nOpinion of the Court\nwho \"not only expected but invoked [infringing use] by\nadvertisement\" was liable for infringement \"on principles\nrecognized in every part of the law.\" Kalem Co. v. Harper\nBrothers, 222 U. S., at 62-63 (copyright infringement).\nSee also Henry v. A. B. Dick Co., 224 U. S., at 48-49 (con\ntributory liability for patent infringement may be found\nwhere a good's \"most conspicuous use is one which will\ncooperate in an infringement when sale to such user is\ninvoked by advertisement\" of the infringing use); Thom-\nson-Houston Electric Co. v. Kelsey Electric R. Specialty\nCo., 75 F. 1005, 1007-1008 (CA2 1896) (relying on adver\ntisements and displays to find defendant's \"willingness . . .\nto aid other persons in any attempts which they may be\ndisposed to make towards [patent] infringement\"); Rum-\nford Chemical Works v. Hecker, 20 F. Cas. 1342, 1346 (No.\n12,133) (CC N. J. 1876) (demonstrations of infringing\nactivity along with \"avowals of the [infringing] purpose\nand use for which it was made\" supported liability for\npatent infringement).\nThe rule on inducement of infringement as developed in\nthe early cases is no different today.11 Evidence of \"active\nsteps . . . taken to encourage direct infringement,\" Oak\nIndustries, Inc. v. Zenith Electronics Corp., 697 F. Supp.\n988, 992 (ND Ill. 1988), such as advertising an infringing\nuse or instructing how to engage in an infringing use,\nshow an affirmative intent that the product be used to\ninfringe, and a showing that infringement was encouraged\novercomes the law's reluctance to find liability when a\ndefendant merely sells a commercial product suitable for\nsome lawful use, see, e.g., Water Technologies Corp. v.\nCalco, Ltd., 850 F. 2d 660, 668 (CA Fed. 1988) (liability for\ninducement where one \"actively and knowingly aid[s] and\nabet[s] another's direct infringement\" (emphasis omitted));\nFromberg, Inc. v. Thornhill, 315 F. 2d 407, 412-413 (CA5\n------------\n11Inducement has been codified in patent law. Ibid.\n\nCite as: 545 U. S. ____ (2005)\nOpinion of the Court\n1963) (demonstrations by sales staff of infringing uses\nsupported liability for inducement); Haworth Inc. v. Her\nman Miller Inc., 37 USPQ 2d 1080, 1090 (WD Mich. 1994)\n(evidence that defendant \"demonstrate[d] and recom-\nmend[ed] infringing configurations\" of its product could\nsupport inducement liability); Sims v. Mack Trucks, Inc.,\n459 F. Supp. 1198, 1215 (ED Pa. 1978) (finding induce\nment where the use \"depicted by the defendant in its\npromotional film and brochures infringes the . . . patent\"),\noverruled on other grounds, 608 F. 2d 87 (CA3 1979). Cf.\nW. Keeton, D. Dobbs, R. Keeton, & D. Owen, Prosser and\nKeeton on Law of Torts 37 (5th ed. 1984) (\"There is a\ndefinite tendency to impose greater responsibility upon a\ndefendant whose conduct was intended to do harm, or was\nmorally wrong\").\nFor the same reasons that Sony took the staple-article\ndoctrine of patent law as a model for its copyright safe-\nharbor rule, the inducement rule, too, is a sensible one for\ncopyright. We adopt it here, holding that one who distrib\nutes a device with the object of promoting its use to in\nfringe copyright, as shown by clear expression or other\naffirmative steps taken to foster infringement, is liable for\nthe resulting acts of infringement by third parties. We\nare, of course, mindful of the need to keep from trenching\non regular commerce or discouraging the development of\ntechnologies with lawful and unlawful potential. Accord\ningly, just as Sony did not find intentional inducement\ndespite the knowledge of the VCR manufacturer that its\ndevice could be used to infringe, 464 U. S., at 439, n. 19,\nmere knowledge of infringing potential or of actual infring\ning uses would not be enough here to subject a distributor\nto liability. Nor would ordinary acts incident to product\ndistribution, such as offering customers technical support\nor product updates, support liability in themselves. The\ninducement rule, instead, premises liability on purposeful,\nculpable expression and conduct, and thus does nothing to\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\n\nOpinion of the Court\ncompromise legitimate commerce or discourage innovation\nhaving a lawful promise.\nIII\nA\nThe only apparent question about treating MGM's\nevidence as sufficient to withstand summary judgment\nunder the theory of inducement goes to the need on\nMGM's part to adduce evidence that StreamCast and\nGrokster communicated an inducing message to their\nsoftware users. The classic instance of inducement is by\nadvertisement or solicitation that broadcasts a message\ndesigned to stimulate others to commit violations. MGM\nclaims that such a message is shown here. It is undis\nputed that StreamCast beamed onto the computer screens\nof users of Napster-compatible programs ads urging the\nadoption of its OpenNap program, which was designed, as\nits name implied, to invite the custom of patrons of Nap\nster, then under attack in the courts for facilitating mas\nsive infringement.\nThose who accepted StreamCast's\nOpenNap program were offered software to perform the\nsame services, which a factfinder could conclude would\nreadily have been understood in the Napster market as\nthe ability to download copyrighted music files. Grokster\ndistributed an electronic newsletter containing links to\narticles promoting its software's ability to access popular\ncopyrighted music. And anyone whose Napster or free\nfile-sharing searches turned up a link to Grokster would\nhave understood Grokster to be offering the same file-\nsharing ability as Napster, and to the same people who\nprobably used Napster for infringing downloads; that\nwould also have been the understanding of anyone offered\nGrokster's suggestively named Swaptor software, its\nversion of OpenNap. And both companies communicated a\nclear message by responding affirmatively to requests for\nhelp in locating and playing copyrighted materials.\n\nCite as: 545 U. S. ____ (2005)\nOpinion of the Court\nIn StreamCast's case, of course, the evidence just de\nscribed was supplemented by other unequivocal indica\ntions of unlawful purpose in the internal communications\nand advertising designs aimed at Napster users (\"When\nthe lights went off at Napster . . . where did the users go?\"\nApp. 836 (ellipsis in original)). Whether the messages\nwere communicated is not to the point on this record. The\nfunction of the message in the theory of inducement is to\nprove by a defendant's own statements that his unlawful\npurpose disqualifies him from claiming protection (and\nincidentally to point to actual violators likely to be found\namong those who hear or read the message). See supra, at\n17-19. Proving that a message was sent out, then, is the\npreeminent but not exclusive way of showing that active\nsteps were taken with the purpose of bringing about in\nfringing acts, and of showing that infringing acts took\nplace by using the device distributed. Here, the summary\njudgment record is replete with other evidence that Grok\nster and StreamCast, unlike the manufacturer and dis\ntributor in Sony, acted with a purpose to cause copyright\nviolations by use of software suitable for illegal use. See\nsupra, at 6-9.\nThree features of this evidence of intent are particularly\nnotable. First, each company showed itself to be aiming to\nsatisfy a known source of demand for copyright infringe\nment, the market comprising former Napster users.\nStreamCast's internal documents made constant reference\nto Napster, it initially distributed its Morpheus software\nthrough an OpenNap program compatible with Napster, it\nadvertised its OpenNap program to Napster users, and its\nMorpheus software functions as Napster did except that it\ncould be used to distribute more kinds of files, including\ncopyrighted movies and software programs. Grokster's\nname is apparently derived from Napster, it too initially\noffered an OpenNap program, its software's function is\nlikewise comparable to Napster's, and it attempted to\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\n\nOpinion of the Court\ndivert queries for Napster onto its own Web site. Grokster\nand StreamCast's efforts to supply services to former\nNapster users, deprived of a mechanism to copy and dis\ntribute what were overwhelmingly infringing files, indi\ncate a principal, if not exclusive, intent on the part of each\nto bring about infringement.\nSecond, this evidence of unlawful objective is given\nadded significance by MGM's showing that neither com\npany attempted to develop filtering tools or other mecha\nnisms to diminish the infringing activity using their soft\nware.\nWhile the Ninth Circuit treated the defendants'\nfailure to develop such tools as irrelevant because they\nlacked an independent duty to monitor their users' activ\nity, we think this evidence underscores Grokster's and\nStreamCast's intentional facilitation of their users' in-\nfringement.12\nThird, there is a further complement to the direct evi\ndence of unlawful objective.\nIt is useful to recall that\nStreamCast and Grokster make money by selling advertis\ning space, by directing ads to the screens of computers\nemploying their software. As the record shows, the more\nthe software is used, the more ads are sent out and the\ngreater the advertising revenue becomes. Since the extent\nof the software's use determines the gain to the distribu\ntors, the commercial sense of their enterprise turns on\nhigh-volume use, which the record shows is infringing.13\n------------\n12Of course, in the absence of other evidence of intent, a court would\nbe unable to find contributory infringement liability merely based on a\nfailure to take affirmative steps to prevent infringement, if the device\notherwise was capable of substantial noninfringing uses. Such a\nholding would tread too close to the Sony safe harbor.\n13Grokster and StreamCast contend that any theory of liability based\non their conduct is not properly before this Court because the rulings in\nthe trial and appellate courts dealt only with the present versions of\ntheir software, not \"past acts . . . that allegedly encouraged infringe\nment or assisted . . . known acts of infringement.\" Brief for Respon\ndents 14; see also id., at 34. This contention misapprehends the basis\n\nCite as: 545 U. S. ____ (2005)\nOpinion of the Court\nThis evidence alone would not justify an inference of\nunlawful intent, but viewed in the context of the entire\nrecord its import is clear.\nThe unlawful objective is unmistakable.\nB\nIn addition to intent to bring about infringement and\ndistribution of a device suitable for infringing use, the\ninducement theory of course requires evidence of actual\ninfringement by recipients of the device, the software in\nthis case. As the account of the facts indicates, there is\nevidence of infringement on a gigantic scale, and there is\nno serious issue of the adequacy of MGM's showing on this\npoint in order to survive the companies' summary judg\nment requests. Although an exact calculation of infringing\nuse, as a basis for a claim of damages, is subject to dis\npute, there is no question that the summary judgment\nevidence is at least adequate to entitle MGM to go forward\nwith claims for damages and equitable relief.\n*\n*\n*\nIn sum, this case is significantly different from Sony and\nreliance on that case to rule in favor of StreamCast and\nGrokster was error. Sony dealt with a claim of liability\nbased solely on distributing a product with alternative\nlawful and unlawful uses, with knowledge that some users\nwould follow the unlawful course. The case struck a bal\n------------\nfor their potential liability. It is not only that encouraging a particular\nconsumer to infringe a copyright can give rise to secondary liability for\nthe infringement that results. Inducement liability goes beyond that,\nand the distribution of a product can itself give rise to liability where\nevidence shows that the distributor intended and encouraged the\nproduct to be used to infringe. In such a case, the culpable act is not\nmerely the encouragement of infringement but also the distribution of\nthe tool intended for infringing use. See Kalem Co. v. Harper Brothers,\n222 U. S. 55, 62-63 (1911); Cable/Home Communication Corp. v.\nNetwork Productions, Inc., 902 F. 2d 829, 846 (CA11 1990); A & M\nRecords, Inc. v. Abdallah, 948 F. Supp. 1449, 1456 (CD Cal. 1996).\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\n\nOpinion of the Court\nance between the interests of protection and innovation by\nholding that the product's capability of substantial lawful\nemployment should bar the imputation of fault and conse\nquent secondary liability for the unlawful acts of others.\nMGM's evidence in this case most obviously addresses a\ndifferent basis of liability for distributing a product open\nto alternative uses.\nHere, evidence of the distributors'\nwords and deeds going beyond distribution as such shows\na purpose to cause and profit from third-party acts of\ncopyright infringement. If liability for inducing infringe\nment is ultimately found, it will not be on the basis of\npresuming or imputing fault, but from inferring a patently\nillegal objective from statements and actions showing\nwhat that objective was.\nThere is substantial evidence in MGM's favor on all\nelements of inducement, and summary judgment in favor\nof Grokster and StreamCast was error. On remand, re\nconsideration of MGM's motion for summary judgment\nwill be in order.\nThe judgment of the Court of Appeals is vacated, and\nthe case is remanded for further proceedings consistent\nwith this opinion.\nIt is so ordered.\n\n_________________\n_________________\nCite as: 545 U. S. ____ (2005)\nGINSBURG, J., concurring\nSUPREME COURT OF THE UNITED STATES\nNo. 04-480\nMETRO-GOLDWYN-MAYER STUDIOS INC., ET AL.,\nPETITIONERS v. GROKSTER, LTD., ET AL.\nON WRIT OF CERTIORARI TO THE UNITED STATES COURT OF\nAPPEALS FOR THE NINTH CIRCUIT\n[June 27, 2005]\nJUSTICE GINSBURG, with whom THE CHIEF JUSTICE and\nJUSTICE KENNEDY join, concurring.\nI concur in the Court's decision, which vacates in full the\njudgment of the Court of Appeals for the Ninth Circuit,\nante, at 24, and write separately to clarify why I conclude\nthat the Court of Appeals misperceived, and hence misap\nplied, our holding in Sony Corp. of America v. Universal\nCity Studios, Inc., 464 U. S. 417 (1984). There is here at\nleast a \"genuine issue as to [a] material fact,\" Fed. Rule\nCiv. Proc. 56(c), on the liability of Grokster or StreamCast,\nnot only for actively inducing copyright infringement, but\nalso or alternatively, based on the distribution of their\nsoftware products, for contributory copyright infringe\nment. On neither score was summary judgment for Grok\nster and StreamCast warranted.\nAt bottom, however labeled, the question in this case is\nwhether Grokster and StreamCast are liable for the direct\ninfringing acts of others. Liability under our jurispru\ndence may be predicated on actively encouraging (or in\nducing) infringement through specific acts (as the Court's\nopinion develops) or on distributing a product distributees\nuse to infringe copyrights, if the product is not capable of\n\"substantial\" or \"commercially significant\" noninfringing\nuses. Sony, 464 U. S., at 442; see also 3 M. Nimmer & D.\nNimmer, Nimmer on Copyright 12.04[A][2] (2005). While\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\n\nGINSBURG, J., concurring\nthe two categories overlap, they capture different culpable\nbehavior. Long coexisting, both are now codified in patent\nlaw.\nCompare 35 U. S. C. 271(b) (active inducement\nliability), with 271(c) (contributory liability for distribu\ntion of a product not \"suitable for substantial noninfring\ning use\").\nIn Sony, 464 U. S. 417, the Court considered Sony's\nliability for selling the Betamax video cassette recorder. It\ndid so enlightened by a full trial record. Drawing an\nanalogy to the staple article of commerce doctrine from\npatent law, the Sony Court observed that the \"sale of an\narticle . . . adapted to [a patent] infringing use\" does not\nsuffice \"to make the seller a contributory infringer\" if the\narticle \"is also adapted to other and lawful uses.\" Id., at\n441 (quoting Henry v. A. B. Dick Co., 224 U. S. 1, 48\n(1912), overruled on other grounds, Motion Picture Patents\nCo. v. Universal Film Mfg. Co., 243 U. S. 502, 517 (1917)).\n\"The staple article of commerce doctrine\" applied to\ncopyright, the Court stated, \"must strike a balance be\ntween a copyright holder's legitimate demand for effec-\ntive--not merely symbolic--protection of the statutory\nmonopoly, and the rights of others freely to engage in\nsubstantially unrelated areas of commerce.\" Sony, 464\nU. S., at 442. \"Accordingly,\" the Court held, \"the sale of\ncopying equipment, like the sale of other articles of com\nmerce, does not constitute contributory infringement if the\nproduct is widely used for legitimate, unobjectionable\npurposes. Indeed, it need merely be capable of substantial\nnoninfringing uses.\" Ibid. Thus, to resolve the Sony case,\nthe Court explained, it had to determine \"whether the\nBetamax is capable of commercially significant noninfring\ning uses.\" Ibid.\nTo answer that question, the Court considered whether\n\"a significant number of [potential uses of the Betamax\nwere] noninfringing.\" Ibid. The Court homed in on one\npotential use--private, noncommercial time-shifting of\n\nCite as: 545 U. S. ____ (2005)\nGINSBURG, J., concurring\ntelevision programs in the home (i.e., recording a broad\ncast TV program for later personal viewing). Time-\nshifting was noninfringing, the Court concluded, because\nin some cases trial testimony showed it was authorized by\nthe copyright holder, id., at 443-447, and in others it\nqualified as legitimate fair use, id., at 447-455. Most\npurchasers used the Betamax principally to engage in\ntime-shifting, id., at 421, 423, a use that \"plainly satis-\nfie[d]\" the Court's standard, id., at 442. Thus, there was\nno need in Sony to \"give precise content to the question of\nhow much [actual or potential] use is commercially signifi\ncant.\" Ibid.1 Further development was left for later days\n------------\n1 JUSTICE BREYER finds in Sony Corp. of America v. Universal City Stu\ndios, Inc., 464 U. S. 417 (1984), a \"clear\" rule permitting contributory\nliability for copyright infringement based on distribution of a product\nonly when the product \"will be used almost exclusively to infringe\ncopyrights.\" Post, at 9-10. But cf. Sony, 464 U. S., at 442 (recognizing\n\"copyright holder's legitimate demand for effective--not merely sym-\nbolic--protection\").\nSony, as I read it, contains no clear, near-\nexclusivity test. Nor have Courts of Appeals unanimously recognized\nJUSTICE BREYER's clear rule. Compare A&M Records, Inc. v. Napster,\nInc., 239 F. 3d 1004, 1021 (CA9 2001) (\"[E]vidence of actual knowledge\nof specific acts of infringement is required to hold a computer system\noperator liable for contributory copyright infringement.\"), with In re\nAimster Copyright Litigation, 334 F. 3d 643, 649-650 (CA7 2003)\n(\"[W]hen a supplier is offering a product or service that has noninfring\ning as well as infringing uses, some estimate of the respective magni\ntudes of these uses is necessary for a finding of contributory infringe\nment. . . . But the balancing of costs and benefits is necessary only in a\ncase in which substantial noninfringing uses, present or prospective,\nare demonstrated.\"). See also Matthew Bender & Co., Inc. v. West Pub.\nCo., 158 F. 3d 693, 707 (CA2 1998) (\"The Supreme Court applied [the\nSony] test to prevent copyright holders from leveraging the copyrights\nin their original work to control distribution of . . . products that might\nbe used incidentally for infringement, but that had substantial nonin\nfringing uses. . . . The same rationale applies here [to products] that\nhave substantial, predominant and noninfringing uses as tools for\nresearch and citation.\"). All Members of the Court agree, moreover,\nthat \"the Court of Appeals misapplied Sony,\" at least to the extent it\nread that decision to limit \"secondary liability\" to a hardly-ever cate\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\nGINSBURG, J., concurring\nand cases.\nThe Ninth Circuit went astray, I will endeavor to ex\nplain, when that court granted summary judgment to\nGrokster and StreamCast on the charge of contributory\nliability based on distribution of their software products.\nRelying on its earlier opinion in A&M Records, Inc. v.\nNapster, Inc., 239 F. 3d 1004 (CA9 2001), the Court of\nAppeals held that \"if substantial noninfringing use was\nshown, the copyright owner would be required to show\nthat the defendant had reasonable knowledge of specific\ninfringing files.\" 380 F. 3d 1154, 1161 (CA9 2004). \"A\ncareful examination of the record,\" the court concluded,\n\"indicates that there is no genuine issue of material fact as\nto noninfringing use.\" Ibid. The appeals court pointed to\nthe band Wilco, which made one of its albums available for\nfree downloading, to other recording artists who may have\nauthorized free distribution of their music through the\nInternet, and to public domain literary works and films\navailable through Grokster's and StreamCast's software.\nIbid. Although it acknowledged MGM's assertion that\n\"the vast majority of the software use is for copyright\ninfringement,\" the court concluded that Grokster's and\nStreamCast's proffered evidence met Sony's requirement\nthat \"a product need only be capable of substantial nonin\nfringing uses.\" 380 F. 3d, at 1162.2\nThis case differs markedly from Sony. Cf. Peters, Brace\nMemorial Lecture: Copyright Enters the Public Domain,\n51 J. Copyright Soc. 701, 724 (2004) (\"The Grokster panel's\nreading of Sony is the broadest that any court has given it\n------------\ngory, \"quite beyond the circumstances to which the case applied.\" Ante,\nat 16.\n2Grokster and StreamCast, in the Court of Appeals' view, would be\nentitled to summary judgment unless MGM could show that that the\nsoftware companies had knowledge of specific acts of infringement and\nfailed to act on that knowledge--a standard the court held MGM could\nnot meet. 380 F. 3d, at 1162-1163.\n\nCite as: 545 U. S. ____ (2005)\nGINSBURG, J., concurring\n. . . .\"). Here, there has been no finding of any fair use and\nlittle beyond anecdotal evidence of noninfringing uses. In\nfinding the Grokster and StreamCast software products\ncapable of substantial noninfringing uses, the District Court\nand the Court of Appeals appear to have relied largely on\ndeclarations submitted by the defendants. These declara\ntions include assertions (some of them hearsay) that a\nnumber of copyright owners authorize distribution of their\nworks on the Internet and that some public domain material\nis available through peer-to-peer networks including those\naccessed through Grokster's and StreamCast's software.\n380 F. 3d, at 1161; 259 F. Supp. 2d 1029, 1035-1036 (CD\nCal. 2003); App. 125-171.\nThe District Court declared it \"undisputed that there\nare substantial noninfringing uses for Defendants' soft\nware,\" thus obviating the need for further proceedings.\n259 F. Supp. 2d, at 1035. This conclusion appears to rest\nalmost entirely on the collection of declarations submitted\nby Grokster and StreamCast. Ibid.\nReview of these\ndeclarations reveals mostly anecdotal evidence, sometimes\nobtained second-hand, of authorized copyrighted works or\npublic domain works available online and shared through\npeer-to-peer networks, and general statements about the\nbenefits of peer-to-peer technology. See, e.g., Decl. of Janis\nIan 13, App. 128 (\"P2P technologies offer musicians an\nalternative channel for promotion and distribution.\");\nDecl. of Gregory Newby 12, id., at 136 (\"Numerous au\nthorized and public domain Project Gutenberg eBooks are\nmade available on Morpheus, Kazaa, Gnutella, Grokster,\nand similar software products.\"); Decl. of Aram Sinnreich\n6, id., at 151 (\"file sharing seems to have a net positive\nimpact on music sales\"); Decl. of John Busher 8, id., at\n166 (\"I estimate that Acoustica generates sales of between\n$1,000 and $10,000 per month as a result of the distribu\ntion of its trialware software through the Gnutella and\nFastTrack Networks.\"); Decl. of Patricia D. Hoekman 3-\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\n\nGINSBURG, J., concurring\n4, id., at 169-170 (search on Morpheus for \"President\nBush speeches\" found several video recordings, searches\nfor \"Declaration of Independence\" and \"Bible\" found vari\nous documents and declarant was able to download a copy\nof the Declaration); Decl. of Sean L. Mayers 11, id., at 67\n(\"Existing open, decentralized peer-to-peer file-sharing\nnetworks . . . offer content owners distinct business advan\ntages over alternate online distribution technologies.\").\nCompare Decl. of Brewster Kahle 20, id., at 142 (\"Those\nwho download the Prelinger films . . . are entitled to redis\ntribute those files, and the Archive welcomes their redis\ntribution by the Morpheus-Grokster-KaZaa community of\nusers.\"), with Deposition of Brewster Kahle, id., at 396-\n403 (Sept. 18, 2002) (testifying that he has no knowledge\nof any person downloading a Prelinger film using Mor\npheus, Grokster, or KaZaA). Compare also Decl. of Rich\nard Prelinger 17, id., at 147 (\"[W]e welcome further\nredistribution of the Prelinger films . . . by individuals\nusing peer-to-peer software products like Morpheus, Ka-\nZaA and Grokster.\"), with Deposition of Richard Prelinger,\nid., at 410-411 (Oct. 1, 2002) (\"Q. What is your under\nstanding of Grokster?\nA. I have no understanding of\nGrokster. . . . Q. Do you know whether any user of the\nGrokster software has made available to share any Prelin\nger film? A. No.\"). See also Deposition of Aram Sinnreich,\nid., at 390 (Sept. 25, 2002) (testimony about the band\nWilco based on \"[t]he press and industry news groups and\nscuttlebutt.\"). These declarations do not support summary\njudgment in the face of evidence, proffered by MGM, of\noverwhelming use of Grokster's and StreamCast's soft\nware for infringement.3\n------------\n3 JUSTICE BREYER finds support for summary judgment in this motley\ncollection of declarations and in a survey conducted by an expert\nretained by MGM. Post, at 4-8. That survey identified 75% of the files\navailable through Grokster as copyrighted works owned or controlled\nby the plaintiffs, and 15% of the files as works likely copyrighted. App.\n\nCite as: 545 U. S. ____ (2005)\nGINSBURG, J., concurring\nEven if the absolute number of noninfringing files copied\nusing the Grokster and StreamCast software is large, it does\nnot follow that the products are therefore put to substantial\nnoninfringing uses and are thus immune from liability. The\nnumber of noninfringing copies may be reflective of, and\ndwarfed by, the huge total volume of files shared. Further,\nthe District Court and the Court of Appeals did not sharply\ndistinguish between uses of Grokster's and StreamCast's\nsoftware products (which this case is about) and uses of\npeer-to-peer technology generally (which this case is not\nabout).\nIn sum, when the record in this case was developed,\nthere was evidence that Grokster's and StreamCast's\nproducts were, and had been for some time, overwhelm\ningly used to infringe, ante, at 4-6; App. 434-439, 476-\n481, and that this infringement was the overwhelming\nsource of revenue from the products, ante, at 8-9; 259\nF. Supp. 2d, at 1043-1044. Fairly appraised, the evidence\nwas insufficient to demonstrate, beyond genuine debate, a\nreasonable prospect that substantial or commercially\nsignificant noninfringing uses were likely to develop over\n------------\n439.\nAs to the remaining 10% of the files, \"there was not enough\ninformation to form reasonable conclusions either as to what those files\neven consisted of, and/or whether they were infringing or non-\ninfringing.\" App. 479. Even assuming, as JUSTICE BREYER does, that\nthe Sony Court would have absolved Sony of contributory liability\nsolely on the basis of the use of the Betamax for authorized time-\nshifting, post, at 3-4, summary judgment is not inevitably appropriate\nhere. Sony stressed that the plaintiffs there owned \"well below 10%\" of\ncopyrighted television programming, 464 U. S., at 443, and found,\nbased on trial testimony from representatives of the four major sports\nleagues and other individuals authorized to consent to home-recording\nof their copyrighted broadcasts, that a similar percentage of program\ncopying was authorized, id., at 424.\nHere, the plaintiffs allegedly\ncontrol copyrights for 70% or 75% of the material exchanged through\nthe Grokster and StreamCast software, 380 F. 3d, at 1158; App. 439,\nand the District Court does not appear to have relied on comparable\ntestimony about authorized copying from copyright holders.\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\nGINSBURG, J., concurring\ntime. On this record, the District Court should not have\nruled dispositively on the contributory infringement\ncharge by granting summary judgment to Grokster and\nStreamCast.4\nIf, on remand, the case is not resolved on summary\njudgment in favor of MGM based on Grokster and\nStreamCast actively inducing infringement, the Court of\nAppeals, I would emphasize, should reconsider, on a fuller\nrecord, its interpretation of Sony's product distribution\nholding.\n------------\n4The District Court's conclusion that \"[p]laintiffs do not dispute that\nDefendants' software is being used, and could be used, for substantial\nnoninfringing purposes,\" 259 F. Supp. 2d 1029, 1036 (CD Cal. 2003);\naccord 380 F. 3d, at 1161, is, to say the least, dubious. In the courts\nbelow and in this Court, MGM has continuously disputed any such\nconclusion. Brief for Motion Picture Studio and Recording Company\nPetitioners 30-38; Brief for MGM Plaintiffs-Appellants in No. 03-\n55894, etc. (CA9), p. 41; App. 356-357, 361-365.\n\n_________________\n_________________\nCite as: 545 U. S. ____ (2005)\nBREYER, J., concurring\nSUPREME COURT OF THE UNITED STATES\nNo. 04-480\nMETRO-GOLDWYN-MAYER STUDIOS INC., ET AL.,\nPETITIONERS v. GROKSTER, LTD., ET AL.\nON WRIT OF CERTIORARI TO THE UNITED STATES COURT OF\nAPPEALS FOR THE NINTH CIRCUIT\n[June 27, 2005]\nJUSTICE BREYER, with whom JUSTICE STEVENS and\nJUSTICE O'CONNOR join, concurring.\nI agree with the Court that the distributor of a dual-use\ntechnology may be liable for the infringing activities of\nthird parties where he or she actively seeks to advance the\ninfringement. Ante, at 1. I further agree that, in light of\nour holding today, we need not now \"revisit\" Sony Corp. of\nAmerica v. Universal City Studios, Inc., 464 U. S. 417\n(1984). Ante, at 17. Other Members of the Court, how\never, take up the Sony question: whether Grokster's prod\nuct is \"capable of 'substantial' or 'commercially significant'\nnoninfringing uses.\" Ante, at 1 (GINSBURG, J., concurring)\n(quoting Sony, supra, at 442).\nAnd they answer that\nquestion by stating that the Court of Appeals was wrong\nwhen it granted summary judgment on the issue in Grok-\nster's favor. Ante, at 4. I write to explain why I disagree\nwith them on this matter.\nI\nThe Court's opinion in Sony and the record evidence (as\ndescribed and analyzed in the many briefs before us)\ntogether convince me that the Court of Appeals' conclusion\nhas adequate legal support.\nA\nI begin with Sony's standard. In Sony, the Court con\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\n\nBREYER, J., concurring\nsidered the potential copyright liability of a company that\ndid not itself illegally copy protected material, but rather\nsold a machine--a Video Cassette Recorder (VCR)--that\ncould be used to do so. A buyer could use that machine for\nnoninfringing purposes, such as recording for later view\ning (sometimes called \" 'time-shifting,' \" Sony, 464 U. S., at\n421) uncopyrighted television programs or copyrighted\nprograms with a copyright holder's permission. The buyer\ncould use the machine for infringing purposes as well,\nsuch as building libraries of taped copyrighted programs.\nOr, the buyer might use the machine to record copyrighted\nprograms under circumstances in which the legal status of\nthe act of recording was uncertain (i.e., where the copying\nmay, or may not, have constituted a \"fair use,\" id., at 425-\n426). Sony knew many customers would use its VCRs to\nengage in unauthorized copying and \" 'library-building.' \"\nId., at 458-459 (Blackmun, J., dissenting). But that fact,\nsaid the Court, was insufficient to make Sony itself an\ninfringer. And the Court ultimately held that Sony was\nnot liable for its customers' acts of infringement.\nIn reaching this conclusion, the Court recognized the\nneed for the law, in fixing secondary copyright liability, to\n\"strike a balance between a copyright holder's legitimate\ndemand for effective--not merely symbolic--protection of\nthe statutory monopoly, and the rights of others freely to\nengage in substantially unrelated areas of commerce.\" Id.,\nat 442. It pointed to patent law's \"staple article of com\nmerce\" doctrine, ibid., under which a distributor of a\nproduct is not liable for patent infringement by its cus\ntomers unless that product is \"unsuited for any commer\ncial noninfringing use.\" Dawson Chemical Co. v. Rohm &\nHaas Co., 448 U. S. 176, 198 (1980). The Court wrote that\nthe sale of copying equipment, \"like the sale of other arti\ncles of commerce, does not constitute contributory in\nfringement if the product is widely used for legitimate,\nunobjectionable purposes. Indeed, it need merely be capa\n\nCite as: 545 U. S. ____ (2005)\nBREYER, J., concurring\nble of substantial noninfringing uses.\" Sony, 464 U. S., at\n442 (emphasis added). The Court ultimately characterized\nthe legal \"question\" in the particular case as \"whether\n[Sony's VCR] is capable of commercially significant nonin\nfringing uses\" (while declining to give \"precise content\" to\nthese terms). Ibid. (emphasis added).\nIt then applied this standard. The Court had before it a\nsurvey (commissioned by the District Court and then\nprepared by the respondents) showing that roughly 9% of\nall VCR recordings were of the type--namely, religious,\neducational, and sports programming--owned by produc\ners and distributors testifying on Sony's behalf who did\nnot object to time-shifting.\nSee Brief for Respondent\nUniversal Studios et al. O. T. 1983, No. 81-1687, pp. 52-\n53; see also Sony, supra, at 424 (7.3% of all Sony VCR use\nis to record sports programs; representatives of the sports\nleagues do not object). A much higher percentage of VCR\nusers had at one point taped an authorized program, in\naddition to taping unauthorized programs. And the plain-\ntiffs--not a large class of content providers as in this\ncase--owned only a small percentage of the total available\nunauthorized programming. See ante, at 6-7, and n. 3\n(GINSBURG, J., concurring). But of all the taping actually\ndone by Sony's customers, only around 9% was of the sort\nthe Court referred to as authorized.\nThe Court found that the magnitude of authorized\nprogramming was \"significant,\" and it also noted the\n\"significant potential for future authorized copying.\" 464\nU. S., at 444.\nThe Court supported this conclusion by\nreferencing the trial testimony of professional sports\nleague officials and a religious broadcasting representa\ntive. Id., at 444, and n. 24. It also discussed (1) a Los\nAngeles educational station affiliated with the Public\nBroadcasting Service that made many of its programs\navailable for home taping, and (2) Mr. Rogers' Neighbor\nhood, a widely watched children's program. Id., at 445.\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\n\nBREYER, J., concurring\nOn the basis of this testimony and other similar evidence,\nthe Court determined that producers of this kind had\nauthorized duplication of their copyrighted programs \"in\nsignificant enough numbers to create a substantial market\nfor a noninfringing use of the\" VCR. Id., at 447, n. 28\n(emphasis added).\nThe Court, in using the key word \"substantial,\" indi\ncated that these circumstances alone constituted a suffi\ncient basis for rejecting the imposition of secondary liabil\nity.\nSee id., at 456 (\"Sony demonstrated a significant\nlikelihood that substantial numbers of copyright holders\"\nwould not object to time-shifting (emphasis added)).\nNonetheless, the Court buttressed its conclusion by find\ning separately that, in any event, unauthorized time-\nshifting often constituted not infringement, but \"fair use.\"\nId., at 447-456.\nB\nWhen measured against Sony's underlying evidence and\nanalysis, the evidence now before us shows that Grokster\npasses Sony's test--that is, whether the company's prod\nuct is capable of substantial or commercially significant\nnoninfringing uses. Id., at 442. For one thing, petitioners'\n(hereinafter MGM) own expert declared that 75% of cur\nrent files available on Grokster are infringing and 15% are\n\"likely infringing.\" See App. 436-439, 6-17 (Decl. of Dr.\nIngram Olkin); cf. ante, at 4 (opinion of the Court). That\nleaves some number of files near 10% that apparently are\nnoninfringing, a figure very similar to the 9% or so of\nauthorized time-shifting uses of the VCR that the Court\nfaced in Sony.\nAs in Sony, witnesses here explained the nature of the\nnoninfringing files on Grokster's network without detailed\nquantification. Those files include:\n--Authorized copies of music by artists such as Wilco,\n\nCite as: 545 U. S. ____ (2005)\nBREYER, J., concurring\nJanis Ian, Pearl Jam, Dave Matthews, John Mayer, and\nothers.\nSee App. at 152-153, 9-13 (Decl. of Aram\nSinnreich) (Wilco's \"lesson has already been adopted by\nartists still signed to their major labels\"); id., at 170, 5-\n7 (Decl. of Patricia D. Hoekman) (locating \"numerous\naudio recordings\" that were authorized for swapping); id.,\nat 74, 10 (Decl. of Daniel B. Rung) (describing Grokster's\npartnership with a company that hosts music from thou\nsands of independent artists)\n--Free electronic books and other works from various\nonline publishers, including Project Gutenberg. See id., at\n136, 12 (Decl. of Gregory B. Newby) (\"Numerous author\nized and public domain Project Gutenberg eBooks are\nmade available\" on Grokster.\nProject Gutenberg \"wel\ncomes this widespread sharing . . . using these software\nproducts[,] since they assist us in meeting our objectives\");\nid., at 159-160, 32 (Decl. of Sinnreich)\n--Public domain and authorized software, such as WinZip\n8.1. Id., at 170, 8 (Decl. of Hoekman); id., at 165, 4-7\n(Decl. of John Busher)\n--Licensed music videos and television and movie seg\nments distributed via digital video packaging with the\npermission of the copyright holder. Id., at 70, 24 (Decl. of\nSean L. Mayers)\nThe nature of these and other lawfully swapped files is\nsuch that it is reasonable to infer quantities of current\nlawful use roughly approximate to those at issue in Sony.\nAt least, MGM has offered no evidence sufficient to sur\nvive summary judgment that could plausibly demonstrate\na significant quantitative difference. See ante, at 4 (opin\nion of the Court); see also Brief for Motion Picture Studio\nand Recording Company Petitioners i (referring to \"at\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\n\nBREYER, J., concurring\nleast 90% of the total use of the services\"); but see ante, at\n6-7, n. 3 (GINSBURG, J., concurring). To be sure, in quan\ntitative terms these uses account for only a small percent\nage of the total number of uses of Grokster's product. But\nthe same was true in Sony, which characterized the rela\ntively limited authorized copying market as \"substantial.\"\n(The Court made clear as well in Sony that the amount of\nmaterial then presently available for lawful copying--if\nnot actually copied--was significant, see 464 U. S., at 444,\nand the same is certainly true in this case.)\nImportantly, Sony also used the word \"capable,\" asking\nwhether the product is \"capable of\" substantial noninfring\ning uses. Its language and analysis suggest that a figure\nlike 10%, if fixed for all time, might well prove insufficient,\nbut that such a figure serves as an adequate foundation\nwhere there is a reasonable prospect of expanded legiti\nmate uses over time. See ibid. (noting a \"significant po\ntential for future authorized copying\"). And its language\nalso indicates the appropriateness of looking to potential\nfuture uses of the product to determine its \"capability.\"\nHere the record reveals a significant future market for\nnoninfringing uses of Grokster-type peer-to-peer software.\nSuch software permits the exchange of any sort of digital\nfile--whether that file does, or does not, contain copy\nrighted material. As more and more uncopyrighted infor\nmation is stored in swappable form, it seems a likely\ninference that lawful peer-to-peer sharing will become\nincreasingly prevalent. See, e.g., App. 142, 20 (Decl. of\nBrewster Kahle) (\"The [Internet Archive] welcomes [the]\nredistribution [of authorized films] by the Morpheus-\nGrokster-KaZaa community of users\"); id., at 166, 8\n(Decl. of Busher) (sales figures of $1,000 to $10,000 per\nmonth through peer-to-peer networks \"will increase in the\nfuture as Acoustica's trialware is more widely distributed\nthrough these networks\"); id., at 156-164, 21-40 (Decl.\nof Sinnreich).\n\nCite as: 545 U. S. ____ (2005)\nBREYER, J., concurring\nAnd that is just what is happening. Such legitimate\nnoninfringing uses are coming to include the swapping of:\nresearch information (the initial purpose of many peer-to-\npeer networks); public domain films (e.g., those owned by\nthe Prelinger Archive); historical recordings and digital\neducational materials (e.g., those stored on the Internet\nArchive); digital photos (OurPictures, for example, is\nstarting a P2P photo-swapping service); \"shareware\" and\n\"freeware\" (e.g., Linux and certain Windows software);\nsecure licensed music and movie files (Intent MediaWorks,\nfor example, protects licensed content sent across P2P\nnetworks); news broadcasts past and present (the BBC\nCreative Archive lets users \"rip, mix and share the BBC\");\nuser-created audio and video files (including \"podcasts\"\nthat may be distributed through P2P software); and all\nmanner of free \"open content\" works collected by Creative\nCommons (one can search for Creative Commons material\non StreamCast).\nSee Brief for Distributed Computing\nIndustry Association as Amicus Curiae 15-26; Merges, A\nNew Dynamism in the Public Domain, 71 U. Chi. L. Rev.\n183 (2004). I can find nothing in the record that suggests\nthat this course of events will not continue to flow natu\nrally as a consequence of the character of the software\ntaken together with the foreseeable development of the\nInternet and of information technology. Cf. ante, at 1-2\n(opinion of the Court) (discussing the significant benefits\nof peer-to-peer technology).\nThere may be other now-unforeseen noninfringing uses\nthat develop for peer-to-peer software, just as the home-\nvideo rental industry (unmentioned in Sony) developed for\nthe VCR. But the foreseeable development of such uses,\nwhen taken together with an estimated 10% noninfringing\nmaterial, is sufficient to meet Sony's standard. And while\nSony considered the record following a trial, there are no\nfacts asserted by MGM in its summary judgment filings\nthat lead me to believe the outcome after a trial here could\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\n\nBREYER, J., concurring\nbe any different.\nThe lower courts reached the same\nconclusion.\nOf course, Grokster itself may not want to develop these\nother noninfringing uses. But Sony's standard seeks to\nprotect not the Groksters of this world (which in any event\nmay well be liable under today's holding), but the devel\nopment of technology more generally. And Grokster's\ndesires in this respect are beside the point.\nII\nThe real question here, I believe, is not whether the\nrecord evidence satisfies Sony. As I have interpreted the\nstandard set forth in that case, it does. And of the Courts\nof Appeals that have considered the matter, only one has\nproposed interpreting Sony more strictly than I would\ndo--in a case where the product might have failed under\nany standard.\nIn re Aimster Copyright Litigation, 334\nF. 3d 643, 653 (CA7 2003) (defendant \"failed to show that\nits service is ever used for any purpose other than to in\nfringe\" copyrights (emphasis added)); see Matthew Bender\n& Co., Inc. v. West Pub. Co., 158 F. 3d 693, 706-707 (CA2\n1998) (court did not require that noninfringing uses be\n\"predominant,\" it merely found that they were predomi\nnant, and therefore provided no analysis of Sony's bounda\nries); but see ante, at 3 n. 1 (GINSBURG, J., concurring); see\nalso A&M Records v. Napster, Inc., 239 F. 3d 1004, 1020\n(CA9 2001) (discussing Sony); Cable/Home Communica\ntion Corp. v. Network Productions, Inc., 902 F. 2d 829,\n842-847 (CA11 1990) (same); Vault Corp. v. Quaid Soft\nware, Ltd., 847 F. 2d 255, 262 (CA5 1988) (same); cf. Dy\nnacore Holdings Corp. v. U. S. Philips Corp., 363 F. 3d\n1263, 1275 (CA Fed. 2004) (same); see also Doe v. GTE\nCorp., 347 F. 3d 655, 661 (CA7 2003) (\"A person may be\nliable as a contributory infringer if the product or service\nit sells has no (or only slight) legal use\").\nInstead, the real question is whether we should modify\n\nCite as: 545 U. S. ____ (2005)\nBREYER, J., concurring\nthe Sony standard, as MGM requests, or interpret Sony\nmore strictly, as I believe JUSTICE GINSBURG's approach\nwould do in practice. Compare ante, at 4-8 (concurring)\n(insufficient evidence in this case of both present lawful\nuses and of a reasonable prospect that substantial nonin\nfringing uses would develop over time), with Sony, 464\nU. S., at 442-447 (basing conclusion as to the likely exis\ntence of a substantial market for authorized copying upon\ngeneral declarations, some survey data, and common\nsense).\nAs I have said, Sony itself sought to \"strike a balance\nbetween a copyright holder's legitimate demand for effec-\ntive--not merely symbolic--protection of the statutory\nmonopoly, and the rights of others freely to engage in\nsubstantially unrelated areas of commerce.\" Id., at 442.\nThus, to determine whether modification, or a strict inter\npretation, of Sony is needed, I would ask whether MGM\nhas shown that Sony incorrectly balanced copyright and\nnew-technology interests. In particular: (1) Has Sony (as I\ninterpret it) worked to protect new technology? (2) If so,\nwould modification or strict interpretation significantly\nweaken that protection? (3) If so, would new or necessary\ncopyright-related benefits outweigh any such weakening?\nA\nThe first question is the easiest to answer. Sony's rule,\nas I interpret it, has provided entrepreneurs with needed\nassurance that they will be shielded from copyright liabil\nity as they bring valuable new technologies to market.\nSony's rule is clear. That clarity allows those who de\nvelop new products that are capable of substantial nonin\nfringing uses to know, ex ante, that distribution of their\nproduct will not yield massive monetary liability. At the\nsame time, it helps deter them from distributing products\nthat have no other real function than--or that are specifi\ncally intended for--copyright infringement, deterrence\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\n\nBREYER, J., concurring\nthat the Court's holding today reinforces (by adding a\nweapon to the copyright holder's legal arsenal).\nSony's rule is strongly technology protecting. The rule\ndeliberately makes it difficult for courts to find secondary\nliability where new technology is at issue. It establishes\nthat the law will not impose copyright liability upon the\ndistributors of dual-use technologies (who do not them\nselves engage in unauthorized copying) unless the product\nin question will be used almost exclusively to infringe\ncopyrights (or unless they actively induce infringements as\nwe today describe). Sony thereby recognizes that the\ncopyright laws are not intended to discourage or to control\nthe emergence of new technologies, including (perhaps\nespecially) those that help disseminate information and\nideas more broadly or more efficiently. Thus Sony's rule\nshelters VCRs, typewriters, tape recorders, photocopiers,\ncomputers, cassette players, compact disc burners, digital\nvideo recorders, MP3 players, Internet search engines, and\npeer-to-peer software. But Sony's rule does not shelter\ndescramblers, even if one could theoretically use a de\nscrambler in a noninfringing way. 464 U. S., at 441-442;\nCompare Cable/Home Communication Corp., supra, at\n837-850 (developer liable for advertising television signal\ndescrambler), with Vault Corp., supra, at 262 (primary use\ninfringing but a substantial noninfringing use).\nSony's rule is forward looking. It does not confine its\nscope to a static snapshot of a product's current uses\n(thereby threatening technologies that have undeveloped\nfuture markets).\nRather, as the VCR example makes\nclear, a product's market can evolve dramatically over\ntime. And Sony--by referring to a capacity for substantial\nnoninfringing uses--recognizes that fact.\nSony's word\n\"capable\" refers to a plausible, not simply a theoretical,\nlikelihood that such uses will come to pass, and that fact\nanchors Sony in practical reality. Cf. Aimster, supra, at\n651.\n\nCite as: 545 U. S. ____ (2005)\nBREYER, J., concurring\nSony's rule is mindful of the limitations facing judges\nwhere matters of technology are concerned. Judges have\nno specialized technical ability to answer questions about\npresent or future technological feasibilility or commercial\nviability where technology professionals, engineers, and\nventure capitalists themselves may radically disagree and\nwhere answers may differ depending upon whether one\nfocuses upon the time of product development or the time\nof distribution.\nConsider, for example, the question\nwhether devices can be added to Grokster's software that\nwill filter out infringing files. MGM tells us this is easy\nenough to do, as do several amici that produce and sell the\nfiltering technology.\nSee, e.g., Brief for Motion Picture\nStudio Petitioners 11; Brief for Audible Magic Corp. et al.\nas Amicus Curiae 3-10. Grokster says it is not at all easy\nto do, and not an efficient solution in any event, and sev\neral apparently disinterested computer science professors\nagree. See Brief for Respondents 31; Brief for Computer\nScience Professors as Amicus Curiae 6-10, 14-18. Which\naccount should a judge credit? Sony says that the judge\nwill not necessarily have to decide.\nGiven the nature of the Sony rule, it is not surprising\nthat in the last 20 years, there have been relatively few\ncontributory infringement suits--based on a product\ndistribution theory--brought against technology providers\n(a small handful of federal appellate court cases and per\nhaps fewer than two dozen District Court cases in the last\n20 years). I have found nothing in the briefs or the record\nthat shows that Sony has failed to achieve its innovation-\nprotecting objective.\nB\nThe second, more difficult, question is whether a modi\nfied Sony rule (or a strict interpretation) would signifi\ncantly weaken the law's ability to protect new technology.\nJUSTICE GINSBURG's approach would require defendants\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\n\nBREYER, J., concurring\nto produce considerably more concrete evidence--more\nthan was presented here--to earn Sony's shelter. That\nheavier evidentiary demand, and especially the more\ndramatic (case-by-case balancing) modifications that MGM\nand the Government seek, would, I believe, undercut the\nprotection that Sony now offers.\nTo require defendants to provide, for example, detailed\nevidence--say business plans, profitability estimates,\nprojected technological modifications, and so forth--would\ndoubtless make life easier for copyrightholder plaintiffs.\nBut it would simultaneously increase the legal uncertainty\nthat surrounds the creation or development of a new\ntechnology capable of being put to infringing uses. Inven\ntors and entrepreneurs (in the garage, the dorm room, the\ncorporate lab, or the boardroom) would have to fear (and\nin many cases endure) costly and extensive trials when\nthey create, produce, or distribute the sort of information\ntechnology that can be used for copyright infringement.\nThey would often be left guessing as to how a court, upon\nlater review of the product and its uses, would decide\nwhen necessarily rough estimates amounted to sufficient\nevidence. They would have no way to predict how courts\nwould weigh the respective values of infringing and nonin\nfringing uses; determine the efficiency and advisability of\ntechnological changes; or assess a product's potential\nfuture markets. The price of a wrong guess--even if it\ninvolves a good-faith effort to assess technical and com\nmercial viability--could be large statutory damages (not\nless than $750 and up to $30,000 per infringed work). 17\nU. S. C. 504(c)(1). The additional risk and uncertainty\nwould mean a consequent additional chill of technological\ndevelopment.\nC\nThe third question--whether a positive copyright impact\nwould outweigh any technology-related loss--I find the\n\nCite as: 545 U. S. ____ (2005)\nBREYER, J., concurring\nmost difficult of the three. I do not doubt that a more\nintrusive Sony test would generally provide greater reve\nnue security for copyright holders. But it is harder to\nconclude that the gains on the copyright swings would\nexceed the losses on the technology roundabouts.\nFor one thing, the law disfavors equating the two differ\nent kinds of gain and loss; rather, it leans in favor of\nprotecting technology. As Sony itself makes clear, the\nproducer of a technology which permits unlawful copying\ndoes not himself engage in unlawful copying--a fact that\nmakes the attachment of copyright liability to the crea\ntion, production, or distribution of the technology an ex\nceptional thing. See 464 U. S., at 431 (courts \"must be\ncircumspect\" in construing the copyright laws to preclude\ndistribution of new technologies). Moreover, Sony has\nbeen the law for some time. And that fact imposes a seri\nous burden upon copyright holders like MGM to show a\nneed for change in the current rules of the game, including\na more strict interpretation of the test. See, e.g., Brief for\nMotion Picture Studio Petitioners 31 (Sony should not\nprotect products when the \"primary or principal\" use is\ninfringing).\nIn any event, the evidence now available does not, in my\nview, make out a sufficiently strong case for change. To\nsay this is not to doubt the basic need to protect copy\nrighted material from infringement. The Constitution\nitself stresses the vital role that copyright plays in advanc\ning the \"useful Arts.\" Art. I, 8, cl. 8. No one disputes\nthat \"reward to the author or artist serves to induce re\nlease to the public of the products of his creative genius.\"\nUnited States v. Paramount Pictures, Inc., 334 U. S. 131,\n158 (1948). And deliberate unlawful copying is no less an\nunlawful taking of property than garden-variety theft.\nSee, e.g., 18 U. S. C. 2319 (criminal copyright infringe\nment); 1961(1)(B) (copyright infringement can be a predi\ncate act under the Racketeer Influenced and Corrupt\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\n\nBREYER, J., concurring\nOrganizations Act); 1956(c)(7)(D) (money laundering\nincludes the receipt of proceeds from copyright infringe\nment).\nBut these highly general principles cannot by\nthemselves tell us how to balance the interests at issue in\nSony or whether Sony's standard needs modification. And\nat certain key points, information is lacking.\nWill an unmodified Sony lead to a significant diminution\nin the amount or quality of creative work produced? Since\ncopyright's basic objective is creation and its revenue\nobjectives but a means to that end, this is the underlying\ncopyright question. See Twentieth Century Music Corp. v.\nAiken, 422 U. S. 151, 156 (1975) (\"Creative work is to be\nencouraged and rewarded, but private motivation must\nultimately serve the cause of promoting broad public\navailability of literature, music, and the other arts\"). And\nits answer is far from clear.\nUnauthorized\ncopying\nlikely\ndiminishes\nindustry\nrevenue, though it is not clear by how much. Compare\nS. Liebowitz, Will MP3 Downloads Annihilate the\nRecord Industry? The Evidence So Far, p. 2 (June 2003),\nhttp://www.utdallas.edu/~liebowit/intprop/records.pdf\n(all Internet materials as visited June 24, 2005, and avail\nable in Clerk of Court's case file) (file sharing\nhas caused a decline in music sales), and Press Release,\nInforma Media Group Report (citing Music on the Internet\n(5th ed. 2004)) (estimating total lost sales to the music\nindustry\nin\nthe\nrange\nof\n$2\nbillion\nannually),\nat\nhttp://www.informatm.com,\nwith\nF.\nOberholzer\n& K. Strumpf, The Effect of File Sharing on Record\nSales: An Empirical Analysis, p. 24 (Mar. 2004),\nwww.unc.edu/~cigar/papers/FileSharing_March2004.pdf\n(academic study concluding that \"file sharing has\nno statistically significant effect on purchases of the\naverage album\"), and McGuire, Study: File-Sharing\nNo\nThreat\nto\nMusic\nSales\n(Mar.\n29,\n2004),\nhttp://www.washingtonpost.com/ac2/wp-dyn/A34300-2004\n\nCite as: 545 U. S. ____ (2005)\nBREYER, J., concurring\nMar29?language=printer (discussing mixed evidence).\nThe extent to which related production has actually and\nresultingly declined remains uncertain, though there is\ngood reason to believe that the decline, if any, is not sub\nstantial. See, e.g., M. Madden, Pew Internet & American\nLife Project, Artists, Musicians, and the Internet, p. 21,\nhttp://www.pewinternet.org/pdfs/PIP_Artists.Musicians_\nReport.pdf (nearly 70% of musicians believe that file shar\ning is a minor threat or no threat at all to creative indus\ntries); Benkler, Sharing Nicely: On Shareable Goods and\nthe Emergence of Sharing as a Modality of Economic\nProduction, 114 Yale L. J. 273, 351-352 (2004) (\"Much of\nthe actual flow of revenue to artists--from performances\nand other sources--is stable even assuming a complete\ndisplacement of the CD market by peer-to-peer distribu\ntion . . . . [I]t would be silly to think that music, a cultural\nform without which no human society has existed, will\ncease to be in our world [because of illegal file swapping]\").\nMore importantly, copyright holders at least potentially\nhave other tools available to reduce piracy and to abate\nwhatever threat it poses to creative production. As today's\nopinion makes clear, a copyright holder may proceed\nagainst a technology provider where a provable specific\nintent to infringe (of the kind the Court describes) is pre\nsent. Ante, at 24 (opinion of the Court). Services like\nGrokster may well be liable under an inducement theory.\nIn addition, a copyright holder has always had the legal\nauthority to bring a traditional infringement suit against\none who wrongfully copies. Indeed, since September 2003,\nthe Recording Industry Association of America (RIAA) has\nfiled \"thousands of suits against people for sharing copy\nrighted material.\" Walker, New Movement Hits Universi\nties: Get Legal Music, Washington Post, Mar. 17, 2005,\np. E1. These suits have provided copyright holders with\ndamages; have served as a teaching tool, making clear\nthat much file sharing, if done without permission, is\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\n\nBREYER, J., concurring\nunlawful; and apparently have had a real and significant\ndeterrent effect. See, e.g., L. Rainie, M. Madden, D. Hess,\n& G. Mudd, Pew Internet Project and comScore Media\nMetrix Data Memo: The state of music downloading\nand file-sharing online, pp. 2, 4, 6, 10 (Apr. 2004),\nwww.pewinternet.org/pdfs/PIP_Filesharing_April_04.pdf\n(number of people downloading files fell from a peak of\nroughly 35 million to roughly 23 million in the year follow\ning the first suits; 38% of current downloaders report\ndownloading fewer files because of the suits); M. Madden\n& L. Rainie, Pew Internet Project Data Memo: Music and\nvideo downloading moves beyond P2P, p. 7 (March 2005),\nwww.pewinternet.org/pdfs/PIP_Filesharing_March05.pdf\n(number of downloaders has \"inched up\" but \"continues to\nrest well below the peak level\"); Groennings, Note, Costs\nand Benefits of the Recording Industry's Litigation\nAgainst Individuals, 20 Berkeley Technology L. J. 571\n(2005); but see Evangelista, Downloading Music and\nMovie Files is as Popular as Ever, San Francisco Chroni\ncle, Mar. 28, 2005, p. E1 (referring to the continuing \"tide\nof rampant copyright infringement,\" while noting that the\nRIAA says it believes the \"campaign of lawsuits and public\neducation has at least contained the problem\").\nFurther, copyright holders may develop new technologi\ncal devices that will help curb unlawful infringement.\nSome new technology, called \"digital 'watermarking' \" and\n\"digital fingerprint[ing],\" can encode within the file infor\nmation about the author and the copyright scope and date,\nwhich \"fingerprints\" can help to expose infringers. RIAA\nReveals Method to Madness, Wired News, Aug. 28, 2003,\nhttp://www.wired.com/news/digiwood/0,1412,60222,00.html;\nBesek, Anti-Circumvention Laws and Copyright: A Report\nfrom the Kernochan Center for Law, Media and the\nArts, 27 Colum. J. L. & Arts 385, 391, 451 (2004). Other\ntechnology can, through encryption, potentially restrict\nusers' ability to make a digital copy. See J. Borland,\n\nCite as: 545 U. S. ____ (2005)\nBREYER, J., concurring\nTripping the Rippers, C/net News.com (Sept. 28, 2001),\nhttp://news.com.com/Tripping+the+rippers/2009=1023_3=\n273619.html; but see Brief for Bridgemar Services Ltd. as\nAmicus Curiae 5-8 (arguing that peer-to-peer service\nproviders can more easily block unlawful swapping).\nAt the same time, advances in technology have discour\naged unlawful copying by making lawful copying (e.g.,\ndownloading music with the copyright holder's permission)\ncheaper and easier to achieve. Several services now sell\nmusic for less than $1 per song. (Walmart.com, for exam\nple, charges $0.88 each). Consequently, many consumers\ninitially attracted to the convenience and flexibility of\nservices like Grokster are now migrating to lawful paid\nservices (services with copying permission) where they can\nenjoy at little cost even greater convenience and flexibility\nwithout engaging in unlawful swapping. See Wu, When\nCode Isn't Law, 89 Va. L. Rev. 679, 731-735 (2003) (noting\nthe prevalence of technological problems on unpaid swap\nping sites); K. Dean, P2P Tilts Toward Legitimacy,\nwired.com,\nWired\nNews\n(Nov.\n24,\n2004),\nhttp://\nwww.wired.com/news/digiwood/0,1412,65836,00.html;\nM.\nMadden & L. Rainie, March 2005 Data Memo, supra, at 6-\n7 (percentage of current downloaders who have used paid\nservices rose from 24% to 43% in a year; number using\nfree services fell from 58% to 41%).\nThus, lawful music downloading services--those that\ncharge the customer for downloading music and pay royal\nties to the copyright holder--have continued to grow and\nto produce substantial revenue. See Brief for Internet\nLaw Faculty as Amici Curiae 5-20; Bruno, Digital Enter\ntainment: Piracy Fight Shows Encouraging Signs (Mar. 5,\n2005), available at LEXIS, News Library, Billboard File\n(in 2004, consumers worldwide purchased more than 10\ntimes the number of digital tracks purchased in 2003;\nglobal digital music market of $330 million in 2004 ex\n\nMETRO-GOLDWYN-MAYER STUDIOS INC. v.\n\nGROKSTER, LTD.\n\nBREYER, J., concurring\npected to double in 2005); Press Release, Informa Media\nReport, supra (global digital revenues will likely exceed $3\nbillion in 2010); Ashton, [International Federation of the\nPhonographic Industry] Predicts Downloads Will Hit the\nMainstream, Music Week, Jan. 29, 2005, p. 6 (legal music\nsites and portable MP3 players \"are helping transform the\ndigital music market\" into \"an everyday consumer experi\nence\"). And more advanced types of non-music-oriented\nP2P networks have also started to develop, drawing in\npart on the lessons of Grokster.\nFinally, as Sony recognized, the legislative option re\nmains available. Courts are less well suited than Con\ngress to the task of \"accommodat[ing] fully the varied\npermutations of competing interests that are inevitably\nimplicated by such new technology.\" Sony, 464 U. S., at\n431; see, e.g., Audio Home Recording Act of 1992, 106 Stat.\n4237 (adding 17 U. S. C., ch. 10); Protecting Innovation\nand Art While Preventing Piracy: Hearing Before the\nSenate Comm. on the Judiciary, 108th Cong., 2d Sess.\n(July 22, 2004).\nI do not know whether these developments and similar\nalternatives will prove sufficient, but I am reasonably\ncertain that, given their existence, a strong demonstrated\nneed for modifying Sony (or for interpreting Sony's stan\ndard more strictly) has not yet been shown. That fact,\nalong with the added risks that modification (or strict\ninterpretation) would impose upon technological innova\ntion, leads me to the conclusion that we should maintain\nSony, reading its standard as I have read it. As so read, it\nrequires affirmance of the Ninth Circuit's determination of\nthe relevant aspects of the Sony question.\n*\n*\n*\nFor these reasons, I disagree with JUSTICE GINSBURG,\nbut I agree with the Court and join its opinion."
    },
    {
      "category": "Resource",
      "title": "clark_app_arch21.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/esd-68j-communications-and-information-policy-spring-2006/25c3241752429eb4dba5e7494d53b327_clark_app_arch21.pdf",
      "content": "Architecting a Networked Application\nDavid D. Clark\nVersion of Jan 12, 2005\n1 Introduction\n\nThe primary function of a computer network is to provide communication among application\nprograms running in end systems. Application builders, who are generally distinct from network\nbuilders, use this communication service without requiring a detailed knowledge of its inner\nworkings.\n\nNetwork builders depend upon design principles that they call \"network architecture\"; in layerist\nterms, network architecture is concerned with protocol layers up to and including the transport\nlayer. In this low-level view of architecture, the application layer is a black box that is designed\nby someone else, the application builder. Application builders, of course, have their own\nabstractions. The most common abstraction is the \"distributed system\" model, in which the end\napplication programs are components of a distributed application.\n\nThis section surveys a range of important design issues for network-based applications:\napplication-layer servers, adversarial design, application-level naming and identity, robustness\nand resistance to attack, performance, economics, and user empowerment. These application-\nlayer design considerations (which could be called \"application architecture\") are in part\northogonal to the architectural concepts at the network layers, although there are some areas of\ninteraction.\n\nThe Internet already has a rich set of distributed applications; the most popular today are the\nWeb, email, and peer-to-peer (P2P) computing. This section will draw on these applications for\nexamples to illustrate the principles under consideration.\n2 Application-Layer Servers\n\nThe dichotomy between network architecture and application design is being weakened by the\nrapid proliferation of middleboxes containing application-layer servers (ALSs). An ALS is\nlogically part of one or more applications, but it is located \"within\" the network. From the\nviewpoint of the application designer, the ALS is part of the application, even though it executes\non a machine remote from the users' end systems and not under their control. ALS middleboxes\nare interposed in some way in the communication path between the end points. An ALS may be\nspecific to a particular application, or it may be a common ALS that provides a service available to\nany application. An ALS is sometimes called \"middleware\", but this term is overloaded and\nsuspect.\n\nThe existence of ALSs is an apparent contradiction of the traditional end-to-end arguments. These\narguments imply that all application-specific code should run in user end systems; the core of the\nnetwork should be simple, application-independent, and focused on the basic network service of\ndata carriage. However, this is an over-simplistic interpretation of the end-to-end arguments.\nFirst, from the network perspective, these applications are still end to end, because these ALSs\nare not part of the network. So the application may have many hops or stages in its design, but\neach of these seems to be end to end. From the application perspective, the design process has\n\ncome to a more complex design: most of the popular applications today are not simply end-to-\nend. Email is not sent directly between user computers, it is sent from user computer to mail\nserver to mail server to user computer. The Web, which was initially a simple system of end\ncomputers playing the role of client and server, is now rich with caches, proxies, and the like.\n\nIn fact, there are many possible good reasons for moving parts of an application from the user\nend-nodes onto ALSs. For example, an ALS can:\n\na) Stage content or cache data close to where it is needed, to reduce latency, reduce cross-\nnetwork traffic, and improve performance (see Section 6.1).\n\nb) Reformat or preprocess information before sending it over very slow links or to end-\nnodes with limited capabilities (see Section 6.2).\n\nc) Make applications more robust to attack by distributing and replicating content (see\nSection 5.4).\n\nd) Manage identity and support cross-application reputation management, non-\nrepudiation of identity, etc. (see Section 4.1).\n\ne) Control the extent to which each party's identity is revealed to others (see Section 4.2).\n\nf) Allow rendezvous in a world with Network Address Translators (NATs) (see Section\n5.1).\n\ng) Allow staged interaction among machines like laptops that are not always online, and\nhold copies of content so it is available even if the original source is unavailable.\n\nh) Relieve users of operational problems by outsourcing part of the application (see\nSection 2.1).\n\ni) Provide the opportunity to observe, monitor and even modify (e.g., filter) content,\nperhaps in unwelcome ways.\n\nj) Pre-screen incoming messages to detect unwelcome senders or unwelcome content\n(see Section 5.3).\n\nk) Constrain what users can do, to create tiers of service that can be priced differentially.\n\nl) Provide financial returns to the operators, which can drive the deployment of the\napplication.\n\nThe ALS architecture is relevant to many other aspects of application design, as indicated by the\nsection references in this list.\n2.1 Helping an Application to Grow Up\n\nApplications have different needs at different stages of their maturity. Many new applications\nstart out either as pure end-to-end implementations (i.e., code running only on the user end nodes)\nor as end-to-end designs supported by some simple central server (e.g. to manage location,\n\nidentity, or rendezvous.) But as an application becomes popular, different parties will see a\nchanging set of needs. If an application comes to represent a significant component of overall\ntraffic, ISPs will want to take steps (like caching) to reduce traffic loads. The application may be\nseen as a source of revenues by a number of players. Governments may be interested in\nobserving, regulating, or constraining what is done using the application. Many of these interests\nwill manifest as attempts to inject different players into the application's behavior by way of\nALSs. So an application that is mostly end-to-end when it is young may grow up into a much\nmore ALS-oriented architecture.\n\nThere is a parallel here with the need for \"application management\". When an application is\nyoung, there is usually no role for a person who is the \"application manager\". The users are the\nmanagers--they detect that something is broken and do their best to fix it. However, as\napplications mature and the base of users shifts from early adaptors to main-stream (less well\ntrained and adventurous) users, there is an increasing need to outsource the management to\nprofessionals who can make the service more reliable and robust with less user involvement.\nMost individual users don't run their own POP or SMTP servers, although the architecture would\nlet them do so.\n\nA set of rules for an application might be: it should work \"out of the box\" without any ALS\nsupport, when necessary, but it should allow ALSs and external management to be added\nincrementally as needed.\n\nPeer-to-peer (P2P) systems represent a very interesting special case in this spectrum of\nmanaged/unmanaged and end-to-end/ALS. P2P systems assume that there are no special\nmachines designated as \"servers\", but that all the participants in the application play both the role\nof server and client. Users of the application help each other by providing resources. This pattern\ncould represent a very interesting way for an application to start growing up--as enough users\nappear but before the application has attracted the attention of \"professional service providers\",\nthe users can support each other, as services are needed beyond what the end points can do for\nthemselves. At the same time, looking at P2P from a critical perspective, applications designed in\nthis way may suffer from a form of arrested development; they may never be able to become fully\nmature. This is because the P2P design is so deeply embedded into the architecture that it is\nimpossible for a service provider to offer a managed P2P service and attract users. In the drive to\nmake sure that there is no central locus of control, many P2P systems remove the user\nempowerment to pick what services and servers they want to depend on.\n\nA very interesting design challenge would be to design an application that can shift\n\"automatically\" from pure end-to-end to a peer-to-peer mode to a managed ALS mode as an\napplication matures. These mode transitions should also be possible in the reverse direction: using\nmanaged services when they are well run and tussle-free, falling back on a peer-to-peer structure\nif the servers are missing or unwelcome, and at the end falling back to a pure end-to-end mode if\nonly two machines are left running the application.\n2.2 Application Identifiers in Initial Request Messages\n\nMost applications have some sort of initial request message to establish contact with a remote\nservice. Examples include an HTTP get request or a Telnet login. In early protocols like Telnet,\nthe end-machine initiating the request did the translation from name to location, and then it just\nsent a message with an entity identifier relative to that location. If a user wanted to log into\nmachine mit.edu as \"bob\", the Telnet client would look up the string \"mit.edu\" in the DNS, get an\n\nIP address, and then connect to that machine. It might then send a login containing the string\n\"bob\", but the string \"mit.edu\" would not be sent. In this case, the receiver could not tell if the\nconnection actually came to the right machine. Furthermore, it was impossible to insert an ALS\nor relay in the path from the source to the destination, because the ALS/relay did not know the\nfinal destination.\n\nThe first version of the Web had a similar problem: when a browser extracted the DNS name\nfrom the URL, the DNS name was not sent to the server. This meant that it was not practical to\nhave multiple web servers with different names on the same physical machine. Later versions of\nHTTP included the whole URL, including the DNS part. This made it possible for a single\nmachine to act as multiple servers by using the DNS portion to disambiguate the request, and it\nallowed a cache or proxy ALS to attempt to satisfy the user request.\n\nIn contrast, email messages have always carried the full destination email address in the header of\nthe message. Any server along the path can look at the message and see where the email is\nsupposed to go. In fact, a server along the way may have a different idea (hopefully a better idea)\nof where the mail should go. Without the full email strings in the email header, the relayed\narchitecture of Internet email would not work.\n\nThis suggests the design rule:\n\n- Application messages should contain explicit, full application-level names.\n\nThis allows an ALS to be interposed in the application-level connection. Assuming that this is\nwhat the users actually want, it is an important and useful capability.\n3 Designing against Adversaries --Tussle\n\nIn a simple world, all parties to a communication would have consistent shared interests, but this\nis not realistic today. A very important aspect of application system design is protecting the\napplication from its adversaries and their goals. The word \"tussle\" [Clark2000] has been used to\ncapture the reality that parties with adverse interests vie to determine what actually happens in the\nnetwork. Tussle pervades everything that users do. For example, a user may want to send mail\nprivately, but the government might be observing it; a user might want to look at web pages in\nprivate, but the ISP may be gathering a profile of what the user is looking at; a user may want to\nreceive mail, but not from spammers; a user might want to share music files, but the music\nindustry wants to block unlawful distribution.\n\nThere are several forms of tussle, which can be cataloged as follows:\n\n- Two (or more) users with common interests try to operate in presence of hostile or adverse\nthird parties. This pattern captures the tussle between the desire for privacy and the\ngovernment's desire to wiretap, for example.\n\n- Two (or more) parties may want to communicate, but may have conflicting interests and\nwant help. In this case, some third party may be involved to constraint or validate what is\nbeing sent. For example, a user may employ an incoming mail server that checks\nattachments for viruses, or a buyer and a seller may depend on a credit card company to\nprovide protection from fraud. The end-points deliberately reveal (perhaps part of) what\nthey are doing so a third party can become involved.\n\n- One party wants to participate in an application, but not with some other party, who\nintrudes. The most obvious example of this is spam--users want to use email, but not to\nreceive mail from spammers.\n\nIt is important for an application designer to consider how each of these patterns is manifested in\nthe specific application. Following sections contain detailed examples.\n4 Openness and Identity\n\nSince the email application was designed for a totally open community, it provides an easy space\nfor spammers to invade. Most instant messaging (IM) systems use a more restricted model: even\nthough user names are globally managed, a potential recipient has to add the sender name to her\nbuddy list before the message can be sent. In contrast to the open nature of email, this is a more\nclosed system, somewhat Victorian in its nature--you cannot talk to someone until you have been\nintroduced. It is easy to conceive of totally closed communities that don't even utilize global\nnames. However, a system that does not use global names cannot easily merge two user\ncommunities later, even if they desire it, because of the possibility of name conflict.\n\nThere are, of course, proposals for controlling spam that don't involve filtering based on identity.\nBut, since identity is an important part of many applications, it is worth looking a little more\ndeeply at the issues there\n4.1 Managing identity\n\nA system that is not totally open needs some sort of identity verification or authentication. If one\nsender can masquerade as another, then controls on who can send are of little value.\nOne approach is pair-wise identity management, in which each recipient maintains the\ninformation necessary to authenticate all senders it will accept. This is reasonable where the\npattern of communication is limited -- the set of senders for any recipient is small. This pattern is\nthe descendent of the era when a user would have a different password for any system he could\nlog into (and the process of \"introduction\" often involved going and talking to a person to present\nreal-world credentials in order to get a user name and password). When the number of pair-wise\nconnections is great, having each recipient maintain the identity verification information for all\nsenders is a burden for both the recipient and for the sender (who has to remember or maintain the\nnecessary information for each recipient).\n\nAnother approach is to move identity verification to an ALS that is provided as part of the\napplication. Most IM systems work this way: a participant's identity is validated by a central\nservice before he/she can connect to other participants. Many multi-player game systems also\nwork this way: identity is maintained in the game server, along with attributes of that identity, all\nof which can thus be vouched for by \"the game\".\n\nThe end-point of this process is shared identity, in which identity management is removed from\nthe application and operated as a free-standing service available to multiple applications.\nExamples of this include the Microsoft Passport system and the competing Liberty Alliance\nProject. The use of SSL in the Web is an example of a solution with a mix of these features. The\ncertificate hierarchy is available for use by any application, and the providers of browsers imbed a\ntable of \"valid\" certificate authorities into each browser so that the user does not have to maintain\n\nthis data for himself, but each web site may require a login from a user (a pair-wise solution), and\nonly very few Web sites use personal certificates to validate the user to the server.\n\nThe tradeoffs among these schemes are well understood and much debated. The annoyance of\nhaving each user maintain multiple identities, one for each partner, must be traded off against the\npossible loss of privacy that comes from having a single identity that is shared across many of the\ndifferent activities that a person engages in, a fear that is compounded when the identity is\nmaintained by a large corporation whose motives may not be clear. The point here is that the\ndesigner of an application must be sensitive to this tradeoff and make a thoughtful set of design\ndecisions. Different outcomes bias the tussle among different parties and will be more or less\nsuited to different situations.\n\nOf course, just having a verifiable identity does not solve the previous question of who can talk to\nwhom. One of the advantages of building a shared identity system is that a shared identity can\nprovide a basis for shared reputation maintenance systems, which are a subject of research today.\n4.2 Hiding identity\n\nIdentity is something that one end reveals to the other as part of establishing communication. At\nthe same time, one end may want to hide aspects of identity from the other end, revealing only\nthat which is necessary in the context of the application. Which aspects of identity can be hidden\nand which must be revealed is a tussle space, of course. Many web sites will offer free services,\nbut the \"price\" is that the user has to reveal personal information. Sometimes what must be\nrevealed is a matter of law. In the US, it is illegal to send a fax without including the correct\nsending telephone number, and recent spam legislation requires that bulk mail have a valid return\naddress. On the other hand, some chat groups don't reveal the sender's full email address to the\ngroup, so it is only possible to reply to the group, not the sender. Of course, the server that runs\nthe group knows the sender's full email address.\n\nIn general, passing communication through an ALS allows more control on what each party\nreveals to the other. One benefit of having IM messages go through a server is that the IP address\nof each party need not be revealed to the other. An IP address may not seem like an important\npart of identity, but knowing an IP address opens up that machine to various forms of exploration\nand harassment. Opening a direct connection necessarily reveals the IP address of each party to\nthe other, unless some NAT service can be interposed.\n\nFinally, any discussion of revealing and hiding identity must discuss the importance, in some\napplications, of specifically allowing anonymous participation. There are often very important\nsocial and economic benefits of allowing anonymous behavior, but since it is hard to police a\nworld with no accountability and there is little accountability without identity, systems that permit\nanonymous operation may have to impose much more restrictive technical constraints up front, to\nprevent rather than punish misbehavior.\n4.3 Naming Application Entities\n\nIn some applications like email, IM, and VoIP, the entities that the applications deal with are\npeople, so the only namespace of importance is the namespace of users. For other applications,\nsuch as the Web or content sharing, the application deals with information entities, and there must\nbe some way to name these entities as well as the users. The Internet provides a low-level naming\nscheme, the Domain Name System, or DNS. This is a system that allows a machine to keep the\n\nsame name even when its IP address changes. But with certain exceptions (e.g., the MX mail\nrecords), the DNS is intended to name computers -- physical end-points attached to the network.\nAt the application level, it is very seldom a physical end-point that really needs to be identified. If\nthe application hooks people together, for example via Internet telephony, instant messaging, or\nteleconferencing, the application needs to name people and the problem is to find their current\nlocation. If an application provides access to information, the application needs to name the\ninformation objects and the problem is to find a legitimate copy. If the copy is authoritative, it\ndoes not matter where in the network it comes from.\n\nSome application designers have been tempted to use the existing DNS to name application\nentities, even though it may not be optimal. Thus, the Web embeds DNS names in URLs. This\napproach had the advantage that the Web could be launched without building a whole new name\nresolution mechanism first, which might have doomed it. It has the disadvantage that when the\nDNS name for a Web server changes, the served URLs change, so names for information objects\nmay have less permanence than might be desired.\n\nMany modern applications build their own directory to catalog their objects and use the DNS\nonly as a way of finding the directory. Music sharing programs don't put the names of tunes into\nthe DNS, nor do instant message (IM) systems put people in the DNS. Instead they use an\napplication namespace that is tailored to its requirements, at the cost of more complexity in the\ndesign.\n\nIn these examples, the directory and the lookup service is designed specifically for each\napplication, so there is no sharing of mechanism among applications beyond the DNS. The\nobvious next step is to design a mechanism for naming higher-level entities in an application-\nindependent way. The Session Initiation Protocol (SIP) is one such example. It was conceived as\na protocol to set up Internet phone calls, but it has been used to set up multi-player games, and\nother purposes besides VoIP. It would typically be used to name people. The URI working\ngroup of the IETF designed a location-independent and application-independent name space for\nobjects [URI], and CNRI has developed the Handle System to provide persistent names for digital\nobjects on the Internet.1 So there are number of options for entity naming other than complete\ndesign from scratch that are open to application designers today.\n\nOne end-point of this design process would be to pull application-level naming down into the\nnetwork layer. Gritter and Cheriton [Gritter2001] have proposed that individual information\nobjects be given IP-style identifiers, and that the routing mechanisms in the Internet be used to\ncompute a path to the closest copy when it is requested. This raises a variety of issues, from the\nsize of the routing table to the concern about whether ISPs (and the Internet layer generally)\nshould be given the total control over the algorithm for finding a desirable copy of an object.\n5 Robustness Against Attack\n\nIf an application becomes successful and society starts to depend on it, then it will become a\ntarget of attack. An application designer should think about how an application can be robust\nenough to be \"mission-critical\".\n\nMany of the issues about attacks will be specific to what the application \"does\", of course, and\nare outside the scope of this discussion. And issues of poor implementation and the resulting low-\n\n1 See http://www.handle.net/\n\nlevel vulnerabilities should need no more than passing mention. But there are some issues that\napply in common across applications.\n5.1 Rendezvous in a Threatening World\n\nOne aspect of hiding one's identity (or in fact one's existence) is to put all of one's machines\nbehind a Network Address Translation (NAT) box. Machines that don't have public IP addresses\nare better shielded from probing and attack. However, the use of NAT boxes raises an important\nquestion for any application designer--how can communication be initiated between machines\nwhen none of them are visible on the net? This so-called rendezvous problem is becoming more\ncritical as more and more of the end-nodes on the net vanish behind NAT boxes.\n\nRendezvous refers to the process by which two machines that want to interact in the context of\nsome application identify each other, make initial contact, and successfully establish\ncommunication. Today, the simple model is that one machine gets an IP address for another and\nsends an initial packet to that address. But as noted above, more and more machines are hidden\nbehind NAT boxes and don't even have a public IP address. And many users are uncomfortable\nrevealing their IP address to others, even though they are willing to have some restricted\ninteraction with them.\n\nAn ALS architecture can solve these problems. IM systems that use a central server can work\neven if all the machines are behind NAT boxes. Each machine makes an outgoing connection to\nthe server, and then the server passes data back and fourth between the two. But it is much\ntrickier, if indeed possible in general, to build an end-node-only application that can work when\nall the machines are behind a NAT box. Kazaa, for example, solves this problem by finding a\nparticipant that is not behind a NAT box and causing it to become a relay between the two hidden\nhosts. Rendezvous in the presence of NAT boxes is a current topic of discussion in the IETF.\n\nThe problem of session initiation, or rendezvous, may be handled by a set of common ALSs in\nthe future, as an alternative to an application-specific server architecture.\n\nFinally, rendezvous is a process that may need to be better protected from prying eyes. Due to the\ndesign of IP and the DNS, rendezvous uses public packet headers. The original DNS did not\ncatalog services on a host, but just hosts themselves; services on a host are identified by \"well\nknown ports\" that are statically assigned to applications. The well-known port visible in every\npacket reveals what application it is a part of. This allows ISPs to monitor what applications their\nusers are using, block certain applications or deflect them to servers of their choice, and so on.\n\nA recent extension to the DNS [RFC2782] allows the registration of a service on a host, not just a\nhost; looking up a service name returns a port as well as an IP address. This could be exploited to\nmodify the balance of power in the tussle world, by returning a random port number unique to the\nhost rather than a universal well-known port. If the Internet worked this way, the balance of\nattack and defense around ports would totally change. A firewall could no longer easily block or\nallow specific applications for all hosts by blocking port numbers. On the other hand, port scans\nwould be must harder to exploit, since finding an active port would give no hint as to what\napplication was behind it. Since server ports could be picked from the full 16-bit port space, port\nscans would be very inefficient, in any case. ISPs could no longer track or block application\nusage. This might make network engineering much harder, since one could not track the growth\nof specific applications. On the other hand, ISPs might be more motivated to offer different QoS\nas part of service stratification, as opposed to blocking or enabling different applications. Finally,\n\nit would be straightforward for several machines behind a NAT box to offer the same service,\nsince they would not have to \"share\" the same well-known port.\n5.2 Data Visibility\n\nThere was little encryption of data in the early days of the Internet. This raised the risk of\nunwelcome disclosure but made \"benign peeking\" possible, for debugging, delegation of function\nto servers inside the network, and so on. With increasing concerns about disclosure, some\napplications have incorporated application-specific mechanisms like SSH to provide encryption\nunder specific circumstances. And application-independent approaches like SSL are quite popular\ntoday, even if encryption is not the norm in the Web.\n\nSome application designers have concluded that the decisions about the need for disclosure and\nintegrity controls are not a part of the application, but a consequence of the relationship between\nthe parties, the sensitivity of the information, and so on. In this view, the decision to use\nencryption should be handed off to a lower-level mechanism such as IPSec or VPN tunnels. This\nmay be satisfactory in cases where both parties have compatible and easy means to activate such\ntool, but it may fail on grounds of complexity and difficulty of use.\n\nDoing encryption right, including key distribution and protection, is a specialty that many\napplication designers are not trained for. It is good that encryption has reached a stage of maturity\nthat makes it available as a stand-alone system that application designers can incorporate.\nHowever, it is not clear to what extent encryption can always be extracted from the application. If\nan application wants to encrypt some but not all of a communication, for example, the lower-\nlayer schemes like IPsec and SSL will not be useful.\n\nAn important tussle is the relationship between hidden content and content filtering. Encrypting\nthe contents of messages limits the filtering that a third party can do. Among trusting parties, this\nlimitation may be exactly what is desired--for example to sidestep government censorship. But\namong parties that don't trust each other totally, filtering may be desirable. Users may want to\nhave their email scanned for viruses, and adults may want to filter their children's communication\nto prevent the receipt of objectionable material. Since the wishes of the different parties to the\ncommunication may differ, it is complex to sort out how the application should actually function\nin these cases. It is a question of who is in charge, how that fact is expressed, how the application\nresponds to it, and whether the resulting behavior can be seen and understood by all the parties, or\nwhether parts of the action are hidden.\n5.3 Denial of service\n\nDenial of service (DoS) attacks and their more aggressive relative, distributed denial of service\n(DDoS) attacks, attempt to overload a machine to the point where it cannot provide service to\nlegitimate users. Many of the attacks today have focused on lower layers, such as TCP, and\nattacks on the application should be considered in that context.\n\nThe nature of most attacks on TCP is not just to overload the processor, but to exhaust some\nlimited resource, such as the storage for TCP connection state information. The goal is to trick the\nTCP software into expending effort to set up needless state, which is then maintained for some\ntime to the exclusion of legitimate requests. One of the factors that make attacks at the TCP level\nworse is that TCP has to set up a connection descriptor on receipt of the first packet, before it\n\nknows anything about the identity of the sender or even if the sender's IP address is legitimate.\nMany attacks at the TCP level involve false source addresses.\n\nOne way that these problems might be solved is to let the application provide hints to the TCP\nlayer about what source IP addresses are more or less likely to be valid. The application might\nkeep track, for example, of what IP addresses had ever been seen before, and instruct the TCP\nlayer to give them higher priority in times of overload. This idea might be helpful, but would\nrequire a redesign of the lower levels or the preprocessing of incoming traffic at the packet level\nbefore it even reaches the host running the application. This option is not easy to exploit today,\nbut it is worth keeping in mind since it implies something about what information the application\nmay want to store for later use.\n\nIf the TCP attack problems can be solved, we can expect that DOS attacks will be directed at the\napplications themselves. How might an application be made more resistant to these sorts of\nattacks? In general, the same reasoning applies--avoid a design that requires the application\ncode to invest much effort or create much state until it is sure that it is talking to a legitimate\npartner. The Web actually has a tool that is helpful here, although some users view it with\nsuspicion: cookies. Cookies allow a user to show that the other end previously knew him, and to\nsend the credential in the first message sent. It is worth thinking about how mechanisms such as\ncookies can be made robust to forgery, replication and theft.\n\nAnother class of defense is the so-called \"puzzle\": a challenge sent back to the client that the\nclient must solve and return before the server will take any significant action. The idea is to\ndemand enough effort of the attacker that he runs out of resources before the server does. The\napplication designer has an advantage here over the TCP layer. TCP must generate some sort of\nresponse upon receipt of the first packet, but the application will not receive an incoming message\nuntil the TCP connection is established, which implies that the source address is valid. Even in a\nDDoS attack that uses many machines to overload the target, the source IP addresses in each of\nthe attacks must be valid, so many attacks from the same machine can be detected as such. Of\ncourse, puzzles and related mechanisms have the effect of adding round trip delays in the\nconnection initiation, which is contrary to most design objectives.\n\nAnother theoretical means of protection is to make a sender include in the first message a micro-\npayment that the recipient can refund if the sender proves legitimate. This implies a framework\nfor micro-payments that we lack today, but it is an interesting speculation.\n5.4 Defense in depth\n\nOne way to an overloaded server is to permit the server to \"outsource\" protection to other\nmachines. This is an example of \"defense in depth\", applied to the problem of denial of service. If\nthe incoming load of requests can be pre-processed or spread out among a number of machines, a\nDoS attack may be diffused and rendered ineffective.\n\nCaches and replicated content provide a form of defense-in-depth. Since the content is replicated\nin many places, an attack on any single machine may disrupt a subset of users but will not disable\nthe overall service. An application designer should consider which aspects of an application need\nto be centralized, which can be replicated, and how preprocessing or preliminary interaction with\nthe source can help separate attacks from legitimate requests.\n\nOf course, if there is a central server in the application design, it can still be vulnerable to a direct\nattack if the attacker can bypass the first line of defense. If the IP address of the server is known,\nthen only low-level restrictions on routing can prevent a potential attacker from sending directly\nto the server. At this point, the options becomes more complex: either the server only accepts\nconnections that come indirectly from one of the pre-processors, or routing is restricted so that all\npackets have to pass through some checkpoint where legitimate packets can be distinguished in\nsome way. There are proposals to create a packet-level mechanism that works this way, for\nexample I3 [Stoica2002]. But for the moment, the application designer is on his own.\n5.5 Attack amplification\n\nOne vulnerability to avoid if possible is a design in which one node in the application can be\nsubverted and turned against other nodes. In particular, it is critical to prevent an attacker from\nusing a node as an amplifier for an attack, so that a successful attack on one node becomes a\nsubsequent attack on many. In general, this requires an analysis of application level behavior, to\ndetect places where incoming requests from one node turn into outgoing requests to other nodes.\nMailing lists suggest the potential for amplification, as do any other sort of \"one to many\"\npatterns. Email attacks that use the address book of a victim to pass themselves on to others are a\nreal concern today, and lead to analysis of attacks in terms of propagating epidemics. One class of\nprotection, which may have as much to do with implementation as design, is to require that a\nhuman be in the loop for actions that seem to imply amplification. This will have a slowing\neffect, as well as perhaps detecting the attack. Limits on outgoing rates can also help, provided\nthey can be set up so they do not interfere with normal operation.\n6 Performance Adaptation.\n\nAn application designer must take into account that users may attempt to use the application\nunder very different circumstances, in terms of performance and computational capability. Some\nof these differences may seem to be outside the scope of this document--whether the user has a\nsmall display or a large one, a keyboard or a speech input, a powerful processor or a feeble one,\nand so on. But some performance issues are directly related to the network--whether the user is\non a fast or slow connection with high or low latency, and so on. Some of the issues above relate\nto topics of interest here.\n6.1 Caching and pre-fetching\n\nIf there is a high-latency, slow, or congested link along the path from the source to the\ndestination, the application may benefit if content can be pre-staged or cached near the user. Then\nthe user experience can avoid these impairments. This approach makes less sense for applications\nthat require real-time interaction, access to real time data or to another person; they make more\nsense with information that can be cached or with human communication, like email, that can be\nstaged.\n\nTo implement a caching or pre-staging approach, several things are necessary:\n\n- The application must support some sort of caching or pre-fetching in its architecture.\n\n- There must be a set of servers positioned to perform this function.\n\n- The application must be able to figure out the right locations for these servers, and which\nserver to use for a given request.\n\nThe Internet email system has a full relay architecture built into it, but the design is not focused\non the goal of staging the email \"close to\" the recipient. In fact, the POP server can be, and often\nis, at a great distance from the user. The email design was focused more on reliability, the\nmanagement of the server, and do on. The Web offers examples that more directly address\nperformance and locality. Many access providers have web content caches in their sites that can\nserve up web content without having to retrieve it from across the net. The firm Akamai has made\na business of pre-positioning content near users, and dynamically computing which of the various\nAkamai servers is the best, in terms of performance, to provide the content.\n6.2 Reformatting of content\n\nIf the user's computer is particularly limited in processing capacity, display capability, and so on,\nand/or if this computer is at the end of a particularly constricted communication link, the\napplication may be designed to permit the pre-processing or reformatting of incoming messages\nbefore they are sent over that slow link to the user. This concept is equally applicable to real time\napplications and to those where content can be cached or pre-staged. Examples of preprocessing\ninclude reducing the resolution of a video image, mixing several audio streams to produce a\nsingle one, reformatting a web page for a small display, and stripping attachments off of email\nand truncating long messages.\n\nIf the set of reformatting operations has been standardized, they can be implemented at the source\nfor the benefit of the destination. But since new devices are introduced from time to time, there is\na benefit of allowing new sorts of conversions to be implemented by placing them in new servers\ndesigned for the purpose. This approach, in the extreme, allows an application to extend beyond\nthe Internet itself, to devices and end-nodes on different sorts of networks. In this case the relay\npoint reformats the whole interaction, not just the data.\n7 Economics\n\nThe common economic model of the Internet is a simple one: the user pays a single access fee\n(e.g. a monthly flat rate) and expects in return to get access to all the applications and services of\nthe network. The user does not expect to pay extra for email, Web access, and so on. This is not\ntotally true, of course; users understand that they have to pay for things like Web hosting, some\nthird-party email services, and some content. But access to most applications comes \"for free\"\nonce the user signs up for the Internet.\n\nThis bundled approach makes a lot of sense as a pricing strategy in the market--the consumer\nmight not tolerate a plethora of small bills for specific services. On the other hand, it raises a\ncritical question: if parts of an application are running on ALSs, as opposed to simply running on\nthe end-nodes, who is providing those services, and what is their compensation?\n\nThe DNS is seen as so important that all ISPs just support it as part of their core business.\nSimilarly, email is seen as so central to the net that essentially all ISPs provide POP and SMTP\nservers as a basic cost of doing business. But beyond that, there is little clarity or consistency in\nthe economic structure of applications. ISPs appear to provide Web proxies both because they\nimprove the user experience and because they save the ISP cost by reducing traffic on the trunk\n\ninto the Internet. Akamai servers are paid for by the content providers, both to improve the user\nexperience and to reduce the demand on (and thus the capacity and cost of) their primary servers.\n\nFor more recent applications, where there is no history of free use, fees are starting to emerge.\nInternet telephony or VoIP requires rather costly servers to transfer calls into the circuit-switched\ntelephone systems. As a result, most VoIP services, such as NetToPhone or Vonage, have either a\nmonthly or a per-minute fee. It will be interesting to see if SIP servers become part of the\ninfrastructure that ISPs provide as part of their base service, or come to be a service that requires\nan incremental fee.\n\nGames provide a number of examples of economic models. Some game developers sell the\nsoftware and run a server as a part of the product, others give away the software but require a\nsubscription to the service, and others use an informal scheme in which some of the players\nbecome temporary servers, thus removing the need for the game provider to provide any servers\nto support the game.\n\nIn this context, the emergence of the peer-to-peer systems is significant. P2P systems are based\non a different economic model, which is a barter system. Nobody pays anyone else in money;\neach party just contributes part of the service. This is actually a very good system in some cases,\nalthough its use for the propagation of copyrighted content has given it a bad name.\n7.1 Design for making money\n\nMost Internet applications do not have a built-in model of cost recovery, commercialization, or\nprofit. A catalog of the economic motivations that drive application providers on the network\nreveals a variety of approaches to making money.\n\n-\nMany Web sites offer free content in order to sell advertising.\n\n-\nSome proprietary applications give the \"viewer\" away in order to generate sales for\nservers.\n\n-\nSome sites charge direct subscription fees or sell individual units of content for a fee\n(including iTunes and the New York Times archives.)\n\nIt is not unreasonable for service and content providers to make money, notwithstanding the\nInternet history of \"free\" applications. This reality begs an important question--should\napplication design take into account the economics of the service, or is the business/economic\ncontext something that can just be wrapped around the protocols after they are done?\n\nBuilding a complete model of pricing and billing into an application's architecture is almost\ncertainly a very bad idea. First, there will always be cases where the application is offered for\nfree--for example inside a corporation to its employees. Second, marketing departments will\nalways want to invent new sorts of pricing models--fixed vs. incremental payment for service,\nsite licenses, and so on. But are there \"pricing building blocks\" that might be built into an\napplication that would facilitate commercialization of applications? This topic has received very\nlittle attention, and what attention it has received has been hostile. There is a sentiment, quite\npossibly justified, that if it is easy to bill for an application, then providers will do so, which will\nerode the \"bundled pricing\" model that seems to work so well for the Internet.\n\nDespite these concerns, it is not wise simply to ignore this set of issues. By doing so, designers\nlose the opportunity to shape how the economics of an application matures. Specifically, if there\nare no \"economic hooks\" in the protocols, service providers may try to exploit other features of\nthe protocol to change the economic landscape, to the detriment of overall operations. Here is one\nexample, hard to prove or document but rumored none the less. Some web hosting providers,\nsince they are paid based on the number of hits, may be marking static web pages as\n\"uncachable\" to keep downstream providers from holding a cached copy. This phenomenon\nrepresents a tussle between two providers with different economic motivations--one wants to\nreduce the number of hits to the upstream copy, one wants to increase it. In this case, a correction\nmight be to take information such as \"uncachable\" and imbed it into the data itself in a way that\ncannot be modified without detection, so that the setting represents the opinion of the creator, and\nnot of an intermediate server. But it may take more experience than most of us have to think of\nthese sorts of things in advance.\n\nOne specific consideration is direction of value flow. The phone system has two sorts of long-\ndistance calls, those where the sender pays, and those, the \"800\" calls where the receiver pays.\nOne of the problems with the Internet is that one cannot tell which way the value flows just by\nlooking at the flow of packets. But knowing whether the sender or the receiver is prepared to pay\nfor an action might help sort out a number of billing problems. Note that specifying which way\nvalue flows in no way sets the price. That can be done in a separate transaction.\n8 User Empowerment--Tilting the Playing Field\n\nThe list of possible ALS functions in Section 4.2.2 reminds us that application-layer servers in the\nnetwork represent a rich space in which the tussle of interests will be carried out. The application\ndesigner, by crafting the server architecture of the application, is crafting the tussle space that will\nemerge as the application emerges. Many network designers and application designers share a\nvalue that has been called user empowerment, or freedom of choice and action, or an open\nmarketplace. All of these terms try to capture the idea that the Internet is a place where users can\nrun the applications they choose and pick the providers on whom they will depend; it is not a\nplace where monopolists gain the power to impose restrictions on user action. Of course, this is a\ntussle space, not a given right, but many designers see the individual user as potentially at the\nmercy of \"big business\", or \"repressive government\", and tend to make design choices that favor\nthe end-user when they can. We need techniques to tilt the playing field toward the end-user as\nwe design a server architecture.\n\nFor the application designer, user empowerment is the ability of the user to pick the server(s) to\nuse and to avoid the server(s) he chooses to avoid. Implementation of that empowerment is\ngoverned by a set of simple rules concerning what is visible, hidden, and protected in messages.\n\n- That which is encrypted (or missing) cannot be seen.\n\n- That which is signed cannot be changed (without being detected).\n\n- That which cannot be seen cannot be acted on.\n\n- Aggregated content whose aggregation boundaries cannot be seen cannot be treated\nselectively.\n\nConsider a simple example--a user trying to send a piece of mail. Normally, the user picks the\nSMTP server he wants to use. Giving that choice to the user seems right to most of us. But\nrecently, there have been cases where an access ISP (for example, a provider of residential\nbroadband service) prevents the user from connecting to any SMTP server but the one the ISP\nprovides. There may be claims that this is for \"reliability\" or some such, but the practical reason\nseems to be to restrict the form of the \"from\" email address being used to only those provided by\nthe ISP. By doing this, users are prevented from using a third party email service or their\ncorporate email address, and they may be persuaded to upgrade their service to a more expensive\nversion. One response by a crafty user is to use an SSL connection on a different port rather than\nraw SMTP, to prevent the ISP from seeing what is going on and blocking it. Of course, the ISP\ncould block SSL connections, which leads to further escalation. There are many applications\ntoday that are being designed to work \"over the Web\", either as an option or as the only transport\nmode. This may be seen simply as a demonstration of horrid design taste, or as a crafty way to\ncommingle this application traffic with a class of traffic (http) so important that any ISP or\nfirewall more or less has to let it through. By encrypting and aggregating traffic, the user can\nattempt to impose his choices of servers, despite the motivations of his providers.\n\nAll this has been worked out for email in an ad hoc manner, long after the basic email protocols\nwere designed. But any application designer today should think through how this might work out\nfor his application in the future.\n\n- Should the application have a native \"encrypted mode\" that the sending application can\neasily trigger? If so, how are the keys managed? What is the relation between the key that\nlinks an end-point to a server and a key that links end-points?\n\n- Are there parts of the message that a server may want to change (for good reasons), and\nother parts that ought to be signed to prevent changes?\n\n- Should the application have a \"Web mode\" or other aggregated mode that commingles the\ntraffic with that of other applications?\n\n- How does the user \"get started\" in using this application? How does he find the first\nservers he needs? Does the access ISP provide the server (as it does the DNS), is there is\na central service run by a third party (such as the application provider), or does the user\nmanually configure his software to select a server of his choice, perhaps using\ninformation that was advertised on the Web (as happens with some email services)?\nCould this process of selection be automated as part of the application design?\n8.1 Receiver empowerment\n\nAll the discussion to this point has been from the viewpoint of the sender. To first order, it is the\nsender that picks the recipient. But of course, this is too simplistic. Consider mail: the receiver\npicks his \"incoming\" mail server and configures the DNS so that the sending server connects to\nthis server. Consider the web: queries to URLs can be deflected by the receiving end to one or\nanother server in a number of ways. The user can be given a different URL based on where he is\ncoming from, or the DNS that defines the URL can be programmed to give different answers\nbased on the current circumstances. Again, most examples of this today are being retrofitted onto\napplications where the idea was originally missing, but a designer today ought to consider what\noptions should be installed in the application itself.\n\nThere are also proposals to control routing at the network level to meet the needs of receivers--\nschemes like I3. [Stoica2002]\n9 Conclusions\n9.1 Application design techniques/goals\n\n- Try to sort out the motivations of the parties that may participate in the application.\n\n- Consider the importance of user empowerment: Let the users pick who they want to\ncommunicate with and what servers they use.\n\n- Use encryption as a tool to control what can be seen, what can be changed, and what is\nhidden. Think about the needs of trusting and wary users when making these choices.\nEven trusting users may benefit from an application architecture that involves servers,\nwhich may imply revealing certain parts of the communication. Consider if aggressive\nuse of information hiding may cause the application to be banned in some contexts.\n\n- Design for the life cycle of an application. Design so servers are not needed with small\nnumbers of users, but can be added as application grows up. Consider using a peer-to-\npeer architecture as a stage of growth and a fallback mode, not as an immutable feature\nof the design.\n\n- Include full application entity information in the messages themselves, rather than\nimplying part of it implicitly by the Internet destination, so that servers can participate in\nthe mechanism. Encryption can hide this information from prying eyes.\n\n- Do not create a new form of spam in a new application. There is no reason to make it easy\nfor unwelcome users to intrude on others, but be aware that they may have a strong\neconomic incentive to do so.\n\n- Do not provide an unwitting tool for attack amplification.\n\n- Include a concept of identity, and consider giving the receiving user control over how\nrestrictive he wants to be in what he accepts. Sometimes, anonymous communication is\nsocially or economically valuable.\n9.2 Some Useful Common Services\n\nMost of the common services listed here have a strong social component, and will be the target of\ntussle and debate. We do not mean to minimize any of that, but to invite the debate in an orderly\nand coherent manner by calling for the services.\n\n- A service to manage identity and support cross-application reputation management, non-\nrepudiation of identity etc.\n\n- Naming services for different sorts of entities, such as SIP, URIs and the Handle System.\n\n- RFC2872 service lookup to avoid well-known ports.\n\n- Encryption layers that provide different sorts of information hiding and signing.\n9.3 Possible Changes to the Network Architecture\n\nProvide:\n- New modes of routing to support applications.\n\n- Routing to an identity that is not an IP address, to protect the address and control the traffic\nto the destination.\n\n- A means to link application-level identity to packet-level identity, so that packet-level\nfiltering and routing can be controlled by receiver specification.\n\n- A service that provides abstracted information about network topology and performance, to\nassist application with locating servers within the application."
    }
  ]
}