{
  "course_name": "Education Technology Studio",
  "course_description": "No description found.",
  "topics": [
    "Teaching and Education",
    "Educational Technology",
    "Teaching and Education",
    "Educational Technology"
  ],
  "syllabus_content": "Course Meeting Times\n\nSeminar: 1 session / week; 3 hours / session\n\nPrerequisites\n\nNone\n\nCourse Description\n\nStudents use media and technology to develop new forms of learning experiences in schools, workplaces, and informal settings. Students participate in a range of new and ongoing projects that hone understanding and skills in learning science, instructional design, development and evaluation. Topics vary from year to year, and include developing new media and activities for Massive Open Online Courses, creating practice spaces for practitioners in the professions and humanities, and developing new approaches to assessment in complex learning environments. Students taking graduate version complete additional assignments.\n\nCourse Goals\n\nWe have four goals for this course. We hope you:\n\nEngage firsthand in the development, deployment, and evaluation of education technology projects.\n\nExplore and deploy new skills in instructional design, design-based research, and learning analytics with a focus on user-centered design and engaging stakeholders in the design of new media.\n\nGet a grounding in some of the foundational texts in practice-based teacher education, learning analytics, and accessibility, as well as exposure to new research and thinking in education technology.\n\nPractice effective oral and written communication to a variety of education technology stakeholders.\n\nCourse Structure\n\nEducation Technology Studio is a studio course about the design, implementation, and evaluation of educational technology to develop effective and equitable forms of learning experiences in schools, workplace, and informal settings. Our primary modes of inquiry will be reading, hands-on projects, reflection, and discussion. Most of the activities will have a technical focus. While previous knowledge of data analysis and programming is useful, it is not required. The scope of the assignments can be adapted to students' prior technical background and technical support will be provided from peers and instructors as appropriate.\n\nPolicies and Expectations\n\nWe have designed a preliminary syllabus of topics and readings, which we are willing to add to or amend. Over the semester, we look forward to learning about each other's interests, and using those interests to shape what we do together in the course. For this reason, we are open to changing topics, readings, and assignments to let students bring their expertise into the course and to pursue what we're most interested in together.\n\nThe fundamental commitment that we ask you to make is to:\n\nAttend every session with undivided attention. The instructors have put a great deal of thought and energy into communicating the course material in an exciting, engaging, and relevant way. We thank you for displaying your utmost professionalism by not checking devices/social media during class. Your physical and mental presence will maximize your own experience in the course as well as that of your classmates.\n\nComplete the assignments with your best effort and energy; you will gain from this class what you put into it.\n\nThe participation and engagement of every student in the course and outside of class is essential to a successful studio course.\n\nGrading\n\nAssignments\n\nPercentages\n\nClass Participation\n\n20%\n\nMini Projects\n\n50%\n\nFinal Project\n\n30%\n\nStudent mini-projects and the final project will be rated using the generic criteria/scale below. The instructor will make modifications to the generic rubric to best fit the nature of the individual mini-projects and will notify students accordingly. In addition, in determining a student's grade consideration will be given for elegance of presentation, creativity, imagination, and originality, where these may appropriately be called for. Audience members and stakeholder/user guests will also be asked to fill out a rubric to provide the student with additional feedback.\n\nWritten and Presentation Rubric\n\nElement expecations\n\nPercentages\n\nProblem definition:\nEstablishes clear, well-defined problem\n\n20%\n\nUser-centered design:\nIdentifies user, context, and or/ application\n\n10%\n\nClarity of learning objective:\nClearly articulates learning objective and/or research question\n\n10%\n\nJustification for use of technology to solve the problem\n**:** Provides a clear, well-reasoned, and well-articulated rationale for using the technology selected to solve the identified problem\n\n10%\n\nPrototype\n\n50%",
  "files": [
    {
      "category": "Resource",
      "title": "CMS.594 Education Technology Studio, Daily Exit Ticket",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/cms-594-education-technology-studio-spring-2019/d99432721c809b33a3de636f978200ee_MITCMS_594S19_exit.pdf",
      "content": "EdTech Design Studio Daily Exit\nTicket\nWhat unit was today's class?\nUnit 0: Welcome\nUnit 1: Learning Analytics\nUnit 2: Practice Spaces\nUnit 3: Accessibility\nUnit 4: Final Project\nHow are you feeling right now about today's class?\nGreen light - I am good to go\nYellow light - I have some minor questions or concerns\nRed light - I have some major questions or concerns\nNEXT\n\nEdTech Design Studio Daily Exit\nTicket\nWhat is one piece of information that you took away from\ntoday's class?\nYour answer\nWhat question/s do you have about today's class?\nYour answer\nBACK\nSUBMIT\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nCMS.594/CMS.894 Education Technology Studio\nSpring 2019\nFor more information about citing these materials or our Terms of Use, visit:\nhttps://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "CMS.594 Education Technology Studio, Session 1: Introduction",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/cms-594-education-technology-studio-spring-2019/66ad4f2ec6bcb1e3c4f1d042b0ff3287_MITCMS_594S19_ses1.pdf",
      "content": "Introduction & welcome\nCMS.594/894- Education\nTechnology Studio\nSpring 2019\n\nDesign thinking\nexercise\n\nactivity: Quest for the \"perfect\" breakfast\nUsing the Innovator's Compass as a framework, design the\nperfect breakfast for a friend.\n\nShare out\nCourtesy of *NN07\"5034h C0.1\"44 by &la Ben-Ur see innoWatorscoNQass.orH. Used under CC BY-NC-4\".\n\nMeet Your design\njournal\n\nFeb.6- Activity: what is your Professional and/or\nPersonal motivation for taking this class?\n\nShare out- Meet your classmates\n●\nName/Pronouns\n●\nYear/Major\n●\nProfessional and/or personal motivation for taking class\n●\nWhat you hope to get out of this class\n\nBreak - please return in\n10 minutes\n\nOverview of course\nunits\n\nUnit 1: What is Learning Analytics?\n...collection, analysis and reporting of data about learners\nand their contexts, for purposes of understanding and\noptimising learning and the environments in which it occurs...\n\nUnit 2: Using technology to improve teacher practice\nPractices spaces are learning experiences\nthat help teachers practice and reflect\non key teaching decisions.\n!\nTeaching is complex\n!\nTeachers have limited opportunities\nto practice specific skills\n!\nTechnology as a way to scale up\nteacher learning and feedback\n!\nFocus on authenticity of task rather\nthan authenticity of setting\n\nUnit 3: What is accessible design?\nCourtesy of auntylaurie on Flickr. Used under CC BY.\nCourtesy of borkazoid on Flickr. Used under CC BY-NC.\nRamp stairs photo by Beau Lebens.\n\nUnit 4: What will the final project look like?\n1. Review reflections on each mini-\nproject\n2. Decide on project\n3. Conduct stakeholder/user interview\n4. Incorporate feedback\n5. Conduct playtest\n6. Incorporate feedback\n7. Final prototype, presentation, and\nwritten product (select one of\nmultiple options)\n\nSyllabus\nhighlights,\nQ&A\n\nCourse expectations\n!\nParticipation\n\"\nYou need to be an active participant in class\n\"\nAttend every session with undivided attention\n!\nComplete the assignments with your best\neffort and energy\n\"\nShort design journal reflection or technical\nprep assignments\n\"\nThree unit mini-projects\n\"\nFinal project, presentation, and written product\n!\nSubmitting assignments\n\"\nSpecified in the syllabus so please\nread carefully\n\"\nGenerally, submission in design journal or to\ncourse website\n\nCourse Grades\n!\n20% on class participation\n\"\ndesign journal\n\"\ntechnical preparation activities\n\"\nactive participation during in-class activities\n(e.g. \"exit tickets\")\n!\n50% on the three mini projects combined\n\"\nMini-Project 1: Due Feb 27th\n\"\nMini-Project 2: Due Mar 20th\n\"\nMini-Project 3: Due Apr 17th\n!\n30% on the final project\n\"\nDue May 15th\n!\nWritten Product & Prototype\nRubric(Syllabus appendix)\n\nPreparing for the\nnext class\n\nUnit 1 Overview\n●\nDeveloping your own learning analytics mini-project based\non HarvardX-MITx MOOC data\n●\nClass 1:\n○\nOverview of Learning Analytics\n○\nMeet the dataset and start brainstorming about the mini-project\n●\nClass 2:\n○\nReview of your homework due today and class provides feedback on it\n○\nHard work on mini-project in class. Instructors help align objectives\nand solve the challenges of the mini-project\n●\nClass 3:\n○\nPresentation to the rest of the class of mini-projects\n○\nIf there is enough time, we will review some real world applications\nof learning analytics\n\nUnit 1 Preparations\n●\nBefore you leave today\n○\nTake the Welcome Survey\n○\nWe'll facilitate group formation during next class\nbased on your feedback\n●\nPreparing for the next class:\n○\nIntroductory readings about learning analytics\n○\nLearning or reviewing the basics of data analysis with\nR or Python. Support will be provided!\n○\nFamiliarize yourself with the HarvardX-MITx Person-\nCourse Academic Year 2013 De-Identified dataset\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nCMS.594/CMS.894 Education Technology Studio\nSpring 2019\nFor more information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "CMS.594 Education Technology Studio, Session 10: Mini Project 3 Demo & Final Project Review",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/cms-594-education-technology-studio-spring-2019/6960db204c2513b180a0c5ad067cc552_MITCMS_594S19_ses10.pdf",
      "content": "CMS.594/894- Education\nTechnology Studio\nSpring 2019\nMini-Project 3 demo &\nfinal project preview\n\nFinal Notes on UDL\n\nA challenge in Educational Research\nStudents that could most\nbenefit from help are\nfrequently the least likely\nto seek it\n\nGoing beyond performance data\nthe process of learning\nSee handout\n\nUDL Mini-Project\nDEMOs!!!\n\noverview of Unit 4\n& final project\n\nCourse map: Where have we been?\nUnit 1, Learning Analytics\nCollecting, analyzing,\nreporting data about\nUnit 2, Practice Spaces\nUnit 3, Accessibility\nDesigning for\nvariability in the way\nwe learn from the start\nby considering the how,\nwhat, and why of\nlearning\n(c) source unknown. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\nlearners and their\nenvironments to optimize\nteachers practice and\nCreating learning\nexperiences that help\nlearning and the\nreflect on key teaching\nlearning environment\ndecisions\n\n...And now Where are we Going?\nUnit 4, Final Project: Improving your innovation by...\nLearning more about your\nuser's needs\nEffectively\ncommunicating your\ninnovation and its value\nto users and\nstakeholders\nUnderstanding the\neducation ecosystem in\nwhich you are designing\nin order to maximize\nyour impact\n\nHOW WILL WE GET THERE?\nWeek 0:\nReflect\n★\nReview your final\nreflections from each\nmini-project\n★\nComplete the final\nproject survey\nIdentify a problem\n★\nIdentify a problem of\npractice\n★\nResearch existing\nsolutions\n★\nPropose or enhance\nyour solution\n★\nDraft an interview\nprotocol to learn more\nabout your user\nWeek 1:\nIdeation & prototyping\n★\nCome ready to discuss\nfindings from your user\ninterview\n★\nCome with prototype\nand playtest protocol\n★\nConduct playtest\nWeek 2:\nPlaytest\n★\nCollect data during\nclass playtest to\nimprove final project\n★\nPractice presentations\nWeek 3\nFinal Public Presentation*\n★\nDue: (1) final protoypte,\n(2) presentation slide\ndeck, (3) written\nproduct\n★\nInvite 2 guests\nWeek 4:\nR\n★\nDress up!\n\nFinal project expectations (also see syllabus)\n●\nGoal: to prototype, test, and refine an innovative edtech\nsolution to a problem of practice in education\n●\nThree possible paths (working individually or in pairs):\n○\nOption 1: identify an extension of one of your mini-projects--must\nreflect a substantial new contribution to your project\n○\nOption 2: identify a project of your own choosing, in consultation with\nthe instructor(s)\n○\nOption 3: remix a classmate's project-- must ask their permission and\nalso must reflect a substantial new contribution to the project\n●\nRelated requirements\n○\nComplete a user/stakeholder interview\n○\nConduct a playtest\n○\nPresent at Teaching Systems Lab public presentations\n○\nTurn in prototype, slide deck, and a written product\n\nFinal project- Flow of key activities\n1.\nReview reflections on each\nmini-project\n2.\nDecide on project\n3.\nCreate interview protocol\n4.\nConduct stakeholder/user interview\n5.\nIncorporate feedback\n6.\nConduct playtest\n7.\nIncorporate feedback\n8.\nFinal prototype, presentation, and\nwritten product (select one of\nmultiple options)\n9.\nCelebrate!\n\nRevisiting course requirements\n●\n20% on class participation\n○\ndesign journal\n○\ntechnical preparation activities\n○\nactive participation during in-class activities\n(e.g. \"exit tickets\")\n●\n50% on the three mini projects combined\n○\nMini-Project 1\n○\nMini-Project 2\n○\nMini-Project 3\n●\n30% on the final project\n●\nWritten Product & Prototype Rubric (in\nsyllabus appendix)\n\nPreparing for the\nnext class\n\nDue before next week's class\n●\nBefore you leave today\n○\nPlease complete the exit ticket about today's class\n●\nComplete this week\n○\nTake the Final Project Survey\n○\nDesign journal reflection preview (next slide)\n○\nStart thinking about a stakeholder or user who you might\nreach out to for an interview\n○\nSyllabus readings\n●\nIf you are stuck, do not wait until the last minute...\n○\nCome to office hours\n\nhomework: selecting a final project\nAfter reviewing your design journal \"reflection\" slide at\nthe end of each mini-project: (1) Which proposed\nimprovements do you feel more excited about? (2) Which\nimprovements seem most promising to you? (3) Of the the\npotential extensions you have identified, what challenges do\nyou anticipate in implementing your own recommendations? You\nmay also conclude that none of your mini-projects are\nsuitable for further exploration and propose a new\ninnovation for a user/partner of your choosing.\nYou may include text plus images, sketches, code, or other\nmedia in your response. Be prepared to share your responses\nin class.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nCMS.594/CMS.894 Education Technology Studio\nSpring 2019\nFor more information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "CMS.594 Education Technology Studio, Session 11: Problem Finding",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/cms-594-education-technology-studio-spring-2019/e75265ad66eba79fea8fd6eb0b007b75_MITCMS_594S19_ses11.pdf",
      "content": "Technology Studio\nProblem finding\nCMS.594/894- Education\nTechnology Studio\nSpring 2019\n\nUnit 4: now Where are we Going?\nUnit 4, Final Project: Improving your innovation by...\nLearning more about your\nuser's needs\nUnderstanding the\neducation ecosystem in\nwhich you are designing\nin order to maximize\nEffectively\ncommunicating your\ninnovation and its value\nto users and\nstakeholders\nEffectively\ncommunicati\nour\nUndersta\nar\nea\near\ny\nyour impact\n\nHOW WILL WE GET THERE?\nWeek 0:\nReflect\n★\nReview your final\nreflections from each\nmini-project\n★\nComplete the final\nproject survey\nIdentify a problem\n★\nIdentify a problem of\npractice\n★\nResearch existing\nsolutions\n★\nPropose or enhance\nWeek 1:\nIdeation & prototyping\n★\nCome ready to discuss\nfindings from your user\ninterview\n★\nCome with prototype\nand playtest protocol\nWeek 2:\nPlaytest\n★\nCollect data during\nclass playtest to\nimprove final project\n★\nPractice presentations\nWeek 3\nde\nIde\nyour solution\n★\nConduct playtest\n★\nDraft an interview\nprotocol to learn more\nabout your user\nFinal Public Presentation*\n★\nDue: (1) final protoypte,\n(2) presentation slide\ndeck, (3) written\nproduct\n★\nInvite 2 guests\nWeek 4:\n★\nDress up!\n\nOverview of\ntoday's class\n\nToday's class\n●\nPart 1: Discuss this week's readings to\nlearn more about U.S. k-12 education\necosystem to design for impact\n●\nPart 2: Identify a problem of practice\nfor your final project & share\n●\nPart 3: Draft empathy interview\nprotocols\n\nPart 1:\nthe k-12 us\neducation\necosystem\n\nWhat can we learn from two us ed tech policy reports?\n●\nHow can we ensure we are\ndesigning for impact?\n●\nHow can we ensure we are\nUnderstanding the\ninnovating and not just\neducation ecosystem in\ndigitizing?\nwhich you are designing\n●\nHow can we ensure that our\nin order to maximize\nproposed solutions don't\nyour impact\nincrease the \"digital divide\"\n(e.g. Reich & Ito, 2017)?\n7 Sources: USED (2015), USED (2017)\n\nthe US national education technology plan\n●\nPresents a vision for technology-powered student\nlearning\n●\nDescribes how technology helps personalize student\nlearning\n●\nHow to embed technology-based assessments into learning\n●\nNew role for teachers as they act on insights from data\n●\nEnvisions learning infrastructure that provides access\nto people and resources at all levels of ed system\n●\nIncrease efficiencies in school system (e.g. reduced\ntime on teacher administrative tasks)\nSources: USED (2015), USED (2017)\n\nWarm up-\npromises & perils\nof ed Tech\n\nTurn to your\nneighbor\nBased this week's readings,\nwhat do you see as the\npromise and perils of ed\ntech in the k-16 education\necosystem? Jot it down on\npaper or in a blank slide in\nyour design journal. Be\nready to share with the\ngroup.\nInnovate, don't digitize!\nWhat does technology make\npossible that would not\nhave been possible before?\nSource: USED (2015)\n\ned tech\nopportunities that\nmaximize impact\n\nPolicy considerations affecting design & logistics\n●\nDo teachers have the training to use your app\nin the right way?\n●\nHow do privacy and accessibility laws intersect\nwith the features you want to include?\n●\nWho makes the decision to purchase your tool,\nand how long does purchasing take?\n●\nCan your app be equally effective at school and\nhome?\n●\nWhat features are most important to parents and\ncaregivers?\nSource: USED (2015)\n\nProblem finding: choosing the best opportunity\n●\nOpportunity 1: Improving Mastery of\nAcademic Skills\n○\nIncreasing opportunities to practice core skills\nin authentic environments\n○\nHelp students take control of their learning\n○\nE.g. Khan Academy, Dreambox\n●\nOpportunity 2: Lifelong Learning Skills\n○\nPaper on growth mindset research\n○\n\"Growth Mindset\" app aims to strengthen students'\nacademic and social-emotional success\n○\nSelf-regulation, behavior management (e.g. Class\nDojo)\n○\nMuch to learn from game designers!\nSource: USED (2015)\n\nProblem finding (continued)\n●\nOpportunity 3: Increasing Family Engagement\nSource: USED (2015)\n○\nImportance of involving parents and caregivers of all\nbackgrounds in learning process\n○\n○\nPBS Parent Play & Learn, ZerotoThree play\nUS Dept. of Ed. family engagement resources\n○\nLots of opportunities to improve access and engagement\nthrough technology!\n●\nOpportunity 4: Planning for Future Education\nOpportunities\n○\nNavigating college application, financial aid, completion\n○\nTechnology can help students and families make informed\ndecisions, apply, and complete postsecondary education\n○\nLots of room for innovation! Financial aid navigators, course\nplanners, remote college counseling, college-to-career maps,\ncollege course catalogs, look familiar?\n\nProblem finding (continued 2)\n●\nOpportunity 5: Designing Effective Assessments\nSource: USED (2015)\n○\nTeachers must know what students know and what they are learning\n○\nNeed for efficiencies- teachers spend hours reviewing and grading!\n○\nWell-designed formative and summative assessments can provide\njust-in-time feedback, personalize learning, and adjust instruction\n○\nInnovation opportunities include tools for teachers to share and\ncreate formative assessments, automate grading, streamline feedback,\nmore sophisticated test questions (simulations, heat maps, ranking)\n●\nOpportunity 6: Improving Educator Professional Dev't (PD)\n○\nJust-in-time professional, personalized learning also benefits\neducators through teaching tips, access to experts\n○\nPD should be job-embedded, differentiated, on-demand access, align\nwith adult learning standards (e.g. growth mindset)\n\nProblem finding (continued 3)\n●\nOpportunity 7: Improving Educator Productivity\n○\nReducing educator administrative burden (e.g. preparing lessons,\ngrading, finding teaching materials, grading, reporting,\ncommunicating with parents)\n○\nAreas for innovation include tools that help teachers personalize\nstudent learning, facilitating feedback to students/parents, tools to\ncreate, share, and adapt lesson plans and resources with other\neducators, make sense of data, track student progress (one example is\nthe Ellevation software)\n○\nNeed for custom productivity tools found in other professions\nSource: USED (2015)\n\nProblem finding (continued 4)\n●\nOpportunity 8: Making Learning Accessible to All Students\n○\nAddressing students' differing educational needs so that all learners\ncan participate in learning activities\n■\nFunctionality (e.g. font size, text read aloud)\n■\nAddress specific learning needs (e.g. digital word board)\n■\nPersonalize learning to adapt to variety of learner needs\n○\nResources: CAST website, National Center for Learning Disabilities\n○\nGenerally content should be communicated in multiple forms\n○\nFeatures that customize delivery must not clutter or confuse\n○\nImportant note: Schools will not be able to use your innovation if it\nis not accessible to students with disabilities\n■\nSee guidance on two civil rights laws, Section 504 of the\nRehabilitation Act and the Americans with Disabilities Act\nSource: USED (2015)\n\nProblem finding (continued 5)\n●\n●\nOpportunity 9: Closing Opportunity Gaps\n○\nUnequal access to resources or opportunities (e.g. rural students,\nless wealthy communities)\n○\nTechnology gaps\n○\nAll students have a right to an equitable education (see US Dept. of\nEducation Office of Civil Rights Dear Colleague Letter)\n○\nInnovation opportunities: tools that make reams of open education\nresources (OER) easier to sift through, teachers' access to expertise\n○\nBe mindful of technical accessibility/connectivity\nOpportunity 10: Closing Achievement Gaps\n○\nRelatedly, achievement gaps persist in the U.S. on standardized\ntests, Advanced Placement (AP) course enrollment, completion, testing\n(e.g. females and minorities are underrepresented in AP Computer\nScience)\n\nProblem finding wrap up\n●\nFocus on problems that have a significant impact\non your intended user\n●\nWhich opportunities identified in the Ed Tech\nDeveloper's Guide does your proposed project\naddress?\n●\nAfter reading the Ed Tech Developer's Guide and\nthe National Education Technology Plan, what\nquestions do you have for policy experts and\ngovernment officials?\n\nPart 2:\nIdentifying your\nproblem of practice\n\nBrainstorming features of your final project\n1.\nProblem of practice: state the educational problem of practice where your\ninnovation provides a potential solution\n2.\nExisting solution: how have others addressed this problem?\n3.\nProposed solution: describe how the proposed extension to your select\nmini-project can help with the problem of practice in a way that addresses\nlimitations of or adds value to existing solutions.\n4.\nProposed learning objective: what specific objective should your proposed\nsolution accomplish for the user?\n5.\nPotential user: brainstorm what a suitable context would be for testing\nyour innovation. Who would be the end user? You may suggest specific\npartners or contexts if it helps conceptualize your innovation.\n6.\nJustification for use of technology: Why is your medium the optimal one?\n\nAdditional resources\n●\nIdentifying existing solutions\n○\nApp Review Websites: EdTech Index (by EdSurge), Graphite (Common\nSense Media)\n○\nSee how crowded certain spaces are (e.g. Math, ELA)\n●\nEvaluating what works\n○\n●\n...and what might not work\n○\nNew York Times article on web-based personalized learning, Summit\nInstitute of Education Sciences What Works Clearinghouse\n\nBreak - please return in\n10 minutes\n\nPart 3:\nDraft an empathy\ninterview protocol\n\nIdentifying a\nuser/stakeholder\nto interview\nHow can you identify\ninterviewees that will help\nyou design a solution for\neveryone?\n\"Your solution must\nmanifest your deep\nunderstanding of\neducators' daily struggles\nand small victories. That\nunderstanding is the\nbeginning of empathy,\nwithout which you cannot\nsucceed.\"\n-Stevn Hodas, former\nExecutive Director of\nInnovatate NYC Schools\n\nworked example: School report Card design challenge\n●\nProblem of practice: How can states design\nfamily-friendly approaches to school \"report cards\" that\nmake school data more transparent and accessible?\n●\nExisting solutions: This information is a key resource to\nhelping parents and communities understand how their\nschool is performing, evaluate what is working and what\nneeds to change, and drive changes that help kids\nsucceed. Yet, few current report cards are not accessible\nto the public. What do you think about Massachusetts'\nschool report cards?\n●\nWhich award-winning report card is your favorite design?\n\nWho are the stakeholders? Who are the users?\n1.\nWho are the experts you might interview?\n2.\nWho are the extremes and mainstreams?\n3.\nWhat questions might you ask them?\nWho is\nmissing?\n\nWork time\nDevelop an empathy user/\nstakeholder interview\nprotocol due Friday @5pm\nInterview must be conducted\nby start of class\n\"...we've since realized a\nproblem with personas.\nThey are inherently an\namalgamation, an average\nof attributes that we\nimagine our average\ncustomer has. And there's\nno such thing as the\naverage customer.\" -\nMicrosoft Design\n\nHomework\nAssignment due by Friday: Stakeholder interview protocol:\nDesign an interview protocol based on the examples provided\nin class to conduct with (1) an expert in the field who\ndirectly understands the needs of your end user; or (2)\ninterview extreme users and those in the middle or\n\"mainstream\" of your target audience.\nWhere to submit: Upload to the course website.\n\nPreparing for the\nnext class\n\nDue before next week's class\n1.\nConduct your stakeholder/user interview (take field notes\nor record it - with permission from interviewee)\n2.\nReport on following elements in your design journal and\ncome ready to share\na.\nInterviewee\nb.\nKey takeaways\nc.\nDesign refinements\nd.\nPotential roadblocks\n\nFinal project Resources\n1.\nInterviewing tools\na.\nVoice transcription: https://otter.ai/login\nb.\nIdeo resources: http://www.designkit.org/methods\n2.\nExamples of writing in different genres (coming soon)\na.\nStakeholder/funder pitch\nb.\nConference proposal\nc.\nPolicy brief\nd.\nEdTech news article\ne.\nInfographic\n\nwrap up\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nCMS.594/CMS.894 Education Technology Studio\nSpring 2019\nFor more information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "CMS.594 Education Technology Studio, Session 12: Ideation and Prototyping",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/cms-594-education-technology-studio-spring-2019/f58c2d2fd4226576afb008dc91f9b419_MITCMS_594S19_ses12.pdf",
      "content": "Technology Studio\nIdeation and prototyping\nCMS.594/894- Education\nTechnology Studio\nSpring 2019\n\nEffectively\ncommunicating your\ninnovation and its value\nto users and\nUnderstanding the\nUnit 4: now Where are we Going?\nUnit 4, Final Project: Improving your innovation by...\nLearning more about your\nuser's needs\near\near\ny\nstakeholders\neducation ecosystem in\nwhich you are designing\nin order to maximize\nyour impact\n\nHOW WILL WE GET THERE?\nWeek 0:\nReflect\n★\nReview your final\nreflections from each\nmini-project\n★\nComplete the final\nproject survey\nIdentify a problem\n★\nIdentify a problem of\npractice\n★\nResearch existing\nsolutions\n★\nPropose or enhance\nWeek 1:\nIdeation & prototyping\n★\nCome ready to discuss\nfindings from your user\ninterview\n★\nCome with prototype\nand playtest protocol\nWeek 2:\nPlaytest\n★\nCollect data during\nclass playtest to\nimprove final project\n★\nPractice presentations\nWeek 3\n★\nat\nIdeat\n★\nyour solution\n★\nConduct playtest\n★\nDraft an interview\nprotocol to learn more\nabout your user\nFinal Public Presentation*\n★\nDue: (1) final prototype,\n(2) presentation slide\ndeck, (3) written\nproduct\n★\nInvite 2 guests\nWeek 4:\n★\nDress up!\n\nOverview of\ntoday's class\n\nToday's class\n●\nPart 1: Share key findings from\nstakeholder interviews\n●\nPart 2: Self-evaluate progress on final\nproject through design journal & share\n●\nPart 3: Discuss role of edtech in the\n●\nU.S. k-12 education ecosystem with\nPart 4: Prepare for next week's final\nproject playtest\n●\nPart 5: Final project housekeeping\n\nPart 1:\nstakeholder/user\ninterview\nfindings\n\nShare out - stakeholder/user interview findings\n●\nKey takeaways: What are some key takeaways from\nyour empathy stakeholder interview? What surprised\nyou?\n●\nDesign refinements: How will you integrate feedback\nfrom your interview to make refinements to your\nprototype? Propose 2-3 ideas for changes that you\nwill make based on your interviewee's responses.\n●\nPotential roadblocks: What challenges do you\nanticipate in implementing these refinements and\nwhat resources might help you address them?\n\nPart 2:\nSelf-evaluate\nprogress on final\nproject\n\nDesign sprint:\nDraft your final\npresentation\nMake a copy of the final\nproject presentation\ntemplate and complete as\nmuch as you can now. Be\nready to share out.\nFormat: 10 minutes\npresentation + 5 minutes\naudience questions/comments\n●\nCustomize but include\n●\n●\nall headers\nUse effective visuals\nBrief demos are helpful\n●\nPractice w/ a critical\nfriend and a timer!\n\nAdditional resources\n●\nEdTech resources from your peers\n●\nIdentifying existing solutions\n○\nApp Review Websites: EdTech Index (by EdSurge), Graphite (Common\nSense Media)\n○\nSee how crowded certain spaces are (e.g. Math, ELA)\n●\nEvaluating what works\n○\nInstitute of Education Sciences What Works Clearinghouse\n●\n...and what might not work\n○\nNew York Times article on web-based personalized learning, Summit\n\nShare out- Final presentation sprint\n●\nWhat elements feel solid?\n●\nWhat elements are missing?\n●\nWhat supports do you need to meet your goals and feel\nready for your final presentation?\n\nPart 3:\nRole of edtech in\nu.S. k-12\necosystem\n\nBreak - please return in\n10 minutes\n\nPart 4:\nPreparing to\nplaytest your\nprototype\n(Next week!)\n\nSample Playtest\nPurpose: to collect data\non your final project\nprotocols\nprototype to improve your\nPlease use this template to\nproject.\ncreate a flow for how you\nwill playtest your\nprototype.\n\nPart 5:\nFinal project\nhousekeeping\n\nFinal project Resources\n●\nReview the directions in the syllabus- important details!\nHave you decided which written product you will complete?\n1.\nStakeholder/funder pitch\n2.\nConference proposal\n3.\nPolicy brief\n4.\nEdTech news article\n5.\nInfographic\n\nPreparing for the\nnext class\n\nHomework- Due at start of class next week,\n●\nIf you are completing your interview, complete the design\njournal interview report out\n●\nAdd the link to your prototype\n●\nAdd the link to your playtest protocol\nWhere to submit: Design Journal\nHW=Homework :-)\n\nwrap up\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nCMS.594/CMS.894 Education Technology Studio\nSpring 2019\nFor more information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "CMS.594 Education Technology Studio, Session 13: Playtesting",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/cms-594-education-technology-studio-spring-2019/87414b74817f16360403be2a7c7218ef_MITCMS_594S19_ses13.pdf",
      "content": "Technology Studio\nplaytesting\nCMS.594/894- Education\nTechnology Studio\nSpring 2019\n\nUnit 4: now Where are we Going?\nUnit 4, Final Project: Improving your innovation by...\nLearning more about your\nuser's needs\nUnderstanding the\neducation ecosystem in\nwhich you are designing\nin order to maximize\nyour impact\nEffectively\ncommunicating your\ninnovation and its value\nto users and\nstakeholders\n\nHOW WILL WE GET THERE?\nWeek 0:\nReflect\n★\nReview your final\nreflections from each\nmini-project\n★\nComplete the final\nproject survey\nIdentify a problem\n★\nIdentify a problem of\npractice\n★\nResearch existing\nsolutions\n★\nPropose or enhance\nyour solution\n★\nDraft an interview\nWeek 1:\nIdeation & prototyping\n★\nCome ready to discuss\nfindings from your user\ninterview\n★\nCome with prototype\nand playtest protocol\n★\nConduct playtest\nWeek 2:\nPlaytest\n★\nCollect data during\nclass playtest to\nimprove final project\n★\nPractice presentations\nWeek 3\nP\nprotocol to learn more\nabout your user\nFinal Public Presentation*\n★\nDue: (1) final prototype,\n(2) presentation slide\ndeck, (3) written\nproduct\n★\nInvite 2 guests\nWeek 4:\n★\nDress up!\n\nOverview of\ntoday's class\n\nToday's class\n●\nPart 1: Playtest your prototype\n●\nPart 2: Learn about the role of lab\nplaytesting in product design with guest\n(MIT M.Eng. student)\n●\nPart 3: Final project logistics\n●\nPart 4: End-of-course housekeeping\n\nPart 1:\nPlaytest your\nprototype\n\nPlaytest session 1\nFormat:\n20 minutes then swap\nDon't forget:\nYour playtest protocol\nYou will need to report\nhow you used data from\nthe playtest to improve\nyour prototype\n\nPlaytest session 2\nFormat:\n20 minutes + 20 minutes\n\nBreak - please return in\n10 minutes\n\nPart 2:\nrole of lab\nplaytesting in\nproduct design\n\nPart 3:\nFinal project\nlogistics\n\nPreparing your final presentation (see syllabus rubrics)\n●\n●\n●\n●\n●\n●\n●\n●\nCustomize template but include all headers\nPrioritize visuals over text\nInclude a brief demo/screen shots when possible\nPractice with a critical friend and a timer!\nRemember: 10 min. pres. + 5 min. audience questions\nBudget your time wisely\nWrite out a few key points for each slide in the notes\nPrepare a null response, \"That's a really good question.\nI [wish I knew the answer myself, will have to get back\nto you, would need some more time to think about it...]\"\nProofread (spell check, references, sources documented,\nAPA format, make sure links are working/shareable)\n\nFinal project Resources\n●\nFinal written product: Examples of writing in different\ngenres compiled\n●\nReview the directions in the syllabus- important details!\nHave you decided which written product you will complete?\n1.\nStakeholder/funder pitch\n2.\nConference proposal\n3.\nPolicy brief\n4.\nEdTech news article\n5.\nInfographic\n\nPart 4:\nEnd-of-course\nhousekeeping\n\nEnd-of-course evaluation & debrief\n●\nA brief debrief: Questions for the class\n○\nGeneral\n■\nHow well did the ordering of Units work?\n■\nHow well did you think the units were integrated across the\ncourse?\n■\nWhat technology supports would have been helpful?\n■\nInterested in advanced version of course?\n○\nFinal project:\n■\nHow prepared did you feel for the final project? What would have\nmade you feel more prepared?\n■\nWould you have liked to have more explicit focus on presentation/\nreporting in the course (e.g. more practice presentations, more\nemphasis in grading)?\n\nwrap up\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nCMS.594/CMS.894 Education Technology Studio\nSpring 2019\nFor more information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "CMS.594 Education Technology Studio, Session 2: Introduction to Learning Analytics",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/cms-594-education-technology-studio-spring-2019/decbfdfa9e692515eb944b71f50aa1fb_MITCMS_594S19_ses2.pdf",
      "content": "CMS.594/894- Education\nTechnology Studio\nSpring 2019\nIntroduction to Learning Analytics\nand Educational Data Mining\n\nClass outline\n●\nPart 1\n○\nGroup brainstorm activity\n○\nShort lecture on learning analytics (LA) research\n○\nMini-project #1 partner/group formation\n●\nPart 2\n○\nMOOC and dataset review of the dataset\n○\nLearning analytics mini-project brainstorm activity\n○\nShare out to the class\n○\nPlanning for next class\n\nBrainstorm\nActivity\n\nDue Today!\n●\nYou had four readings to complete today:\n○\nSiemens & Long (2011): General paper about the field of LA\n○\nFerguson (2012): General paper about the field of LA\n○\nChatti et al. (2012): Provides a reference model for LA based on four\ndimensions: what, who, why and how\n○\nVeeramachaneni et al. (2014): a technical paper that explains the\nfeature engineering process in MOOCs\n●\nActivity: Form five groups...\n\nactivity: Brainstorming around these questions\nNo looking at the papers! Use your critical thinking skills\nto answer the following questions:\n●\nDefine your own view of learning analytics, point out\nyour keywords\n●\nLA has grown a lot in the last decade. What have been the\nenablers and drivers?\n●\nWhat are the steps in the LA process? List examples of\neach step.\n●\nWhat value can LA bring to education?\n●\nWhat are the main challenges of LA?\n\nLearning\nAnalytics overview\n\nRelated Fields or Concepts\n●\nAcademic Analytics: More focused on the institutional\nside, e.g. use of resources or admission process\n●\nAction Research: Focused on teaching practices and\nquality, e.g. qualitative methods, teachers and students\n●\nEducational Data Mining: Developing methods, different\ntypes of ed data e.g. new Item Response Theory (IRT)\nalgorithm or method adapted feedback\n●\nRecommender Systems: Based on previous data, what items\ncan we recommend? Content-based or Collaborative\nFiltering (CF)\n●\nPersonalized Adaptive Learning: Adaptivity (course\nmaterials adapt automatically) vs. Adaptability (learners\npersonalize those materials)\nSource: Chatti et al. (2012)\n\nThe Broad view of Learning Analytics\n...collection, analysis and reporting of data about learners\nand their contexts, for purposes of understanding and\noptimising learning and the environments in which it occurs...\nSource: First Learning Analytics\nand Knowledge Conference\nLA builds on the aforementioned areas to become a generic\nand all-encompassing term\n\nThe Learning Analytics Process\n\nReference Model of LA (Chatti et al., 2012, p.7)\nWe apply this reference\nmodel in the following 4\nslides\n(c) Chatti et al. All rights reserved. This content is excluded from our\nCreative Commons license. For more information,\nsee https://ocw.mit.edu/help/faq-fair-use/\n\nData and Environments (What?)\nWhat kinds of data and environments are used in the analysis?\n●\nLearning Management Systems (Stellar,Sakai,Moodle, WebCT)\n●\nPersonal Learning Environments\n●\nIntelligent Tutoring Systems\n●\nMassive Open Online Courses (edX, Coursera, FutureLearn...)\n●\nGames for Learning\n●\nSimulation environments\n●\nIn-classroom settings using multimodal data e.g. face to\nface collaboration using wearables, camera and voice\n●\n... and many more happening in informal settings!\nStackOverFlow, Pinterest, YouTube\nSource: Chatti et al. (2012)\n\nStakeholders (Who?)\nWho is involved?\n●\nStudents (personal data, help in learning, evaluation)\n●\nTeachers (improve teaching, not feeling controlled, new\nliteracy and competencies)\n●\nEducational institutions and administrators (support\ndecision making, students at risk)\n●\nPrivate educational companies (selling their solutions)\n●\nGovernmental institutions (funding, education policy)\n●\nEducation technologists (implementation of solutions)\n●\nLearning Analytics researchers (transfer research to\npractice challenge)\nSource: Chatti et al. (2012)\n\nObjectives (Why?)\nMultiple objectives depending on the point of view of\nstakeholders (useful ideas or in-depth references):\n●\nMonitoring and analysis: ANALYSE visualization dashboard\n●\nPrediction and intervention: Self-regulation intervention\n●\nAssessment and feedback: Immediate and adapted feedback\n●\nAdaptation: Exercise difficulty or gaming the system\n●\nPersonalization and recommendation: Courses or threads\n●\nIn-class support: Multimodal approaches in the classroom\nand real-world examples in China\nSource: Chatti et al. (2012)\n\nMethods (How?)\n(\n)\nWhat techniques are being applied to meet the objectives?\n(useful ideas or in-depth references):\n●\nExploratory statistics: Simple descriptive metrics, e.g.\nmean, mode, median, variance, charts\n●\nInformation visualization: Dashboards\n●\nData mining techniques:\n○\nClassification: Dropout prediction in MOOCs\n○\nRegression: Predicting learning gains\n○\nClustering: Profiles of engagement in gamified environments\n○\nHeuristics algorithms: Cheating@Scale in MOOCs\n●\nSocial network analysis: Modeling based on graphs, e.g.\ninteractions and participants' roles in MOOCs\nSource: Chatti et al. (2012)\n\nGroup formation\n\nBreak - please return in\n10 minutes\n\nMOOCs and\nDataset review\n\nMassive Open Online Courses (MOOCs)\n●\nThe term MOOC was coined in 2008 after CCK08 (cMOOC)\n●\nIn 2012 Coursera, edX and Udacity emerged (xMOOC)\n○\nExciting for practitioners and for human development\n●\nPlenty of data to study the worldwide classroom\n○\n...but research did not accomplish a huge impact\n●\nA number of regional initiatives emerged (e.g.\nEdraak, MiriadaX, XuentangX, FUN...)\n○\nMany of these use Open edX software\n●\nIn 2013 Udacity announced first MOOC-based MSc\n○\nSeeking financial sustainability\n○\nNumerous Small Private Online Courses (SPOCs)\n\nHarvardX-MITx Dataset items\n●\nThe dataset has three items\n○\nCreating the dataset and anonymization process:\n■\nEdX and ToS, raw data, edx2bigquery processing,\nanonymization (careful with quasi-identifiers, e.g.\nNetflix challenge)\n○\nA codebook (i.e. description the contents,\nstructure, and layout of a dataset)\n○\nA comma-delimited file with the person-course data\nwhere each row represents the registration of an\naccount to a course\n●\nWhy is this dataset important?\n\nACTIVITY:\nPLAY TIME!\n\nmini-project #1 brainstorm\n●\nDo you have a clear idea of what to do for your\nmini-project #1? If so, go for it! If not:\n○\nSummary of variables, draw some charts, do some\nreadings, ask instructors...\n●\nDesign journal activity (see slide 4)\n○\nIdea/problem\n○\nDesign process\n○\nTechnical implementation\n●\nEach group will share their slide with the class.\nYou can work on one slide but copy to all journals\n●\nI will share some ideas after the group shares out\n\nMore ideas - of varying technical complexity\n1.\nLow complexity: Reports with summary statistics/charts\n○\nMixed methods analysis on the influence of course in demographics and\nparticipation funnel\n○\nMOOC summary report for high level stakeholders i.e. donors or\ninstitutional leaders e.g. see these reports\n2.\nMedium complexity: Viz dashboards or data mining\n○\nViz dashboards: Tableau Public or R Shiny dashboard for Administrators\nor Instructors? E.g. see this post\n○\nClassification or regression models? E.g. see this study\n○\nClustering of different profiles of students or courses\n3.\nHigh complexity: Advanced analysis or combination\n○\nCombining visualization dashboards with data mining\n○\nAnomaly detection to find outliers, e.g. maybe to detect academic\ndishonesty or data processing issues\n○\nNetwork analysis of courses/students\n\nPreparing for the\nnext class\n\nDue next week: first mini-project #1 analysis\nDue next week first mini project #1 analysis\n●\nHomework\n○\nAdditional reading on LA visualizations\n○\nGain deeper knowledge of your selected method\n○\nDesign journal assignment: Your first LA analysis or\nvisualization\n○\nNeed help? Let me know!\n●\nNext week's class\n○\nShare out your homework, receive peer/instructor\nfeedback and make improvements\n○\nIn-class work on mini-projects with instructors' help\nto align objectives and solve tech issues\n○\nThe work during this session will be key to your mini-\nproject #1!\n\nBefore you leave class today...\nPlease complete an exit ticket\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nCMS.594/CMS.894 Education Technology Studio\nSpring 2019\nFor more information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "CMS.594 Education Technology Studio, Session 3: Playtesting",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/cms-594-education-technology-studio-spring-2019/f110f5b57ba8ffce90a0685c30fde7b9_MITCMS_594S19_ses3.pdf",
      "content": "Technology Studio\nPlaytesting your analysis and data\nvisualizations\nCMS.594/894- Education\nTechnology Studio\nSpring 2019\n\nClass outline\n●\nPart 1\n○\nSharing your homework with the class and feedback\n○\nWork on mini-project\n●\nPart 2\n○\nKeep working on mini-project\n○\nWhat did you improve during today's work?\n○\nPlanning for mini-project presentation and submission\n\nShare out\nhomework with\nclass\n\nDue Today!\n●\nYou had to complete your first analysis or data\nvisualizations for today responding to these questions:\n○\nWhat is your objective?\n○\nFill in with some of the analysis that you completed\n○\nWhat did you learn based on this analysis?\n●\nLet's share out the results of each group\n○\nBe generous and active, feedback to your peers is valuable\n○\nHow can you peers improve their objectives, design or\nanalysis?\n○\nHow can they expand their current work for the final\nmini-project?\n\nBreak - please return in\n10 minutes\n\nWorking on\nMini-projects\n\nGroup work: mini-project #1\nDirections:\n●\nUsing the feedback received by peers and instructors\nduring today's class, work on implementing improvements\nto your project\n●\nInstructors are available to answer questions\n●\nYou will have almost the rest of the class to work on the\nproject\n●\nAt the end of class, you will be expected to share one\nthing that you were able to improve in your project based\non the feedback you received and explain how you made\nthose improvements\n\nShare out: What did you improve and how?\n●\nBased on the feedback that you have received today,\nexplain one thing that you were able to improve and\nexplain how you made those improvements\n\nExtra Resources:\n●\n●\n●\n●\nColorBrewer Palette generator\nHuman Development Index by Country\nCombat Imbalance Class Machine Learning\nInformation Visualization\n○\nFundamentals of Data Visualization\n●\nFinding similar students - clustering\n○\nKmeans in R or Python\n\nPreparing for the\nnext class\n\nDue next week: first mini-project #1\n●\nFull instructions are in the syllabus\n●\nDue before the next class: Report (between 2-5 pages)Upload to\ncourse website\nB\nIntroduction\nC\nLearning objective\nD\nUser and context\nE\nDesign and method\nF\nResults of your prototype\nG\nReproducing your work\n●\nPresentation (10 + 5 of Q/A max), similar to report in format\n●\nDesign journal\nB\nAdd slide with the link to the presentation\nC\nWhat would you do with 4 more weeks?\n\nNext Class and exit ticket\nNext Class and exit ticket\n●\nNext week's class\n○\nPresentations of mini-projects\n○\nIf we have some extra time we will review some\nreal-world applications of learning analytics\n○\nIntroduction of next unit: Practice Spaces\n●\nPlease complete an exit ticket\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nCMS.594/CMS.894 Education Technology Studio\nSpring 2019\nFor more information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "CMS.594 Education Technology Studio, Session 4: Demonstrations of Your Data-Driven Work",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/cms-594-education-technology-studio-spring-2019/4d7432cc3920243fbabd0cc3c8b2b635_MITCMS_594S19_ses4.pdf",
      "content": "Technology Studio\nFinal demonstration of your\ndata-driven work\nCMS.594/894- Education\nTechnology Studio\nSpring 2019\n\nClass outline\n●\nPart 1\n○\nPresentations of learning analytics mini-projects\n●\nPart 2\n○\nContinue presentations\n○\nReal-world learning analytics examples\n○\nPreparing for next unit on Practice Spaces\n\nLearning\nAnalytics\nMini-project\npresentations\n\nPresentation format\n●\nFormat of 10 minutes presentation + 5 of questions\n(we will be strict with the timing)\n○\nWill show a sign after 5 and 9 minutes\n●\nPeer feedback will weight on participation grade (min\nof 2 participations per student) e.g:\n○\nDoubts: I did not understand completely how you applied\nthat analysis and why\n○\nFeedback for improvements: Applying the same colors for\neach variable across charts would improve readability\n○\nIssues: I think the method that you applied was actually\nnot correct because...\n\nBreak - please return in\n10 minutes\n\nLearning\nAnalytics in\nPractice\n\nSome Real World Examples of Learning Analytics\n●\nKhan Academy: Great learning analytics dashboard\n(registration is required)!\n●\nPresentation Trainer: Improving your presentation skills\nwith immediate feedback\n●\nWOW ROOM 360: Support for virtual classroom environments\n●\nEmotions & Classroom: Using emotions to improve learning\n●\nDreambox: True adaptive learning\n●\nUSC ICT's Virtual Humans lab: Detecting human emotions for\nself-reflection and training\n●\nData and Dance: Teaching how to dance\n●\nAnalytics and Admissions: Using historical data to make\ndecisions on admissions\n\nPreparing for the\nnext class-\nUnit 2, Practice\nspaces\n\nNext Class: unit 2, Practice spaces\nNext Class unit 2, Practice spaces\nPractices spaces are learning experiences inspired by\ngames and simulations that allow teachers to practice\nkey teaching decisions\n\nWhy teacher practice spaces?\nWhy teacher practice spaces?\n●\nResearch on deliberate practice (Ericsson, Krampe, &\nTesch-Rоmer, 1993; Ericsson, 2002) which found that\nrepetition and feedback are critical to improving\nperformance\n●\nNew teachers have few opportunities to practice. Most\nteacher preparation programs do not give students\nopportunities to apply skills until they are already in\nthe classroom.\n●\nDrills vs Scrimmages. Classrooms are complex places --\ndifficult to practice specific skills when you are new to\na skill and there's a lot going on (Grossman et al.,\n2009.\n\nReadings for next week\nReadings for next week\n●Keep in Mind: What do the authors have to\nsay about:\n○the benefits of practice\n○what simulations and approximations\nreveal about teachers' practice\n○the instructional supports needed to\nsupport deliberate practice\n○implications for equity in teaching\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nCMS.594/CMS.894 Education Technology Studio\nSpring 2019\nFor more information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "CMS.594 Education Technology Studio, Session 5: Introduction to Practice Spaces",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/cms-594-education-technology-studio-spring-2019/91f6d9886d7e5625c975cecb836af07c_MITCMS_594S19_ses5.pdf",
      "content": "CMS.594/894- Education\nTechnology Studio\nSpring 2019\nIntroduction to practice spaces\n\nClass outline\n● Part 0: End-Of-Unit Survey Unit 1\n● Part 1: Try out some practice spaces\n○\nA lighting-round playtest of Teaching Systems Lab (TSL)\npractice spaces: Swipe Right for CS, Teacher Moments, and\nBaldermath\n● Part 2: Jigsaw Activity\n○\nWe will breaks into groups to do a close examination of the\nreadings.\n● Part 3: Introducing Mini-Project #2\n● Part 4: Work time\n○\nTeams will have time to work on outlining their proposed\npractice space for the mini-project.\n\nLighting round\nplaytest\n\nActivity: Instructions for playtest lighting round\n● You will have 8 minutes to experience and reflect on each\npractice space\n○\nGroup 1: Swipe Right, Teacher Moments, Baldermath\n○\nGroup 2: Teacher Moments, Baldermath, Swipe Right\n○\nGroup 3: Baldermath, Swipe Right, Teacher Moments\n● When the alarm goes off switch to the next activity\n\nActivity:Instructions for playtest lighting round\nTeacher Moments\nOrder: 1, 2, 3\nHow to play: Computer or\nphone\nLink:\nAP is not for me:\nbit.ly/aptest-demo\nTurner Scenario:\nbit.ly/turnerscenario-demo\nNote: You can choose\neither scenario. Use\nheadphones for the Turner\nScenario. You do not need\nto respond out loud if you\nare not comfortable.\nSwipe Right for CS\nOrder: 2, 3, 1\nHow to play: Computer or\nphone (better)\nLink:\nbit.ly/swiperight-demo\nNote: This is a demo link\nso you will only be able\nto see your responses in\nRound 3.\nBaldermath\nOrder: 3, 2, 1\nHow to play: Come to the\nfront of the room.\nLink: None, instructions\ncan be found here\nNote: Bring a pen or\npencil with you.\n\nDesign journal Reflection\nIn your design journals respond to the following prompts\nabout Swipe Right for CS, Teacher Moments, and Baldermath?\nYou have 5 minutes.\n1. What would you describe as the learning objective of each\npractice space?\n2. What questions do you have about each practice space?\n\nJigsaw activity\n\nActivity: close examination of the readings\n\nPart 1: Count-off by 4s and we break off into four groups. Each\ngroup will be assigned a reading to answer the following question:\n1.\nBased on the readings, how can practice/simulations be used to\nsupport learning?\n2.\nDescribe specific design elements within a practice or simulated\nsetting that help users learn.\nDiscuss first as a group\nGroup 1: \"Decomposition of Practice: The Naming of the Parts\"\n(Grossman et al., 2009) p.2068-2076\nGroup 2: \"Approximating Practice in Professional Education: Learning\nto Kayak on Calm Waters\" (Grossman et al., 2009) p.2076- 2091\nGroup 3: \"Findings\" (Dotger & Ashby, 2014) p.121-126\nGroup 4: Whole article (Robinson, Jahanian & Reich, 2018)\n\nActivity: close examination of the readings\nPart 1 Share Out:\n1.\nBased on the readings, how can practice/simulations be used to\nsupport learning?\n2.\nDescribe specific design elements within a practice or simulated\nsetting that help users learn.\n\nActivity: close examination of the readings\nPart 2: Count-off by 4s again and form new groups. In you\ngroup answer the following question:\nWhat design elements from the readings are present in Swipe\nRight for CS, Teacher Moments, and Baldermath?\nDiscuss first as a group\n\nActivity: close examination of the readings\nPart 2 Share Out: What design elements from the readings are\npresent in Swipe Right for CS, Teacher Moments, and\nBaldermath?\n\nIntroduction to\nDesigning teacher\npractice spaces\n\nDesign Elements of a teacher practice space\nPlay Mechanics\nLearning objectives\nFeedback and reflection\nData and analytics\nSource: Reich et al. (2018)\n\nWorked example: Swipe right for cs\nPlay Mechanics: Swiping apps (e.g., Tinder)\nLearning Objectives: Support high school CS teachers in\ndeveloping communication skills for actively recruiting\nstudents into computer science\nFeedback and Reflection: During Round 3, participants\nview their workshop's responses and reflect on what\narguments were most effective.\nData and Analytics: Game records responses and these are\nreported back in Round 3.\n\nWorked example: Swipe right for cs\n\nThings to consider when building a practice space\n● Who is going to be using this practice\nspace?\n● In what setting is this going to\noccur?\n● How much time do you have?\n● What other supports will occur outside\nof the practice space?\n\nGroup formation\n\nBreak - please return in\n10 minutes\n\nMini project 2\noverview\n\nMini project #2: Objective\nGoal: Design a teacher practice space for an\neducational setting of your choosing. Must be\nbuilt for a specific setting and user.\nDoes not need to be K-12 education\nMust be designed for teachers and not students\nUnit 2 Rubric\n\nMini project #2: Example topics from tsl work\n● Learning to recognize bias against certain\ngroups of students\n● Preparing to lead discussions on politically\ncontroversial topics\n● Responding appropriately to students who have\nexperienced trauma\n● Recognizing and responding to students'\nscientific misconceptions\n● Analyzing data on class compositions for\nevidence of bias\n\nMini project #2: other requirement\n● Can use technology but it is not required\n● Has to be be playable - even if it's a paper\nprototype or a slide deck\n● If reflection, feedback, and analytics are not\nbuilt into the practice space you will need to\ndescribe how they will be supported by other\nlearning experiences outside of the practice\nspace (e.g., reflection exercises)\n\nWork time\n\nmini-project #2: brainstorm\n● Brainstorm ideas for your mini project #2\n● Respond to the prompt in your design journal (due\nby Friday 5 PM)\n○\n(1) the problem of practice your practice space\naddresses, (2) the intended user, (3) the proposed\nsetting, and (4) skills you want the user to practice.\n\nPreparing for the\nnext class\n\nMini project #2: timeline\n● By this Friday at 5PM: You should respond in your design\njournal with the (1) the problem of practice your practice\nspace addresses, (2) the intended user, (3) the proposed\nsetting, and (4) skills you want the user to practice.\n● Next week: Prototype of your proposed practice space (e.g.,\nexamples screenshots, drawings, descriptions of game play)\n● Final project: Playable prototype to playtest in class.\n\nDue next week: mini-project #2 prototype\n● Homework\n○ Reading on design considerations when creating\npractice spaces\n○ Finish design journal entry\n○ Need help? Let me know!\n● Next week's class\n○ Learning more about designing practice spaces\n○ Share out your practice space prototype with the rest\nof the class\n○ In-class work on mini-projects\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nCMS.594/CMS.894 Education Technology Studio\nSpring 2019\nFor more information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "CMS.594 Education Technology Studio, Final Project: Collaborative Textbook Policy",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/cms-594-education-technology-studio-spring-2019/29cf54c8a54cb92fd10ebcf67846eeae_MITCMS_594S19_final_textbook.pdf",
      "content": "Collaborative Textbook Policy Brief\nThe Collaborative Textbook is a tool that intends to foster community and collaboration\naround a textbook by providing multiple means of engagement and representation. A consistent\nproblem with how students use textbooks is that they are often read and learned from in\nisolation. While this is not a problem for all students, some students who find themselves\nstruggling with material after reading a textbook may never find their questions explicitly\nanswered. This is often because students are too shy to share what they are confused about, and\nbecause of this the teacher will never know.\nWith the collaborative textbook we hope to fix this and foster a community of connected\nlearning. It is an online textbook that is interconnected with a student and teacher dashboard. The\nonline textbook is created using a Qualtrics form format with highlight question types. The types\nof highlights students can do are \"Confused\", \"Important\", \"Interesting\", and \"Unimportant\".\nHowever, teachers can change these highlights very easily in the forms if they would like to\nfocus on different aspects of student learning. By putting the textbook in this format all student\nhighlights are saved. This saved data is very valuable information and can be used in many\ndifferent ways. One way it can be used is to create a student and teacher dashboard which can\nboth facilitate a community of learning.\nThe teacher dashboard will be organized by dropdown menus. There will be dropdown\nmenus that correspond to different \"sections\". It is my intention that teachers can decide how\nthese sections will be broken down. For example, a teacher could decide that sections are\ntextbook sections and/or class sections. Different teachers may desire different formats\n\ndepending on their class size and reading materials. Giving the teachers as much power over the\nproduct as possible will make it as powerful as it can be.\nAfter deciding how these sections are broken down, they will be given the ability to have\nbetter, tailored lessons. They will see what students in their classes are confused about, and by\nseeing this they can modify their lessons as necessary to focus on topics where a large chunk of\npopulation is struggling. It is my intention that the final product of this prototype will shows\nteachers the most densely highlighted parts of the textbook for all types of highlights. This would\nbe especially helpful for teachers with especially large numbers of students. A teacher with over\n200 students will obviously not be able to go through each individual student; however, with a\ntool that shows what most of the class is confused about, they can still tailor their lessons to help\nclear up this lack of clarity. They can also still go through certain students who are struggling in\nthe class to work on material with students who potentially need more help.\nThe student dashboard will be very similar to the teacher dashboard; however, one major\ndifference is that students will not be able to see what certain peers highlighted within the\ntextbook. By keeping this data anonymous in the student dashboard version, it will be assured\nthat students will not be embarrassed that they are confused by certain topics. As one of the\nmajor uses of this community of learning will be that all students' questions have potential to be\nanswered, we would not want the risk of any students to be scared to admit any confusion.\nWith the student dashboard, students will have a lot of notes and power directly at their\nfingertips. Like with the teacher dashboard, in my final version of the prototype I would like the\nstudent dashboard to show the most highlighted parts of the text for each section and by each\ntype of highlight. With this data, students can learn from their peers. They will be able to see\nwhat other students marked as \"Important\" and \"Interesting\". If it seems that many students\n\nmarked something as \"Important\" and they did not pay any attention to that part of the material\nthey will know to spend more time on that material. By gathering data from many students'\nperspectives, they will be assured that they will not miss anything important. This also will be\nincredibly useful for students who struggle with reading due to disability. This tool would show\nthem all the most important parts of the textbook from student perspectives, allowing them to\nnarrow in on the most crucial aspects of the material.\nI have gone over why students and teachers will benefit from this tool and how this will\ncreate a community of learning about the textbook, which is often plagued as a tool of isolated\nlearning. However, besides just students and teachers, this Collaborative Textbook tool could\npotentially help textbook companies and authors with the incredible amounts of data they will\nreceive.\nEvery time a student highlights that data is sent to the form dashboard. I will have it so\nthat it is transmitted automatically to the student and teacher dashboards; however, a dashboard\ncould be created for textbook companies that will display information on how students feel about\ncertain parts of the textbook. Imagine a heatmap of student highlights in the textbook. Authors\nand companies will be able to see chunks of areas where students are especially \"Confused\" or\nbelieve that certain areas are \"Unimportant\". With this information, they would be getting direct\nfeedback from students on where their textbook is useful, and students are highlights things as\n\"Important\" or \"Clear\" (could be added in for textbook company purposes). One EdTech expert\neven mentioned during my presentation, \"textbook companies would definitely love this tool as\nfeedback often has to go through many middle men and is hard to be acted on.\" With this tool,\nthe feedback would be direct and from the students who are the main users of the textbook. This\nwould be an incredibly useful tool for companies and authors, and it would not be difficult to\n\nimplement. Over time, they could point out areas that students typically mark as \"Important\" or\n\"Difficult\" to help out other students when reading this textbook.\nTo conclude, the Collaborative Textbook tool will be useful for students and teachers in\ncreating a community of learning. Teachers can tailor their lessons for certain student needs, and\nstudents will be able to learn from each other and look at material in multiple perspectives.\nFinally, this tool can be used by textbook companies to make improves as they can receive data\ndirectly from all student users of the tool.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nCMS.594/CMS.894 Education Technology Studio\nSpring 2019\nFor more information about citing these materials or our Terms of Use, visit:\nhttps://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "CMS.594 Education Technology Studio, Final Project: Hands-On Physics",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/cms-594-education-technology-studio-spring-2019/ca4028e363f7ea60197295889d6b706f_MITCMS_594S19_final_lab.pdf",
      "content": "Practice Space Prepares Teachers for\nHands-On Physics\nThe Lab, a practice space designed for teaching assistants in physics laboratory\nclasses, sprung out of my own personal experiences as a student and teaching assistant in\nMIT's Junior Lab. These experiences informed the design and the goals of the practice space.\nAs a student, I was attracted to Junior Lab's goal of fully simulating the experience of\nbeing a real practicing physicist, communicated through open-ended lab protocols and\nauthentic experiments and equipment. The lab experience, although frequently intense, left me\nwith a deep appreciation for simulation as a tool for learning and also, of course, physics as a\nwhole. This experience led me to return to Junior Lab as a teaching assistant.\nAs a teaching assistant, I realized that I knew a great deal about the physics of the labs,\nand could easily sit down and fix a student's malfunctioning equipment. However, I was much\nless adept at communicating my knowledge. I had all the answers, but I had no practice in\nguiding students to the right solution without giving everything away. The brief orientation for\nteaching assistants at the start of the class urged us to avoid giving answers or doing things for\nstudents, but provided no practice in these areas.\nOther existing professional development solutions across the advanced physics lab\ncommunity, such as the ALPhA series of conferences and workshops, tend to assume that lab\ninstructors are coming from a teaching background, and devote their time and energy towards\nincreasing technical knowledge.\nMeanwhile, practice spaces for teacher training, such as the MIT Teaching Systems\nLab's ELK (Eliciting Learner Knowledge), simulate a traditional classroom that bears little\nresemblance to the hectic environment of a lab. Lab teachers must juggle equipment and\nprotocols in addition to managing students, watching for safety hazards and knowing exactly\nwhen to intervene.\nIn response to these issues and specific gaps in the existing work, I developed a new\nteacher practice space, designed to prepare new teaching assistants to prioritize conceptual\nlearning over equipment-fixing and answer-giving when faced with a complex lab environment.\nThis practice space has three primary components: roleplay personas, authentic lab equipment,\nand mechanics for representing student misconceptions. These components are general\nenough that this practice space could easily extend beyond the physics lab context.\n\nRoleplay personas help to replicate the drama and tense interactions that can take place\nin lab. One player takes the role of the teacher and receives a sheet summarizing their basic\nteaching philosophy. The other player takes the role of a student and receives a sheet\nsummarizing their (problematic) attitude to the lab class. For playtesting, I gave student players\nthe task of playing as a student who thinks they know everything about the lab and has no\ninterest in talking to the teaching assistant.\nAuthentic lab equipment increases the immersion and accuracy of the simulation. In\nparticular, teacher players must learn how to watch what students are physically doing on the\nlab equipment, balancing this with note-taking or consulting the protocol. The physical\nequipment is fun, but also increases cognitive load on the players in ways that match reality. For\nplaytesting, I gave players the modules pictured below, allowing players to flip switches, plug in\ncables, and turn dials.\nMechanics for representing student misconceptions keep the players from having to\nremember their own misconceptions. Each player receives a labeled diagram of the lab\nequipment, along with notes on the lab protocol that say both what steps to take and why to\ntake them. Differences in these diagrams and protocols between the student and the teacher\nrepresent what the student has misunderstood. Both players have an interest in these\ndifferences: the teacher wants to find as many differences as possible, especially conceptual\nmisunderstandings, while the student just wants their apparatus to match the final lab solutions\nand doesn't care about intervening steps and misconceptions.\nA playtest with these essential game components revealed a wide variety of playstyles\nand approaches to the game. One playtest had mechanics-focused players who collaborated to\nfind all of the non-conceptual misconceptions, efficiently reaching the correct setup by the end\nof the lab. In this run, the teacher forgot to ask conceptual questions entirely and only realized\n\ntheir mistake when presented with the full list of misconceptions after the game was over. This is\na successful outcome as far as the learning objective: the teacher was given the opportunity to\nreflect on their default approach. The other playtest had roleplay-focused players who\ngenerated a great deal of tension and drama. The student player took their character sheet\nextremely seriously and refused to speak to the teacher at all. The teacher got increasingly\nfrustrated, reaching out to use the equipment themselves and chastising the student for \"setting\nthemselves on fire.\" This is also a successful outcome for the learning objective: it's much better\nfor teaching assistants to practice dealing with frustration in a controlled environment.\nOverall, the playtest shows that players approach the basic mechanics of the game in a\nwide variety of ways. I think that this variation is a good thing for the game: there are new things\nto learn from every configuration of players. Going forward, I plan to expand the number of\nstudent profiles and look into ways of increasing the number of people that can play at once.\nOne avenue suggested at a public presentation of this work was to have two student players\nand one teacher player, simulating the existence of lab partners and increasing the number of\nplaystyles in the game.\nNext semester, I plan to act as a teaching assistant for Junior Lab again. Ideally, I'll\nimplement my practice space for the benefit of all of the teaching assistants. Over the course of\ninterviewing permanent Junior Lab staff for the design of this game, I started to publicize the\npractice space, making implementation into a possible reality. Either way, though, I have still\nlearned a great deal about my own teaching from watching the playtests and implementing the\ngame.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nCMS.594/CMS.894 Education Technology Studio\nSpring 2019\nFor more information about citing these materials or our Terms of Use, visit:\nhttps://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "CMS.594 Education Technology Studio, Final Project: Troll",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/cms-594-education-technology-studio-spring-2019/34aaafa8fbcf3682f5ae4945a80e9361_MITCMS_594S19_final_troll.pdf",
      "content": "____________________________________________________________\n____________________________________________________________\nTroll: A Game-Based Program for Enhanced Computer\nTroubleshooting in the Classroom [Policy Brief]\nA Computer Troubleshooting Game\nIntroduction to the Problem of Practice: How is technology currently\naffecting the K-12 classroom?\nStudents of the future need to know how to interface with their computer to solve common\ntechnical issues. As states continue to adopt and develop technology curriculum standards, as\nwell as bring more technology into everyday classroom use, student interaction with technology\nis becoming a forefront issue in educational progress. With this comes the rise of technical\nchallenges faced by teachers and students alike. In a live, high-stakes classroom environment,\ntechnical issues could slow down the pace of a lesson and provide an unnecessary barrier to\ntechnology integration. Often, schools' IT departments cannot solve every possible issue that\narises, requiring a need for such troubleshooting skills to be in the hands of students and\nteachers. According to a 2016 national education survey, 19% of surveyed teachers reported\nthat \"software glitches\" and 21% that \"insufficient support from IT staff\" were \"significant\"\nbarriers to technology use in the classroom (Cortez, 2016). Here, we introduce a\n\n____________________________________________________________\ncomputer-based simulation to allow students to practice common troubleshooting skills that\ncould accelerate the process of learning and helping their peers with such issues, as well as\nreduce one barrier to technology in the classroom. Our game, Troll, simulates common issues\nthat may arise on a students' computer, and with Troll, we hope to build the confidence of\nstudents to troubleshoot and thus smoothen the process of technology integration.\nThe Intended User and Context: How can students benefit from\ntroubleshooting skills?\nWe have chosen to focus on students in high school first. One, because they should have more\nknowledge of the how a computer system works and have had some encounters with the\ncomputer terminal, and two, a desire and ability to learn more about how to interface with their\ncomputer's terminal. According to the Massachusetts states' technology standard handbook,\ntroubleshooting is listed under one of their four guiding standards: Computing Systems (CS). In\nline with CS, students should be able to \"use troubleshooting strategies to solve routine\nhardware and software problems,\" a standard we hope this game addresses, specifically the\nsoftware component. An overarching goal of the standards is that \"digital literacy and computer\nscience ideas should be explored in ways that stimulate curiosity, create enjoyment, and\ndevelop depth of understanding\" (Massachusetts Department, 2016). Through the\nimplementation of a game that makes something that causes undue frustration more\nmanageable, we hope to allow students to explore how to interact with their computers in a fun,\nmeaningful, and useful way. We specifically intend to target students wanting to learn more\nabout their computer through acquiring basic knowledge of the command terminal. We want to\nmotivate students to independently troubleshoot and thus help their peers.\nThis leads to our learning objective:\nWe believe students of the future should be able to employ creative problem-solving\nskills to learn how to interface with their computer and gain the confidence to quickly\ntroubleshoot common computer software issues.\n\n____________________________________________________________\nWe include the goal of confidence because we intend this game to instill in students the\nconfidence to independently solve computer issues and then use their knowledge to teach other\nstudents without unnecessarily straining a teacher in charge of managing a full classroom.\nExisting Solutions and Design Aspirations: What has been done\nabout technological literacy?\nCurrently, there exist some solutions for helping computer-users troubleshoot. Many online\ntutorials exist for how to use the command line. Some tutorials are even interactive (for\nexample, Learn Shell). Additionally, there are various tools online for the purpose of interrupting\nusers to motivate them to stay on task (for example, parental controls, break reminders, and\nonline task managers). We wanted to create a user experience that both felt interactive and was\nhighly motivating. In order to learn command prompts, users often have to sift through long,\njargony manuals (for example, the BASH manual), affording them little opportunities to put their\nreading skills to practical use. This is why we chose a game that simulates common computer\nissues, forcing a user to implement problem-solving skills on the spot to eliminate the issue. A\npopular concept in video game psychology is the principle of \"flow.\" Within a state of flow, a user\nis at their maximum motivation level and is intrinsically motivated to solve a problem. If either\ntheir ability or the difficulty of challenge are mismatched, the user is not at their maximum\nperformance (Csikszentmihalyi, 1990) (See Figure below). Most often, video games achieve a\nstate of flow because the level of the game is adjusted as the user progresses. Although Troll\ncurrently does not support multiple levels, that is something we hope to implement in future\niterations.\n\n____________________________________________________________\nInnovative Solution and Technology Justification: How might we\nincrease students' troubleshooting skills?\nWe introduce Troll: A Computer Troubleshooting Game, in which we hope to appropriately\nengage and challenge users to acquire troubleshooting skills that they can confidently apply\nwhen they face them in real life. Troll currently has three different challenges:\n(1) One of the user's CPU cores is being taken up, significantly slowing down the computer.\nThey must find the program that is doing this in the background and end it.\n(2) A program is leaking memory in the RAM. Everything will be fine for a while, but the\ncomputer will significantly slow down after a while, and in some cases, completely\nfreeze. They must find the program that is doing this in the background and end it.\n(3) The user has forgotten where a certain important file is on the computer and has to\nlocate it.\nHere, we walk through the workflow for sample challenge (1):\nPrompt to tell the user that something undesired is happening and gives a hint on how to fix the\nissue.\n\nSearching for the command `top` as suggested in the hint.\nThe command `top` running. The programs are sorted by CPU-usage and 'troll' is the first in the\nlist.\n\n____________________________________________________________\nSuccess message when the user has successfully completed the task by ending the 'troll'\nprogram.\nPlaytest and Interviews: How did we apply user-centered design\ninsights to Troll?\nTo gather insights from users, we interviewed two college students and one current 6th-grade\nteacher. Each of them had some basic understanding of troubleshooting, although powering\noff/on, Ctrl+C, or Googling were their most common techniques. However, using a search\nengine like Google to look up common commands is something we incorporated into our game.\nBased on user feedback, we included a hint for suggestions on what command to use or what to\n\"google,\" since even that can be an overwhelming task. Our teacher interviewee, Ms. Johanna\nSpears, provided some additional insight into how technology impacts the classroom. Her\nschool funds iPads for each student to use, leading to a host of technical issues, such as Wi-Fi\nconnectivity and being locked out of applications. Although our game does not yet teach\ntroubleshooting these issues, they are something to keep in mind if expanding the game's\nrepertoire. Spears commented on the need for teachers to be able to quickly help students,\nsaying that it \"takes a lot of time and exploration\" to solve computer issues. We decided to take\nthis need and target the student users. Putting troubleshooting skills in the hands of students\ncould help classroom management, since one teacher cannot individually assist a class of about\n20-30 students.\nAdditionally, we performed two in-class playests with our peers in CMS.594. Both had some\nbasic troubleshooting knowledge, but emphasized the use of hints as appropriate guidance for\nthose learning these skills. They recommended that users be empowered to choose the\n\n____________________________________________________________\n____________________________________________________________\nfrequency of encountering the simulated issues (rather than random \"trolls,\" which was the initial\ninspiration for our game and logo). Users also commented on having a reward-based system in\nwhich one can achieve points or a mark of success. We currently indicate a user successfully\ncompleted a challenge, hopefully making troubleshooting a more fun experience. Users can\nalso repeat a challenge until they feel they have learned that skill.\nFuture Work: What can we iterate upon moving forward?\nThere are many ideas we would want to add to a final version. First, we would want to add more\nfeatures. This would include adding more challenges, difficulty levels, additional hints, and a\npoint system to track progress. Next, we want to make the game cross-platform. Currently the\nUser Interface (UI) only works on Linux/Mac, but it could be easily ported to the Windows\nOperating System (OS). Similarly, we want to make OS-specific challenges, such as dealing\nwith the forced reboot of Windows. Lastly, we want to make the game a background process so\nit could spawn programs randomly or at a set time instead of needing to manually start it; users\nwould then be able to choose the frequency of trolls (if choosing the random option) or set a\nspecific time to undergo the simulation. With a revised prototype, we would plan to do further\nuser testing with actual high school students. We are also considering expanding the intended\nuser to teachers and population groups new to computing in order to increase computer literacy.\nAcknowledgments\nWe would like to thank the Edtech teaching staff of CMS.594 for guiding and supporting us\nthroughout the semester and providing a wonderful introduction to the field of educational\ntechnology!\nThank you to our classmates for providing good class discussions and playtesting our prototype.\nThank you to all our interviewers as well for providing thoughtful insights. We appreciate\neveryone's support during this project!\n\n____________________________________________________________\nReferences\nCortez, M. B. (2016). Teachers Are Confident About Using Technology, Now More Than Ever.\nRetrieved from\nhttps://edtechmagazine.com/k12/article/2016/07/teachers-are-confident-about-using-te\nchnology-now-more-ever.\nCsikszentmihalyi, M. (1990). Flow: The Psychology of Optimal Experience. New York: Harper\nand Row.\nGNU Bash manual. (2019). GNU Project - Free Software Foundation. Retrieved from\nhttps://www.gnu.org/software/bash/manual/.\nKerrisk, M. (2019). User Commands. Linux man-pages. Retrieved from\nhttp://man7.org/linux/man-pages/man1/top.1.html.\nLearn Shell. (n.d.). Retrieved from https://www.learnshell.org/.\nMassachusetts Department of Elementary and Secondary Education. (2016). DIGITAL\nLITERACY AND COMPUTER SCIENCE CURRICULUM FRAMEWORK. Retrieved\nfrom http://www.doe.mass.edu/frameworks/dlcs.pdf.\nProject Hamster. (2017). Retrieved from http://projecthamster.org/\nInterviews:\nChang, H., personal communication. April 30, 2019.\nSpears, J., personal communication. May 9, 2019.\nReddy, S, personal communication. April 30, 2019.\nPlaytests:\nGraham, E., personal communication. May 8, 2019.\nVasudevan, S., personal communication. May 8, 2019.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nCMS.594/CMS.894 Education Technology Studio\nSpring 2019\nFor more information about citing these materials or our Terms of Use, visit:\nhttps://ocw.mit.edu/terms."
    }
  ]
}