{
  "course_name": "The Mathematics in Toys and Games",
  "course_description": "We will explore the mathematical strategies behind popular games, toys, and puzzles. Topics covered will combine basic fundamentals of game theory, probability, group theory, and elementary programming concepts. Each week will consist of a lecture and discussion followed by game play to implement the concepts learned in class.",
  "topics": [
    "Engineering",
    "Computer Science",
    "Fine Arts",
    "Game Design",
    "Mathematics",
    "Social Science",
    "Game Theory",
    "Engineering",
    "Computer Science",
    "Fine Arts",
    "Game Design",
    "Mathematics",
    "Social Science",
    "Game Theory"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 1 session / week, 2 hours / session\n\nObjectives\n\nStudents will learn to apply mathematical strategies to both play and implement their own games. This year the course will try to focus on some open problems in the field of combinatorial game theory. Most of all, we will have fun while playing games and learning math concepts at the same time!\n\nMaterials\n\nThere is no textbook for this class, but students are expected to read weekly course notes. Occasional outside readings will be assigned.\n\nRecommended Readings\n\nReadings are not necessary to understand the topics in class, but offer a chance to further explore the games we encounter.\n\nBerlekamp, Elwyn R., John H. Conway, and Richard K. Guy.\nWinning Ways for your Mathematical Plays.\nVol 1. Natick, MA: AK Peters, Ltd., 2001. ISBN: 9781568811307.\n\nConway, John H.\nOn Numbers and Games.\nNatick, MA: AK Peters, Ltd., 2000. ISBN: 9781568811277.\n\nGrading/Expectations\n\nThe course is graded on a pass/fail basis. The project will be either in the form of a paper or a coding project.\n\nACTIVITIES\n\nPERCENTAGES\n\nAttendance and participation\n\n30%\n\nFinal project\n\n70%\n\nFinal project grade determined as follows:\n\nACTIVITIES\n\nPERCENTAGES\n\nCheckpoint I\n\n10%\n\nCheckpoint II\n\n10%\n\nTurned in on time\n\n20%\n\nCreativity/depth\n\n20%\n\nWriting quality (paper)/implementation (coding or game creation)\n\n20%\n\nPresentation\n\n20%",
  "files": [
    {
      "category": "Resource",
      "title": "Markov and Mr. Monopoloy Make Millions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/ad072f715cb7794f25a6a6b68e1f954e_MITES_268S10_Ses7_Prob.pdf",
      "content": "Markov and Mr. Monopoly Make Millions\nSpring 2011\nProbability\nProbability is key to many fields, such as econometrics, quantum mechanics,\nsignal processing, and theoretical computer science. We will go through a\ngentle introduction to the basics of probability, then discuss how probability\ncan be used to analyze Monopoly. We will focus on discrete probability here,\nthough we could easily convert to the continuous analogs.\nSets\nA set is a collection of items. An example of a set can be all the Course XIV\nclasses offered at MIT: {14.01, 14.02, 14.04, 14.05, 14.32, 14.33, 14.36 . . . }. For\nthe following definitions and examples, let A and S be arbitrary sets.\nAn element of a set is something belonging to that set. We write a ∈ A if\na is a member of the set A, and a /∈ A if a is not a member of the set A.\nA subset is a set contained within another set, in other words, if all members\nof a set belongs to another set. A is a subset of S if all members of A belong\nto S, and we write A ⊆ S. Note that:\n- A = S if and only if A ⊆ S and S ⊆ A.\nES.268\n\nMonopoly\n- The empty set ∅, or a set with no elements, is a proper subset of every\nset.\n- A proper subset is a set that is strictly contained in another set.\nThat is, A is a proper subset of S if and only if there is at least one\nelement contained in S that is not contained in A, and all elements of\nA are contained in S.\nThe cardinality of a set, denoted |A| here, is the number of elements in that\nset. If A ⊆ S, then |A| ≤|S|. If A ⊂ S, then |A| < |S|.\nProbability and Sets\nNow that we have defined sets generally, let's look at how sets are used when\napplied to probability. The 'things' or 'items' that we're concerned with are\noutcomes-outcomes from flipping coins, dealing hands or cards, etc. The\nsample space is the set of all possible outcomes, denoted Ω. A subset of a\nsample space consists of the outcomes that we're interested in, called events.\nSuppose we have the events A, B, and C. The interesction of two events\nis the event that they both occur. C = A ∩ B if the event C represents both\nA and B occuring. If A ∩ S = φ, then the two sets are called disjoint or\nmutually exclusive. The union of two events is the event that either one\nor the other occurs, denoted C = A ∪ B.\nLaws of set operations:\n- Commutative:\nA ∪ B = B ∪ A\nA ∩ B = B ∩ A\n- Associative:\n(A ∪ B) ∪ C = A ∪ (B ∪ C)\n(A ∩ B) ∩ C = A ∩ (B ∩ C)\nES.268\n\nX\nMonopoly\n- Distributive:\n(A ∪ B) ∩ C = (A ∩ C) ∪ (B ∩ C)\n(A ∩ B) ∪ C = (A ∪ C) ∩ (B ∪ C)\nThe probability of an event is a mapping from the set of events to the interval\n[0,1]. When we talk about the probability of some event A in Ω, it will always\nfollow these axioms:\n1. The probability of the sample space, Ω, is P (Ω) = 1;\n2. P (A) ≥ 0 for all A ∈ Ω.\n3. If A1 and A2 are disjoint, then\nP (A1 ∪ A2) = P (A1) + P (A2).\nMore generally, if Ai for i = 1, 2, 3, . . . are disjoint, then\ninf\n\ninf\nP\nAi\n=\nP (Ai).\ni=1\ni=1\nThe inclusion-exclusion principle is very useful in calculating probabilities.\nIt states that for two events, A1 and A2, not necessarily disjoint as in the\nthird axiom above,\n|A1 ∪ A2| = |A1| + |A2| -|A1 ∩ A2|.\nThe third term in in the equation above subtracts the overlap in A1 and A3,\nwhich was counted twice. The probability version of the inclusion-exclusion\nprinciple is\nP (A1 ∪ A2) = P (A1) + P (A2) - P (A1 ∩ A2).\nThe complement of a set A, commonly denoted A0, Ac, or A, is all elements\nES.268\n\nMonopoly\nin the sample space that don't belong to that set.\nAc = Ω - A,\n|Ac| = |Ω| -|A|,\nP (Ac) = P (Ω) - P (A)\n= 1 - P (A).\nFor most problems, the goal will be to find the likelihood that an event E\nhappens, or P (E), out of the set of possible outcomes S. When all the\noutcomes are equally likely,\n|E|\nP (E) =\n.\n|S|\nWe're adding up all the elements in E and all the elements in S, then dividing\nthem. This leads us to the topic of counting, which is used when dealing with\ndiscrete, finite sample spaces.\nCounting\nWe make the assumption that all the outcomes are equally likely, also known\nas the assumption of uniform probability. All that needs to be done then is\nadd up the number of outcomes that we care about and divide that by the\nnumber of all possible outcomes. The trickiest part is defining the event and\nsample space and making sure that we count everything the right number of\ntimes.\nCounting Rules\nWe've seen the Sum Rule already, just not labeled with the name. If\nA1, A2, . . . , An are disjoint sets, then\n|A1 ∪ A2 ∪ . . . ∪ An| = |A1| + |A2| + . . . + |An|.\nWhat's the probability version of the Sum Rule?\nES.268\n\nMonopoly\nExample 1\nExcuse this somewhat lame example, but its purpose is to show the sum rule\nat work. In a group of 150 students, 15 use Internet Explorer as their web\nbrowser of choice, 80 use Firefox, 15 use Safari, and 40 use Chrome. If being\n\"cool\" means you use Firefox or Chrome as your main web browser, what is\nthe probability that we pick one student who is \"cool?\"\nLet the set C be the set of \"cool\" students; there are 80 + 40 students in C,\nby the sum rule. Let S be the set of all students; there are 150 students in\ntotal, as stated in the problem. Therefore, the probability of picking a cool\nstudent is:\n|C|\nP (picking a cool student) =\n=\n= .\n|S|\nThe multiplication rule states that for a length-k sequence, where the first\nterm is chosen out of set S1, the 2nd term is chosen out of set S2 . . . the last\nterm is chosen out of Sk, then\n|Total # of sequences| = |S1 × S2 × · · · × Sk|\n= |S1| · |S2| · · · |Sk|.\nExample 2\nThe Athena combination lock just got changed again. You're far from any\nQuickstation and there's no one else nearby. Suppose you wanted to try your\nluck at guessing the combo (and you don't have SIPB's hint board). How\nmany possible combinations could you try?\nThe athena door locks have 5 buttons, 3 on the top row and 1 on the bottom\nrow (the bottom-right button is a reset, so it doesn't count). The athena\npasscode is 5 digits. Let Di, for i = 1, 2, 3, 4, 5, represent the set of buttons\nES.268\n\nMonopoly\npossible for each digit.\n|Total # of combinations| = |D1 × D2 × D3 × D4 × D5|\n= |D1| · |D2| · |D3| · |D4| · |D5|\n= 5 · 5 · 5 · 5 · 5\n= 55\nPermutations\nThe set of permutations on a collection of objects is an example of the\nalgebraic structure called a 'group,' which was covered in the Rubik's Cube\nlecture. Here we'll use 'a set of ordered objects' as a working definition of\npermutations. For a collection of n objects, there are n(n-1)(n-2) · · · (1) =\nn! different orderings of the objects.\nExample 3: The Birthday Problem\nYou're in a room with a bunch of people, say n ≤ 365 people.\na) What is the probability that two people in the room have the same birth\nday? Ignore complications with leap years and assume there are 365 days\nin a year. We also assume that birthdays are random (not exactly true).\nThis problem is best approached the other way around, with the proba\nbility that no two people have the same birthday.\nLet A be the event that two people have the same birthday. Then Ac is\nthe event that no two people have the same birthday. Note that P (A) =\n1-P (Ac). We start with person 1; this person can have any 1 of 365 days\nout of the year. A second person can only have a birthday on the 364\ndays out of the year that hasn't been 'taken.' By assumption of random\nbirthdays, and of uniform probability, the chance that this person has any\nof the 364 birthdays is 364 . A third person can only have a birthday out\nES.268\n\nMonopoly\nof the 353 days not 'taken,' and the corresponding probability of such an\nevent is 363 . This continues until we've covered all n people.\n365 · 364 · 363 · · · (365 - n + 1)\nP (Ac) =\n365n\nP (A) = 1 - P (Ac)\n365!\n= 1 - 365n · n!\nb) What is the probability that someone shares your birthday?\nEach person can have your birthday with probability 1 . There are n - 1\npeople besides you, so the probability that someone shares your birthday\nn-1\nis\n.\nThe answers to part a) and part b) are quite different, but the way the ques\ntions were phrased were only slightly different. Half the work in probability\nquestions is usually figuring out what the question wants from you...\nWhat happens if n > 365? You can answer part a) without doing any math,\nby the Pigeonhole Principle. The Pigeonhole Principle states that in a\nmapping from set X to set Y , if |X| > |Y |, then more than one element of\nX map to some element in Y .\nCombinations\nWe will also want to deal with collections that are unordered. How many\nways are there to take r objects out of a set of n objects?\nFor the first object, we have n to choose from. For the 2nd object, we have\nn - 1 to choose from. For the rth object, we have n - r + 1 to choose from.\nBut note that once we've selected r objects this way, they are in some kind\nof order, and the answer n(n - 1)(n - 2) · · · (n - r +1) =\nn!\nis not correct.\n(n-r)!\nWe must divide by r!, which is the number of ways you can order (permute)\nr objects.\nES.268\n\nMonopoly\nThe number of ways that we can take r objects out of a set of n objects is\ntherefore\n\nn!\nn\n=\n.\nr!(n - r)!\nr\nExample 4: Hands of cards\nIn this example we're using a standard 52-card deck.\na) How many ways are there to deal a 5-card hand?\n52!\n=\n= 2598960\n5!(47)!\nb) How many ways are there to deal a flush, a 5-card hand with all cards\nthe same suit?\nThere are\n1 ways to choose the suit, and\nways to choose the 5\ncards out of that suit.\n# of ways to deal a flush = 4\n= 5148\nc) How many ways are there to deal a 5-card hand with 1 pair?\nThere are 13 ways to choose the card value of the pair, and 4 ways\n\nto choose the suits of the pair; then there are\nways to choose the\nremaining 3 cards of the 5-card hand.\n# of ways to deal a hand with 1 pair = 13\n= 1528800\nd) How many ways are there to deal a 5-card hand with only 1 pair?\nAs before, there are 13 ways to choose the card value of the pair, and\n4 ways to choose the suits of the pair. But the problem specifies only\n1 pair. The remaining 3 cards in the hand cannot contain a pair. So\nES.268\n\nMonopoly\nthere are are\nways to choose 3 different values besides the value\nthat's already a pair, and they can be from any suit.\n# of ways to deal a hand with only 1 pair = 13 4\n12 43 = 1098240\ne) How many ways are there to deal a 3-of-a-kind?\nThere are 13 ways to choose the card value of the 3-of-a-kind, and 4\n\nways to choose the suits of the pair; then there are\n2 ways to choose\nthe remaining 2 cards of the 5-card hand, making sure that the value of\nthe 3-of-a-kind doesn't get chosen (otherwise we'd get a 4-of-a-kind).\n# of ways to deal a 3-of-a-kind = 13\n= 58656\nf) How many ways are there to deal a full house, a 5-card hand with 3 of\none kind and 2 of another?\nAs before, there are\n13 ways to choose the card value of the 3-of-a\nkind, and 4 ways to choose the suits of the pair. Then there are 12\n\nways to choose the value of the 2-of-a-kind and 4\n2 ways to choose the\nsuit.\n# of ways to deal a full house = 13\n= 3744\nConditional Probability\nIf we're interested in the probability that some event A occurs given that\nsome event B has already occurred, the sample space becomes B. The prob\nability of A conditioned on B becomes a probability on the space B.\nThe Multiplication Law states that P (A ∩ B) = P (A|B)P (B).\nES.268\n\nX\n\nMonopoly\nSo we get that\nP (A ∩ B)\nP (A|B) =\n,\nfor P (B) = 0.\nP (B)\nWith some rearranging, we get Baye's Rule, which is commonly seen in\nmany different forms:\nP (B|A)P (A) = P (A|B)P (B).\nThe Law of Total Probability gives us the ability to isolate the probability\nof one event on a partitioned probability space. Given a space Ω that is\npartitioned by Bn : n = 1, 2, . . . , and an event A,\nn\nP (A) =\nP (A ∩ Bi)\ni=1\nExample 5\nMelissa and I are going to assign your P/F grades for this seminar by picking\nthem out of a hat. We take 100 slips of paper and mark P on half of them,\nF on the other half. Then we put the slips of paper in two hats, and pick\na slip of paper from one of the hats. Whatever we pick will be your grade.\nBut, being as merciful and fair as we so obviously are, and curious how much\nyou got out of this class, we'll leave it up to you to place the slips of paper\ninto the two hats any way you want. How will you do it?\nMonopoly\nThe game of MONOPOLY R came about during the Great Depression, orig\ninating from Charles Darrow of Germantown, Pennsylvania. It started out\nas handmade sets sold in a shop in Philadelphia, and as people grew to love\nES.268\n\nMonopoly\nthe game, Darrow approached Parker Brothers to enlarge the production\nscale (he'd actually been rebuffed by the Parker Brothers the first time in\n1933 due to 52 'fundamental playing flaws'). Today, MONOPOLY R is the\nbest-selling board game in the world, distributed in 111 countries and 43\nlanguages. Some fun facts from the MONOPOLY R website:\n- The longest MONOPOLY R game ever played was 1, 680 hours long.\n- The MONOPOLY\nR man isn't a Parker Brother. His name is Mr.\nMonopoly.\n- Parker Brothers once sent an armored car with a million MONOPOLY R dollars\nto Pittsburgh because a marathon game there had run out of money.\n- MONOPOLY R comes in a Braille version.\n- The four most-landed-on squares are Jail, Illinois Avenue, \"Go\", and\nthe B&O Railroad.\nThe last in the list of fun facts above is more than meets the eye. What makes\ncertain game squares more likely to be landed-on than others? Illinois Avenue\ndoesn't seem to be special compared to other properties. . . It turns out that\nwe can model the MONOPOLY R game board to calculate the probability of\nlanding on a certain square.\nRules\nThe objective of the game is to bankrupt all opponents, though most games\nplayed with family and friends end when it is apparent that someone will\nwin. A typical game of MONOPOLY R uses the following items:\n- 1 game board\n- 2 dice\n- token for players (11 official MONOPOLY R ones)\nES.268\n\nMonopoly\n- 32 houses\n- 12 hotels\n- 16 Chance cards\n- 16 Community Chest cards\n- property deeds for each of the 22 MONOPOLY R properties\n- $15140 in MONOPOLY R money\nThe Chance and Community Chest cards are placed face down on the game\nboard, and a player must pick one of the cards when he lands on the Chance\nor the Community Chest game squares. Each player is given $1500 to be\ngin the game. All remaining money, game piece, houses, hotels, and deeds\nof unsold property go to the Bank. The Bank collects all taxes, fines,\nloans, and interest. The Bank never goes 'broke.' If the Bank runs out\nof MONOPOLY R money, then more can be issued (see fun fact above).\nPlayers begin on the Go square, roll two dice, and advance as many steps as\ndots displayed on the the two dice. A player can buy any property, utility,\nor railroad that isn't already owned by another player, or must to draw\nChance/Community Chest cards, pay rent, fines, or go to Jail as dictated\nby the square he lands on. If a player throws a double, then he moves his\ntoken the number of steps, is subject to whatever privileges or penalties of\nthe square he lands on, and then tosses the dice again. If a player tosses\nthree doubles in a single turn, he must go to Jail.\nLanding on the Jail square is just 'visiting Jail', while landing on the 'Go to\nJail' square, drawing a 'Go to Jail' card, and tossing doubles 3 times during\na turn are actual Jail sentences. Any Jail term lasts 3 turns. A player tosses\ndice at each turn, and if he tosses a double, then he is free to get out of jail\nand advances the number of steps as his double shows. That player does not\ntake another turn. A player gets out of Jail if he has a 'Get out of Jail Free'\ncard, or if another player is willing to sell him a 'Get out of Jail Free' card\nat a negotiated price, or if the player pays a $50 fine.\nES.268\n\nMonopoly\nIf a player lands on a property owned by another player, then the owner\ncollects rent based on the information on the property deed. Rents are much\nhigher for properties with houses or hotels. When a player owns all the\nMONOPOLY R properties in a color group, then he has the option to build\nhouses on those properties. If he buys one house, he can put them on any\none of those properties. The next house he buys must be erected on one of\nthe unimproved properties of that or any other complete color group, and so\non. Thus, players must build evenly across all his properties in a color group.\nMore details of the rules of the game will unfurl as we analyze the game.\nFirst, a bit of linear algebra.\nMatrices, Eigenvalues, and Eigenvectors\nThe linear equation Ax = b is at the heart of most introductory linear\nalgebra courses. A is a matrix, and x and b are vectors; the matrix A\n'operates' on x to give b; x and b lie on the same vector space but are in\ndifferent directions unless A is the identity matrix I.\nEigenvectors are special vectors associated with every operating matrix.\nThese vectors don't change directions when multiplied by the matrix, and\nwe get the equation Ax = λx. Each eigenvector has its own eigenvalue\nλ. Most 2 × 2 matrices have two eigenvectors and their two corresponding\neigenvalues.\nWhat happens when A operates on x more than once? As in, what's A2x?\nA3x? A100x?\nThe number λ is an eigenvalue of A if and only if A-λI (which is a matrix) is\nsingular, or det (A - λI) = 0. A singular matrix is a square matrix that has\nno inverse, or det A = 0. Then, for each eigenvalue, we solve (A - λI)x = 0,\nor Ax = λx to find the eigenvector x.\nES.268\n\nMonopoly\nExample 6\nFind the eigenvalues and eigenvectors of A =\n1 2 .\n2 4\n1-λ\nA - λI =\n4-λ\nTake the determinant of this matrix.\n1-λ\ndet\n= (1 - λ)(4 - λ) - (2)(2) = λ2 - 5λ.\n4-λ\nSet the determinant to 0, and solve for λ.\nλ2 - 5λ = 0 gives λ1 = 0 and λ2 = 5.\nSolve (A - λI)x = 0 separately for λ1 = 0 and λ2 = 5.\n1 2\nx1\n(A - 0I) =\n2 4\nx2 =\n0 gives eigenvector\n-1\n1 2\nx1\n(A - 5I) =\nx2 =\ngives eigenvector\n2 4\nAs a side note, because the vectors that make up A are constant multiples of\neach other, we know that A itself is a singular matrix. The determinant of\na matrix can be found by taking the product of all its eigenvalues, so if the\ndeterminant is zero, then we know one of the eigenvalues must be zero.\nMarkov Chains\nMarkov chains are the probabilistic versions of deterministic finite automata.\nFor our\n,\nanalysis of MONOPOLY R\nwe'll consider each of the 40 game\nsquares to be a state H. At each time step n, the probabilistic state dis\ntribution Xn will be a 40 × 1 vector, with each element representing the\nES.268\n\nX\n\nMonopoly\nprobability that a player ends his turn in that state. Our state, H, belongs\nto the set S of the state space of size 40. The Markov chain is described\nin terms of its transition probabilities pij , which is the probability that\nwe'll go from state i to state j at a time step. The transition probabilities\nsum to 1.\npij = P (Hn+1 = j|Hn = i),\ni, j ∈ S\npij = 1\nj\nThe probability that we're in a certain state at time step n depends only\non our state at time step n - 1, and is independent of all states besides the\nprevious state:\nP (Hn+1 = j|Hn = i, Hn-1 = i - 1, . . . , Ho = io) = P (Hn+1 = j|Hn = i) = pij\nThe transition matrix captures all the transition probabilities and operates\non our state distribution vector. Such a matrix is called a Markov matrix,\nand it is also a square matrix.\n⎤\n⎡\nT\n⎢⎢⎢⎣\np00\np01\n. . . p0m\np10\np11\n. . . p1m\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\npm0 pm1 . . . pmm\n⎥⎥⎥⎦\nSpecial matrices will have special eigenvalues and eigenvectors, and for Markov\nmatrices, all entries are positive and every column sums to 1. Can you see\nwhy they must add to 1? The largest eigenvalue is 1, and the corresponding\neigenvector is the state that comes out at the end. The eigenvectors of other\neigenvalues fall to 0 over time.\nExample 7\nThe ESG elevator has two states: SLOW and BROKEN. If it is SLOW\ntoday, then the probability that it becomes BROKEN tomorrow is 0.6, and\nES.268\n\nh i\n\nMonopoly\nthe probability that it stays SLOW the next day is 0.4. If it is BROKEN,\nthen the probability that MIT Facilities comes to try to fix it (making it\nSLOW) is 0.2, but most likely, with probability 0.8, it'll just stay BROKEN.\nIf we start the school year in the fall with a SLOW elevator, what kind of\nelevator will we have at the end of the school year?\nOur initial state distribution is\nx\nx\n1 , with x1 representing the probability of\nhaving a BROKEN elevator, and x2 representing the probability of having a\nSLOW elevator.\n.6 .8\nOur transition matrix is A =\n. It has eigenvalues 1 and -.2, but over\n.4 .2\ntime, the eigenvector associated with -.2 will be multiplied by (-.2)n → 0.\nWe consider the eigenvector with eigenvalue 1.\n(A - I)x = 0 =⇒ (normalized) x =\nWe are twice as likely to end up with a BROKEN elevator.\nMONOPOLY R\nIan Stewart, a math professor at the University of Warwick, wrote a column\nin the April, 1996 issue of Scientific American seeking to answer the question:\n'Is Monopoly fair?' In other words, is every MONOPOLY R square equally\nlikely to be occupied? His initial analysis was only a mathematical exercise,\nand his model abstracted many of the realistic playing rules.\nInitial Analysis\nWe abstract away the rules about rolling doubles, Chance/Community Chest\nsquares, and the complications involving going to Jail. Then on each roll of\nour dice the number of steps we could possibly take (sum of rolling two dice)\nis distributed as follows:\nES.268\n\nMonopoly\nNumber on the two dice Probability\n6, 8\n5, 9\n4, 10\n3, 11\n2, 12\nThe initial position probability vector, H0, is a 40-dimensional-vector with\n1 as the 0th element and 0 everywhere else. If we index the board from 0\nthrough 39, beginning at 'Go', then after the first turn, the vector of position\nprobabilties H1 would be:\n[0, 0,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n, 0, 0, 0, . . . , 0]0 .\n36 36 36 36 36 36 36 36 36 36 36 |\n{z\n}\n27 zeros\nThe 1st column of our 40 × 40 Markov transition matrix M would be H1.\nThe second column of the matrix would be this vector with 3 zeros before\nthe beginning of the fractions and 27 zeros after, in essence, the same vector\n'shifted' over by 1. The third row would be shifted over again, so on until\nwe've completed all 40 rows of the matrix.\nTo get our state probability vector after moving n times, we would just\ncalculate AnH0. For sufficiently large n, our state probability vector would\nbe the eigenvector of A that corresponds to eigenvalue 1. The eigenvector\nfor the simple model of Monopoly has all entries equal to 1, because the\ntransition from any square on the board is the same.\nThe Real Game\nWe made a few simplifying assumptions in the last section: tossing doubles,\nthe \"Go to Jail\" square, and Chance/Community Chest cards.\nTo deal with the rule about tossing doubles, we can modify the initial vector\nand the transition matrix. The maximum number of spaces a player can\nES.268\n\nMonopoly\nmove is 35, (if a player rolls a {(6,6),(6,6),(6,5)}). If a player lands on 'Go\nto Jail', then he would go immediately to Jail and end his turn there. If a\nplayer rolls three doubles in row, then he would also have to go to jail.\nThe transition at each turn would be a vector of probabilities allowing up\nto 2 tosses with doubles. The transition matrix will have this vector for\neach column (with appropriate offsets). Then we adjust the probabilities for\nthe Jail square, which is the sum of what it had from routine tossing, the\nprobability of the \"Go to Jail\" square, and probability of tossing 3 doubles\nin a row (63/363 = 1/63).\nThe Chance/Community Chest cards are actually not as complicated as\nthey seem. There are 16 Chance cards, 10 of which tell the player to\nmove to another square. The probability of staying in Chance is thus 1\nthe probability it had before, and each of the 10 destinations is increased\nby 10 × P (probability of landing on Chance). The same goes for Commu\nnity Chest, which only has 2 cards that send players to other squares. The\nprobabilities would be adjusted accordingly.\nAs a consequence of the \"Go to Jail\" square, tossing doubles, and Chance and\nCommunity Chest cards sending players to different squares, the probability\ndistribution is no longer uniformly distributed over all 40 squares. Instead,\nit is skewed toward certain squares. Players are almost twice as likely to be\nin Jail than in any other square; the next-most-frequented square is Illinois\nAvenue, and GO is the third most likely square. B&O Railroad is the most-\noften occupied railroad.\nWhere and When to Build?\nRent-collecting is when things actually start to get interesting. After all, the\nwhole point of the game is to bankrupt the other players. What strategy\nshould we take in building houses and hotels? What can we use from our\nprobabilistic analysis? If we take the actual decimal values of the probabil\nities and analyze the time of the break-event point (total cost of buildings\ndivided by expected earnings from property per turn; how would you calcu\nlate the expected earnings?) which is when rents collected becomes greater\nES.268\n\nMonopoly\nthan the cost of building the houses and hotels, we find that with 2 houses\nor fewer, it typically takes 20 moves or more to break even. With 3 houses,\nthe chances are significantly better. It is even better than building 4 houses\nor a hotel. This is preferable strategy because one of the principle strategies\nof MONOPOLY R is to deplete accounts of other players fast while accumu\nlating fast yourself (so that you can purchase more property and build more\nbuildings). If the break-even point takes too long, then we are wasting valu\nable resources that could have been allocated to buildings on other properties\nand raising the rents of those properties.\nRemarks\nOther similar board games can be modeled in the same way. The premesis of\nMarkov chains is that the next state is independent of all previous states-it\nony depends on the current state.\nES.268\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nES.268 The Mathematics in Toys and Games\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "ES.268 AI and game search, Course Notes 4",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/7e2bc0702dcc4718b597f3a98592aa09_MITES_268S10_Ses4_AI.pdf",
      "content": "Introduction to AI Techniques\nGame Search, Minimax, and Alpha Beta Pruning\nJune 8, 2009\nIntroduction\nOne of the biggest areas of research in modern Artificial Intelligence is in\nmaking computer players for popular games. It turns out that games that\nmost humans can become reasonably good at after some practice, such as\nGO, Chess, or Checkers, are actually difficult for computers to solve.\nIn exploring how we could make machines play the games we play, we are\nforced to ask ourselves how we play those games. Although it seems that\nhumans use some notion of \"intelligence\" in playing a game like chess, our\napproaches in solving such games have not progressed much farther than the\nsort of brute force approaches that we experimented with in the 50s. Unfor\ntunately, present computer players usually rely on some sort of search over\npossible game outcomes to find the optimal move, rather than using what\nwe would deem intelligent behavior.\nIn this discussion we will see some of the ideas behind these computer play\ners, as well as future directions the field might take, and how these computer\napproaches can both help us learn to play the games better as well as point\nout some fundamental differences between human play and machine play.\nAs a quick time line to show how (not very) far we have come since Claude\nShannon's (a famous MIT professor, the father of Information Theory, etc.)\nProgramming a Computer Playing Chess, 1948 :\n- 1948 Claude Shannon\n\nAI Techniques For Solving Games\n- 1951 Alan Turing works out a plan on paper for a chess-playing com\nputer program.\n- 1966-1967 Mac Hack 6, developed at MIT, first chess program to beat\na person in tournament play\n- 1997 Deep Blue beats Kasparov, the reigning world chess champion at\nthe time, in a best out of 6 match. This was seen as a landmark in\nthe chess program world, but really Deep Blue was just like previous\nchess playing machines with bigger and better computing power, and\nno more \"intelligence\" than any previous model.\nWell-known Players\nThe most popular recent game to be solved is checkers, which had up to 200\nprocessors running night and day from 1989 to 2007. Checkers has 5 ∗ 1020\npossible positions on its 8 by 8 board. It is now known that perfect play\nby each side results in a draw. You can play around with the database on\nthe Chinook project's website:\nThe\ngame is strongly solved, and for every move Chinook tells you whether it\nleads to a winning strategy, a losing strategy, or a draw.\nAnother famous computer player is Deep Blue, who beat chess world cham\npion Garry Kasparov in 1997, which was capable of evaluating 200 million\npositions per second.\nHow To Solve a Game?\nWhat if we just give the computer simple rules to follow in what is known as a\nknowledge based approach. This is how a lot of beginner and sometimes\nadvanced human players might play certain games, and in some games it\nactually works (we'll take a closer look using Connect Four next time). Take\nthe following rules for tic-tac-toe, for instance.\nYou give it the following\ninstructions to blindly follow in order of importance:\n1. If there is a winning move, take it.\n2. If your opponent has a winning move, take the move so he can't take\nit.\nhttp://webdocs.cs.ualberta.ca/~chinook/.\nES.268\n\nAI Techniques For Solving Games\n3. Take the center square over edges and corners.\n4. Take corner squares over edges.\n5. Take edges if they are the only thing available.\nLet's see what happens when the computer plays this game (picture taken\nfrom Victor Allis's Connect Four Thesis):\nThis approach clearly will not always work. There are so many exceptions to\nrules that for a game like chess enumerating all the possible rules to follow\nwould be completely infeasible. The next logical option to try is search. If a\nplayer could predict how the other player would respond to the next move,\nand how he himself would respond to that, and how the next player would\nrespond next, etc., then clearly our player would have a huge advantage and\nwould be able to play the best move possible. So why don't we just build\nour computer players to search all the possible next moves down the game\ntree (which we will see in more detail soon) and chooses the best move from\nthese results? I can think of at least two of many good reasons:\n- Complexity - As we will see below, if a game offers players b different\npossible moves each turn, and the game takes d moves total, then\nthe possible number of games is around bd .\nThat's an exponential\nsearch space, not looking good! For tic-tac-toe, there are about 255,168\npossible games. Definitely reasonable. But for chess, this number is\naround 3640, something like more than the number of particles in the\nuniverse. No good.\n- It's not intelligence! Brute computational force is not exactly intell\ngience. Not very exciting science here, at least not for us theoretical\nCourtesy of Victor Allis. Used with permission. Figure 2.5 in \"A Knowledge-based Approach of\nConnect-Four. The Game is Solved: White Wins.\" Master's Thesis, Vrije University, 1988, pp. 14.\n\nAI Techniques For Solving Games\npeople. Maybe exciting for the hardware guys that build faster pro\ncessors and smaller memory to that we have the computational power\nto solve these games, but other than that not very cool... It would be\nmuch more exciting to come up with a \"thinking\" player.\nSo what should we do? We can't use just simple rules, but only using search\ndoesn't really work out either. What if we combine both? This is what is done\nmost of the time. Part of the game tree is searched, and then an evaluation,\na kind of heuristic (to be discussed more soon) is used. This approach works\nrelatively well, and there is a good deal of intelligence needed in designing\nthe evaluation functions of games.\nGames as Trees\nFor most cases the most convenient way to represent game play is on a graph.\nWe will use graphs with nodes representing game \"states\" (game position,\nscore, etc.) and edges representing a move by a player that moves the game\nfrom one state to another:\nUsing these conventions, we can turn the problem of solving a game into a\nversion of graph search, although this problem differs from other types of\ngraph search. For instance, in many cases we want to find a single state in\na graph, and the path from our start state to that state, whereas in game\nsearch we are not looking for a single path, but a winning move. The path\nwe take might change, since we cannot control what our opponent does.\nBelow is a small example of a game graph. The game starts in some ini\ntial state at the root of the game tree. To get to the next level, player one\nchooses a move, A, B, C, or D. To get to the next level, player two makes a\nmove, etc. Each level of the tree is called a ply.\n\nAI Techniques For Solving Games\nSo if we are player one, our goal is to find what move to take to try to ensure\nwe reach one of the \"W\" states. Note that we cannot just learn a strategy\nand specify it beforehand, because our opponent can do whatever it wants\nand mess up our plan.\nWhen we talk about game graphs some terms you might want to be familiar\nwith are:\n- Branching factor (b)\nThe number of outgoing edges from a single node. In a game graph,\nthis corresponds to the number of possible moves a player can make.\nSo for instance, if we were graphing tic-tac-toe, the branching factor\nwould be 9 (or less, since after a person moves the possible moves are\nlimited, but you get the idea)\n- Ply\nA level of the game tree.\nWhen a player makes a move the game\ntree moves to the next ply.\n- Depth (d)\nHow many plys we need to go down the game tree, or how many moves\nthe game takes to complete. In tic-tac-toe this is probably somewhere\naround 6 or 7 (just made that up...). In chess this is around 40.\n\nAI Techniques For Solving Games\nMinimax\nThe most used game tree search is the minimax algorithm. To get a sense\nfor how this works, consider the following:\nHelen and Stavros are playing a game.\nThe rules of this game are very\nmysterious, but we know that each state involves Helen having a certain\nnumber of drachmas at each state. Poor Stavros never gets any drachmas,\nbut he doesn't want Helen to get any richer and keep bossing him around.\nSo Helen wants to maximize her drachmas, while Stavros wants to minimize\nthem. What should each player do? At each level Helen will choose the move\nleading to the greatest value, and Stavros will move to the minimum-valued\nstate, hence the name \"minimax.\"\nFormally, the minimax algorithm is described by the following pseudocode:\ndef max-value(state,depth):\nif (depth == 0): return value(state)\nv = -infinite\nfor each s in SUCCESSORS(state):\nv = MAX(v,min-value(s,depth-1))\nreturn v\ndef min-value(state,depth):\nif (depth == 0): return value(state)\nv = infinite\nfor each s in SUCCESSORS(state):\nv = MIN(v,max-value(s,depth-1))\nreturn v\n\nAI Techniques For Solving Games\nWe will play out this game on the following tree:\nThe values at the leaves are the actual values of games corresponding to the\npaths leading to those nodes. We will say Helen is the first player to move.\nSo she wants to take the option (A,B,C,D) that will maximize her score. But\nshe knows in the next ply down Stavros will try to minimize the score, etc. So\nwe must fill in the values of the tree recursively, starting from the bottom up.\nHelen maximizes:\nStavros minimizes:\nES.268\n\nAI Techniques For Solving Games\nHelen maximizes:\nSo Helen should choose option C as her first move.\nThis game tree assumes that each player is rational, or in other words they\nare assumed to always make the optimal moves. If Helen makes her decision\nbased on what she thinks Stavros will do, is her strategy ruined if Stavros\ndoes something else (not the optimal move for him)? The answer is no! Helen\nis doing the best she can given Stavros is doing the best he can. If Stavros\ndoesn't do the best he can, then Helen will be even better off!\nConsider the following situation: Helen is smart and picks C, expecting that\nafter she picks C that Stavros will choose A to minimize Helen's score. But\nthen Helen will choose B and have a score of 15 compared to the best she\ncould do, 10, if Stavros played the best he could.\nSo when we go to solve a game like chess, a tree like this (except with many\nmore nodes...) would have leaves as endgames with certain scores assigned\nto them by an evaluation function (discussed below), and the player to move\nES.268\n\nAI Techniques For Solving Games\nwould find the optimal strategy by applying minimax to the tree.\nAlpha-Beta Pruning\nWhile the minimax algorithm works very well, it ends up doing some extra\nwork. This is not so bad for Helen and Stavros, but when we are dealing\nwith trees of size 3640 we want to do as little work as possible (my favorite\nmotto of computer scientists... we try to be as lazy as possible!).\nIn the example above, Helen really only cares about the value of the node\nat the top, and which outgoing edge she should use. She doesn't really care\nabout anything else in the tree. Is there a way for her to avoid having to\nlook at the entire thing?\nTo evaluate the top node, Helen needs values for the three nodes below.\nSo first she gets the value of the one on the left. (we will move from left to\nright as convention). Since this is the first node she's evaluating, there aren't\nreally any short cuts. She has to look at all the nodes on the left branch.\nSo she finds a value of 7 and moves on to the middle branch. After looking\nat the first subbranch of her B option, Helen finds a value of 7. But what\nhappens the next level up? Stavros will try to minimize the value that Helen\nmaximized. The left node is already 7, so we know Stavros will not pick\nanything greater than 7. But we also know Helen will not pick anything in\nthe middle branch less than 7. So there is no point in evaluating the rest of\nthe middle branch. We will just leave it at 7:\nHelen then moves on to the rightmost branch. She has to look at the 10 and\nthe 11. She also has to look at the 2 and 15. But once she finds the 15, she\nknows that she will make the next node up at least 15, and Stavros is going\nES.268\n\nAI Techniques For Solving Games\nto choose the minimum, so he will definitely choose the 10. So there is no\nneed to evaluate the 7.\nSo we saved evaluating 6 out of 26 nodes. Not bad, and often alpha-beta\ndoes a lot better than that.\nFormally, the alpha-beta pruning optimization to the minimax algorithm\nis as follows:\na = best score for max-player (helen)\nb = best score for min-player (stavros)\ninitially, we call max-value(initial, -infinite, infinite, max-depth)\ndef max-value(state, a, b, depth):\nif (depth == 0): return value(state)\nfor s in SUCCESSORS(state):\na = max(a, min-value(s,a,b,depth-1))\nif a >= b: return a \\\\ this ia a cutoff point\nreturn a\ndef min-value(state, a, b, depth):\nif (depth == 0): return value(state)\nfor s in SUCCESSORS(state):\nb = min(b,max-value(s,a,b,depth-1))\nif b <= a: return b \\\\ this is a cutoff point\nreturn b\nThere are a couple things we should point out about alpha-beta compared\nto minimax:\nES.268\n\nAI Techniques For Solving Games\n- Are we guaranteed a correct solution?\nYes! Alpha-beta does not actually change the minimax algorithm, ex\ncept for allowing us to skip some steps of it sometimes. We will always\nget the same solution from alpha-beta and minimax.\n- Are we guaranteed to get to a solution faster?\nNo! Even using alpha-beta, we might still have to explore all bd nodes.\nA LOT of the success of alpha-beta depends on the ordering in which\nwe explore different nodes. Pessimal ordering might causes us to do\nno better than Manama's, but an optimal ordering of always exploring\nthe best options first can get us to only the square root of that. That\nmeans we can go twice as far down the tree using no more resources\nthan before. In fact, the majority of the computational power when\ntrying to solve games goes into cleverly ordering which nodes are ex\nplored when, and the rest is used on performing the actual alpha-beta\nalgorithm.\nInteresting Side Note - Konig's Lemma\nI will use this opportunity to introduce an interesting theorem from graph\ntheory that applies to our game graphs, called Konig's Lemma:\nTheorem: Any graph with a finite branching factor and an infinite num\nber of nodes must have an infinite path.\nProof: Assume we have a graph with each node having finitely many branches\nbut infinitely many nodes. Start at the root. At least one of its branches\nmust have an infinite number of nodes below it. Choose this node to start\nour infinite path. Now treat this new node as the root. Repeat. We have\nfound an infinite path.\nHow does this apply to our game trees? This tells us that for every game,\neither:\n1. It is possible for the game to never end.\n2. There is a finite maximum number of moves the game will take to\nterminate.\nES.268\n\nAI Techniques For Solving Games\nNote that we are assuming a finite branching factor, or in other words, each\nplayer has only finitely many options open to them when it is his or her turn.\nImplementation\nAs we have said over and over again, actually implementing these huge game\ntrees is often a huge if not impossible challenge. Clearly we cannot search\nall the way to the bottom of a search tree. But if we don't go to the bottom,\nhow will we ever know the value of the game?\nThe answer is we don't. Well, we guess. Most searches will involve search\ning to some preset depth of the tree, and then using a static evaluation\nfunction to guess the value of game positions at that depth.\nUsing an evaluation function is an example of a heuristic approach to solv\ning the problem. To get an idea of what we mean by heuristic, consider the\nfollowing problem: Robby the robot wants to get from MIT to Walden Pond,\nbut doesn't know which roads to take. So he will use the search algorithm\nhe wrote to explore every possible combination of roads he could take lead\ning out of Cambridge and take the route to Walden Pond with the shortest\ndistance.\nThis will work...\neventually.\nBut if Robby searches every possible path,\nsome other paths will end up leading him to Quincy, some to Providence,\nsome to New Hampshire, all of which are nowhere near where he actually\nwants to go. So what if Robby refines his search. He will assign a heuristic\nvalue, the airplane (straight line) distance to each node (road intersection),\nand direct his search so as to choose nodes with the minimum heuristic value\nand help direct his search toward the goal. The heuristic acts as an estimate\nthat helps guide Robby.\nSimilarly, in game search, we will assign a heuristic value to each game state\nnode using an evaluation function specific to the game. When we get as far\nas we said we would down the search tree, we will just treat the nodes at\nthat depth as leaves evaluating to their heuristic value.\nES.268\n\nAI Techniques For Solving Games\nEvaluation Functions\nEvaluation functions, besides the problem above of finding the optimal or\ndering of game states to explore, is perhaps the part of game search/play\nthat involves the most actual thought (as opposed to brute force search).\nThese functions, given a state of the game, will compute a value based only\non the current state, and cares nothing about future or past states.\nAs an example evaluation, consider one of the type that Shannon used in\nhis original work on solving chess. His function (from White's perspective)\ncalculates the value for white as:\n- +1 for each pawn\n- +3 for each knight or bishop\n- +5 for each rook\n- +9 for each queen\n- + some more points based on pawn structure, board space, threats,\netc.\nit then calculates the value for black in a similar manner, and the value of\nthe game state is equal to White's value minus Black's value. Therefore the\nhigher the value of the game, the better for white.\nFor many games the evaluation of certain game positions have been stored in\na huge database that is used to try to \"solve\" the game. A couple examples\nare:\n- OHex - partial solutions to Hex games\n- Chinook - database of checkers positions\nAs you can see, these functions can get quite complicated. Right now, eval\nuation functions require tedious refinements by humans and are tested rig\norously through trial and error before good ones are found. There was some\nwork done (cs.cmu.edu/ jab/pubs/propo/propo.html) on ways for machines\nto \"learn\" evaluation functions based on machine learning techniques. If ma\nchines are able to learn heuristics, the possibilities for computer game playing\nES.268\n\nAI Techniques For Solving Games\nwill be greatly broadened beyond our current pure search strategies.\nLater we'll see a different way of evaluating games, using a class of num\nbers called the surreal numbers, developed by John Conway.\nSolving a Game\nWe often talk about the notion of \"solving\" a game. There are three basic\ntypes of \"solutions\" to games:\n1. Ultra-weak The result of perfect play by each side is known, but the\nstrategy is not known specifically.\n2. Weak The result of perfect play and strategy from the start of the\ngame are both known.\n3. Strong The result and strategy are computed for all possible positions.\nHow far do we need to Search?\nHow far do we need to search down the tree for our computer player to be\nsuccessful? Consider the following graph (the vertical axis is a chess ability\nscore):\n(taken from 6.034 coursenotes).\nDeep Blue used 32 processors, searched 50-10 billion moves in 3 minutes, and\nlooked at 13-30 plys per search.\nClearly, to approach the chess -playing level of world champion humans,\nES.268\n\nAI Techniques For Solving Games\nwith current techniques searching deeper is the key. Also obvious, is that\nreal players couldn't possibly be searching 13 moves deep, so there must be\nsome other factor involved in being good at chess.\nIs game-play all about how many moves we see ahead?\nIf searching deep into the game tree is so hard, how are humans able to\nplay games like Chess and GO so well? Do we play by mentally drawing\nout a game board and performing minimax? It seems that instead humans\nuse superior heuristic evaluations, and base their moves on experience from\nprevious game play or some sort of intuition. Good players do look ahead,\nbut only a couple of plys. The question still remains as to how humans can\ndo so well compared to machines. Why is it hardest for a machine to do\nwhat is easiest for a human?\nAlternative Search Methods\nThere are countless tweaks and alternatives to the maximin and alpha-beta\npruning search algorithms. We will go over one, the proof-number search,\nhere, and leave another variation, conspiracy number search, for our discus\nsion next week on connect four.\nPN-search\nWhile alpha-beta search deals with assigning nodes of the game tree con\ntinuous values, proof number search decides whether a given node is a win\nor a loss. Informally, pn-search can be described as looking for the shortest\nsolution to tell whether or not a given game state is a win or a loss for our\nplayer of interest.\nBefore we talk about proof number search, we introduce AND-OR trees.\nThese are two level alternating trees, where the first level is an OR node, the\nsecond level consists of AND nodes, etc. The tree below is an example:\nES.268\n\nAI Techniques For Solving Games\nIf we assign all the leaves to values (T)rue or (F)alse, we can move up the\ntree, evaluating each node as either the AND of its leaves or the OR of its\nleaves. Eventually we will get the value of the root node, which is what we\nare looking for.\nFor any given node, we have the following definitions:\n- PN-number: The proof number of a node is the minimum number of\nchildren nodes required to be expanded to prove the goal.\n- AND: pn = Σ(pn of all the children nodes)\n- OR: pn = (argmin(pn of children nodes))\n- DN-number: The disproof number is the minimum number of chil\ndren nodes required to disprove the goal.\n- AND: dn = argmin(dn of children nodes)\n- OR: dn = Σ(dn of children nodes)\nES.268\n\nAI Techniques For Solving Games\nWhen we get to a leaf, we will have (pn,dn) either (0, inf), (inf, 0), or (1,1),\nsince the game is either a sure win or sure loss at that point, with itself as\nits proof set. The tree is considered solved when either pn = 0 (the answer\nis true) or dn = 0 (the answer is false) for the root node.\nWhen we take a step back and think about it, an AND/OR tree is very\nmuch a minimax tree. The root starts out as an OR node. So the first player\nhas his choice of options, and he will pick one that allows his root node to\nevaluate to true. The second player must play at an AND node: unless he\ncan make his node T no matter what, (so F for player 1), then player one\nwill just take one of the favorable options left for him. So an AND/OR tree\nis just a min/max tree in a sense, with ORs replacing the MAX levels and\nAND replacing the MIN levels.\nPN search is carried out using the following rough outline:\n1. Expand nodes, update pn and dn numbers.\n2. Take the node with the lowest pn or dn, propagate the values back up\nuntil you reach the root node ∗ .\n3. Repeat until the root node has pn=0 or dn = 0.\nThe slightly tricky part of this is the second step. What we really want to\nfind is the Most Proving Node. Formally, this is defined as the frontier\nnode of an AND/OR tree, which by obtaining a value of True reduces the\ntree's pn value by 1, and obtaining a value of False reduces the dn by 1.\nSo evaluating this node is guaranteed to make progress in either proving or\ndisproving the tree.\nAn important observation is that the smallest proof set to disprove a node\nand the smallest proof set to prove a node will always have some nodes in\ncommon. That is, their intersection will not be empty. Why is this? In a\nbrief sketch of a proof by contradiction, assume for the contrary that they\nhad completely disjoint sets of nodes. Then we could theoretically have a\ncomplete proof set and a complete disproof set at the same time. But we\ncannot both prove and disprove a node! So the sets must share some nodes\nin common.\nES.268\n\nAI Techniques For Solving Games\nWhat we get out of all of this is that we don't really have to decide whether\nwe will work on proving or disproving the root node, as we can make progress\ndoing both. So now we can be certain of what we will do at each step of the\nalgorithm. The revised step 2 from above is:\nAt an OR level, choose the node with the smallest pn to expand. At an\nAND level, choose the node with the smallest dn to expand.\nThe tree below is an example of pn search, taken from Victor Allis's \"Search\ning for Solutions, \" in which \"R\" is the \"most-proving node.\"\nOthers\nI will just briefly mention a couple of other variations on game search that\nhave been tried, many with great success.\n- Alpha-beta, choosing a constrained range for alpha and beta before\nhand.\n- Monte Carlo with PN search: randomly choose some nodes to expand,\nand then perform pn-search on this tree\n- Machine learning of heuristic values\n- Group edges of the search tree into \"macros\" (we will see this)\n- A gazillion more.\nCourtesy of Victor Allis. Used with permission. Fig. 2.3 from \"Searching for Solutions in Games and\nArticial Intelligence.\" Doctoral Thesis. State University of Limburg in Maastricht, 1994, pp. 24.\nES.268\n\nAI Techniques For Solving Games\nNext Time: Connect Four and Conspiracy Number Search!\nReferences\n- Victor Allis, Searching for Solutions, http://fragrieu.free.fr/SearchingForSolutions.pdf\n- Intelligent Search Techniques:\nProof Number Search, MICC/IKAT\nUniversiteit Maastricht\n- Various years of 6.034 lecture notes\nES.268\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nES.268 The Mathematics in Toys and Games\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "ES.268 AI and game search, Slides 4",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/eb00dffa33db1a6bfb6a653cd5bd9338_MITES_268S10_ses4_slides2.pdf",
      "content": "Artificial Intelligence and Games\nES.268 Spring 2010\n\nOutline\nComplexity, solving games\nKnowledge-based approach (briefly)\nSearch\n± Chinese Checkers\nMinimax\nEvaluation function\nAlpha-beta pruning\n± Go\nMonte Carlo search trees\n\nSolving Games\nSolved game: game whose outcome can be\nmathematically predicted, usually assuming\nperfect play\nUltra weak: proof of which player will win,\noften with symmetric games and a strategy-\nstealing argument\nWeak: providing a way to play the game to\nsecure a win or a tie, against any opponent\nstrategies and from the beginning of the game\nStrong: algorithm for perfect play from any\nposition, even if mistakes were made\n\nSolved Games\nTic ʹ Tac ʹ Toe: draw forceable by either player\nM,n,k ʹ game: first-player win by strategy-\nstealing; most cases weakly solved for k <= 4,\nsome results known for k = 5, draw for k > 8\nGo: boards up to 4x4 strongly solved, 5x5 weakly\nsolved for all opening moves, humans play on\nϭεdzϭεdZAƌEƐƐƚsuuǁZƌUsYOZYsƚ\nNim: strongly solved for all configurations\nConnect Four: First player can force a win, weakly\nsolved for boards where width + height < 16\nCheckers: strongly solved, perfect play by both\nsides leads to a draw\n\nGame Complexity\nState-space complexity: number of legal game\npositions reachable from initial game position\nGame tree size complexity: total number of\npossible games that can be played\nDecision complexity: number of leaf nodes in the\nsmallest decision tree that establishes the value\nof the initial position\nGame-tree complexity: number of leaf nodes in\nthe smallest full-width (all nodes at each depth)\ndecision tree that establishes the value of the\ninitial position; hard to even estimate\nComputational complexity: as the game grows\narbitrarily large, such as if board grows to nxn\n\nKnowledge-based method\n/YZƌEGƌZIswƉZƌƚAYĐG\n1. /IƚSGƌGƐAǁsYYsYOwZǀGƚAUGsƚ\n2. If the opponent has a winning move, take it\n3. Take the center square over edges and corners\n4. Take any corners over edges\n5. dAUGGEOGƐsIƚSGLJƌGƚSGZYuLJƚSsYOAǀAsuAduG\nWhite ʹ human; black -- computer\nCourtesy of Victor Allis. Used with permission. Figure 2.5 in\n\"A Knowledge-based Approach of Connect-Four. The Game is Solved: White Wins.\" Master's Thesis, Vrije University, 1988, pp. 14.\n\nChinese Checkers\n\nOriginated from a game called Halma,\ninvented in 1883 or 1884, first\nmarketed as Stern-Halma (Star\nHalma) in Germany\n\nEAwGESsYGƐGSGĐUGƌƐIZƌdGƚƚGƌ\nmarketing in the United States\n\n2-6 players\n\nStar-shaped board with 6 points, 121\nholes\n\nGoal: move all 10 marbles from your\nbeginning point of the star to the\nopposite end\n\nCan move marble to adjacent hole, or\ncan jump (multiple contiguous jumps\nare allowed) over another marble\n\nNo captures (i.e. jumped pieces are\nnot removed)\nCourtesy of Paula Sjoland. Used with permission.\n\nSearch Trees\nNodes\nrepresent\nstates of the\ngame\nEdges\nrepresent\npossible\ntransitions\nEach state can\nbe given a\nvalue with an\nevaluation\nfunction\n\nMinimax\nApplied to two-player games with perfect\ninformation\nEach game state is an input to an evaluation\nfunction, which assigns a value to that state\nThe value is common to both players, and one\nperson tries to minimize the value, while the\nother tries to maximize it\nTo keep the tree size tractable, could limit\nsearch depth or prune branches\nEnd-of-game detection at end of every turn\n\nChinese Checkers Evaluation Function\nEvaluate the situation and decide which\nmoves are best.\nOutput of the evaluation function should be\ncommon to both players\nIdeas for criteria?\n\nChinese Checkers Evaluation Function\nMoving marbles a long distance via a\nsequence of jumps are best;\nMarbles can move laterally, but is that\nefficient? Æ put more weight on moves that\nemphasize the middle of the board;\nTrailing marbles that cannot hop over\nanything take really long to catch up Æ put\nmore weight on moves that get rid of trailing\nmarbles;\n\nAlpha-beta pruning\nCourtesy of Paula Sjoland. Used with permission.\n\nGeneralization\nThink about criteria for a good evaluation\nfunction of the game state\nStart with the basic mini-max algorithm, and\napply optimizations\nPlay around with search order in alpha-beta\npruning\nLook into other more efficient algorithms such\nAƐ\n\nMonte Carlo tree search ʹ computer Go\nFor each potential move, playing out\nthousands of games at random on the\nresulting board\nPositions evaluated using some game score or\nwin rate out of all the hypothetical games\nMove that leads to the best set of random\ngames is chosen\nRequires little domain knowledge or expert\ninput\nTradeoff is that some times can do tactically\ndumb things, so combined with\n\nUCT -- 2006\nhƉƉGƌZYIsEGYĐGdZƵYEAƉƉusGEƚZdƌGGƐ\nExtension of Monte Carlo Tree Search (MCTS)\nFirst few moves are selected by some tree\nsearch and evaluation function\nRest played out in random like in MCTS\nImportant or better moves are emphasized\n\n^sEGƋƵGƐƚsZY\ntSAƚƐƚSG\nshortest\npossible\ngame of\nChinese\nTo see a diagram of David Fabian's 30 move game of Chinese Checkers, please\ngo to page 8 of the following article:\nBell, George I. The Shortest Game of Chinese Checkers and Related Problems.\nIntegers: Electronic Journal of Combinatorial Number Theory 9 (2009).\nCheckers?\nPart of a set\nof army-\nmoving\nproblems by\nMartin\nGardner\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nES.268 The Mathematics in Toys and Games\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "ES.268 Blackjack/poker, Slides 9",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/91d992f1d8be60e2069ee56422ce08e9_MITES_268S10_ses9_slides.pdf",
      "content": "Mathematics of Card Games Appendix\nProbability of Cribbage Scores\nScore\nProbability\n0.0788\n0.007801\n0.2188\n0.03929\n0.2212\n0.05419\n0.1375\n0.05803\n0.08604\n0.02719\n0.02887\n0.003241\n0.02374\n0.001172\n0.006729\n0.00066\n0.004407\n0.0008613\n0.000173\n0.0006024\n0.0001902\n0.00003417\n0.0000274\n0.0002832\n0.00000585\n0.000000308\nBlackjack Odds of Busting\nHand Value\n11 or less\n% Bust if you Hit\n100%\n92%\n85%\n77%\n69%\n62%\n58%\n56%\n39%\n31%\n0%\n\n\"Basic\" Blackjack Strategy\nHard Hands: Starting hand does not contain an Ace\n- If you have eight or less, always hit.\n- If you have Nine: Double if the dealer has 3 thru 6 - otherwise hit.\n- If you have Ten : Double if the dealer has 2 thru 9 - otherwise hit.\n- If you have Eleven: Double if the dealer has 2 thru 10, Hit if dealer has Ace.\n- If you have Twelve: Hit if the dealer has 2 or 3, Stand if the dealer has 4 thru 6,\notherwise hit.\n- If you have 13- 16: Stand if the dealer has2 thru 6, otherwise hit.\n- If you have 17 - 21: Always Stand.\nSoft Hands: Starting hand contains an Ace\n- If you have Ace 2 or Ace 3: Double if the dealer has 5 or 6 - otherwise hit.\n- If you have Ace 4 or Ace 5: Double if the dealer has 4 thru 6 - otherwise hit.\n- If you have Ace 6: Double if the dealer has 3 thru 6 - otherwise hit.\n- If you have Ace 7: Stand if the dealer has 2, 7 or 8. Double 3 -thru 6 - otherwise\nhit.\n- If you have Ace 8 or Ace 9: Always Stand.\nPairs: Starting hand contains a pair\n- If you have a pair of Aces or Eights: Always split.\n- If you have a pair of twos or threes: Split if the dealer has 2 - 7, otherwise hit.\n- If you have a pair of fours: Split if the dealer has 5 or 6 - otherwise hit.\n- If you have a pair of fives: Double if the dealer has 2 thru 9 - otherwise hit.\n- If you have a pair of sixes: Split if the dealer has 2 thru 6 - otherwise hit.\n- If you have a pair of sevens: Split 2 thru 7 - otherwise hit.\n- If you have a pair of nines: Split 2 thru 6, and 8 or 9. Stand if the dealer has 7, 10\nor Ace.\n- If you have a pair of tens: Always Stand.\nCard Game Rules\nCribbage Gameplay\n1. The Deal: The players cut for first deal, and the dealer shuffles and deals five or\nsix cards to each player, depending on the number of players. For two players,\neach is dealt six cards; for three or four players, each is dealt five cards. In the\ncase of three players, a single card is dealt face down in the centre of the table to\nstart the crib. Once the cards have been dealt, each player chooses four cards to\nretain, then discards the other one or two face-down to form the \"crib\" which will\nbe used later by the dealer. At this point, each player's hand and the crib will\ncontain exactly four cards. The player on the dealer's left cuts the deck and the\n\ndealer reveals the top card, called the \"starter\". If this card is a Jack, the dealer\nscores two points for \"his nibs.\"\n2. The Play: Starting with the player on the dealer's left, each player lays one card\nin turn onto a personal discard pile, stating the cumulative value of the cards laid\n(for example, the first player lays a five and says \"five\", the next lays a six and\nsays \"eleven\", and so on), without the total going above 31. Once no more cards\ncan be played, the cumulative position is reset to zero and those players with\ncards remaining repeat the process until all players' cards have been played.\nPlayers score points during this process for making a total of fifteen, for reaching\nexactly, or as close as possible to a total of thirty-one, for runs and for pairs.\n3. The Show: Once the play is complete, each player in turn receives points based\non the content of his hand in conjunction with the starter card. Points are scored\nfor combinations of cards totaling fifteen, runs, pairs, flushes and having nibs.\nThe dealer scores his hand last and then turns the cards in the crib face up. These\ncards are then scored by the dealer as an additional hand in conjunction with the\nstarter card. Scores between 0 and 29 are all possible, with the exception of 19,\n25, 26 and 27.\nBlackjack Gameplay\nBefore each round of play, the player places his bet. Each player and the dealer\ninitially receive two cards; only one of the dealer's cards is shown to the player. A card's\nvalue is equal to its rank, but picture cards are worth 10; an ace is worth either 1 or 11.\nFor simplicity, refer to all 10-valued cards as 10. The player has several options,\ndepending on his cards. He may:\n-\nHit: Draw another card. A player is allowed to hit any hand not exceeding 21. If\nthe player's card total exceeds 21, he has 'busted,' and automatically loses his bet.\n-\nStand: Draw no more cards.\n-\nDouble down: Double the original bet and receive one card only. This option is\nallowed on a two-card hand only.\n-\nSplit: If the player has two cards of equal value, he may place another bet equal\nto his original one, and play each card as a separate hand. Exceptions: if the\nplayer splits two aces, he receives only one card on each; an (A 10) counts as 21,\nnot blackjack; and even if resplitting is allowed otherwise, the player may not\nresplit aces.\nFive-Card Draw Poker Gameplay\n1. Big/Small blind put in antes (or there's the recreational variation where everyone\nputs in a small ante).\n2. Each player is dealt five cards.\n\n3. One round of betting, starting with the dealer's left.\n4. Trade in from 0 to three cards from the remaining deck (if you have an ace you\ncan trade 4 cards).\n5. After receiving new cards, there is another round of betting.\n6. Players show their hands to determine who won the pot (using standard hand\nrankings).\nTexas Hold'em Poker Gameplay\n1. The two players to the left of the dealer put out blind bets. The player directly to\nthe dealer's left puts out the small blind while the player two to the dealer's left\nputs out the big blind.\n2. Every player is dealt two cards, face down. These are called hole or pocket cards.\n3. The action, or the first move, falls on the player to the left of the big blind. She\ncan either call the bet, raise it, or fold. Betting continues around the table,\nclockwise.\n4. After the betting is completed, three cards are dealt face up in the center of the\ntable, which is referred to as the board. The first three cards in Texas Hold'em are\ncalled the flop. These cards are \"community cards\" meaning everyone can (and\nwill) use them in combination with their own hole cards to make the best hand.\n5. From the flop on, betting begins with the player to the dealer's left, who can\ncheck or bet.\n6. A fourth card is dealt face up onto the board. This is called fourth street or the\nturn card.\n7. Another round of betting.\n8. The final card is dealt face up. This card is also called fifth street or the river.\n9. A final round of betting occurs. The remaining players show their cards and the\nperson who can make the best five card hand by combining their pocket cards\nwith the cards on the board wins.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nES.268 The Mathematics in Toys and Games\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "ES.268 Connect four and additional AI topics, Course Notes 5",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/94a5d1da64c57cbc5fdf135d985445a9_MITES_268S10_Ses5_ConFour.pdf",
      "content": "Intro to A.I. Topics\nConnect Four\nMarch 12, 2009\nIntroduction\nConnect Four is a tic-tac-toe like game in which two players drop discs into\na 7x6 board. The first player to get four in a row (either vertically, horizon\ntally, or diagonally) wins.\nThe game was first known as \"The Captain's Mistress\", but was released\nin its current form by Milton Bradley in 1974. In 1988 Victor Allis solved\nthe game, showing that with perfect play by both players, the first player\ncan always win if he plays the middle column first, and if he chooses another\ncolumn first the second player can always force a draw.\nToday we will explore the different strategies involved in playing connect\nfour, how a computer could emulate these strategies, and how these tech\nniques relate to other artificial intelligence topics involved in solving games\nwith large search spaces.\nFor convenience, we will call the first player white (W) and the second player\nblack (B).\nNote that we initially get somewhat detailed about game situations, but\ndo not get bogged down in the details. The important part is how we will\nuse the fact that these details exist to make a game-winning strategy.\n\nConnect Four / Intro to A.I. and Board Representation\nSolvability\nWhen looking for a strong solution to a game (recall from last time that\na strong solution means knowing the outcome of the game from any given\nboard position) one strategy to try would be storing all possible game posi\ntions in a database, exploring the tree of game play from each position, and\ndetermining the winner in each case. We will see that this strategy, at least\nat this time, is not really feasible for Connect Four (and even much less so\nfor more complex games like GO and chess...).\nFirst we look for an upper bound on the number of possible Connect Four\nboard positions. Each grid square can be in one of 3 states: black, white,\nor empty. Since there are 7x6 = 42 squares, this gives a very crude upper\nbound of 342 ≥ 1020 . A not so much closer look reveals that we can get a\nmuch tighter upper bound by noticing that many positions we counted before\nwere illegal. For instance, if one square is empty in a column, then all the\nsquares above it must also be empty. So we throw these possible positions\nout. Removing these configurations gives a better upper bound of 7.1 ∗ 1013\npossible positions.\nThere are other types of illegal positions that are harder to detect.\nFor\ninstance, if we are assuming that white moves first, then some game config\nurations, such as a stack in one column from bottom up of BWBWBW is\nimpossible, since black would have had to move first. It turns out that no\none has been able to weed out all of these positions from databases, but the\nbest lower bound on the number of possible positions has been calculated by\na computer program to be around 1.6 ∗ 1013 . So we would need at least that\nmany positions stored to do a brute force search of the game. That would\ntake an estimated 4 Terabytes of memory. Not so practical...\nAs we saw last time with the tic-tac-toe example, this strategy won't al\nways work. In general, we must classify these sorts of rules into two classes:\n- Rules that guarantee a certain results (and require proof that they do\nso)\n- Heuristic rules that are generally advantageous but are not without\ndownfall (like the strategy given above)\nES.268\n\nConnect Four / Intro to A.I. and Board Representation\nWe'll explore possible strategies to follow for Connect Four below. After\ndescribing a set of general rules to follow, we will see a new type of search,\nconspiracy number search, related to the pn-search technique from last week.\nFirst we'll learn some terminology associated with describing the strategy.\nNomenclature We will number the 7 x 6 board with columns a to g left to right and\nnumbers 1 to 6 from bottom to top. So the coveted middle bottom\nsquare is d1.\nThreat A threat is a square that if taken by opponent forms a game-winning\ngroup of four. For example, in the game board below White has threats\nat b1 and f1.\nUseless Threat A useless threat is a threat that will never be able to be carried out\nCourtesy of Victor Allis. Used with permission. Figure 3.9 in \"A Knowledge-based Approach of\nConnect-Four. The Game is Solved: White Wins.\" Master's Thesis, Vrije University, 1988, pp. 22.\nES.268\n\nConnect Four / Intro to A.I. and Board Representation\nby the opponent. Note that a threat can only be carried out if the\nopponent is forced to play the square below the threat.\nThe picture below illustrates the concept of a useless threat. In this\ngame, it is White's turn to move. It appears that White has threats\nat b2, b3, b4, b5, b6, f2, f3, f4, f5, and f6. But Black has threats at\nb2, b6, f2, and f6. Clearly the lower numbered squares will be filled in\nfirst, and so since both White and Black have threats at b2 and f2, no\nother threats matter, since they are all above threats shared between\nplayers. So all squares but b2 and f2 are useless threats.\nOdd and Even Threats It is clear that a threat can only be carried out if the opponent is forced\nto play the square below (or he allows you to play below the threat).\nIn analyzing threats, certain patterns show up in how the squares are\ndividing among players.\nThe odd/evenness of a threat is determined by the row number. So\nd1 is an odd threat, etc. If we were to just fill up the board, for the\nmost part, White will get the odd squares and Black will get the evens.\nClearly, White starts with an odd square (1). Say we have filled up\nthe entire board except the last column. If play continues until the\nboard is filled up, it must be true that White will get the remaining\nodd squares and Black the remaining evens: we must end with Black,\nsince play alternates between players and there are an even number of\nsquares, and so black must get the top (6), white must get 5, etc. This\neven/odd pattern continues throughout the game in general (of course\nit is possible for White to get some even squares and Black to get some\nCourtesy of Victor Allis. Used with permission. Figure 3.1 in \"A Knowledge-based Approach of Connect-Four.\nThe Game is Solved: White Wins.\" Master's Thesis, Vrije University, 1988, pp. 16.\nES.268\n\nConnect Four / Intro to A.I. and Board Representation\nodds). So if we get to the last column and White has an even threat\nand Black has an odd threat, the game will end in a draw.\nIf White has an odd threat and Black has an even threat in the same col\numn, the lower threat will win. If the threats are in different columns,\nWhite's is stronger. In general, we see the following patterns:\n- White has an odd threat, Black even: White wins\n- White and Black both have even threats: there is no column where\nan odd number of squares can be played, so both players will get\ntheir normal squares (as defined above), and Black will be able to\nrefute White's threat and win.\n- White has an even threat, Black an odd threat: draw.\n- White and Black both have odd threats: usually neither of these\nthreats end up working and depend on other threats.\nIn a careful analysis of threats it is important to make sure that taking\ncare of one threat does not allow another threat to be created.\nZugzwang The formal definition of this strange German word: a situation where\na player is forced to make a move when he would rather make no move\nat all.\nIn connect four, a player is able to \"control the zugzwang\" if the player\nis able to guide the way odd and even squares are divided up among\nplayers.\nAs an example, we look at the following game situation (Allis 26),\nwhere White is about to move:\nES.268\n\nConnect Four / Intro to A.I. and Board Representation\nNote that all columns contain an even number of pieces, so White will\nnever fill up a column since it must take only odd squares. So Black\ncan just play \"follow-up\" and mimic White's every move. This will\nresult in the following position:\nNow White must play either b1 or f1, which Black will follow, and win\nthe game with a group of four on the second row.\nSo in conclusion, Zugzwang involves being able to divide up how even\nand odd squares are distributed to the two players. Black wanted only\neven squares because eventually it would be able to fulfill its threat at\neither b2 or f2. But if it had wanted odd squares, it could have just\nstopped playing follow up and played in a different column.\nRules\nAs an example of using a knowledge based approach to teach a computer\nto play a game, the following rules were used in programming VICTOR to\nCourtesy of Victor Allis. Used with permission. Figure 4.2 in \"A Knowledge-based Approach of\nConnect-Four. The Game is Solved: White Wins.\" Master's Thesis, Vrije University, 1988, pp. 25.\nCourtesy of Victor Allis. Used with permission. Figure 4.3 in \"A Knowledge-based Approach of\nConnect-Four. The Game is Solved: White Wins.\" Master's Thesis, Vrije University, 1988, pp. 26.\n\nConnect Four / Intro to A.I. and Board Representation\nwin connect four. Each rule classifies threats and gives solutions to some of\nthem. Each rule is valid for the player that controls the Zugzwang, which\nis assumed to be black in the following examples. Each of these \"rules\" is a\npossible winning connection for the player.\nClaimeven Controller of zugzwang can get all empty even squares which are not\ndirectly playable by letting the opponent play all empty odd squares.\nRequired: Two squares, directly above each other. Both squares are\nempty, the upper square must be empty.\nSolutions: All groups which contain the upper square.\nBaseinverse Based on the fact that a player cannot play two directly playable\nsquares in one turn.\nRequired: Two directly playable squares\nSolutions: All groups which contain both squares.\nVertical Based on the face that a player cannot play two men in the same col\numn in one turn, while by playing one man in the column, the square\ndirectly above becomes immediately playable.\nRequired: two squares directly above each other. Both squares empty,\nupper square must be odd.\nSolutions: all groups which contain both squares\nAftereven Side-effect of one or more claimevens. If a player in control of zugzwang\ncan complete a group using squares from claimeven, he will eventually\nbe able to finish the group.\nRequired: a group which can be completed by the controller of the\nzugzwang, using only squares of a set of claimevens.\nSolutions: all groups which have at least one square in all aftereven\ncolumn,s above the empty aftereven group in that column. Also, all\ngroups which are solved by the claimevens.\nES.268\n\nConnect Four / Intro to A.I. and Board Representation\nLowinverse Based on the face that the sum of two odd numbers is even.\nRequired: two different columns, each with 2 squares lying directly\nabove each other. All must be empty and the upper square must be\nodd.\nSolution: All groups which contain both upper squares, all groups\nwhich are solved by verticals.\nHighinverse Based on the same principle as lowinverse:\nRequired: Two columns which 3 empty squares each, upper square\nis even.\nSolutions: all groups which contain the two upper squares, groups\nwhich contain the two middle squares, all vertical groups which contain\nthe two highest squares of one of the highinverse columns\nIf the lower square of the first columns is directly playable: all groups\nwhich contain both he lower square of the first column and the upper\nsquare of the second.\nIf the lower square of the second column is directly playable: all groups\nwhich contain both the lower square of the second column and the\nupper square of the first column.\nBaseclaim Combination of two basinverses and a claimeven.\nRequired:Three directly playable squares and the square above the sec\nond playable square. The non-playable square must be even.\nSolutions:Solutions: All groups which contain the first playable square\nand the square above the second playable square. All groups which\ncontain the second and third playable square.\nBefore Based on a combination of claimevens and verticals\nRequired: A group without men of the opponent, which is called the\nBefore group. All empty squares of the Before group should not lie in\nES.268\n\nConnect Four / Intro to A.I. and Board Representation\nthe upper row of the board.\nSolutions:All groups which contain all squares which are successors of\nempty squares in the Before group. All groups which are solved by the\nVerticals which are part of the Before. All groups which are solved by\nthe Claimevens which are part of the Before\nSpecialbefore A version of the before\nRequired: A group without men of the opponent, which is called the\nSpecialbefore group.\nA directly playable square in another column.\nAll empty squares of the Specialbefore group should not lie in the up\nper row of the board. One empty square of the Before group must be\nplayable.\nSolutions: All groups which contain all successors of empty squares\nof the Specialbefore group and the extra playable square. All groups\nwhich contain the two playable squares. All groups which are solved\nby one of the Claimevens. All groups which are solved by one of the\nVerticals.\nComputer Solution Implementation\nVictor Allis's program VICTOR developed a method of finding an optimal\nstrategy based on the 9 rules given above. The position evaluator (white or\nblack) is given a description of the board and comes up with an optimal next\nmove.\nFirst all possible instances of the nine rules above are found and checked\nagainst all 69 possibilities to connect winning groups. The rule applications\nthat solve at least one problem are stored in a list of solutions with a list of\nthe groups solved by the solution and a list of other solutions that can be\nused to solve the problem.\nThe next step is finding which solutions can work together.\nFirst all so\nES.268\n\nConnect Four / Intro to A.I. and Board Representation\nlutions are assembled as nodes into an undirected graph, where two nodes\nare connected if and only if they can't be used simultaneously. These con\nnections are stored in an adjacency matrix. Then, the problems (threats) are\nadded as nodes, and solutions are connected with problems if they solve the\nproblem (no problems are connected).\nNote that two rules might not necessarily be able to be used at the same\ntime. The following table describes the relationships between rules (taken\nfrom Allis, section 7.4):\nThen we solve the following problem:\nGiven: Two sets of nodes, S(olutions) and P (roblems). Try to find an in\ndependent subset C of S with the property that P is contained in the set\nof all neighbors of C, B(C). (Note this is a potentially NP-complete problem)\nThe following recursive algorithm was used by Allis:\nCourtesy of Victor Allis. Used with permission. In \"A Knowledge-based Approach of Connect-Four.\nThe Game is Solved: White Wins.\" Master's Thesis, Vrije University, 1988, pp. 50.\nES.268\n\nConnect Four / Intro to A.I. and Board Representation\nif (P == EmptySet) {\nEureka() /* We have found a subset C which meets all constraints. */\n} else {\nMostDifficultNode = NodeWithLeastNumberOfNeighbours(P);\nfor (all neighbours of MostDifficultNode) {\nFindChosenSet(P - { MostDifficultNode },\nS - AllNeighboursOf(ChosenNeighbour));\n}\n}\n}\nConspiracy Number Search\nThe actual solution to connect four was arrived at using the above methods\ncombined with search tables storing the values of different game positions\nas well as using traditional game search methods. In particular, Allis used\nconspiracy-number search, which is very closely related to the proof num\nber search that we talked about last week. In the instance of connect four,\nconsider three types of nodes: -1 black can at least draw the game, 1 the\ngame is a win for white, or 0 the game is as yet undecided. Now any node\nthat has as a child a node with a value of 1 can be colored 1. Any node that\nhas all nodes colored -1 can be colored -1. Note it is much easier to change\na node to a 1 than a -1.\nThe conspiracy number of a node is a tuple of counts for the number of\nchildren needed to \"conspire\" to change the value of the node to each of the\npossible values. Let (x, y) be the conspiracy number of a node, with x the\nnumber of nodes that need to conspire to change the value to 1, and y to\n-1. We know x will always be 1, since we only need one child of value 1 to\nchange our value to 1. But y is the number of ones of the node yet to be\nevaluated if all those evaluated so far have been -1. If sons have already been\nevaluated to 1, then y is inf.\nThe purpose of conspiracy number search, like pn-search is to evaluate as\nfew nodes as possible to find the result of the game tree. Therefore, we try\nto avoid evaluating nodes with large conspiracy numbers. If we want to eval\nuate a node at the top of the tree, we choose the neighbors with the lowest\nFindChosenSet(P, S)\n{\nCourtesy of Victor Allis. Used with permission. In \"A Knowledge-based Approach of Connect-Four.\nThe Game is Solved: White Wins.\" Master's Thesis, Vrije University, 1988, pp. 59.\nES.268\n\nConnect Four / Intro to A.I. and Board Representation\nconspiracy numbers to evaluate until we are sure of their value. We move up\nthe tree in this way, whenever possible avoiding evaluating nodes with large\nconspiracy numbers.\nES.268\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nES.268 The Mathematics in Toys and Games\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "ES.268 Connect four and additional AI topics, Slides 5",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/93065d11435de67c6e650adc02b6c202_MITES_268S10_ses5_slides.pdf",
      "content": "Introduction\nSolvability\nRules\nComputer Solution Implementation\nConnect Four\nMarch 9, 2010\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nConnect Four is a tic-tac-toe like game in which two players drop\ndiscs into a 7x6 board. The first player to get four in a row (either\nvertically, horizontally, or diagonally) wins.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nThe game was first known as \"The Captain's Mistress\", but was\nreleased in its current form by Milton Bradley in 1974. In 1988\nVictor Allis solved the game, showing that with perfect play by\nboth players, the first player can always win if he plays the middle\ncolumn first, and if he chooses another column first the second\nplayer can always force a draw.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nToday we will explore the different strategies involved in playing\nconnect four, how a computer could emulate these strategies, and\nhow these techniques relate to other artificial intelligence topics\ninvolved in solving games with large search spaces.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nFor convenience, we will call the first player white (W) and the\nsecond player black (B).\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nRecall: a strong solution to a game means knowing the\noutcome of the game from any given board position.\nOne strategy to try would be storing all possible game\npositions in a database, exploring the tree of game play from\neach position, and determining the winner in each case.\nWe will see that this strategy, at least at this time, is not\nreally feasible for Connect Four (and even much less so for\nmore complex games like GO and chess).\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nFirst we look for an upper bound on the number of possible\nConnect Four board positions.\nEach grid square can be in one of 3 states: black, white, or\nempty.\nSince there are 7x6 = 42 squares, this gives a very crude\nupper bound of 342 ≥ 1020 .\nA not so much closer look reveals that we can get a much\ntighter upper bound by noticing that many positions we\ncounted before were illegal. For instance, if one square is\nempty in a column, then all the squares above it must also be\nempty. So we throw these possible positions out. Removing\nthese configurations gives a better upper bound of 7.1 ∗ 1013\npossible positions.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nThere are other types of illegal positions that are harder to detect.\nFor instance, if we are assuming that white moves first, then\nsome game configurations, such as a stack in one column\nfrom bottom up of BWBWBW is impossible, since black\nwould have had to move first.\nIt turns out that no one has been able to weed out all of these\npositions from databases\nThe best lower bound on the number of possible positions has\nbeen calculated by a computer program to be around\n1.6 ∗ 1013 . So we would need at least that many positions\nstored to do a brute force search of the game.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nInstead of a brute force search, we can try a knowledge-based\napproach. Instead of searching the entire game space, we can\nformulate general rules that tell which player will win in which\nsituations. We saw this approach fail last week for a computer\nplaying tic-tac-toe.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\n1. If there is a winning move, take it.\n2. If your opponent has a winning move, take the move so he\ncan't take it.\n3. Take the center square over edges and corners.\n4. Take corner squares over edges.\n5. Take edges if they are the only thing available.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nApparently this strategy won't always work. In general, we must\nclassify these sorts of rules into two classes:\nRules that guarantee a certain results (and require proof that\nthey do so)\nHeuristic rules that are generally advantageous but are not\nwithout downfall (like the strategy given above)\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nWe'll explore possible strategies to follow for Connect Four below.\nFirst we'll learn some terminology associated with describing the\nstrategy.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nWe will number the 7 x 6 board with columns a to g left to right\nand numbers 1 to 6 from bottom to top. So the coveted middle\nbottom square is d1.\nCourtesy of Victor Allis. Used with permission. Figure 3.9 in\n\"A Knowledge-based Approach of Connect-Four. The Game is Solved: White Wins.\" Master's Thesis, Vrije University, 1988, pp. 22.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nThreat: A threat is a square that if taken by opponent forms\na game-winning group of four. For example, in the game\nbelow White has threats at b1 and f1:\nCourtesy of Victor Allis. Used with permission. Figure 3.9 in\n\"A Knowledge-based Approach of Connect-Four. The Game is Solved: White Wins.\" Master's Thesis, Vrije University, 1988, pp. 22.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nUseless Threat: A useless threat is a threat that will never be\nable to be carried out by the opponent.\nConnect Four\n\nConnect Four\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nThe picture below illustrates the concept of a useless threat.\nCourtesy of Victor Allis. Used with permission. Figure 3.1 in\n\"A Knowledge-based Approach of Connect-Four. The Game is Solved: White Wins.\" Master's Thesis, Vrije University, 1988, pp. 16.\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nIt is clear that a threat can only be carried out if the opponent is\nforced to play the square below (or he allows you to play below the\nthreat). In analyzing threats, certain patterns show up in how the\nsquares are divided among players.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nOdd and Even Threats\nThe odd/evenness of a threat is determined by the row\nnumber. So d1 is an odd threat, etc.\nIn normal game play, white is most likely to get odd squares,\nwhile black is most likely to get even squares. Why?\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nIn general, we see the following patterns:\nWhite has an odd threat, Black even: White wins\nWhite and Black both have even threats: there is no column\nwhere an odd number of squares can be played, so both\nplayers will get their normal squares (as defined above), and\nBlack will be able to refute Whites threat and win.\nWhite has an even threat, Black an odd threat: draw.\nWhite and Black both have odd threats: usually neither of\nthese threats end up working and depend on other threats.\nIn a careful analysis of threats it is important to make sure that\ntaking care of one threat does not allow another threat to be\ncreated.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nZugzwang:\nThe formal definition of this strange German word: a situation\nwhere a player is forced to make a move when he would rather\nmake no move at all.\nIn connect four, a player is able to \"control the zugzwang\" if\nthe player is able to guide the way odd and even squares are\ndivided up among players.\nAs an example, we look at the following game situation (Allis\n26), where White is about to move:\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nCourtesy of Victor Allis. Used with permission. Figure 4.2 in\n\"A Knowledge-based Approach of Connect-Four. The Game is Solved: White Wins.\" Master's Thesis, Vrije University, 1988, pp. 25.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nNote that all columns contain an even number of pieces, so White\nwill never fill up a column since it must take only odd squares. So\nBlack can just play \"follow-up\" and mimic Whites every move.\nThis will result in the following position:\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nCourtesy of Victor Allis. Used with permission. Figure 4.3 in\n\"A Knowledge-based Approach of Connect-Four. The Game is Solved: White Wins.\" Master's Thesis, Vrije University, 1988, pp. 26.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nNow White must play either b1 or f1, which Black will follow, and\nwin the game with a group of four on the second row.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nSo in conclusion, Zugzwang involves being able to divide up how\neven and odd squares are distributed to the two players. Black\nwanted only even squares because eventually it would be able to\nfulfill its threat at either b2 or f2. But if it had wanted odd\nsquares, it could have just stopped playing follow up and played in\na different column.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nAs an example of using a knowledge based approach to teach a\ncomputer to play a game, the following rules were used in\nprogramming VICTOR to win connect four.\nEach rule classifies threats and gives solutions to some of\nthem.\nEach rule is valid for the player that controls the Zugzwang,\nwhich is assumed to be black in the following examples. Each\nof these \"rules\" is a possible winning connection for the player.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nClaimeven:\nController of zugzwang can get all empty even squares which\nare not directly playable by letting the opponent play all emtpy\nodd squares.\nRequired: Two squares, directly above each other. Both\nsquares are empty, the upper square must be even.\nSolutions: All groups which contain the upper square.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nCourtesy of Victor Allis. Used with permission. Figure 6.1 in\n\"A Knowledge-based Approach of Connect-Four. The Game is Solved: White Wins.\" Master's Thesis, Vrije University, 1988, pp. 36.\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nBaseinverse:\nBased on the fact that a player cannot play two directly\nplayable squares in one turn.\nRequired: Two directly playable squares\nSolutions: All groups which contain both squares.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nConnect Four\nCourtesy of Victor Allis. Used with permission. Figure 6.2 in\n\"A Knowledge-based Approach of Connect-Four. The Game is Solved: White Wins.\"\nMaster's Thesis, Vrije University, 1988, pp. 37.\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nVertical:\nBased on the face that a player cannot play two men in the\nsame column in one turn, while by playing one man in the\ncolumn, the square directly above becomes immediately\nplayable.\nRequired: two squares directly above each other. Both squares\nempty, upper square must be odd.\nSolutions: all groups which contain both squares\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nCourtesy of Victor Allis. Used with permission. Figure 6.3 in\n\"A Knowledge-based Approach of Connect-Four. The Game is Solved: White Wins.\" Master's Thesis, Vrije University, 1988, pp. 38.\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nAftereven:\nSide-effect of one or more claimevens. If a player in control of\nzugzwang can complete a group using squares from claimeven,\nhe will eventually be able to finish the group.\nRequired: a group which can be completed by the controller of\nthe zugzwang, using only squares of a set of claimevens.\nSolutions: all groups which have at least one square in all\naftereven columns above the empty aftereven group in that\ncolumn. Also, all groups which are solved by the claimevens.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nCourtesy of Victor Allis. Used with permission. Figure 6.4 in\n\"A Knowledge-based Approach of Connect-Four. The Game is Solved: White Wins.\" Master's Thesis, Vrije University, 1988, pp. 39.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nLowinverse:\nBased on the fact that the sum of two odd numbers is even.\nRequired: two different columns, each with 2 squares lying\ndirectly above each other. All must be empty and the upper\nsquare must be odd.\nSolution: All groups which contain both upper squares, all\ngroups which are solved by verticals.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nCourtesy of Victor Allis. Used with permission. Figure 6.6 in\n\"A Knowledge-based Approach of Connect-Four. The Game is Solved: White Wins.\" Master's Thesis, Vrije University, 1988, pp. 41.\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nHighinverse:\nBased on the same principle as lowinverse:\nRequired: Two columns with 3 empty squares each, upper\nsquare is even.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nSolutions: all groups which contain the two upper squares, groups\nwhich contain the two middle squares, all vertical groups which\ncontain the two highest squares of one of the highinverse columns\nIf the lower square of the first columns i directly playable: all\ngroups which contain both the lower square of the first\ncolumn and the upper square of the second.\nIf the lower square of the second column is directly playable:\nall groups which contain both the lower square of the second\ncolumn and the upper square of the first column.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nBaseclaim:\nCombination of two baseinverses and a claimeven.\nRequired: Three directly playable squares and the square above\nthe second playable square.\nThe non-playable square must be even.\nSolutions:\nAll groups which contain the first playable square and the\nsquare above the second playable square.\nAll groups which contain the second and third playable square.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nCourtesy of Victor Allis. Used with permission. Figure 6.7 in\n\"A Knowledge-based Approach of Connect-Four.The Game is Solved: White Wins.\" Master's Thesis, Vrije University, 1988, pp. 42.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nBefore:\nBased on a combination of claimevens and verticals\nRequired: A group without men of the opponent, which is\ncalled the Before group. All empty squares of the Before group\nshould not lie in the upper row of the board.\nSolutions: All groups which contain all squares which are\nsuccessors of empty squares in the Before group.\nAll groups which are solved by the Verticals which are part of\nthe Before.\nAll groups which are solved by the Claimevens which are part\nof the Before\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nCourtesy of Victor Allis. Used with permission. Figure 6.8 in\n\"A Knowledge-based Approach of Connect-Four. The Game is Solved: White Wins.\" Master's Thesis, Vrije University, 1988, pp. 43.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nSpecialbefore:\nA version of the before\nRequired:\nA group without men of the opponent, which is called the\nSpecialbefore group.\nA directly playable square in another column.\nAll empty squares of the Specialbefore group should not lie in\nthe upper row of the board.\nOne empty square of the Before group must be playable.\nSolutions: All groups which contain all successors of empty\nsquares of the Specialbefore group and the extra playable\nsquare.\nAll groups which contain the two playable squares.\nAll groups which are solved by one of the Claimevens.\nAll groups which are solved by one of the Verticals.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nConnect Four\nCourtesy of Victor Allis. Used with permission. Figure 6.10 in\n\"A Knowledge-based Approach of Connect-Four. The Game is Solved: White Wins.\"\nMaster's Thesis, Vrije University, 1988, pp. 45.\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nVictor Allis's program VICTOR developed a method of finding an\noptimal strategy based on the 9 rules given above. The position\nevaluator (white or black) is given a description of the board and\ncomes up with an optimal next move.\nConnect Four\n\nFirst all possible instances of the nine rules above are found and\nchecked against all 69 possibilities to connect winning groups. The\nrule applications that solve at least one problem are stored in a list\nof solutions with a list of the groups solved by the solution and a\nlist of other solutions that can be used to solve the problem.\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nThe next step is finding which solutions can work together. First\nall solutions are assembled as nodes into an undirected graph,\nwhere two nodes are connected if and only if they can't be used\nsimultaneously. These connections are stored in an adjacency\nmatrix. Then, the problems (threats) are added as nodes, and\nsolutions are connected with problems if they solve the problem\n(no problems are connected).\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nNote that two rules might not necessarily be able to be used at the\nsame time. The following table describes the relationships between\nrules (taken from Allis, section 7.4):\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nConnect Four\nCourtesy of Victor Allis. Used with permission. In\n\"A Knowledge-based Approach of Connect-Four. The Game is Solved: White Wins.\"\nMaster's Thesis, Vrije University, 1988, pp. 50.\n\nThen we solve the following problem:\nGiven: Two sets of nodes, S(olutions) and P(roblems). Try to find\nan independent subset C of S with the property that P is\ncontained in the set of all neighbors of C , B(C ). (Note this is a\npotentially NP-complete problem)\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nThe following recursive algorithm was used by Allis:\nFindChosenSet(P, S) {\nif (P == EmptySet) {\nEureka() /* We have found a subset C meets\nall constraints. */\n} else {\nMostDifficultNode =\nNodeWithLeastNumberOfNeighbours(P);\nfor (all neighbours of MostDifficultNode) {\nFindChosenSet(P - { MostDifficultNode },\nS - AllNeighboursOf(ChosenNeighbour));\n}\n}\n}\nConnect Four\nCourtesy of Victor Allis. Used with permission. In\n\"A Knowledge-based Approach of Connect-Four. The Game is Solved: White Wins.\"\nMaster's Thesis, Vrije University, 1988, pp. 59.\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nOne method used to solve game trees is conspiracy-number\nsearch.\nIn the instance of connect four, consider three types of nodes:\n-1 black can at least draw the game, 1 the game is a win for\nwhite, or 0 the game is as yet undecided.\nNow any node that has as a child a node with a value of 1\ncan be colored 1. Any node that has all nodes colored -1 can\nbe colored -1.\nNote it is much easier to change a node to a 1 than a -1.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nThe conspiracy number of a node is a tuple of counts for the\nnumber of children needed to \"conspire\" to change the value\nof the node to each of the possible values.\nLet (x, y) be the conspiracy number of a node, with x the\nnumber of nodes that need to conspire to change the value to\n1, and y to -1.\nWe know x will always be 1, since we only need one childe of\nvalue 1 to change our value to 1.\nBut y is the number of ons of the node yet to be evaluated if\nall those evaluated so far have been -1.\nIf sons have already been evaluated to 1, then y is inf.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nThe purpose of conpsiracy number search is to evaluated as few\nnodes as possible to find the result of the game tree. Therefore, we\ntry to avoid evaluating nodes with large conspiracy numbers. If we\nwant to evaluate a node at the top of the tree, we choose the\nneighbors with the lowest conspiracy numbers to evaluate until we\nare sure of their value. We move up the tree in this way, whenever\npossible avoiding evalutating nodes with large conspiracy numbers.\nConnect Four\n\nIntroduction\nSolvability\nRules\nComputer Solution Implementation\nConnect Four tournament!\nConnect Four\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nES.268 The Mathematics in Toys and Games\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "ES.268 Constraint logic, Slides 12",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/3c063e9fc173320088576b51415a8e71_MITES_268S10_ses12_slides2.pdf",
      "content": "b\nun\nComplexity of Games & Puzzles\n[Demaine, Hearn & many others]\n\nounded\nbounded\nNP\nPSPACE\nEXPTIME\nP\nUndecidable\nNEXPTIME\nPSPACE\nPSPACE\nRengo Kriegspiel?\nbridge?\nImage courtesy of\nJason Whittaker.\nCourtesy of\nBigJ_Smack\nImage courtesy of\nNguyen Dai.\nImage courtesy of\nHerman Hiddema\nImage courtesy of\nMarie-Lan Nguyen.\nImage courtesy\nof PartsnPieces.\nImage is in the\npublic domain.\nCourtesy of Sam\nCancilla. Used\nwith permission.\nCourtesy of Glenn Peters.\nUsed with permission.\n0 players\n1 player\n2 players\nteam,\n(simulation)\n(puzzle)\n(game)\nimperfect info The computer game Minesweeper.An image of the game Tetris. A square falls from the top of the screen.\nImages by MIT OpenCourseWare.\n\nConstraint Logic\nConstraint Logic\n[Hearn & Demaine 2009]\n[Hearn & Demaine 2009]\nbounded\nunbounded\nPSPACE\nEXPTIME\nP\nUndecidable\nNEXPTIME\nPSPACE\nNP\nPSPACE\n0 players\n1 player\n2 players\nteam,\n(simulation)\n(puzzle)\n(game)\nimperfect info\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nConstraint Graphs\nMachine = graph,\nred & blue edges\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nConstraint Graphs\nMachine state\n= orientation\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\nconstraint graph\n\nConstraint Logic\n= 1\n= 2\nRule: at least 2 units\nincoming at a vertex\nMove: reverse an edge, preserving Rule\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nAND vertex\nFT\nF\nT\nT\nT\ninputs\noutput\nF\nT\nnot your usual\nRule: at least 2 units\nAND gate!\nincoming at a vertex\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nSPLIT vertex\nT\nT\nF\nF\nF\noutputs\ninput\nT\nF\nRule: at least 2 units\nincoming at a vertex\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nOR vertex\nFT\nF\nT\nT\nT\ninputs\noutput\nTF\nT\nnot your usual\nRule: at least 2 units\nOR gate!\nincoming at a vertex\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nDecision Problem\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\ncan you reverse this edge?\n\nConstraint Logic\nConstraint Logic\n[Hearn & Demaine 2009]\n[Hearn & Demaine 2009]\nbounded\nunbounded\nPSPACE\nEXPTIME\nP\nUndecidable\nNEXPTIME\nPSPACE\nNP\nPSPACE\n0 players\n1 player\n2 players\nteam,\n(simulation)\n(puzzle)\n(game)\nimperfect info\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nDecision Problem\n\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\ncan you reverse this edge?\nTheorem:\nPSPACE-complete\n\nSliding\nSliding--Block\nBlock\nPuzzles\nPuzzles\nCourtesy of Dr. Jim Storer. Used with permission.\n\nSliding\n-Block Puzzles\nCorollary:\n[Hearn & Demaine 2002]\n\nPSPACE-complete\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nSliding\n-Block Puzzles\nCorollary:\n[Hearn & Demaine 2002]\n\nPSPACE-complete\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nWiring Vertices Together\nAND wants red\nOR wants blue\nOR\nAND\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nRed\n-Blue Conversion\nassume an even number of conversions\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nRed\n-Blue Conversion\nassume an even number of conversions\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nBoolean\nFormulas\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. De\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\nmaine.\n\nQuantified Boolean Formulas\n(QBF)\nx x\ny y\nw w\nz z\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nExistential Quantifier\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\nUniversal Quantifier\n\nLatch\nA\nB\nlocked\nun\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nUniversal Quantifier\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nCrossover Gadget\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nOR from\n\nProtector OR\n\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nRush Hour\n\n[Hearn & Demaine 2002]\nPSPACE-completeness known [Flake & Baum 2002]\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nTriangular\nRush Hour\n[Hearn & Demaine 2009]\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nOpen: 1\n×1 Rush Hour\n[Tromp & Cilibrasi 2008]\n\n- P or PSPACE-complete or ...?\nImage courtesy of John Tromp. Used with permission.\n\nPlank Puzzles\n[Hearn 2004]\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nSokoban\n\n[Hearn & Demaine 2002]\nPSPACE-completeness known [Culberson 1998]\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nPush\nPush--2F\n2F\n[Demaine, Hearn, Hoffmann 2002]\n[Demaine, Hearn, Hoffmann 2002]\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nConstraint Logic\nConstraint Logic\n[Hearn & Demaine 2009]\n[Hearn & Demaine 2009]\nbounded\nunbounded\nPSPACE\nEXPTIME\nP\nUndecidable\nNEXPTIME\nPSPACE\nNP\nPSPACE\n0 players\n1 player\n2 players\nteam,\n(simulation)\n(puzzle)\n(game)\nimperfect info\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nConstraint Logic\nConstraint Logic\n[Hearn & Demaine 2009]\n[Hearn & Demaine 2009]\nbounded\nunbounded\nPSPACE\nEXPTIME\nP\nUndecidable\nNEXPTIME\nPSPACE\nNP\nPSPACE\n0 players\n1 player\n2 players\nteam,\n(simulation)\n(puzzle)\n(game)\nimperfect info\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nAmazons\n\n[Hearn 2005]\nfanout\nCopyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.\nReproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nES.268 The Mathematics in Toys and Games\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "ES.268 Dynamic programming with impartial games, Course Notes 3",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/7b7a8f43661ed9eb64a42f24f64f2ae6_MITES_268S10_Ses3_dynamic.pdf",
      "content": ",\n,\n\nLecture 3\nFeb 16, 2010\nPlaying Games with Algorithms:\n- most games are hard to play well:\n- Chess is EXPTIME-complete:\n- n × n board, arbitrary position\n- need exponential (cn) time to find a winning move (if there is one)\n- also: as hard as all games (problems) that need exponential time\n- Checkers is EXPTIME-complete:\nChess & Checkers are the \"same\" computationally: solving one\n⇒\nsolves the other\n(PSPACE-complete if draw after poly. moves)\n- Shogi (Japanese chess) is EXPTIME-complete\n- Japanese Go is EXPTIME-complete\n- U. S. Go might be harder\n- Othello is PSPACE-complete:\n- conjecture requires exponential time, but not sure (implied by\nP = NP)\n- can solve some games fast: in \"polynomial time\" (mostly 1D)\nKayles:\n[Dudeney 1908]\n(n bowling pins)\n- move = hit one or two adjacent pins\n- last player to move wins (normal play)\nLet's play!\nhttp://erikdemaine.org/papers/AlgGameTheory_GONC3\nES.268\n\nFirst-player win:\nSYMMETRY STRATEGY\n- move to split into two equal halves (1 pin if odd, 2 if even)\n- whatever opponent does, do same in other half\n(Kn + Kn = 0 . . . just like Nim)\nImpartial game, so Sprague-Grundy Theory says Kayles ≡ Nim somehow\n- followers(Kn)\n= {Ki + Kn-i-1, Ki + Kn-i-2 | i = 0, 1, . . . , n - 2}\n⇒ nimber(Kn) = mex{nimber(Ki + Kn-i-1),\nnimber(Ki + Kn-i-2)\n| i = 0, 1, . . . , n - 2}\n- nimber(x + y) = nimber(x) ⊕ nimber(y)\n⇒ nimber(Kn) = mex{nimber(Ki) ⊕ nimber(Kn-i-1),\nnimber(Ki) ⊕ nimber(Kn-i-2)\n| i = 0, 1, . . . n - 2}\nRECURRENCE! -- write what you want in terms of smaller things\nHow do we compute it?\nnimber(K0) = 0\n(BASE CASE)\nnimber(K1) = mex{nimber(K0) ⊕ nimber(K0)}\n=\n⊕\n=\nnimber(K2) = mex{nimber(K0) ⊕ nimber(K1),\n=\n⊕\nnimber(K0) ⊕ nimber(K0)}\n=\n⊕\n=\nso e.g. K2 + ∗2 = 0\n2nd player win\n⇒\nnimber(K3) = mex{nimber(K0) ⊕ nimber(K2),\n=\n⊕\nnimber(K0) ⊕ nimber(K1),\n=\n⊕\nnimber(K1) ⊕ nimber(K1)}\n=\n⊕\n=\n\n!\n\nnimber(K4) = mex{nimber(K0) ⊕ nimber(K3),\n=\n⊕\nnimber(K0) ⊕ nimber(K2),\n=\n⊕\nnimber(K1) ⊕ nimber(K2),\n=\n⊕\nnimber(K1) ⊕ nimber(K1)}\n=\n⊕\n=\nIn general: if we compute nimber(K0), nimber(K1), nimber(K2), . . . in order,\nthen we always use nimbers that we've already computed (because smaller)\n- in Python, can do this with for loop:\nk =\n960 - 4\n972 - 4\n984 - 4\n{}\nfor n in range(0, 1000):\n961 - 1\n973 - 1\n985 - 1\nk[n] = mex ([k[i] ˆ k[n - i - 1] for i in range(n)] +\n962 - 2\n974 - 2\n986 - 2\n[k[i] ˆ k[n - i - 2] for i in range(n - 1)])\n963 - 8\n975 - 8\n987 - 8\nprint n, \"-\", k[ ]\n964 - 1\n976 - 1\n988 - 1\n965 - 4\n977 - 4\n989 - 4\ndef mex(nimbers):\n966 - 7\n978 - 7\n990 - 7\nnimbers = set(nimbers)\n967 - 2\n979 - 2\n991 - 2\nn = 0\n968 - 1\n980 - 1\n992 - 1\nwhile n in nimbers:\n969 - 8\n981 - 8\n993 - 8\nn = n + 1\n970 - 2\n982 - 2\n994 - 2\nreturn n\n971 - 7\n983 - 7\n995 - 7\nperiodic mod 12!\n(starting at '72)\n[Guy & Smith 1972]\nDYNAMIC PROGRAMMING\nHow fast? to compute nimber(Kn):\n- look up ≈ 4n previous nimbers\n- compute ≈ 2n nimsums (XOR)\n- compute one mex on ≈ 2n nimbers\n- call all this O(n) work \"order n\"\n- need to do this for n = 0, 1, . . . , m\nX\nm\nm\nX\nm(m + 1)\nO(n) = O\nn\n= O\n= O(n 2)\n⇒\nn=0\nn=0\nPOLYNOMIAL TIME -- GOOD\n\nVariations: dynamic programming also works for:\n- Kayles on a cycle\n(1 move reduces to regular Kayles\n2nd player win)\n⇒\n- Kayles on a tree:\ntarget vertex or 2 adj. vertices\n- Kayles with various ball sizes: hit 1 or 2 or 3 pins\n(still 1st player win)\nCram: impartial Domineering\n- board = m × n rectangle, possibly with holes\n- move = place a domino (make 1 × 2 hole)\nSymmetry strategies:\n[Gardner 1986]\n- even × even: reflect in both axes\n1st player win\n⇒\n- even × odd: play 2 center s then reflect in both axes\n1st player win\n⇒\n- odd × odd: OPEN\nwho wins?\nLiner Cram = 1 × n cram\n- easy with dynamic programming\n- also periodic\n[Guy & Smith 1956]\n- 1 × 3 blocks still easy with DP\n- OPEN : periodic?\nHorizontal Cram: 1 only\nsum of linear crams!\n⇒\n2 × n Cram: Nimbers OPEN\nLet's play!\n3 × n Cram: winner OPEN\n(dynamic programming doesn't work)\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nES.268 The Mathematics in Toys and Games\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "ES.268 Game of life, Slides 10",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/a511f77b041aef8c28b8ee16b1416977_MITES_268S10_ses10_slides2.pdf",
      "content": "Conway's Game of Life\nMelissa Gymrek\nMay 2010\n\nIntroduction\nThe Game of Life is a cellular-automaton, zero player game,\ndeveloped by John Conway in 1970. The game is played on an\ninfinite grid of square cells, and its evolution is only determined by\nits initial state.\n\nThe rules of the game are simple, and describe the evolution of the\ngrid:\n▶Birth: a cell that is dead at time t will be alive at time t + 1\nif exactly 3 of its eight neighbors were alive at time t.\n▶Death: a cell can die by:\n▶Overcrowding: if a cell is alive at time t + 1 and 4 or more of\nits neighbors are also alive at time t, the cell will be dead at\ntime t + 1.\n▶Exposure: If a live cell at time t has only 1 live neighbor or no\nlive neighbors, it will be dead at time t + 1.\n▶Survival: a cell survives from time t to time t + 1 if and only\nif 2 or 3 of its neighbors are alive at time t.\n\nStarting from the initial configuration, these rules are applied, and\nthe game board evolves, playing the game by itself!\nThis might seem like a rather boring game at first, but there are\nmany remarkable facts about this game. Today we will see the\ntypes of \"life-forms\" we can create with this game, whether we can\ntell if a game of Life will go on infinitely, and see how a game of\nLife can be used to solve any computational problem a computer\ncan solve.\n\nUsing this simple game's rules, we can create many different types\nof \"life-forms.\"\n▶Still Life: a stable, finite and nonempty pattern. Examples\ninclude various shapes of ponds, and other patterns shown\nbelow:\n▶Block:\n▶Beehive:2 rows of 2 dots to form a square.\nImage by MIT OpenCourseWare.6 dots shaped like a beehive.\nImage by MIT OpenCourseWare.\n\n▶Boat:\n▶Ship:5 dots in a pattern. 3 on the bottom right and 2 on the top. Vaguely boat shaped.\nImage by MIT OpenCourseWare.6 dots form a slightly boat shaped pattern. 3 dots on the bottom right, 3 dots on the top left.\nImage by MIT OpenCourseWare.\n\n▶Loaf:7 dots form a pattern that looks like an uppercase D or semicircle.\nImage by MIT OpenCourseWare.\n\n▶Periodic Life Forms/Oscillators: the following life-forms\noscillate periodically\nPeriod 2:\nBlinker:\nToad:3 dots on top of each other.\nImage by MIT OpenCourseWare.6 dots form two parentheses.\nImage by MIT OpenCourseWare.\n\nOscillators of many more periods exist:\n\n▶Glider A glider is a simple 5-cell pattern that repeats itself\nevery 4 generations, but is offset diagonally by one cell. The\nsmallest and most common spaceship. The glider is going to\nbe extremely important when we discuss applications of the\nGame of Life. The glider is said to travel with speed c\n4.\n▶Spaceship A pattern that moves across the game board.\n(originally Conway found the Light, Medium, and Heavy\nWeight Space Ship)\nImage by MIT OpenCourseWare.A 5 dot pattern.\n\nc\n▶Light Weight Space Ship (LWSS) (speed 2):\n▶Medium Weight Space Ship (MWSS):A 9 dot pattern that looks like a backwards C. An 11 dot pattern that looks like a backwards C.\nImage by MIT OpenCourseWare.\nImage by MIT OpenCourseWare.\n\n▶Heavy Weight Space Ship (HWSS):A 13 dot pattern shaped like a backwards D.\nImage by MIT OpenCourseWare.\n\n▶Guns A gun periodically shoots out moving patterns. We will\nlook soon at the Glider Gun, the first known gun developed\nby Gosper at MIT.\n\n▶Garden of Eden A pattern that can only exist as initial\npattern. In other words, no parent could possibly produce the\npattern.\n\nIt is not easy to tell from looking at an initial Life pattern exactly\nhow it will evolve. For instance, in looking at what happens to a\nstraight line of n live cells as a start configuration:\n▶n = 1, 2: fades immediately\n▶n = 3: Blinker\n▶n = 4: becomes a Beehive at time 2\n▶n = 5: traffic lights at time 6\n▶n = 6: fades at t = 12\n▶n = 7: makes a symmetric display before terminating in the\nHoney Farm (see picture in Winning Ways)\n▶n = 8: gives 4 blocks and 4 beehives\n▶n = 9: makes two sets of traffic lights\n▶n = 10: turns into pentadecathlon, with life cycle of 15\n▶n = 11: becomes two blinkers\n▶n = 12: makes two beehives\n▶n = 13: turns into two blinkers\n\n▶n = 14, 15: vanish completely\n▶n = 16, 17: becomes 4 blocks\n▶n = 18, 19: vanish completely\n▶n = 20: makes 2 blocks\n\n▶It is not immediately obvious whether a given initial Life\npattern can grow indefinitely, or whether any pattern at all\ncan.\n▶Conway offered a $50.00 prize to whoever could setlle this\nquestion. In 1970 an MIT group headed by R.W. Gosper won\nthe prize by finding the glider gun that emits a new glider\nevery 30 generations. Since the gliders are not destroyed, and\nthe gun produces a new glider every 30 generations\nindefinitely, the pattern grows forever, and thus proves that\nthere can exist initial Life patterns that grow infinitely.\n\n▶In the Game of Life, we can define the \"speed of light\" (c,\njust as in physics) as the maximum attainable speed of any\nmoving object, a propagation rate of one step (horizontally,\nvertically, or diagonally) per generation. This is both the\nmaximum rate at which information can travel and the upper\nbound on the speed of any pattern.\n▶We can find the speed of two patterns we've seen, the glider\nand the lightweight spaceship. The glider takes 4 generations\nto move one cell diagonally, and so has a speed of c\n4. The\nlight weight spaceship moves one cell orthogonally every other\ngeneration, and so has a speed of c\n2.\n▶Although the speed of light is defined as one cell per\ngeneration, we show here that the maximum attainable speed\nof any moving object is either c\nc\n4 diagonally or 2 orthogonally.\nNo spaceships can move faster than our glider or light weight\nspaceship.\n\nTheorem\nNo spaceship can travel diagonally faster than c\n4.\n\nConsider the grid below:\nCourtesy of Nathanial Johnston. Used with permission.\n\n▶Say we have a spaceship on and to the left of the diagonal\nline defined by ABCDE on generation 0. If the spaceship can\ntravel up and to the right faster than c\n4, then cell X would be\nalive at generation 2.\n▶Suppose this is true, and that X is alive at generation 2.\nThen C, U, and V must be alive at generation 1. Then U and\nV must have had 3 alive neighbors in generation 0, and so\nB, C, D, J, and K must have been alive at time 0. Then C\nmust have had at least four live neighbors in generation 0, and\nso couldn't have survived to generation 1. But we needed C\nalive at generation 1, and so we have reached a contradiction.\n▶If the spaceship is behind ABCDE at generation 0, it must be\nbehind UV at generation 2, and so can't travel faster than c\n4.\n\nTheorem\nNo spaceship can travel orthogonally faster than c\n2.\n\nFor the orthogonal case consider the following grid:\nCourtesy of Nathaniel Johnston. Used with permission.\n\n▶If a spaceship is on and below the diagonal lines defined by\nthe solid black squares in generation 0, then we can use the\nargument above to claim that it must be on or below the lines\ndefined by the striped squares at generation 2. Therefore, it\ncan move at most 1 square forward every 2 generations, and\nso has maximum speed c\n2.\n\nOne interesting and surprising application of the Game of Life is\nthat we can construct an initial pattern that will generate the\nprime numbers sequentially. The primer below is due to Dick\nHickerson, 1991:\n\nTo see an image of a primer, please visit the following\nwebsite: http://www.conwaylife.com/wiki/index.php?title=Primer\n\nBefore describing how the primer works, we describe the Sieve of\nEratosthenes. The sieve is a simple ancient algorithm for finding\nall prme numbers up to a specified integer. The algorithm is as\nfollows:\n▶Create a list of consecutive integers from 1 to n.\n▶Set p = 2 (the first prime)\n▶Cross out all multiples of p greater than p.\n▶Find the first number still left that is greater than p.\n▶Repeat steps 3 and 4 until p2 is greater than n.\n▶All he remaining numbers on the list are prime.\n\n▶The primer fires a light weight space ship westward, and\ndestroys the spaceships with gliders from a gun that simulates\nthe Sieve of Eratosthenes.\n▶The light weight spaceship makes it past the left edge of the\ngun at generation 120N if and only if N is a prime number.\n▶There are extensions of the primer that can be used to\ngenerate twin primes, Fermat primes, and several others.\n\nHere we show (glossing over some of the details) how we could use\nthe Game of Life to make functioning logic gates and perform\noperations on bit streams.\n\nComputers represent information as signals or bit streams. We can\nuse a stream of gliders to represent a signal or bit stream as\nfollows:\nCopyright (2001). From Winning Ways for Your Mathematical Plays, Vol. 4 by Elwyn R. Berlekamp,John H. Conway,\nand Ricard K. Guy. Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nBefore we get to building our logical parts, let's examine the\ndifferent reactions we can get when gliders crash into each other.\nThese collisions of gliders will form the building blocks of the\nreactions that will make up our computer.\nWe can simluate crashes that result in the following possiblities\n(we will actually simulate these in class):\n▶(a) Blinker\n▶(b) Block\n▶(c) Pond\n▶(d) Vanishing reaction\n\nCopyright (2001). From Winning Ways for Your Mathematical Plays, Vol. 4 by Elwyn R. Berlekamp,John H. Conway,\nand Ricard K. Guy. Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nWe can use the reactions we learned above to build a logical NOT\ngate. If we let one stream of gliders be our bit stream, we can\n\"invert\" this stream of gliders through the use of a glider gun and\nvanishing reactions. We can construct and position a glider gun\nsuch that every \"space\" or \"0\" in our input glider stream allows\none glider to escape from the glider gun, while every glider, or \"1\"\nin our input stream collides with the glider from the glider gun to\nmake a \"0\". This is illustrated in the image below:\n\nCopyright (2001). From Winning Ways for Your Mathematical Plays, Vol. 4 by Elwyn R. Berlekamp,John H. Conway,\nand Ricard K. Guy. Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nWe will not go into details, but for engineering purposes we note\nthat we can manipulate the direction of a glider stream however we\nwant by positioning glider guns to navigate gliders around corners\nand taking advantage of the different glider-glider reactions we\nhave. From now on we assume we can direct a glider stream to go\nin whatever direction we want.\n\nCopyright (2001). From Winning Ways for Your Mathematical Plays, Vol. 4 by Elwyn R. Berlekamp,John H. Conway,\nand Ricard K. Guy. Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nWe can also get rid of unwanted glider streams by forming an\n\"eater.\" The eater is able to devour gliders. (see demo in class)\nWe also note that we can use gliders as the building blocks for\nalmost all the pieces we will need. For instance, two gliders can\ncollide to make an eater. Gliders can also collide to make blocks\nand ponds, and therefore a whole glider gun!.Two L's on graph paper form an eater.\nImage by MIT OpenCourseWare.\n\nCopyright (2001). From Winning Ways for Your Mathematical Plays, Vol. 4 by Elwyn R. Berlekamp,John H. Conway,\nand Ricard K. Guy. Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.\n\nFor the AND gate, we position our two glider streams that we are\nANDing perpendicular to the line of fire of a glider gun, with an\neater to eat up unwanted gliders. Let us go through all possible\ncases and see why this gives us an AND gate.\n▶A = 1, B = 1\nIf B's stream has a glider, it will vanish when it collides with\nthe glider from G. When the stream gets to A, A's glider will\nbe able to pass through where the vanishing reaction left a\nhole, making the value of A and B 1, as expected.\n▶A = 1, B = 0\nIf B's stream has no glider, the glider from the gun will reach\na collision point with A's glider and cause a vanishing\nreaction, making the output of A and B 0, as expected.\n\n▶A = 0, B = 1\nIf B's stream has a glider, it will vanish when it collides with\nthe glider from G. When the stream gets to A, there will be\nan empty space, and so the glider stream will continue\nupwards and get eaten by the eater, E. Therefore the output\nA and B will be 0, as expected.\n▶A = 0, B = 0\nIf B's stream has no glider, the stream from the glider gun will\ncontinue to cross A's path. A also has no glider, so the glider\nfro the gun continues on to the Eater to be eaten, and the\noutput of A and B is 0, as expected.\n\nFor the OR gate, we again position our two input streams\nperpendicular to the output of the glider stream, and make use of\na second glider gun as well. Let us go through all possible cases\nand see why this gives us an OR gate.\n▶A = 1, B = 1\nIf B's stream has a glider, it will collide with the glider from\nthe gun and create a vanishing reaction. If A has a glider, but\nthere is no space from the incoming glider stream, no glider\nfrom the stream will reach the next node, a collision path with\nanother glider gun. Since there is no glider from the incoming\nstream, the glider from the second gun will reach the output,\nmaking the value of A or B 1, as expected.\n\n▶A = 1, B = 0\nIf B's stream has no glider, the glider from the gun will\ncontinue onward to collide with A, leaving a space to interact\nwith the second glider gun. Therefore, the glider from the\nsecond gun will reach the output, making the value of A or B\n1, as expected.\n▶A = 0, B = 1\nIf B's stream has a glider, it will create a vanishing reaction\nwith the stream from G, leaving a space for A. A also has no\nglider, and therefore there will be no incoming glider to collide\nwith the glider stream from the second gun, and the output\nwill again be 1, as expected.\n\n▶A = 0, B = 0\nIf both A and B have no gliders, there is nothing to interrupt\nthe path of the first glider gun. Therefore, gliders from both\nof the glider guns will collide and vanish, and therefore the\nmake the output, A or B, be 0, as expected.\n\n▶Therefore, using these parts, we could construct a slow and\nprimitive, but functioning, computer out of the Game of Life. The\nGame of Life exhibits a property we call universality, meaning that\nit can theoretically compute anything that can be computed.\n▶For more details on how exactly we could construct a computer\nfrom the Game of Life, see Winning Ways.\n\nAnother equivalent statement to saying Life is universal is that we\ncan build a Turing-machine from it.\nWe start by describing\nTuring Machines. A Turing Machine has:\n▶A finite set of states\n▶Rules for transitioning between states\n▶An infinite sequence of cells (called a \"tape\")\n▶A set of symbols describing the possible contents of each cell in\nthe tape\n▶The ability to read and write the symbol in a single cell\n▶The ability to move along the tape to access different cells.\n\nEach state transition rule specifies:\n▶The current state\n▶The symbol read from the current cell\n▶The state to move to\n▶The symbol to write to the current cell\n▶The direction to move the machine along the tape\n\n▶On each time step, the Turing Machine (TM) reads from the\ncurrent cell on the tape, finds the appropriate transition rule that\nmatches the current state and symbol just read, then changes to\nthe specified new state, writes the specified symbol, and moves the\nmachine in the specified direction.\n▶Here in class we will go through an example Turing machine\ncalculation (slides 37-54 of Rendell slides)\n\n▶The famous Church-Turing Thesis states that \"everything\ncomputable is computable by a Turing Machine.\" This statement\nis not proven, but is almost univerally accepted. If it is true, then\nTM's have power greater than modern day computers.\n▶We call something Turing-complete if it has rules followed in\nsequence that have the same computational power as a Turing\nMachine.\n▶If we can show that the Game of Life is Turing-complete, then we\ncan say that Life is as powerful as any computer, and that we can\ncompute any computational problem using the Game of Life.\n\nNow let us see how we might actually construct a Turing Machine\nfrom the building blocks of the Game of Life.\nWe will go through slides 61-80 of the Rendell notes in class to see\nthe construction. We will also show a demo of the TM in action!\n\nReferences\n▶http://www.math.com/students/wonders/life/life.html\n▶http://www.nathanieljohnston.com/index.php/tag/conways-game-\nof-life/\n▶Winning Ways\n▶Cellular Automata and Turing Universality in the Game of Life by\nPaul Rendell, presented by David Thue\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nES.268 The Mathematics in Toys and Games\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "ES.268 NP-completeness, Slides 11",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/50a061a2f76a503d8473a072965bc8ff_MITES_268S10_ses11_slides.pdf",
      "content": "Minesweeper is NP-Complete\nNotes by Melissa Gymrek\nBased on a paper by Richard Kayes 2000\n\nMinesweeper\nz Reducing 3SAT to generalized Minesweeper\nz Reducing cSAT to well-know version of\nMinesweeper\n\nGeneral Minesweeper\nMINESWEEPER: { G, ξ |G is a graph and ξ is a partial\ninteger labeling of G, and G can be filled\nwith mines in such a way that any node v labeled m has exactly\nm neighboring nodes containing mines.}\nDeciding if a graph is in the MINESWEEPER language is NP-\ncomplete:\n- Polynomial time verification\n- Reduce from 3SAT in polynomial time\n\nPolynomial Time Verification\nz For each node v labeled m:\nz Check that exactly m neighbors contain mines\nz O(E) time - clearly polynomial\n\nReduce from 3SAT\nf(w)\n3SAT instance w\nMINESW instance Z\nz Function f converts a 3SAT instance to a\nMINESW instance in polynomial time\nz Z is satisfiable iff w is satisfiable\n\n3SAT Review\nBoolean 3CNF formula:\n(A V B V C) ^ (~A V D V ~C) ^ ...\nN variables (A, B, C, D) in this instance\nM clauses (here 2 clauses are shown)\nQuestion: Is this boolean formula satisfiable?\n\n3SAT → MINESWEEPER\nxi\n~xi\nMake a gadget for each variable\n\nN\n3SAT → MINESWEEPER\nFor clause (A V B V ~C)\nConnect to variable\ngadgets\nA\nB\nC\nN\nN-1 \"satellite\" nodes\n...\nMake a gadget for each clause\n\n3SAT → MINESWEEPER\nz Conversion took polynomial time:\nz 1 gadget for each of the N vars = O(N)\nz 1 gadget for each of M clauses = O(MN)\nz Total O(N(M+1)) time\n\nMinesweeper as we know it\nMINESWEEPER Problem: Given a rectangular grid\npartially marked with numbers and/or mines, some squares\nbeing left blank, determine whether there is some pattern of\nmines in the blank squares giving rise to the numbers seen.\nDeciding if a graph is in the MINESWEEPER language is NP-\ncomplete:\n- Polynomial time verification\n- Reduce from cSAT in polynomial time\n\nWire\nEither all the x's or all the x''s are mines. If it is the x's, we\ncall it \"true\", if the x''s, we call it \"false\"\nA\ng\nre\ny\nb\na\nck\ng\nro\nu\nnd\n\nwi\nt\nh\n\nx '\ns\n\nd\no\nw\nn\n\nt h\ne\n\nc\ne\nn\nt\ne\nr\n\ns\nu\nr\nr\no u\nn\nd\ne\nd\n\nb y\n\n'\ns\n.\n\nImage by MIT OpenCourseWare.\n\nManipulating Wires\n(c) Springer-Verlag New York. All rights reserved. This content is excluded from our Creative Commons license.\nFor more information, see http://ocw.mit.edu/fairuse.\nKaye, Richard. \"Minesweeper is NP-complete.\" Mathematical Intelligencer 22, no. 2 (2000): 9-15.\n\nMinesweeper is NP-Complete, Kayes\n\nManipulating Wires\n(c) Springer-Verlag New York. All rights reserved.This content is excluded from our Creative Commons license.\nFor more information, see http://ocw.mit.edu/fairuse.\nKaye, Richard. \"Minesweeper is NP-complete.\" Mathematical Intelligencer 22, no. 2 (2000): 9-15.\nMinesweeper is NP-Complete, Kayes\n\nNOT gate\nInverts the sign of a wire\nA\ns\ncr\ne\nen\ns\nh\no\nt\no\nf\nt\nhe\n\ng\na m\ne\n\nM\ni\nn\ne\ns\nw e\ne\np\ne\nr\n.\nImage by MIT OpenCourseWare.\n\nMore gates\nz We can now manipulate/invert wires\nz Cross wires? First make planar XOR, then use\nXOR and three way splitter to cross wires\nz We have NOT, and AND, universal!\n\nMore gates\n(c) Springer-Verlag New York. All rights reserved. This content is excluded from our Creative Commons license.\nFor more information, see http://ocw.mit.edu/fairuse.\nKaye, Richard. \"Minesweeper is NP-complete.\" Mathematical Intelligencer 22, no. 2 (2000): 9-15.\nMinesweeper is NP-Complete, Kayes\n\nAND gate\nMinesweeper is NP-Complete, Kayes\n(c) Springer-Verlag New York. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more information, see http://ocw.mit.edu/fairuse.\nKaye, Richard. \"Minesweeper is NP-complete.\" Mathematical Intelligencer 22, no. 2 (2000): 9-15.\n\nNAND is universal!\nz (A nand A) nand (B nand B) = A v B\nz (A nand B) nand (A nand B) = A ^ B\nz (A nand A) = ~A\n\nTetris is NP‐complete\nRon Breukelaar, Erik Demaine,\nSusan Hohenberger,\nHendrik Jan Hoogeboom,\nWalter Kosters, David Liben‐Nowell\npublished 2004\n\n3‐Partition\n- Given 3s integers a1, a2, ..., a3s, can you\npartition into s triples with the same sum?\n- Know the sum must be T = ∑ai / s\n- This problem is strongly NP‐complete:\nNP‐complete even if ai numbers are sO(1)\n...\n?\nT\ns triples\n\nInitial Board\ns columns\n(one per sum)\n≈ T notches\n(target sum)\nT lock\nbane\n(it is possible to\nactually get here)\n\nPiece Sequence\n- For each input ai:\n(ai reps)\n\nFailure to Launch\n\nForced Moves\n\nFinale\nPieces\n\nFinale\nPieces\n\nFinale\nPieces\n\nFinale\nPieces\n\nFinale\nPieces\n\nFinale\nPieces\n\nSummary\n- If there's a 3‐partition, can win Tetris:\nGet tons of lines, Tetrises, live forever, etc.\n- If there's no 3‐partition, must lose Tetris:\nDie, no lines, no Tetrises, etc.\n\nOpen Problems\n- What if the initial board is empty?\n- What about Tetris with O(1) columns?\n- What about Tetris with O(1) rows?\n- What about restricted piece sets (e.g. just )?\n- What if every move drops from high up\n(no last‐minute slides)?\n- Is two‐player Tetris PSPACE‐complete?\n- What can we say about online (regular) Tetris?\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nES.268 The Mathematics in Toys and Games\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Amoeboid",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/f6bab42dc55228a129ad65fa799b866c_MITES_268S10_amoeba.pdf",
      "content": "Amoeboid: A Partisan Combinatorial\nGame of Chance\nSebastien Dabdoub\nSantiago Cuellar\nRules\nSet up\nThis game can be played on any graph (or n-dimensional board). For sim\nplicity we will consider a n × n Board. The game starts with two amoebae, of\nsize 1, in diametrically opposite corners of the board; each player controls one\namoeba.\nDefinitions\n1. Amoeba:\nIt's a piece that has position, composition, size and owner.\n(a) Position:\nThe place on the board (or node on a graph) occupied by this piece.\n(b) Composition\nThe amoeba is composed of two parts represented by numbers a and\nb. Each number represents each player's control over the piece. It\ncan also be thought as a set of a unit amoebae with a = 1, b = 0\nand b unit amoebae with a = 0, b = 1.\n(c) Size\nThe sum of the two numbers in the composition.\n(d) Owner.\nThe player whose control number over the piece is bigger. If both\nnumbers are equal the piece becomes neutral and has no owner.\nGame play\nThe players A and B alternate taking turns. Each turn consist of the fol\nlowing two elements:\n\n1. Dice roll The player rolls a six sided die, then picks one of their amoebae\nand increases his control number on it by the number on the die (subse\nquently the size increases by the same number).\n2. Move\nThe player chooses a subset of unit amoebae from the set of a controlled\namoeba and move them (as a new single amoeba) to an adjacent space;\nthe adjacent space has to be:\n(a) Empty: In this case we say the player moved\n(b) Occupied by an amoeba of smaller or equal size (of moving amoeba).\nThis results in a single amoeba whose control numbers are summed:\nIn this case we say the player eats an amoeba.\nEnd Game\nThe game ends when one does not own any of the pieces on the board. If a\nplayer owns any amoeba at the end of the game he wins; otherwise it's a tie.\nAnalysis\nAdvantage:\nIn this section we consider two variables of the game that will give us a good\nidea of the development of the game and will be crucial for starting to grab a\nstrategy.\n1. Advantage 1 (simple total difference) The two players are rolling dice al\nternately, let σA and σB be the sum of the rolls for player A and B\nrespectively in a given moment ( If after three turns A has rolled 1,2,3\nand B has rolled 4,5,6, σA = 6 and σB = 15). Also we define δ = σA - σB.\nDefinition: We say player A has advantage 1 over player B if δ > 0,\nsimilarly we say B has advantage 1 if δ < 0.\nClaim : Player A can only win if he has advantage 1 and player B can\nonly win if he has advantage 1.\nProof : If a player wins (Let's say A), the other player does not control\nany amoebae thus in any single amoeba the control of player A is greater\nthan or equal to the size of B. In addition since A won, he controls at least\none Amoeba. Then adding all the sizes of amoebae, size of A's control is\ngreater than the size of B's control and this is exactly σA > σB or δ > 0\nTheorem (Symmetry of difference):\nThe expected value of δ is\nalways 0.\nProof : the players A and B start and play with the same conditions thus\nby symmetry in the game P(δ = k) = P(δ = -k) and\nk P(δ = k)k = 0\nwhich implies that the expected value is 0.\n\nConjecture (Unboundedness of difference):\nLet PM (n) be the\nprobability of δ being bigger than M, before n turns. Then limn→inf PM (n) =\n1 for any integer M.\nJustification: We have run computer modeling that supports this claim.\n2. Advantage 2 (Total size difference): The two players control some amoe\nbae, let ΣA and ΣB be the sum of the sizes of amoebae controlled by player\nA and B respectively in a given moment. Also we define Δ = ΣA - ΣB.\nDefinition: We say player A has advantage 2 over player B if Δ > 0,\nsimilarly we say B has Advantage 2 if Δ < 0.\nClaim : Player A can only win if he has advantage 2 and player B can\nonly win if he has advantage 2.\nProof : If a player wins (Let's say A), the other player does not control\nany amoebae thus ΣB = 0, ΣA > 0 and this is ΣA > ΣB or Δ > 0\nFor two players rolling dice alternately, let σA and σB be the sum of the rolls\nfor player A and B respectively in a given moment. Then we have the following\nconjectures:\nOpening strategies:\nIn the following we analyze the opening strategies where no amoebae has\nbeen eaten or split. We consider different cases depending on the difference of\nsize of initial amoebae, δ will be this difference in size.\nCase I: When the two amoeba are not adjacent and the δ < 3.5.\nWe claim that the optimal strategy here is to move to one of the two adjacent\npositions not adjacent to the enemy amoeba. We will first describe why splitting\nis not an optimal strategy. Splitting in this case guarantees that at least one of\nyour amoebae is smaller than the opponent's amoeba and the δ between each\nof your amoebae and the opponent's amoeba increases in favor of the opponent.\nThis gives you no advantage while weakening your position, so we can rule\nout splitting. The only strategies left are moving to one of the three adjacent\nsquares. One of these squares is adjacent to the opponent's amoeba and moving\nto this square is also not optimal. The expected value of the opponents roll\nis 3.5, so the opponent's amoeba is likely to become bigger than your amoeba.\nTherefore the opponent is likely to gain Advantage 1 and 2, so moving adjacent\nto the opponent would constitute a loss. On the other hand, should the opponent\nnot roll enough to win, his amoeba can split and subsequently avoid immediate\nloss with a chance of a comeback. Moving to this square means likely loss or\nunlikely survival, but no immediate guaranteed victory. Therefore, the best\nstrategy here is to stall the game until you gain in Advantage 1 and 2 by\nincreasing the δ in your favor to a larger amount. This is done by moving\nyour amoeba to one of the two adjacent squares not adjacent to the enemy\namoeba repeatedly. For example at the start of the game, this strategy would\n⎡ A 0\n0 ⎤\n⎡ 0 A 0 ⎤\n⎣\n⎦\n⎣\n⎦\nlook like\nand\nalternating.\n0 B\n0 B\n\nCase II: When two amoebae are not adjacent and δ = 4, 5 or 6.\n- If δ = 4 moving to the center has at least a possibility of 1\n2 of not winning\n(if B rolls 4 he will probably choose to tie because he will roll again and\nget an advantage). So the best choice is to play as in case 1.\n- If δ = 5 moving to the center has at least a possibility of 1\n3 of not winning\n(same as before, B will choose to tie). This is not an extremely good\nsituation but might be very advantageous if the game is advanced (i.e.\nthe two amoebae have a significant size), if this is the case the cases where\nB rolls 1,2,3 or 4 will result on A eating half of B's size giving him a\nhuge advantage. The decision of moving to the center will depend on how\nadvanced the game is and on the previous dice rolls. This is a complicated\ncase which would have to be analyzed case by case. Here is one extreme\ncase:\nSuppose the size of both amoebae is 1000, and in the last 10 turns A and\nB have only roll 5's and 6's and a single 3. Each amoeba is in a corner\nand A rolls a 5. In this case the probability of B rolling 5 or 6 is extremely\nlow, so A shouldn't worry about loosing. More over if B fails to roll a\n6 or 5 (let's say a 4) A will eat at least 500 in size making the amoebae\n(1006,502) and (0,502). (for clarification the tuples given represent the\ncontrol of each player over an amoeba) Then B will never be able to eat\nA until he gets 1006 more in size, this will take him more than 200 turns.\nThus making possibility of A losing small, so A should move to the middle.\n- If δ = 6, A is never going to lose by moving to the center but B will chose\nto tie if he rolls a 6. In all the other cases, with probability 5\n6, A will take\nat least half of B's size, getting a valuable advantage.\nCase III: When the two amoeba are not adjacent and the δ > 6 in your\nfavor.\nWe claim that the optimal strategy here is to move your amoeba to the\ncenter. Splitting here has the chance to get rid of your advantage and serves\nno real purpose. In similar fashion to case 1, splitting can be ruled out. We\ncan show that by moving to the center with an Advantage 2 in your favor, the\nopponent cannot win. After your amoeba moves to the center, your opponent's\namoeba grows but not by more than 6. Therefore in order to avoid losing, the\nopponent's best move is to split in half. Your next optimal play depends on the\nnew Advantage 2. If the new Advantage 2 is greater than 6, the optimal play\nis to split your amoeba enough to make one of the opponent's amoeba neutral\nwhile keeping control of the center. Again your opponent's amoeba must split\nin half to avoid losing and it cannot eat the neutral piece which is twice its size.\nWhile Δ remains larger than 6, the optimal strategy is to repeat this process of\nneutralizing one of the opponent's split amoeba. This repeats until either there\nare no squares left unoccupied in which case you win, or the Δ is no longer\ngreater than 6 in your favor. When your Advantage 2 is no longer greater than\n\n6 (either after the first turn or several after moving to the center), the optimal\nplay is to eat one of the opponent's split amoebae. From here, the Δ may\ncontinue to decrease from your advantage in which case the optimal move is\nto move to an opposite square from your opponent. This would constitute a\nkind of \"reset\" wherein similar to the beginning of the game the Advantage 1 is\nsmall and two players each control one amoeba on opposite sides of the board.\nThe point of having made these plays is that your controlled amoeba now has\nsome of the opponent's amoeba that it ate. So while the Advantage 1 may go in\nyour opponent's favor, your Advantage 2 may still be larger and your opponent\ncannot eat your amoeba to win.\nCase IV: When two amoebae are not adjacent and δ > 44.\nWe claim that, if amoeba from player A is bigger, player A can win the game\nin finitely many turns (A max of 8).\n1. A moves to the center were he is adjacent to the other amoeba. B's only\noption is to split his amoeba, obviously in half. Example:\n⎡ 0\n⎤\n⎡ 0\n⎤\nA moves to the center ⎣ 0 60A\n⎦ B rolls a 6 and splits ⎣ 0 60A 11B ⎦\n16B\n11B\n2. A eats the bigger of the two amoebae with an amoeba just as big. Again\nB can't eat anything without loosing, so he will have to split again in half.\nExample:\n⎡ 0\n⎤\n⎡ 0\n8B\n⎤\nA rolls a 1 and eats\n⎣\n⎦\n⎣\n⎦\n50A\n50A\n9B\n9B\nB rolls 6 and splits\n11a, 11B\n11a, 11B\n3. A repeats step (2) as long as B is splitting, and there is more than one\nsquare empty. Examples:\n⎡\n⎤\n⎡\n⎤\n8B\n7B\n7B\nA rolls 1 and eats\n⎣\n⎦\n⎣\n⎦\n42A\n9A, 9B\nB rolls 6 and splits\n0 42A\n9A, 9B\n11a, 11B\n11a, 11B\n⎡ 0\n7B\n7A, 7B ⎤\n⎡ 6b\n7B\n7A, 7B ⎤\nA rolls 1 and eats\n⎣\n⎦\n⎣\n⎦\n36A\n36A\n9A, 9B\n9A, 9B\nB rolls 6 and splits\n⎡ 6B\nA rolls 1 and eats\n⎣\n⎡ 6B\nA rolls 1 and eats\n6B\n⎣\n11a, 11B\n7A, 7B\n7A, 7B ⎤\n⎡\n30A\n9A, 9B ⎦ B rolls 6 and splits ⎣\n11a, 11B\n7A, 7B\n7A, 7B ⎤\n⎡\n25A\n9A, 9B ⎦ B rolls 6 and splits ⎣\n11a, 11B\n6B\n6B\n11a, 11B\n7A, 7B\n7A, 7B ⎤\n⎦\n30A\n9A, 9B\n11a, 11B\n6A, 6B\n6B\n6B\n7A, 7B\n7A, 7B ⎤\n⎦\n25A\n9A, 9B\n11a, 11B\n4. When only one square is empty A will eat B's amoeba with a number 1\nhigher (gaining control of the amoeba).\n\nB will play same as before. Examples:\n⎡\n⎤\n6A, 6B\n7A, 7B\n7A, 7B\nA rolls 1 and eats\n7A, 6B\n⎣\n⎦\n9A, 9B\nB rolls 6 and splits\n6B\n11a, 11B\n⎡\n⎤\n6A, 6B\n7A, 7B\n7A, 7B\n⎣ 7A, 6B\n⎦\n9A, 9B\n6B\n6B\n11a, 11B\n⎡ 6A, 6B\n7A, 7B\n7A, 7B ⎤\nA rolls 1 and eats\n7A, 6B\n⎣\n⎦\n9A, 9B\n7A, 6B\n6B\n11a, 11B\n5. When all the squares are taken, B can't split any further. He can't eat any\namoeba because the adjacent amoebae are bigger than him (at least 13 if\nhe is 6 and so forth). In any case A has an amoeba of bigger size and can\neat him winning control of the new amoeba, therefor winning the game.\nExample:\n⎡\n⎤\n6A, 6B\n7A, 7B\n7A, 7B\nB doesn't have where to go even if rolling a 6\n7A, 6B\n⎣\n⎦\n9A, 9B\n7A, 6B\n12B\n11a, 11B\n⎡\n⎤\n6A, 12B\n7A, 7B\n7A, 7B\nA eats and wins\n7A, 6B\n⎣\n⎦\n9A, 9B\n7A, 6B\n12A, 12B\n11a, 11B\nImplementation\nBoard Game:\nAs a board game, the best way we found to play this game was with a board\nand coins. For the board, a chess board is suitable as well as anything else\nthat is gridded. As for the amoebae, we found that either using two sets of\ndifferent colored uniform Lego pieces or pennies and dimes work best. The two\ndifferent kinds of pieces represent a players control and eating and splitting is\npreformed by stacking or unstacking the pieces. A player's control can easily be\nkept track of by looking at the proportion of the players pieces in the amoeba.\nThe limitations of the board version is that the amoeba can get unwieldy for\nlarge sizes (imagine 40 stacked pennies and dimes).\nPen and Paper with Example Game:\nWe have found classic pen and paper to be the best way to play. We still need\na die, but amoebae can easily be kept track as tuples of two integers representing\n\neach player's control and the sum of these integers is the amoeba's size. For the\nboard, an N by N grid keeps track of the positions. If the game has not been\nmade clear yet, we end this paper with an example pen and paper game that\nwe played.\n⎡ (1, 0) 0\n⎤\nGame Start: ⎣\n⎦ Player 1 rolls a 3 and moves to the right,\n0 (0, 1)\n⎡ 0 (4, 0) 0 ⎤\n⎣\n⎦\nPlayer 2 rolls a 2 and moves to the left.\nPlayer 1 rolls a 3\n0 (0, 3) 0\nand moves to the right again, Player 2 rolls a 1 and moves to the left again.\n⎡\n⎤\n0 (7, 0)\n⎣\n⎦\nPlayer 1 rolls a 2 and makes a risky move to the center,\n(0, 4) 0\n⎡\n⎤\n⎣\nPlayer 2 rolls a 4 and splits in half upwards.\n(0, 4) (9, 0) 0 ⎦ Player 1 rolls\n(0, 4)\na 5 and eats the amoeba to his left, Player 2 rolls a 2 and splits his amoeba in half\n⎡\n0 ⎤\nto the right. ⎣ (14, 4)\n0 ⎦ Player 1 rolls a 4 and moves to the center,\n(0, 3)\n(0, 3) 0\n⎡\n⎤\nPlayer 2 rolls a 4 and moves that piece to the right. ⎣\n(18, 4)\n⎦\n(0, 3)\n(0, 7)\nPlayer 1 rolls a 6 and neutralizes the bottom right amoeba, Player 2 rolls\n⎡\n⎤\na 4 and splits upwards.\n⎣ (0, 4) (16, 3)\n⎦ Player 1 rolls a 1 and\n(0, 3)\n(8, 8)\nneutralizes the amoeba to its left, Player 2 rolls a 6 and splits to the right.\n⎡\n⎤\n⎣ (5, 5) (12, 2)\n⎦ Player 1 rolls a 5, splits and eats the piece under it.\n(0, 5)\n(0, 4)\n(8, 8)\n⎡\n⎤\nPlayer 2 rolls a 4 and eats player 1's center amoeba. ⎣ (5, 5) (6, 11)\n⎦\n(11, 4) (8, 8)\nPlayer 1 rolls a 5 and eats player 2's center amoeba winning the game.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nES.268 The Mathematics in Toys and Games\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Strategy of Risk",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/fd52915d81aa5752bdbac32c54ba46f3_MITES_268S10_Strat_of_Risk.pdf",
      "content": "The Strategy of Risk\n\nRisk\nRisk is a complex board game produced by Hasbro that involves both luck and skill. The\ngoal is simple: take over the world. Despite this simple goal, the game is very complicated and\ndynamic. Players attempt to take over the world by eliminating all other players. Players are\neliminated when they lose all of their troops on the game board. Players must be skilled in\ntroop deployment and must be aware of the underlying probabilities present in the game. This\npaper will discuss the game board, rules, probabilities, and general strategies of the game.\nThe Board\nThe game board is a map of the world divided into six continents comprised of 42\nterritories, shown below.\nImage courtesy of caselee on flickr.\n\nPlayers may only move between adjacent territories, with the exception of the territories\nconnected by red lines over water. Additionally, Alaska connects to Kamchatka, which is the\neasternmost territory in Asia. The board can be simplified by turning it into a graph where the\nterritories are the nodes and the lines between nodes are the potential paths that can be taken\nfrom territory to territory.\nOne key to victory is control over continents. Players that hold continents at the beginning of a\nturn get bonus reinforcements in an amount roughly proportional to the size of the continent\n(these bonuses will be detailed in the Rules section). Thus, the key positions on the board are\nthe territories on the borders of continents. It is also important to know how to deal with the\n\ngame board, as path efficiency is a key to success. It makes no sense to leave troops in the\ncenter of an area controlled by a player, and choosing the quickest path from end to end of a\ncontinent is of the utmost importance.\nRules of the Game1\nGame Pieces\n-1 game board\n-6 colors of troops\n-42 territory cards + 2 wild cards\n-6 dice (3 white, 3 colored)\nGame Set-Up\nThe game begins by distributing the territories among the players. There are two\ncommon ways to do this. The first method is to roll dice to determine the order of play. Once\nthe order of play is determined, the first player chooses a territory to claim and places a troop\non the claimed territory, followed by the player to his left and proceeding clockwise until all\nterritories have been claimed. The second method is to take the 42 territory cards and divide\nthem evenly among the players. Players then place one troop on each territory shown on the\ncards dealt to them. The second method is quicker the first and is desirable for many players\nbecause it randomly distributes the territories and helps make each game more unique. Once\nall territories have been claimed, players proceed to place the remainder of their initial troop\nallotments one by one in a clockwise fashion. The initial troop allotment per player is\nNote: As set-up and play varies slightly for the 2 player game, these rules assume 3-6 players.\n\ndependent on the number of players participating in the game and can be found in the game's\nrule book.\nGeneral Game Play\nThere are three phases of each player's turn: troop placement, attacking, and troop\nmovement. At the beginning of each player's turn, he or she is given a certain number of\ntroops to place on any territory controlled by that player. The number of troops given is equal\nto the number of territories controlled divided by 3 and rounded down to the next integer.\nPlayers are given a minimum of 3 troops per turn. Additional troop bonuses may be granted;\nthese are detailed later in the Rules section.\nThe second phase of the turn is the attack phase. Players may choose to attack any\nterritory adjacent to his or her own during the attack phase. The player must leave at least one\ntroop back to occupy the territory. Thus, there must be more than one troop in the attacking\ncountry. Players attack by rolling up to three dice. Each dice represents one troop, so the\nattacker may not roll any more dice than the number of troops with which he or she is\nattacking. The defender rolls up to two dice, each representing one troop. Like the attacker,\nthe defender may not roll more dice than troops they have to defend with. Once all dice have\nbeen cast, the highest roll of the attacker is matched up with the highest roll of the defender\nand the second highest roll of the attacker is matched up with the second highest roll of the\ndefender (if applicable). The highest roll in each pairing wins, with ties going to the defender.\nThe losing troop in each pairing is removed from the board and the attack phase continues. An\nattack ends in one of three ways: 1) The attacker decides to end the attack, 2) the attacker runs\nout of troops with which to attack, and 3) the defender loses all troops. In this third case, the\n\nattacker takes over the territory and must move at least as many troops as dice rolled in the\nwinning roll and at most the number of remaining troops in the attacking territory minus the\none troop that must stay behind to occupy the territory. A player can attack as many territories\nas he or she wants during the attack phase of the turn. If the player captured at least one\nterritory during the attack phase, he or she takes a territory card from the pile.\nThe third and final stage of the turn is the troop movement stage. Rules for this stage\nvary depending upon the established house rules, but the most common rule is that players\nmay make a single move of as many troops as they want from one territory to an adjacent\nterritory. Once the troop movement stage of the turn is complete, play passes to the left.\nBonuses\nThere are two kinds of bonuses in the game. The first bonus is for holding a continent.\nIf at the beginning of a turn a player controls all territories on a continent, the player receives a\nbonus sum of troops equal to the number listed on the game board next to the name of that\ncontinent. The bonuses scale with continent size and are as follows: 2 troops for Australia or\nSouth America, 3 for Africa, 5 for North America or Europe, and 7 for Asia.\nThe second kind of bonus is derived from the territory cards received from conquering\nterritories. Each territory card has a picture of a territory and one of three emblems, typically\nan infantryman, a cavalryman, and an artillery piece. There are also two bonus cards that have\none of each emblem on the card. To get the bonus, players must have three matching\nemblems or one of each emblem at the beginning of the turn. There are two variations on\ntroop dispensation. The first is to grant each set of cards an ascending number of troops. This\nis the most common method, as the ascending value sequence is printed on the board. The\n\nsecond method is to assign a number of troops given for each emblem combination before the\ngame. If a player holds 5 cards at the beginning of any turn, he or she is required to cash them\nin for the troop bonus.\nPlayer Elimination\nA player is eliminated when he or she no longer controls any territories on the game\nboard. The eliminated player must then surrender all territory cards to the player that too his\nor her last territory. The game ends when only one player remains.\nProbability\nOne of the dominant principles in the game is probability. Understanding the principles\nof probability that are implicit in the game is a key building block of success. There are six\ndifferent combinations of numbers of dice that can be thrown by the attacker and defender.\nThe probabilities of the outcomes of the rolls are shown below:\nDefender Rolls One Die\nNumber of Dice\nRolled by Attacker:\nDefender Loses One\nTroop\n41.7%\n57.9%\n66.0%\nAttacker Loses One\nTroop\n58.3%\n42.1%\n34.0%\nDefender Rolls Two Dice\nNumber of Dice\nRolled by Attacker:\nDefender Loses Two\nTroops\n25.5%*\n22.8%\n37.2%\nAttacker Loses Two\nTroops\n74.5%*\n44.8%\n29.2%\nBoth Lose One Troop\nN/A\n32.4%\n33.6%\n*- Only one troop lost\n\nThe probability problem is simple when the troop numbers are small, but the problem becomes\nmuch more difficult when the number of troops on each side becomes greater as the event tree\nexpands and the number of possible outcomes and orders of outcomes increases exponentially.\nThus, it is very difficult to explicitly predict the outcome of a scenario and it becomes necessary\nto implement numerical methods to quantify the probability.\nOne such method is the Monte Carlo simulation. A Monte Carlo simulation simulates\neach roll and calculates the outcome of the roll. In this case, the Monte Carlo method used\nfactors the outcome of the roll into the troop strength and continues rolling until the troops of\none side are completely depleted. Given enough simulation iterations for each starting troop\nstrength combination, the percentage of victories for each side will approach the\nprobabilistically expected outcome. The Monte Carlo simulation used here calculated the\npercentage of wins over a 100,000 battle sample set. One important thing to note is that in\nactual game play, the attacking player can choose to end an attack at any point during the\nattack, but the simulation did not break off the attack if the odds became unfavorable for the\nattacker. The code for the Monte Carlo simulation was implemented in MATLAB and is\nattached as an appendix to this paper. Once the simulation had been run for all attacking and\ndefending troop strengths from one to thirty troops per side, the data was tabulated and\nturned into a \"heat map\" showing the probabilities graphically. This data is presented below,\nwith dark red signifying a high probability of attacker victory and dark blue signifying a low\nprobability of attacker victory. The green region of the graph is the area where the probability\nof victory is a virtual coin toss.\n\nAs is expected, a large number of troops attacking a much smaller defending force results in\nvictory almost all the time, and in many cases has a statistically insignificant probability of\nlosing. The converse is also true in that a small attacking force fighting a large defending force\nhas a statistically insignificant probability of success. The most interesting region of the graph is\nthe area where the armies are of relatively equal strength, as it is these battles that will swing\nthe momentum and perhaps even the outcome of the game.\nStrategy\nThere are several points of offensive and defensive strategy that arise from the dice\nprobabilities and from the game board:\n\nTake Small Continents First\nAustralia and South America are the two smallest continents, each with four territories.\nBoth are relatively easy to defend, as Australia only has one entry point and South America has\ntwo. South America and Australia are of critical importance at the beginning of the game\nbecause the territories are spread out evenly and the two-troop bonus for holding either of\nthese continents is a big boost to troop strength at the beginning of the game. Additionally,\nboth of these continents are valuable in the later stages of the game as they have entry points\ninto North America, Africa, and Asia which can be used to attack other players and keep them\nfrom holding those continents.\nAttack Conservatively\nWhile it is clearly advantageous to control lots of territories, taking over too many\nterritories to quickly can leave a player's forces very spread out and vulnerable to attack. Many\nplayers fall into the trap of trying to take over a large continent like Asia or North America in\njust one or two turns because the interiors of the continents are typically sparsely defended.\nWhat these players fail to remember is that holding a continent does no good unless it can be\nheld through the beginning of his or her next turn. Even with a large starting force, the attacker\nis bound to lose troops along the way and is forced to leave at least one troop in each territory,\nso the force left to defend the borders of the continent is much smaller and more vulnerable\nthan it was at the beginning of the attack phase.\nPlay Defense\nPlaying sound defense, while not exciting, is the key to winning the game. By the middle\nof the game, troops tend to end up concentrated on the borders of continents. Players must\n\nact accordingly if they wish to hold continents and maintain an advantage in the game. It is\nimportant to build up forces that can withstand attacks from several smaller armies from\nbordering countries and that can act as a deterrent for large attacking forces. This is especially\ncritical in many of the countries in the middle of the board because they have many entry\npoints from outside their continents. One example is the Middle East, which can be attacked\nfrom Ukraine, Southern Europe, Egypt, and East Africa. Without a strong presence in the\nMiddle East, it is nearly impossible to hold Asia.\nFinal Words\nPerhaps the best strategy for the game is to play a few times and develop a unique\nstrategy. The game is different each time you play and each person you play will have different\ntendencies. Being able to account for the dynamic nature of the game and to adjust playing\nstyle to fit each game are the biggest keys to success in Risk.\n\nAppendix - Monte Carlo Code\nfunction [AttackWinPCT]=SP268a(A,D)\nclose all\nsimnum=100000;\nn=1;\nWins=[0,0];\nwhile n<=simnum\nAttackTroop = zeros(30,1);\nDefendTroop = zeros(30,1);\nAttackTroop(1) = A;\nDefendTroop(1) = D;\ni=2;\nwhile AttackTroop(i-1)>0 && DefendTroop(i-1)>0\nif AttackTroop(i-1)<=3\nxa=AttackTroop(i-1);\nelse\nxa=3;\nend\nif DefendTroop(i-1)<=2\nxd=DefendTroop(i-1);\nelse\nxd=2;\nend\nDice = min(xa,xd);\na = 6*rand(1,xa);\nAttackDice=sort(ceil(a),'descend');\nd = 6*rand(1,xd);\nDefendDice=sort(ceil(d),'descend');\nADice(1)=AttackDice(1);\nDDice(1)=DefendDice(1);\nif ADice(1)>DDice(1)\nDefendT=DefendTroop(i-1)-1;\nAttackT=AttackTroop(i-1);\nelse\nAttackT=AttackTroop(i-1)-1;\nDefendT=DefendTroop(i-1);\nend\nif Dice==2\nADice(2)=AttackDice(2);\nDDice(2)=DefendDice(2);\nif ADice(2)>DDice(2)\nDefendT=DefendT-1;\n\nelse\nAttackT=AttackT-1;\nend\nend\nAttackTroop(i)=AttackT;\nDefendTroop(i)=DefendT;\ni=i+1;\nend\nif DefendT==0\nWins(1)=Wins(1)+1;\nelse\nWins(2)=Wins(2)+1;\nend\nn=n+1;\nend\nAttackWinPCT=round(1000*Wins(1)/simnum)/10;\n\nSources\nhttp://www.centralconnector.com/GAMES/RISK.htm\nhttp://graffletopia.com/stencils/455\nhttp://en.wikipedia.org/wiki/Risk_(game)\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nES.268 The Mathematics in Toys and Games\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "4-D Rubik's Cube",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/1f1f1e2f9aa102f52da8056f0cfad64a_MITES_268S10_4Dcube.pdf",
      "content": "In 1974, Erno Rubik created the Rubik's Cube. It is the most popular puzzle\nworldwide. But now that it has been solved in 7.08 seconds, it seems that the world is in\nneed of a new challenge. Melinda Green, Don Hatch, and Jay Birkenbilt took it upon\nthemselves to meet this challenge. They created a program that is a 4-dimensional analog\nof the Rubik's Cube. This paper will discuss the properties of the hypercube and the\ngeneral idea behind the solution to the 4-dimensional Rubik's cube.\nFirst, we must discuss what the fourth dimension is. Most people regard the fourth\ndimension as time, but that is certainly not how it is going to be presented in this context.\nWe cannot actually perceive a fourth spatial dimension directly, but we can do so by\nanalogy. Suppose that there is a two-dimensional world called Flatland. In Flatland, the\nworld is a plane and all of the inhabitants are two-dimensional creatures. Everything in\nFlatland exists in the plane of Flatland (that is, not sticking out). Now suppose that you\ntell some person on Flatland that there exists a third dimension. The person would\nrespond, \"Third dimension?! There is no third dimension!\" You then proceed to put a rod\nthrough the plane of Flatland and say, \"See? Look, I told you that there is a third\ndimension.\" The person would respond, \"No, there isn't, all I see is a circle.\" The person\nin Flatland cannot perceive the third dimension, but that does not mean that it does not\nexist. Similarly, we cannot perceive the fourth spatial dimension, but that does not mean\nthat it does not exist. In the same vein of a two-dimensional world, think about a sheet of\npaper. For all practical purposes, the sheet of paper has only two dimensions: length and\nwidth. But there is of course a third dimension! The third dimension is the thickness of\nthe paper. However, the thickness is so small compared to the other two dimensions that\nit can be ignored. Similarly, perhaps the fourth dimension is analogous to the paper\n\nexample. That is, that there is a fourth dimension, but it is so thin (perhaps infinitesimally\nthin) that it is ignored, or, we just do not notice it. Thus, the fourth dimension is usually\ndefined via analogies to three-dimensional space.\nNow that we have an idea of what discussed what the fourth dimension is, we can\ndiscuss some properties of the four-dimensional Rubik's cube. Since, as we have pointed\nout, we cannot have a literal four-dimensional cube to hold and play with, it must be\nsimulated on a computer. However, there are some properties that are necessary of the\nfour dimensional analogue that do not require it being on a computer to accurately\ndescribe them. Since the fourth-dimension is defined by analogy to the three-dimensions,\nthe four-dimensional Rubik's cube will be defined by analogy to the three-dimensional\nRubik's cube.\nOn the three-dimensional cube, there are three-dimensional edge pieces and\ncorner pieces. The edge pieces have 2 two-dimensional stickers on them of different\ncolors, while the corner pieces have 3 two-dimensional stickers on them of different\ncolors. In the four-dimensional cube, the edge pieces and corner pieces are four-\ndimensional and they have three-dimensional stickers on them. The edge pieces have 3\nthree-dimensional stickers on them, while the corner pieces have 4 three-dimensional\nstickers on them.\nOn the three-dimensional cube, there are 6 center pieces: one on the positive and\nnegative ends of the x-axis, y-axis, and z-axis. Well, in the fourth dimension, there is an\nadditional axis, which has a positive and negative end; therefore the four-dimensional\ncube will have 8 center pieces. The analogies for the edge pieces and corner pieces are a\n\nbit harder to describe. Because this is a four-dimensional cube, it introduces some new\nproperties.\nThere are now \"face\" pieces and \"edge\" pieces. In a three-dimensional cube, each\nface has a 3-by-3 grid of two-dimensional stickers. Well, by analogy for the fourth\ndimension, there is a 3-by-3-by-3 cube of three-dimensional stickers. On the three-\ndimensional cube, there is no need to describe what connects the centers. There are no\npieces that connect the centers that affect the solved configuration of the cube. However,\nfor the four-dimensional cube, there are pieces between the centers that affect how the\ncube will be solved. On the three-dimensional cube, the 3-by-3 grid can be thought of as\n8 stickers that surround the center. By analogy, the 3-by-3-by-3 cubic face can be thought\nof as 26 three-dimensional stickers that surround a center. This brings in a new level of\npieces, namely the pieces that connect all of the centers together.\nThe \"face\" pieces are somewhat analogous to edge pieces on a Rubik's Cube.\nThese face pieces have only two colors on them. There are a total of 24 of them. There\nare 6 that connect the central face to the adjacent 6 faces. But that is only on one end of\nthe fourth dimensional axis. On the other end of the fourth-dimensional axis, there are 6\nmore. Then, there are four face pieces that connect the top face to four of the faces\nadjacent to the central face. Then there are four face pieces that connect the bottom face\nto four of the faces adjacent to the central face. Finally, there are the four face pieces that\nconnect those four adjacent faces together. Thus the total is 6+6+4+4+4, which equals 24.\nThere are also edge pieces. The edge pieces on a three-dimensional cube connect\none color of a 3-by-3 grid to an adjacent 3-by-3 grid of another color. By analogy, there\nare edge pieces on the four-dimensional Rubik's cube that connect adjacent 3-by-3-by-3\n\ngrids together. Since for any face of the four-dimensional cube, there are three adjacent\nfaces of a different color, the edge pieces on the four-dimensional Rubik's cube contain 3\ncolors. There are a total of 32 of these pieces. There are 12 edge pieces that are connected\nto one end of the fourth-dimensional axis: 4 in the xy-plane, 4 in the yz-plane, and 4 in\nthe xz-plane. Similarly, there are 12 on the other end of the fourth-dimensional axis.\nNow, there are 8 more edge pieces. These pieces connect the pieces that are adjacent to\neach other, but not to the central face, whether that central cube is on the positive or\nnegative axis of the fourth dimension. Thus the total is 12+12+8, which equals 32.\nFinally there are the corner pieces. A corner piece of the three-dimensional cube\nconnects one 3-by-3 grid to two adjacent 3-by-3 grids. By analogy, the corners of the\nfour-dimensional Rubik's cube connect three adjacent 3-by-3-by-3 faces together. There\nis a total of 16 corner pieces. There are 8 corners that connect the central face to the three\nadjacent 3-by-3-by-3 cubic grids. That is only on one end of the fourth-dimensional axis.\nThere are eight more on the other end. Thus, the total number of corner pieces is 8+8,\nwhich equals 16.\nTherefore, the total number of pieces on the four-dimensional Rubik's Cube is: 8\ncenter pieces plus 24 face pieces plus 32 edge pieces plus 16 corner pieces, which equals\n80 pieces. However, the center pieces never move with respect to each other, so there are\nactually only 72 moveable pieces.\nNow that we have a grasp on the structure of the four-dimensional Rubik's cube,\nlet us now consider what happens when you perform twists on a four-dimensional\nRubik's cube. On a three-dimensional Rubik's cube, it is intuitive to think of twisting as\nrotating about an axis. However, that is not helpful to the understanding of twists on the\n\nfour-dimensional Rubik's Cube (indeed, any higher dimensional cube), because it is\nunclear what the fourth dimension is. Thus to say that twisting on the four-dimensional\ncube is like twisting about a four-dimensional axis is meaningless in understanding how\nfour-dimensional twists work. Therefore, twisting needs to be thought of differently.\nThe fact that twisting on a three-dimensional cube can be described as rotating\nabout an axis is merely a special case. It does not fully describe the higher order cases.\nAnother way to think about twisting a face on a three-dimensional cube is to say that you\npick a face, remove that face from the cube, then rotate it without flipping it over, then\nput it back onto the cube. There are only 4 ways to do this, and they all involve rotating\nabout the axis perpendicular to the center. Now this concept can be applied to the four-\ndimensional cube by analogy. To twist a face on a four-dimensional cube, you pick a\nface, remove that face from the hypercube, rotate it without turning it inside out, and then\nput it back in place. On the three-dimensional cube, the face was a 3-by-3 grid, so\nremoving it was like taking it off a plane and later putting it back on the plane. However,\nthe four-dimensional cube has a face that is a 3-by-3-by-3 cube, so removing that face is\nlike taking it out of a box, and then later putting it back in the box. Once you take it out\nof the box, you rotate it. There are a total of 24 ways to do this. You could rotate it 4\nways about the axis in the xy-plane, 4 in the yz-plane, and 4 in the xz-plane. Also, you\ncan rotate about the diagonals of the cube. There are only 3 ways you can rotate about a\ndiagonal. There are 4 diagonals, each connecting opposite corners of the cube that do not\ncontain the same plane. Thus the total number of ways to rearrange a face after a twist is\n4+4+4+3+3+3+3, which equals 24.\n\nNow that we have a conceptual understanding of what the fourth-dimension is and\nwhat the fourth dimensional Rubik's cube structure will contain, we must now consider\nthe computer program that accurately portrays the four-dimensional Rubik's cube,\nnamely, MagicCube 4D. This applet can be downloaded for free from\nhttp://www.superliminal.com/cube/applet.html\nThe cube seems to look somewhat distorted. This is because of the perspective\nchanges that come from projecting down to a lower dimension. Think about drawing a\ncube on a sheet of paper. A cube, by definition has all of the sides perpendicular to each\nother. However, when you draw it on paper, some of the sides may look perpendicular,\nwhile some clearly do not look perpendicular. Additionally, in the Flatland example, if\nyou were to try to show an inhabitant of Flatland that the third dimension exists by\ndrawing them a cube on a sheet of paper, that person would only comprehend a group of\nlines, not the cube itself. A very similar thing happens for the four-dimensional Rubik's\ncube, except worse. The four-dimensional cube is projected into our three-dimensional\nworld, which is then projected onto a two-dimensional computer screen, so it looks even\nmore distorted than usual. Furthermore, since the four-dimensional cube is projected onto\nour three-dimensional world, we can never get an understanding of what the four-\ndimensional cube actually looks like. All we see is a group of cubes. The four-\ndimensional cube looks essentially like a cube of cubes, but only the center face only\nlooks like a two-dimensional projection of a cube that we are used to seeing. This is\nbecause of the distortion that occurs from projecting down two dimensions. Just as\ndrawing a cube on paper can have faces that are square with other distorted faces, putting\n\na four-dimensional object on the screen results in one face looking like a conventionally\ndistorted cube, with the other faces looking like especially distorted cubes.\nEarlier, we said that there are eight center pieces. However, on the applet we only\nsee seven center pieces. Again, this can be explained by analogy to the three-dimensional\ncube. On a three-dimensional cube, it is impossible to see all 6 faces at the same time.\nSimilarly, on a four-dimensional cube, it is impossible to see all 8 faces at the same time.\nThe way the applet is set up, the maximum amount of faces you can see at the same time\nis seven. However, scrambling the cube inherently involves messing up the eighth face,\nso in order to solve the four-dimensional Rubik's Cube, you must somehow be able to see\nthe eighth face. How is this possible? Well, on a three-dimensional cube, although all 6\nfaces cannot be seen at the same time, you can still look at any desired face via a rotation\nabout a principal axis of the cube. The same concept applies to the four-dimensional\ncube, but now, since it is four-dimensional, there is a new axis to rotate about. In order to\nsee the eighth face, you must rotate about the fourth-dimensional axis. In the applet, you\ndo this by holding down the option key and clicking on a sticker on a face that you want\nto move to the central core. The eighth face then replaces the face that you just clicked,\nand the last face that was on the path of moving faces moves out to be the hidden eighth\nface. It is important to note that this creates a motion that turns the four-dimensional cube\ninside out. This is what is commonly accepted as a four-dimensional rotation. Also, this\nfour-dimensional rotation does not affect the state of the cube in terms of how solved it\nis. This makes sense because on a three-dimensional cube, rotating it does not get it any\ncloser to being solved; it just changes the angle at which you view the cube. Similarly, on\nthe four-dimensional cube, the four-dimensional rotation just changes the angle (in the\n\nfourth dimension) with which you view the hypercube; it does not get it any closer to\nbeing solved.\nNow, we must consider a very important part of manipulating the four-\ndimensional Rubik's cube, namely how a twist is performed on the applet. Recall that a\nface is a group of 26 stickers that surround a center. When you want to perform a twist,\nyou highlight a sticker and click on it. The left click twists it counterclockwise with\nrespect to the axis of rotation that is being viewed from above. The right click twists it\nclockwise. The axis of twist goes through the highlighted sticker and the center of the\nface that contains the highlighted sticker.\nIt is important to note that clicking on a sticker on a face twists the face into a new\nposition without changing it. When you use the applet, however, it seems that some 3-by\n3 slices of one face seem to spin or fly onto another face. This can be explained by the\nfact that twisting creates the scrambling effect of the four-dimensional Rubik's Cube. On\nthe three-dimensional cube, twisting a face of the cube does not affect the stickers in the\nsense that all of the stickers stay on the same piece. The state of the stickers on the face\ndoes not change, but the effect of the state of the adjacent faces does change. That is how\nthe cube gets scrambled.\nAn important conceptual leap that needs to be made in order to understand the\napplet is that the faces and stickers are separated by gaps. There seems to be no physical\nconnection between the stickers, so it seems that any sticker can move anywhere,\nhowever, this is not the case. In the applet, although there does not appear to be any\nconnection between the pieces, they are indeed connected! In order to solve the cube, you\nmust keep in mind that the three-dimensional stickers are connected by four-dimensional\n\npieces. However, we cannot see these pieces because that would require that we be in the\nfourth-dimension. Furthermore, on a real four-dimensional Rubik's cube, all of the faces\nand stickers would be slammed together. The applet simply presents an exploded view of\nthe real four-dimensional Rubik's cube so that we can see the internal state, or the central\nface.\nBy now, we should have a good understanding of the structure of the four-\ndimensional cube and how the four-dimensional cube works. Now let us discuss how to\nsolve the cube from a scrambled state. In order to solve the cube, it must first be\nscrambled. To truly solve the puzzle, you must first select from \"Full\" from the\n\"Scramble\" drop-down menu. It is a truly difficult job to solve the cube from a scrambled\nstate. At the time that this paper is written, there have only been 104 people worldwide\nwho have solved the four-dimensional analog of the three-dimensional 3-by-3-by-3\nRubik's Cube.\nIf the challenge of truly solving a fully scrambled cube seems too daunting, then\nthe applet contains several levels of how scrambled the four-dimensional cube can be. It\nis much easier to solve the cube from one random twist. Then, once that feels\ncomfortable, you can move on to two random twists then three, then more. Indeed, this\ncan be quite helpful in solving the puzzle. In the three-dimensional puzzle, before diving\nright into solving the puzzle, it is important to get a good feel of the puzzle. It is\nimportant to gain the conceptual understanding of moving three-dimensional pieces that\ncontain two-dimensional stickers. Your goal is not to move all of the stickers in the right\nplace. Your goal is to move all of the right pieces in the right place. The same concept is\nextremely important in solving the four-dimensional puzzle. You must focus on putting\n\nthe four-dimensional pieces in the right place, not to put the three-dimensional stickers in\nthe right place.\nThe four-dimensional Rubik's cube was created by an analogy to the three-\ndimensional Rubik's cube, so it only makes sense that in order to solve the four-\ndimensional Rubik's Cube, it is at least extremely helpful in understanding how to solve\nthe three-dimensional Rubik's Cube first. On the three-dimensional cube, one way to\nsolve the cube is to first place the two-colored edge pieces in the right place, then the\nthree-colored corner pieces. This essentially means that you are solving from the centers\noutward. Well, on the four-dimensional puzzle, in order to work from the centers\noutward, you must solve the two-colored face pieces, then the three-colored edge pieces,\nand then the four-colored corner pieces. Not surprisingly, solving the two-colored face\npieces on the four-dimensional cube is very similar to solving the two-colored edge\npieces on the three dimensional cube. Furthermore, solving the three-colored edge pieces\non the four-dimensional cube is very similar to solving the three-colored corner pieces on\nthe three-dimensional cube. Thus, it is quite possible to get two-thirds of the way through\nsolving it without learning a lot of new information. Solving the four-colored corner\npieces however, requires learning some new sequences, as there is no analog for the four-\ncolored corner pieces on the three-dimensional cube.\nThe first step in solving the three-dimensional cube is to solve a cross with the\ntwo-colored edge pieces. Well, on the four-dimensional cube, the first step is to solve a\ncross with the two-colored face pieces. The cross on the three-dimensional cube consists\nof a center piece that is surrounded by 4 edge pieces on the same face. The cross on the\nfour-dimensional cube consists of a center piece that is surrounded by 6 face pieces on\n\nthe same face. This step consists of solving center pieces in the central face. The next step\nis to move the outer, hidden face to the center and solve for another cross. After that, the\n\"top face\" face pieces need to be solved. This solves all of the face pieces. Next the three-\ncolored edge pieces will be solved. This step depends more heavily on algorithms than on\na conceptual understanding of shifting pieces around, much like solving the three-\ndimensional cube at this point. Finally, the four-colored corner pieces need to be put in\nthe right place, and then the cube is solved.\nSources\nhttp://www.superliminal.com/cube/faq.html\nhttp://www.superliminal.com/cube/solution/solution.htm\nhttp://www.superliminal.com/cube/solution/pages/cube.htm\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nES.268 The Mathematics in Toys and Games\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    }
  ]
}