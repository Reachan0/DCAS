{
  "course_name": "Probability and Statistics in Engineering",
  "course_description": "This class covers quantitative analysis of uncertainty and risk for engineering applications. Fundamentals of probability, random processes, statistics, and decision analysis are covered, along with random variables and vectors, uncertainty propagation, conditional distributions, and second-moment analysis. System reliability is introduced. Other topics covered include Bayesian analysis and risk-based decision, estimation of distribution parameters, hypothesis testing, simple and multiple linear regressions, and Poisson and Markov processes. There is an emphasis placed on real-world applications to engineering problems.",
  "topics": [
    "Engineering",
    "Mathematics",
    "Probability and Statistics",
    "Engineering",
    "Mathematics",
    "Probability and Statistics"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nCourse Description\n\n1.151 is a first-year graduate subject, very similar in content to\n1.010\n, which is a sophomore-level undergraduate subject. Both aim at introducing students to quantitative uncertainty analysis and risk assessment for engineering applications. The subjects cover similar material, but the 1.151, the graduate version, includes additional topics (such as system reliability) and is faster-paced and more in-depth. The undergraduate course includes weekly recitations mainly to solve problems, review material presented in class, and engage students in bi-weekly 30-minute mini-quizzes. Along with these small quizzes, there is a final exam.\n\nBoth subjects try to strike a balance between mathematical rigor and applications. No previous familiarity with probability or statistics is assumed. However, students should be conversant with basic linear algebra (vectors and matrices) and calculus (derivatives, and integrals).\n\nEmphasis is on probability theory and its applications, with a smaller module at the end covering basic topics in statistics (parameter estimation, hypothesis testing and regression analysis). The probability part includes events and their probability, the Total Probability and Bayes' Theorems, discrete and continuous random variables and vectors, the Bernoulli trial sequence and Poisson process models, conditional distributions, functions of random variables and vectors, statistical moments, second-moment uncertainty propagation and second-moment conditional analysis, and various probability models such as the exponential, gamma, normal, lognormal, uniform, beta and extreme-type distributions. In addition, the graduate subject has a module on system reliability, which covers both second-moment and full-distribution techniques. Throughout the subjects, emphasis is on application to engineering and everyday life problems.\n\nRecommended Text\n\nThe recommended text for this class is:\n\nAng, Alfredo, and Wilson Tang.\nProbability Concepts in Engineering Planning and Design: Vol I - Basic Principles\n. New York, NY: John Wiley & Sons, 1975. ISBN: 047103200X.",
  "files": [
    {
      "category": "Resource",
      "title": "homework_1_2005.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/9b29722140570e99c46770043be53586_homework_1_2005.pdf",
      "content": "Homework Set #1\nProblem 1\nSuppose that the occurrences of earthquakes and high winds are unrelated. Also suppose\nthat, at a particular location, the probability of a \"high\" wind occurring in any single minute\nis 10-5 and the probability of a \"moderate\" earthquake in any single minute is 10-8.\n(a) Find the probability of joint occurrence of the two events during any minute.\nBuilding codes do not require the engineer to design buildings for the\ncombined effects of these loads. Is this reasonable?\n(b) Find the probability of the occurrence of one or the other or both during any\nminute. For rare events, i.e. events with small probabilities of occurrence, the\nengineer frequently assumes:\nP(A U B) ~ P(A) + P(B)\nIs this reasonable?\n(c) If the events in consecutive minutes are mutually independent, what is the\nprobability that there will be no moderate earthquake in a year at this\nlocation? In 10 years?\nProblem 2\nRead Application Example 1 and do Problems 1.1 and 1.5\nProblem 3\nRead Application Examples 2 and do Problem 2.2"
    },
    {
      "category": "Resource",
      "title": "homework_2_2005.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/7e63e1259a2fea62ccebcc6807031f8d_homework_2_2005.pdf",
      "content": "Homework Set #2\nProblem 1\nA machine to detect improper welds in a fabricating shop detects 80 percent of all\nimproper welds, but it also incorrectly indicates an improper weld on 5 percent of all\nsatisfactory welds. Past experience indicates that 10 percent of all welds are improper.\n(a) What is the probability that a weld that the machine indicates to be defective is in\nfact satisfactory?\n(b) What is the probability that a weld which the machine indicates to be satisfactory\nis in fact defective?\n(c) Compare the probabilities in (a) and (b) and comment on their relative\nmagnitudes.\nProblem 2\nThe service stations along a highway are located according to a Poisson process in space,\nwith an average of 1 service station in 10 miles. Because of a gas shortage, there is a\nprobability of 0.3 that a service station would have no gasoline available. Assume that the\navailabilities of gasoline at different service stations are statistically independent.\n(a) What is the probability that there is at most 1 service station in the next 15 miles\nof highway?\n(b) What is the probability that none of the next 3 stations has gasoline for sale?\n(c) A driver on this highway notices that the fuel gauge in his car reads empty; from\nexperience he knows that he can go another 15 miles. What is the probability that\nhe will be stranded on the highway without gasoline?1\nProblem 3\nDuring a 2-month hurricane season, severe hurricanes at a given location occur at\nPoisson times with a rate λ = 1 event/month. Last year, 4 hurricanes occurred and the\nlocal press has blamed \"changes in the climate\" for what they reported as an extremely\nsevere hurricane season. From a statistical point of view, how unusual are seasons of this\nor higher severity? Would you agree or disagree with the press that this was an\nexceptionally severe season?\n1 An important result for Poisson processes is that, if a Poisson process with rate λ is \"thinned\" randomly\nwith probability p (meaning that each point of the process is eliminated with probability p independently of\nthe other points), then the remaining points still form a Poisson process with a reduced mean rate of (1-p)λ.\nApply this result to answer question 1(c)."
    },
    {
      "category": "Resource",
      "title": "homework_3_2005.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/f192877d33886165bf874c0e55333863_homework_3_2005.pdf",
      "content": "Homework Set #3\nProblem 1\nRead Application Example 8 and do Problem 8.1.\nProblem 2\nThe way MIT admits undergraduate students is exemplified in the following table. Each\napplicant is rated to a discrete \"scholastic index\" X (horizontal axis) and a discrete\n\"personal rating index\" Y (vertical axis). The top number in each cell (in bold) is the\nnumber of applicants is a given year with the associated combination. The bottom\nnumber in each cell (in italic) is the probability of being accepted. (Although this is\nindeed the way MIT handles applications, all numbers are fictitious).\n← Scholastic Index, X →\nPersonal Rating,\nY\n90-100\n80-90\n70-80\n60-70\n50-60\n≤ 50\n↓\n1.0\n0.9\n0.7\n0.5\n0.4\n0.3\n0.9\n0.7\n0.5\n0.4\n0.3\n0.2\n0.7\n0.5\n0.4\n0.3\n0.2\n0.1\n0.5\n0.4\n0.3\n0.2\n0.1\n0.0\n0.4\n0.3\n0.2\n0.1\n0.0\n0.0\n≤ 5\n0.3\n0.2\n0.1\n0.0\n0.0\n0.0\n(a) Plot the marginal PMF of the two indices.\n(b) Plot the conditional PMFs of (X|Y = 8) and (X|Y = 6).\n(c) Plot the conditional PMF of (Y|X ≤ 50).\n(d) What is the probability that an applicant with Y = 7 is accepted.\n(e) Are X and Y independent? Why?\n\nProblem 3\nIn Bounty Town, U.S.A., total precipitation during the crop-growing season, Q, has a\nuniform distribution between 2 and 4 inches. The total crop value $ depends on Q in such\na way that ($|Q = q) has uniform distribution (in millions of dollars) between (2q - 1) and\n(2q + 1). Note that the possible values of (Q,$) are inside the parallelepiped shaded in the\nfigure below:\n2q + 1\n$\n2q - 1\nq\n(a) What is the joint PDF of Q and $?\n(b) What is the marginal PDF of $?\n(c) What value of $ is exceeded on average every 5 years?\nRead Application Examples 7, 9 and 10. ."
    },
    {
      "category": "Resource",
      "title": "homework_4_2005.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/83fec47382620c30f1141ed0e6000e79_homework_4_2005.pdf",
      "content": "Homework Set #4\n\nProblem 1\nSuppose that buses arrive at a terminal according to a Poisson Point Process with mean\nrate\n. Simulate the Poisson Point Process of bus arrivals over a period of\n10,000 minutes using the procedure discussed in class i.e. simulate\nrom\nthe uniform distribution between 0 and 1, and calculate the interarrival times as\nmin)\n/(\n=\nλ\nN\nY\n,...,\nY\n,1\nY\nf\n(\ni\nY\nln\ni\nT\n-\nλ\n-\n=\n). To validate this:\n(a) Plot a histogram of the interarrival time T and compare with the theoretical\nexponential distribution.\n(b) Plot the relative frequency of the number of buses in intervals of 20 minutes and\ncompare with the theoretical Poisson probability distribution.\n\nProblem 2\nShow that the function below is the PDF of R, the distance between the epicenter of an\nearthquake and the site of a dam, when the epicenter is equally likely to be at any\nlocation along a neighboring fault (see Figure 4.2). You may restrict your attention to a\nlength of fault\nthat is within a distance r\nA\no of the site because earthquakes at greater\ndistances will have negligible effect at the site.\n\no\n/\nR\nr\n≤\nr\n≤\nd\n\n,\n)\nd\nr(\nr\n=\n)r(\nf\n-\n2 -\nA\n\nSketch the function.\nA\nSite\nB\nro\nro\nd\nl/2\nl/2\nFault\n\n/\nA\n/\nA\n\nFigure 4.2\n\n1 m\nProblem 3\n\nA dam is to be designed to safely retain the water in a reservoir. Let H be the maximum\nwater level in the reservoir in a generic year, and F be the associated horizontal force\nacting on a 1 meter length of the dam.\n\n10 m\nF\nH\n6 m\nFigure 4.1\nF is related to H as:\n\nH\ncH\nF\n=\n=\n\nwhere H is in meters, and F is in kN\n\nSuppose that H has uniform distribution between 6 and 10 meters, so that:\n\n⎪⎩\n⎪⎨\n⎧\n≤\n≤\n=\notherwise\n\n0,\nh\n\n,\n)\nh\n(\nfH\n\n(a) Find the CDF of F.\n(b) Assuming that water levels in different years are independent, plot the distribution\nof the maximum force in 20 years.\n(c) What practical conclusions on the design value of the horizontal force can you\nextract from the result in part (b)?"
    },
    {
      "category": "Resource",
      "title": "homework_5_2005.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/6c786b2002c1204eb865f8c9498c47af_homework_5_2005.pdf",
      "content": "Homework Set #5\n\nProblem 1\n\nX has probability density function as shown below.\n\n)\nx\n(\nfX\n\n⎩\n⎨\n⎧\n≤\n≤\n=\notherwise\n\n0,\nx\n\n,x\n)\nx\n(\nX\nf\n\nX\n\nCalculate the mean value\n, variance\nand second initial moment\n. Verify\nthe relaton E\n.\nX\nm\nX\nσ\n]\nX\n[\nE\nX\nX\nm\n]\nX\n[\nσ\n+\n=\ndx\n\n(x)\nX\nf\n)\nY\nm\n(x\nY\n\nProblem 2\nX has uniform distribution between 2 and 3. Consider a new variable\n.\nX\nY =\n\n(a) Sketch the function\n.\nY(X)\n(b) Find the probability density function of Y.\n(c) Calculate the mean value and variance of X.\n(d) Using the probability density function found in (b), calculate the mean value and\nvariance of Y.\n(e) Verify that m\nand\ncan be obtained also as\nY\nY\nσ\n∫\n=\ndx\n\n(x)\nX\nf\nx\nY\nm\nand σ\n.\n∫\n-\n=\n\nProblem 3\n\nConsider two discrete random variables\nand\n, with the joint probability mass\nfunction shown in the figure below. (Notice that the distribution is concentrated at four\npoints, with equal probability 0.25 at each point).\nX\nX\n\nX2\n-1\n-1\n0.25\n0.25\n0.25\n0.25\n\nX1\n\n(a) Are\nand\nindependent? Briefly explain why or why not.\nX\nX\n(b) Find the mean values\nand\n, the variances\nand\n, and the correlation\ncoefficient ρ between\nand\n\nm\nm\nσ\nσ\nX\nX ."
    },
    {
      "category": "Resource",
      "title": "homework_6_2005.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/064204f71301507ddc6e5c86acca7bd8_homework_6_2005.pdf",
      "content": "Homework Set #6\nProblem 1\nIn planning a building, the number of elevators is chosen on the basis of balancing initial\ncosts versus the expected delay times of the users. These delays are closely related to the\nnumber of stops the elevator makes on a trip. If an elevator runs full (n people) and there\nare k floors, we want to find the expected number of stops R the elevator makes on any\ntrip. Assuming that the passengers act independently and that any passenger chooses a\nfloor with equal probability\nk\n1 . Show that:\n⎡\n- ⎛1 -\n⎜\n⎝\nk\n⎞⎟\n⎠\nn ⎤\n⎥\n⎥⎦\nE[R] =\nk ⎢\n⎢⎣\nHint: It is often useful to define \"indicator random variables\" as follows: Let Xi = 1 if\nk\nthe elevator stops at floor i, and Xi = 0 if it does not. Then observe that R ∑\n=\nXi . Find\n=1\nthe expected value of Xi after finding the probability that Xi = 0.\nProblem 2\nIn the very preliminary planning of some harbor island developments, there was\ndiscussion regarding the cost estimates of building four bridges. There had as yet not\nbeen a preliminary soil survey in the harbor area, and it was recognized that the bridge\ncosts are highly dependent on soil conditions. Therefore, there was great uncertainty in\nthe preliminary cost estimates. A spokesman, however, made this statement; \"I recognize\nthe uncertainty on the cost estimate of any bridge. But I am much more confident of our\nestimate for the total cost of all four bridges because the likelihood that a high estimate\non one will be balanced by a low estimate on another.\"\nDiscuss this statement. Use your knowledge, simply, of the means and variances of sums\nof random variables to support your comments. If your initial intuition lies with the\nspokesman, be sure you resolve in your own mind why it is inconsistent. Compare both\nthe variance and the coefficients of variation of the total cost versus those of an\nindividual cost. If the four bridge sites are relatively close to one another, soil conditions,\nalthough unknown, are probably similar. What implications does this observation have\nfor your analysis?\nProblem 3\nYou finally succumbed to temptation! You are going to invest $1000 in the stock market,\nbut do not know how to best allocate the money between two stocks you especially like.\nHere are the facts: historically, both stocks have had a mean annual gain of 10%, with a\nstandard deviation of 5% for the first stock and 10% for the second stock and a\ncorrelation coefficient ρ = 0.2. Your objective is to minimize the volatility of your\nportfolio by reducing as much as possible the variance of the value of your investment\none year from now. How should you allocate your money between the stocks?\ni\n\nProblem 4\nThe top-floor displacement of a building D depends on wind speed V and the stiffness of\nthe building K as:\n=\nD KV2\nD\nV\nSuppose that K and V are independent random variables with second moment\ncharacteristics:\n~\nK\n(mK , σ2 ) ;\n~\nV\n(mV, σ2 )\nK\nV\n(a) Find in approximation mD and σD using FOSM.\n(b) Compare the FOSM mean value mD with the exact mean value.\n[Hint: If X1 and X2 are independent, then E[g1(X1)g2(X2)] = E[g1(X1\nE\n)]. [g2(X2)]\n(c) Under what conditions is the FOSM estimate accurate?"
    },
    {
      "category": "Resource",
      "title": "homework_7_2005.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/ac58c882b974f870e117e5d896c1ccd3_homework_7_2005.pdf",
      "content": "Homework Set #7\nProblem 1\nConsider a sequence of random variables X1, X2, ..., Xi, ..., for example denoting the\nmonthly profits of a supermarket chain. Suppose that Xi ~ (m,σ2) for all i and that the\ncorrelation coefficient between Xi and Xj, ρij, depends only on the time lag |i-j| as\nj|\nρij = 0.8|i-\nUsing conditional SM analysis, calculate and plot, as a function of k ≥ 1, the variances of\n(Xi+k|Xi) and (Xi+k|Xi,Xi-1). Comment on the results.\nProblem 2\nX is an unknown quantity, say the compressive strength of a concrete column, with mean\nvalue m and variance σ2. Several indirect measurements of X, in the form Zi = X + εi for i\n= 1, ..., n, are made through a nondestructive technique.\nUnder the assumption that the εi are iid measurement errors with zero mean and common\nvariance σ2 , use conditional SM analysis to find the variance of (X|Z ,...,Z ). Plot this\nε\nn\nconditional variance against n for σ2 = 1 and σ2 either 1 or 0.2.\nε\nUseful result on the inverse of covariance matrices with a special \"equicorrelated\"\nstructure. The inverse of an n × n matrix A of the type:\nρ\n⎥⎥\n⎥\n⎥\n⎥\n⎥\n⎥\n⎥\n⎦\n⎤\n⎡\nρ\n⎢\n⎢\n⎢\n⎢\n⎢\n⎢\n⎢⎢⎣\nA σ\n= 2\nis:\n]\n⎡[1\nρ\n+\nρ\n-\n+\n]\n[1\n]\n)\nn\n(\n-ρ\n-ρ\n2)\n-\n(n\n⎤\n⎥\n⎥\n⎥\n⎥\n⎥\n⎥\n⎥\n⎥\n⎥⎦\n-\nA\nσ\n=\n2(1\nρ\n-\n)[ + ( n - 1) ρ\n⎢\n⎢\n⎢\n⎢\n⎢\n⎢\n⎢\n⎢\n⎢⎣"
    },
    {
      "category": "Resource",
      "title": "homework_8_2005.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/a98964041ee2c96fcef5e2c8d5fe8668_homework_8_2005.pdf",
      "content": "Homework Set #8\n\nA plain concrete column is subjected to a random axial load W with lognormal\ndistribution, mean value\nkN\n\nmW =\n[kN = Kilo Newton, a unit of force] and\ncoefficient of variation\n. The resulting compressive stress\nis given by\n2.0\nVW =\nσ\nA\nW\n=\nσ\n, where A is the cross-sectional area of the column. The crushing strength of\nconcrete fc also has lognormal distribution, with mean value\n(m =\nmeter) and coefficient of variation\nf\nkN/m\n\n,\nm c =\n2.0\nV cf\n=\n.\n\n(a) Obtain the probability density function (PDF) of the applied stress σ (which\ndepends on A).\n(b) If the column has a 0.40 m x 0.40 m square cross-section, what is the probability\nPF that it fails i.e.\n]\nf\n[P\nP\nc\nF\n>\nσ\n=\n? Assume W and fc are independent.\n\nHint:\nc\nf\nln\n\nc\nf\n\nc\nf\n<\n⎟\n⎠\n⎞\n⎜\n⎝\n⎛\nσ\n⇔\n<\nσ\n⇔\nσ\n<\n\n(c) Determine the required cross-sectional area of the column for a target failure\nprobability of 10-3.\n(d) Find the mean stress\nA\nm\nm\nW\n=\nσ\nas a function of the failure probability PF. Plot\nagainst\nfor\nbetween 10\n)\nP\n(\nm\nF\nσ\n)\nP\nlog( F\nF\nP\n-4 and 10-1."
    },
    {
      "category": "Resource",
      "title": "homework_9_2005.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/c9f004ad81df5dc754e4897821e44b0f_homework_9_2005.pdf",
      "content": "Homework Set #9\nThe pressure acting on the windows of a high-rise building is Y = CV2, where V is wind\nspeed in km/hr, and C is a local effect factor, the units of which are such that Y is in\nkg/cm2.\nThe local effect factor and the 10-year peak wind speed at the site of the building have\nthe following mean values and standard deviations:\nmC = 0001\n.0\n, σC = 0001\n.0\nmV = 100 , σV = 20\nC and V are uncorrelated.\nThe strength of the window is Y* = 5 kg/cm2.\n(a) Sketch the failure boundary in (C, V) space for 0.0001 < C < 0.0005 and\n100 < V < 200.\n(b) Make the corresponding plot in the space of the normalized variables C' and V':\nC - mC\nV - mV\n'\nC =\nand\n'\nV =\nσC\nσV\n(c) Calculate the second moment reliability index β for a 10-year exposure using the\niterative procedure given in class. Operate in the space of the normalized\nvariables C' and V'.\n(d) On the sketch you made, indicate the iterations and show convergence to the β\npoint."
    },
    {
      "category": "Resource",
      "title": "homework_10_2005.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/99126d861d9b4e42d85f558ffdc6478d_homework_10_2005.pdf",
      "content": "Homework Set #10\n\nProblem 1\n\nSuppose that hurricanes occur according to a Poisson Point Process with unknown\nparameterλ . Given that 5 hurricanes occurred during a two-month period, estimateλ by:\n\n(a) The Method of Moments\n(b) The Method of Maximum Likelihood, and plot the Likelihood function\n\n[In this case, you should consider the random variable N = number of hurricanes in a\ntwo-month period. Notice that N has Poisson distribution with mean value 2λ , where λ\nis in units of 1/month]\n\nProblem 2\n\nConsider a random variable Y with probability density function:\n\n⎪⎩\n⎪⎨\n⎧\n≤\n≤\n⎟\n⎠\n⎞\n⎜\n⎝\n⎛-\n=\notherwise\n\n0,\nb\ny\n\n,\nb\ny\nb\n)\ny\n(\nfY\n\nwhere b is an unknown parameter.\n)\ny\n(\nfY\n\nb\nb\n\nY\n\nThe mean value of Y is\nb\nm Y =\n.\n\nGiven the following sample Y = {\n}\n5 ,3 ,2\nfrom the distribution of Y:\n\n(a) Estimate b by the method of moments .\n(b) Find and plot the likelihood function\n)\nY\n|\nb\n(A\n\n(c) Find the maximum likelihood estimate of b and compare with the result from (a).\n\nProblem 3\n\nThe strength of concrete cylinders, X, is known to have normal distribution with\nunknown mean value m and known variance\n.\n)\npsi\n(\n=\nσ\n\nSuppose that the prior distribution of the mean value m is Normal, with mean value\n, and\n. From crushing tests, you collect the following\nsample of X (in psi):\npsi\nm\nm\n=\n)\npsi\n(\n=\nm\nσ\n\n{\n}\n,\n,\n,\n.\n\nUsing Bayesian Analysis:\n\n(a) Plot the prior distribution of m\n(b) Plot the Likelihood function, normalized to have unit area\n(c) Plot the posterior distribution of m\n\nProblem 4\n\nThe compressive strength of concrete cylinders, X, is known to have normal distribution\nwith mean value m and variance σ2 that depends on the batch considered. In order to\nestimate m and σ2 for a specific batch, a laboratory test is performed in which the value\nof X is measured for n cylinders. Let the resulting statistical sample be X1, ..., Xn. You\nneed to estimate m and σ2 with a certain accuracy, which you set as follows:\n\n(1)\n1.0\nm\nm\nX\nvar\n<\n⎟⎟\n⎠\n⎞\n⎜⎜\n⎝\n⎛\n-\n\n(2)\n1.0\ns\nvar\n<\n⎟\n⎟\n⎠\n⎞\n⎜\n⎜\n⎝\n⎛\nσ\n\n(a) Determine the minimum value of n that satisfies each objective (notice that such\nminimum value may depend on the actual parameters m and σ2).\n(b) In practice, which of the two conditions do you believe is more restrictive for n?\n(c) Based on your response to (b), can you set n without prior knowledge of m and\nσ2?"
    },
    {
      "category": "Exam",
      "title": "quiz_1_2005.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/ff46f197adda3cbe2be9e24765637dcb_quiz_1_2005.pdf",
      "content": "Quiz #1\n1.5 hours - open books and notes\nProblem 1 (25 points)\nA device has a sensor connected to an alarming system. The sensor triggers with\nprobability 0.95 if dangerous conditions exist in a given day and with probability 0.005 if\nconditions are normal during the day. Days with dangerous conditions occur with\nprobability 0.005. Given the above:\n(a) What is the probability of false alarm, i.e. the probability that conditions are\nnormal when the alarm system triggers?\n(b) What is the probability of unidentified critical condition, i.e. the probability that\nconditions are dangerous when the system does not trigger?\n(c) How many false alarms and how many unidentified critical conditions should be\nexpected to occur during a 10-year period? Comment on the effectiveness of the\nalarming system.\nProblem 2 (25 points)\nAt a given site, flood-producing storms occur with mean rate λ = 1/(20 years).\n(a) Considering the three conditions under which a point process is Poisson, state\nreasons for or against modeling the storm arrival times as a Poisson point process.\n(b) Assume Poisson storm arrivals and suppose that the water heights reached during\ndifferent storms are independent with common exponential distribution:\n- h\nFH(h) = 1- e\n2 ;\nh ≥ 0\nwhere water height h is in meters.\nFind the probability that the water height exceeds 3 meters at least once during the\nnext 100 years.\n\nProblem 3 (25 points)\nThe random vector X = ⎡\n⎢\nX1 ⎤ has uniform distribution inside the unit disc. This means\n⎥\n⎣X2 ⎦\nthat its joint probability density function is:\nX2\n⎧ 1\nfor x2 + x2 ≤ 1\nfX1,X2 (x1,x2) = ⎨⎪\nπ ,\n⎪⎩0,\notherwise\n-1\nX1\n-1\n(a) Are X1and X2 independent? Justify your answer.\n(b) Find the marginal probability density function of X1.\nProblem 4 (25 points)\nLet X1and X2 be independent and identically distributed random variables with\ncommon mean value m and common variance σ2 .\n(a) Find the mean value and variance of Y1 = X1 + X2\n(b) Find the mean value and variance of Y2 = X\n2 1\n(c) Are the variances of Y1 and Y2 the same? If not, give an intuitive explanation for\nthe difference.\n(d) Find the covariance between Y1 and Y2"
    },
    {
      "category": "Exam",
      "title": "quiz1_2005_soln.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/a3d43fa175019524b1d3a1509e0f4848_quiz1_2005_soln.pdf",
      "content": "Quiz #1\nSolutions\nProblem 1\nDefine the following events:\nD: dangerous conditions\nDc: normal conditions\nT: alarms indicated dangerous conditions\nTc: alarm indicates normal conditions\nGiven:\nP[T |D] = 95\n0.\nP[Tc | D] =\n\n0.\nP[T | Dc ] = 005\n0.\nP[Tc |Dc ] =\n\n0.\nP[D] = 005\n0.\nP[Dc ] = 995\n0.\n(a) Probability of false alarm:\nP[Dc | T] = P[Dc ].P[T |Dc ]\nP[T]\nP[T] is found using the Total Probability Theorem as\nP[T] = P[T |\nP\n].\nD\n[D] P\n+ [T |Dc P\n]. [Dc ]\nTherefore,\nP[Dc | T] = P[Dc ].P[T |Dc ] = 0.5116\nP[T]\n(b) Probability of unidentified critical condition:\nP[D | Tc ] = P[ ].\nD P[Tc | D] = 0.0002525\nP[Tc ]\n(c) Number of False Alarms = P[Dc | T] × P[T] × 365 × 10 = 18 times\n\nNumber of unidentified dangerous conditions= P[D | Tc ] × P[Tc ] × 365 × 10 = 1 time\nThe alarm system therefore gives 18 false alarms in the 10 year period , which can be a\nhassle. It does however fail to identify only one dangerous condition, so performs well\nhere. Good alarms aim to minimize false alarms and eliminate unidentified conditions.\nProblem 2\n(a) The answer to this question is somewhat subjective, and so will be different\ndepending on who answers, but here are a few ideas that should be included.\nThe three conditions that a point process need to satisfy to be Poisson are:\n1. Stationarity. The probability that an event in a short interval (t, t + ∆t) is\napproximately λ(∆t) for any t.\n2. Non-Multiplicity. The probability of two or more events in (t,t + ∆t) is negligible.\n3. Independence (No Memory). The number of events in an interval of time is\nindependent of the number in any other interval of time.\nIf one wants to model flood-producing storms as a Poisson process, they need to satisfy\nthese three conditions. If one assumes that flood-producing storms are rare, and occur\nrandomly in time, then one can argue that:\nThe condition of stationarity is satisfied, since the longer the time period one considers,\nthe more likely a storm will occur.\nThe condition of non-multiplicity is satisfied because storms don't occur at the same\ntime.\nThe most difficult condition to satisfy is that of independence. This assumes no memory,\nbut weather patterns typically exhibit some persistence, i.e. seasons, and therefore do\nshow dependence.\nAssuming Poisson storm arrivals with , λ = 1/20 years.\nDefine:\nY: the number of storms in time, t. Y is a Poisson variable with PMF:\n(λt)ye λ\n- t\nPY (y) =\n!y\n\nThe probability that the water height exceeds 3 m is given by:\nP[h > 3] = 1 - FH( 3) = e 2\nThe original Poisson Process is thinned with probability P[h > 3] to result in a new\nthinned Poisson Process for storms that cause the water height to exceed 3 m. The new\n*\nrate of the process is λ = λ P[h > 3] .\nDefine:\n*\n*\nY : the number of storms that cause water heights to exceed 3 m in time, t. Y is a\nPoisson variable with PMF:\n*\n*\n* y\n*\n(λ t)\ne λ\n- t\nPY* (y ) =\n*\ny !\nThe probability that that the water height will exceed 3 m at least once during the next\n100 years is given by:\n*\nP [At least one storm occurrence] = 1 - P [No storms] = 1 - P * ( 0) = 1 - e λ t = 0.672\nY\nProblem 3\nGiven the joint density f\nX\n,\nX\n2 (\nx\n,\nx\n2 ) is uniform inside the disk.\n(a)\nThe value of f\nX\n,\nX\n2 (\nx\n,\nx\n2 ) is obtained from knowing that the total volume\nunder the f\nX\n,\nX\n2 (\nx\n,\nx\n2 ) cylinder must be equal to 1.\nTherefore,\nVolume = f\nX\n,\nX\n2 (\nx\n,\nx\n2 ) × πr 2 = 1, and\nf\nX\n,\nX\n2 (\nx\n,\nx\n2 ) =\ninside the disk,\nπ\nf\nX\n,\nX\n2 (\nx\n,\nx\n2 ) = 0 elsewhere.\nX1 and X2 are not independent.\n\nFor X1 and X2 to be independent, fX 1 X\n, 2 (\nx\n,\nx\n2 ) =\n(x 1 )\nfX 1\nfX (x 2 )\nSince, fX 1 X\n, 2 (\nx\n,\nx\n2 ) =\ncannot be expressed as the product of two functions. So, X1\nπ\nand X2 are dependent.\n(b) The marginal PDF of X, fX (x 1 ) is obtained by integrating the joint density over all\nX2.\ninf\n∫\nf\n(x ) =\nX1\nf\ndx2\n(\nx\n,\nx\n)\nX1 X\n,\n-inf\nThe limits of integration are given by the value of X2 at any X1:\n1 x1\n2 , and so:\nx2\n±\n=\n-\n-\n-\nx1\nx1\n=\n∫\nfor -\nfX1(x1)\nfX1 X\n, 2 (x1 x\n, 2)dx\n-\nx1 1\n≤\n≤\n=\nπ\nx1\n-\nfX1(x1) = 0 otherwise\nProblem 4\nBy Linearity of expectation:\n\nE[ Y 1] = E[ X 1] + E[ X2 ] = 2m\nE[ Y 2 ] = 2.E[ X 1] = 2m\nUsing second moment analysis\nVar[ Y 1] = Var[ X 1] + Var[ X2 ] + 2Cov [ X 1, X2 ] = 2 σ2 because of independence.\nVar[ Y 2 ] = 2 Var[ X 1] = 4 σ2\nY1\nX\n⎡\n⎤\n⎡\n⎤\nThe vector\nis a linear function of the vector\n, specifically:\n⎢⎣\n⎥⎦\n⎢⎣\n⎥⎦\nY2\nX 2\nX\nY1\n= 1\n⎡\n⎢⎣\n⎡\n⎤\n⎡\n⎤\n⎤\n⎢⎣\n⎥⎦\n⎢⎣\n⎥⎦\n⎥⎦\nX\nY2\nIf we let B = 1\n⎡\n⎢⎣\n1 ⎤ , then using the results of second moment analysis:\n⎥⎦\n⎡\n⎤\nBT = 2\nσ\n= B ∑ Y\nσ\nσ\n, and so Cov [ Y1, Y2 ] = 2 σ2 .\n⎢\n⎢⎣\n⎥\n⎥⎦\n∑Y\nσ"
    },
    {
      "category": "Exam",
      "title": "quiz_2_fin_2005.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/a8c0eaf63be3257263b1661f9af8e8c2_quiz_2_fin_2005.pdf",
      "content": "Quiz # 2\nIn-class, open books and notes\nProblem 1 (40 Points)\nAn environmental variable X has value Xi in day i. Due to budgetary constraints, X is\nmeasured only every third day. If X is measured in day i, then the observed value of Xi\nis used to estimate the three-day average X = 3 (Xi-1 + Xi + Xi+1) . Given that the\nvariables Xi have multivariate normal distribution with common mean value m and\ncommon variance σ2 and that the correlation coefficient between Xi and X j is\nρij = 0.9|i- j|,\n(a) Find the distribution of (X |X i) . [Hint: start by finding the joint distribution of X\nand Xi ].\n(b) Based on the answer to (a), suggest a better estimator of X from Xi .\nProblem 2 (30 Points)\nIn a river reach, flooding occurs if the water level H exceeds 8 meters. Following a heavy\nrainstorm, the water level is H = H o +\nD\nI\n5.0\n8.0 , where H o is the water level before the\nstorm, I is storm depth in meters/hour (integrated over the river catchment) and D is the\nstorm duration in hours. Suppose that H o is known and equal to 3 meters and that ln (I)\nand ln (D) are independent normal variables with distributions\nln (I) ~ N(0, 1)\nln (D) ~ N(1, 1)\nwhere N(m, σ2) is the normal distribution with mean value m and variance σ2\n(a) Find the distribution of ln ( D\nI\n\n8.0 ).\n(b) State the condition for flooding in terms of ln (I) and ln (D), and evaluate the second\nmoment reliability index β in the [ln (I), ln (D)] plane. For this problem, is Φ(-β) the\nexact probability of flooding?\n\nProblem 3 (30 Points)\nUsing a computer, one can simulate random points with uniform distribution inside the\nunit square {0 ≤ X1 ≤ 0,1 ≤ X2 ≤ 1}.\nX2\nY=1\nY=0\nX1\nLet Y be an indicator variable as follows:\nY = 1 if the point is inside the inscribed circle (see the figure above)\nY = 0 otherwise\nπ\n(a) Show that E[Y] = 4\nπ\nOne may estimate E[Y] (hence 4 ) as the sample average:\nY = ∑Yi\nn i\nwhere {Y1\nY\n.,\n,.........\nn} is a random sample from the distribution of Y obtained through\nrepeated computer simulations.\n(b) Find the mean value and variance of Y\nπ\n(c) What sample size n is needed to estimate 4 with a standard deviation of the\nestimation error equal to 0.001?"
    },
    {
      "category": "Resource",
      "title": "app1_reli_final.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/39650745d241175c8557bdefc67f676b_app1_reli_final.pdf",
      "content": "Application Example 1\n(Probability of combinations of events; binomial and Poisson distributions)\nRELIABILITY OF SYSTEMS WITH VARIOUS\nELEMENT CONFIGURATIONS\nNote: Sections 1, 3 and 4 of this application example require only knowledge of events\nand their probability. Section 2 involves the binomial and Poisson distributions.\n1: SERIES AND PARALLEL SYSTEMS\nMany physical and non-physical systems (e.g. bridges, car engines, air-conditioning\nsystems, biological and ecological systems, chains of command in civilian or military\norganizations, quality control systems in manufacturing plants, etc.) may be viewed as\nassemblies of many interacting elements. The elements are often arranged in mechanical\nor logical series or parallel configurations.\nSeries systems\nSeries systems function properly only when all their components function properly.\nExamples are chains made out of links, highways that may be closed to traffic due to\naccidents at different locations, the food chains of certain animal species, and layered\ncompany organizations in which information is passed from one hierarchical level to the\nnext.\n\nThe reliability of a series system is easily calculated from the reliability of its\ncomponents. Let Yi be an indicator of whether component i fails or not; hence Yi = 1 if\ncomponent i fails and Yi = 0 if component i functions properly. Also denote by Pi = P[Yi\n= 1] the probability that component i fails. The probability of failure of a system with n\ncomponents in series is then\nP[system failure] = 1 - P[system survival]\n= 1- P[(Y1 = 0) ∩ (Y2 = 0) ∩ ... ∩ (Yn = 0)]\n(1)\nIf the components fail or survive independently of one another, then this probability\nbecomes\nn\nP[system failure] = 1 -∏(1 - Pi)\n(2)\ni =1\nIn the even more special case when the component reliabilities are all the same, Pi = P\nand Eq. 2 gives\nP[system failure] = 1 - (1 - P)n\n(3)\nParallel systems\nIn this case, the system fails only if all its components fail. For example, if an office has n\ncopy machines, it is possible to copy a document if at least one machine is in good\nworking conditions.\nSchematic illustration of a parallel system\n\nThe probability of failure of a parallel system of this type is obtained as\nP[system failure] = P[(Y1 = 1) ∩ (Y2 = 1) ∩ ...∩ (Yn = 1)]\nn\n=\nPi\n∏ , if the components fail independently\n(4)\ni=1\n= Pn , if in addition Pi = P for all i\nProblem 1.1 Consider a series system. Plot its probability of failure in Eq. 3 as a\nfunction of the number of components n, for different values of P. Do the same for\nparallel systems, using the last expression in Eq. 4. Comment on the effect of n in the two\ncases.\n2: m-out-of-n SYSTEMS\nSimple series and parallel representations are often inadequate to describe real systems.\nA first generalization, which includes series and parallel systems as extreme cases, is that\nof \"m-out-of-n\" systems. These systems fail if m or more out of n components fail. The\ncase m = 1 corresponds to series systems, the case m = n to parallel systems. Again,\nanalysis is simpler if the components fail independently with the same probability P.\nThen, the probability of failure can be calculated from the binomial distribution: Let M\nbe the number of failed elements. M has binomial distribution with parameters n and P,\nhence its probability mass function is given by\nPM;n(m) = ⎛⎜\nn ⎞⎟ Pm(1 - P)n- m\n(5)\n⎝ m⎠\n⎛ n ⎞\nn!\nwhere ⎜ ⎟ = m!(n - m)! is the binomial coefficient. The probability of failure of the\n⎝ m⎠\nsystem is\n\nP[system failure] = P[M ≥ m]\nn\n=\nPM;n (i)\n∑\n(6)\ni=m\n= 1- FM;n (m -1)\nWhere FM;n(m) = P[M ≤ m] is the cumulative distribution function of M.\nExample 1 Consider the case of a car with one spare tire. The car will become impaired if\n2 (or more) tires are flat. In a conservative approximation, one may assume that all 5 tires\nare simultaneously used and subject to punctures. Then the probability of not completing\na trip is given by Eqs. 5 and 6, with n = 5, m = 2, and P = probability of puncture of a\nsingle tire during the trip.\nProblem 1.2 Compare the probability of completing a car trip in the cases without spare\ntire and with 1 spare tire by using Eq. 6 with (n = 4, m = 1) and (n = 5, m = 2). Make\nthe comparison for P = 0.001, 0.01, 0.1. Comment on the results.\nExample 2 In order to fly, an airplane needs at least half of its engines to be functioning.\nSuppose that, during any given flight, engines fail independently, with probability P.\nWould you be safer in an airplane with 1, 2, 3 or 4 engines?\nUnder the condition of independent and equally likely failures, the number of non-\nfunctioning engines at the end of a generic flight, M, has binomial distribution with\nprobability mass function in Eq. 5. The probability Pn that an airplane with n engines is\nunable to fly is therefore\n\nP1 = PM;n =1(1) = ⎛⎜\n1⎞⎟ P1(1 - P)0 = P\n⎝1⎠\nP2 = PM;n =2(2) = ⎛⎜\n2⎞⎟ P2(1 - P)0 = P2\n⎝ 2⎠\n(7)\n⎛3⎞\nP3 = PM; n=3(2) + PM;n =3(3) = ⎛⎜\n3⎞⎟ P2(1 - P)1 + ⎜ ⎟ P3(1 - P)0 = 3P2 - 2P3\n⎝ 2⎠\n⎝3⎠\n⎛ 4⎞\nP4 = PM;n =4(3) + PM;n= 4(4) = ⎛⎜\n4⎞⎟ P3(1 - P)1 + ⎜ ⎟ P4(1 - P)0 = 4P3 - 3P4\n⎝ 3⎠\n⎝ 4⎠\nProblem 1.3 Plot the probabilities P1, P2, P3, and P4 in Eq. 7 as functions of P, for P in\nthe range [10-4, 10-1]. Comment on the results.\nThe previous analysis rests on the assumption that airplane engines fail independently.\nThis is a rather unrealistic assumption, because in many cases a single \"common cause\"\nmay induce simultaneous or serial failure of several engines. A more sophisticated but\nstill relatively simple model is as follows. Suppose that potentially damaging events\noccur at Poisson times during a flight, with mean rate λ. When one such event occurs,\neach engine of the airplane fails with probability p, independently of the other engines.\nAlso, failure or survival of an engine in different potentially damaging events are\nassumed to be independent events. Notice that, in this case, engine failures are\nconditionally independent given a potentially damaging event. However, unconditionally\n(during a generic flight), engine failures are probabilistically dependent (failure of one\nengine makes it more probable that other engines also failed, because an engine failure\nindicates that at least one damaging event occurred during the flight). For example,\nengine failures may be caused by mulfunctionings of the electrical system or by\nencounters with bird flocks. When any such event occurs, it is likely that several engines\nare damaged.\nBefore we analyze airplane reliability through this revised model, we recall the following\nproperty of Poisson processes. Consider a primary Poisson process {ti} with rate\nparameter λ. A secondary process {t'i} is obtained by \"independently thinning\" {ti}. This\n\nmeans that each point ti is retained in {t'i} with a given probability p, independently of all\nthe other points. Then, {t'i} is itself a Poisson process, with rate parameter λ' = λp.\nApplication of this result to our model shows that failure events of each given engine\noccur at Poisson times, with rate λ' = λp. Considering a trip of duration T, the probability\nof failure of an individual engine is 1-e-λpT. This is also the probability of failure of a\nsingle-engine plane. Therefore, in order to make the results of the two models\ncomparable, we should chose p in the present model so that 1-e-λpT equals P in the earlier\nmodel. This will make the reliability of a single engine plane during one trip the same in\nthe two models.\nTo simplify the analysis of the present model, we make the realistic assumption that\npotentially damaging events are rare, so that, during a single flight, the probability of two\nor more such events is negligible relative to the probability of one event. This means that\nwe exclude from the analysis events like \"an airplane with two engines does not make the\ntrip due to the occurrence of two potentially damaging events, each producing failure of\none engine\". Also notice that, given a potentially damaging event, the probability of\nairplane failure is still given by the expressions in Eq. 7, with p in place of P. In order to\nobtain the probability of airplane failure in a flight of duration T, those probabilities must\nbe multiplied by 1-e-λT, which is the probability of at least one potentially damaging\nevent.\nProblem 1.4 Let T = 6 hours and λ = 1/(104 hours). Plot the probability of airplane\nfailure against P = 1-e-λT for P in the range [10-4,10-1], separately for a plane with 1, 2,\n3, and 4 engines. Compare the results with those for independent engine failures\n(Problem 1.3).\n\n3. MORE COMPLICATED SYSTEM CONFIGURATIONS\nIn even more complex cases, series and parallel connections are intermixed. For example,\nin assembling a car, it is necessary that a large number of components be simultaneously\navailable (this is a series system and is highly vulnerable because the unavailability of\njust one component may force an assembly plant to shut down, as one knows well from\nlabor strikes). To increase system reliability, car manufacturers rely on several alternative\npart suppliers and part-producing plants, which are used \"in parallel\". This corresponds\nto a scheme with several subsets of components (sub-systems). The sub-systems are\nconnected in series, but have an internal parallel structure, as illustrated by the following\nscheme.\nSchematic illustration of a parallel-series system\nSuppose that there are n sub-systems and that sub-system i has mi elements connected in\nparallel. Also denote by Pij the probability of failure of the jth element of sub-system i. In\nthe simple case of independent element failures, the probability of failure of the system is\nn\nP[system failure] = 1 -∏P[ith sub - system survives]\ni =1\nn ⎛\nmi\n⎞\n(8)\n= 1 -∏⎜1-∏ Pij⎟\n⎜\n⎟\ni=1⎝\nj=1\n⎠\n\nThe following is an example of reliability analysis for a moderately complex system,\nwhich includes series and parallel connections, as well as m-out-of-n sub-systems.\nExample Consider a system composed of a heater (R1), two pumps (R2 and R3), and 5\nturbines (R4 through R8). The two pumps work in parallel, meaning that the pump sub-\nsystem operates if at least one of the pumps operates. The turbine sub-system operates if\nat least 3 turbines operate. The heater, pump, and turbine sub-systems are connected in\nseries, meaning that they must all properly work for the whole system to perform\nadequately.\nBetween two scheduled maintenances, each component may fail independently of the\nothers, with the following probabilities\nR1\nR2\nR3\nR4\nR5\nR6\nR7\nR8\n0.05\n0.10\n0.08\n0.20\n0.17\n0.09\n0.15\n0.15\n\nThe reliability of the system id defined as the probability that the system does not fail\nbetween scheduled maintenances. We denote by Wi the event \"component i is working\nproperly\". To calculate system reliability, we first consider the reliability of each sub-\nsystem separately:\n- heater sub-system: Reliability = P[W1] = 1 - 0.05 = 0.95\n- pump sub-system:\nc\nc\nc\n\nReliability = 1 - P[W2\nc ∩ W3 ] = 1 - P[W2 ]P[W3 ] = 1 - (0.10)(0.08) = 0.992\n- turbine sub-system: All possible events for which the turbine sub-system is in working\nconditions and their probabilities are listed below. Since the events are mutually\nexclusive, the probability of their union (which is the same as the event \"the turbine\nsub-system works properly\") is the sum of their individual probabilities, i.e. 0.9733.\nFinally, the reliability of the entire system is (0.95)(0.992)(0.9733) = 0.9172.\nProblem 1.5 Turbines are very expensive. Therefore, there are financial incentives to\nremoving one of them. How would removal of turbine R4, which is the least reliable one,\naffect the reliability of the whole system?\n\n4. SYSTEMS THAT \"SHARE THE LOAD\"\nMany physical and non-physical systems work \"in parallel\" in a sense different from the\ncase considered above. Rather than just having multiple elements connected in parallel\nand requiring that at least one works, the elements share the total applied \"load\" or\ndemand. Parallel systems of this type may function in different ways, depending on the\ncharacteristics of the components. The following are examples of two different types:\n- A first example is a power company that interchangeably uses several power\ngenerating plants to meet total demand. In this case, the system fails if the demand\nexceeds the combined capacity of the power plants; i.e., the system capacity is the\nsum of the capacities of its components;\n- A second example is a rope made of several bundles that share the applied load. If the\nbundles are \"ductile\" (e.g., they are made of mild steel), they are able to redistribute\nthe load among themselves. In this case the strength of the rope is the sum of the\nbundle strengths and the behavior of the system is of the same type as that of the\npower company in the previous example. However, if the bundles are brittle (e.g. they\nare made of glass), then each bundle will break as soon as its capacity is reached. The\nload must then be carried by the surviving bundles. In this case, the strength of the\nrope is less than the sum of the strengths of the individual components.\nFor a system of the first type, the probability of failure is\nP[system failure] = P[D > C1 + C2 + ... + Cn]\n(9)\nwhere D is the demand and C1, ..., Cn are the capacities of the components. We shall see\nlater in the course how to evaluate probabilities of the type in Eq. 9, when D and the Ci\nare random variables.\n\nSystems of the second type are more complicated to analyze, because the capacity of the\nsystem is a complicated nonlinear function of the component capacities. A way to\nevaluate reliability in this and other complicated cases is to use Monte Carlo simulation."
    },
    {
      "category": "Resource",
      "title": "briefnts1_events.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/4d15539bf8b078b782b12148f5122dd8_briefnts1_events.pdf",
      "content": "Brief Notes #1\nEvents and Their Probability\n- Definitions\n\nExperiment: a set of conditions under which some variable is observed\n\nOutcome of an experiment: the result of the observation (a sample point)\nSample Space, S: collection of all possible outcomes (sample points) of an experiment\nEvent: a collection of sample points\n- Operations with events\nAc\n1. Complementation\nAc\nA\n2. Intersection\nA\nB\nA∩B\n3. Union\nA∪B\nB\nA\n- Properties of events\n1. Mutual Exclusiveness - intersection of events is the null set (Ai∩Aj = ∅, for all i = j)\n2. Collective Exhaustiveness (C.E.) - union of events is sample space (A1∪A2∪...∪An = S)\n3. If the events {A1, A2, ... , An} are both mutually exclusive and collectively exhaustive, they\nform a partition of the sample space, S.\n- Probability of events\n- Relative frequency fE and limit of relative frequency FE of an event E\nfE = nE\nn\nFE =\nf\nlim E = lim n E\nn\ninf\n→\nn\ninf\n→\nn\n- Properties of relative frequency (the same is true for the limit of relative frequency\n\n1. 0 ≤ fE ≤ 1\n2. fS = 1\n3. f(A∪B) = fA + fB if A and B are mutually exclusive\n- Properties/axioms of probability\n1. 0 ≤ P(A) ≤ 1\n2. P(S) = 1\n3. P(A∪B) = P(A) + P(B) if A and B are mutually exclusive\n- Two consequences of the axioms of probability theory\n1. P(Ac) = 1 - P(A)\n2. P(A∪B) = P(A) + P(B) - P(A∩B), for any two events A and B,\n⇒ P(A∩B) = P(A) + P(B) - P(A∪B)\n- Conditional Probability\nDefinition:\nP(A | B) = P(A ∩ B)\nP(B)\nTherefore, P(A∩B) can also be obtained as P(A∩B) = P(B)P(A|B) = P(A) P(B|A)\n- Total Probability Theorem\nLet {B1, B2,..., Bn} be a set of mutually exclusive and collectively exhaustive events and let A\nbe any other event. Then the marginal probability of A can be obtained as:\nP(A) = ∑ P(A ∩ B ) = ∑ P(B )P(A | B )\ni\ni\ni\ni\ni\n- Independent events\nA and B are independent if:\nP(A|B) = P(A), or equivalently if\nP(B|A) = P(B), or if\nP(A∩B) = P(A) P(B)\n- Bayes' Theorem\n\n| A)\nP(A | B) = P(A) P(B\nP(B)\nUsing Total Probability Theorem, P(B) can be expressed in terms of P(A), P(Ac) = 1 - P(A),\nand the conditional probabilities P(B|A) and P(B|AC):\nP(B) = P(A)P(B | A) + P(A C)P(B | A C)\nSo Bayes' Theorem can be rewritten as:\nP(A| B) = P(A)\nP(B| A)\nC\nP(A)P(B| A)+\n)P(B\nP(A\n| AC )"
    },
    {
      "category": "Resource",
      "title": "app2_hazards.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/eded921a16f7336053ee400d2e8038d6_app2_hazards.pdf",
      "content": "Application Example 2\n(Total Probability Theorem)\nEVALUATION OF NATURAL AND MAN-MADE RISKS\nAn important application area of probability and statistics is the assessment of natural\nand man-made risks. For example, one may need to evaluate the safety of an engineering\nfacility against extreme environmental actions, such as earthquakes, strong winds,\nextreme floods, ocean waves, etc. Since environmental loads vary in time, one usually\nexpresses reliability through the probability that some undesirable \"failure\" event (severe\nstructural damage or collapse, levee breach, dam overtopping, ship hull buckling, etc.)\noccurs at least once during a reference period of time T, for example 50 or 100 years.\nIn order to quantify risk, one needs to combine two elements:\n1. A description of the severity of the environment, in terms of the probability P[LT > l]\nwith which the maximum environmental load in T years, LT, exceeds various levels l.\nEvaluating P[LT > l] is often referred to as hazard assessment;\n2. A description of the resistance of the facility in terms of the dependence of the\nprobability of system failure Pf on the magnitude l of the environmental load. This\nfunction, Pf(l), is often referred to as the fragility function.\nOnce quantified, the hazard and fragility functions are combined to produce the\nprobability of (at least one) failure in T. This is done by using the Total Probability\nTheorem, which says that, if {B1,..., Bn} is a set of mutually exclusive and collectively\nexhaustive events and A is any other event, then the probability of A can be calculated as\n\nn\nP[A] = ∑P[A | Bi]P[Bi]\n(1)\ni =1\nTo use this result for risk assessment, the environmental load LT is discretized into n\ndistinct levels, say l1, ..., ln and the events A and Bi in Eq. 1 are taken as\nA = \"the facility fails at least once in T\"\nBi = \"LT = li\"\n(2)\nIt is often reasonable to assume that the facility of interest survives in T if it does not fail\nunder the most intense load LT experienced during that period. Under such simplifying\nassumption and with the notation in Eq. 2, the probability of failure in T is obtained from\nEq. 1 as\nP[at least one failure in T] = Σi=1,n P[failure|LT = li] P[LT = li]\n(3)\nEq. 3 shows how the hazard (probabilities P[LT = li]) and the fragility (the probabilities\nP[failure|LT = li]) are combined in the assessment of risk.\nIn practical applications, it is typical for the hazard and the fragility to be quantified by\ndifferent experts. For example, in the case of earthquake risk, a seismologist is usually\nresponsible for assessing the hazard (the frequency with which various levels of ground\nshaking occur at a given site), while an engineer quantifies the fragility of the system (the\nperformance of the facility under various levels of ground shaking).\nExample. In a recent study, the seismic hazard in Boston has been assessed as follows in\nterms of Modified Mercalli Intensity or MMI (MMI is a discrete scale of ground motion\nintensity, with integer values from 1 to 12). Over a period of 100 years, the probability\nthat the maximum MMI value equals I is\n\nI\nP[max MMI in 100 years = I]\n0.3\n0.1\n0.03\n0.01\n0.003\n0.001\n0.0003\nNote: these probabilities do not add to 1 because there is a significant probability that the\nmaximum MMI is Boston in 100 years is less than 6. Values of I smaller than 6 do not\nusually pose significant threat to engineering facilities and are therefore neglected.\nIn a separate study, the seismic fragility of various types of structures was assessed by a\ngroup of engineers. Some of their results are reproduced below in the form of values of\nthe probability of failure for different MMI.\nMMI, I\nPf of bridge\nPf of reinforced\nPf of brick\nconcrete building\nbuilding\n0.00\n0.00\n0.00\n0.01\n0.00\n0.02\n0.03\n0.01\n0.08\n0.10\n0.03\n0.20\n0.20\n0.10\n0.40\n0.50\n0.30\n0.80\n0.90\n0.60\n1.00\nProblem 2.1\n(a) Use the above hazard and fragility assessments to determine the seismic risk in 100\nyear for different structural systems in Boston.\n\n(b) If seismic risk is judged to be excessive, corrective action may be taken by\nstrengthening the structures that are most at risk. This operation, called seismic\nretrofitting, has the effect of modifying the fragility of the structure, not the seismic\nhazard at the site. Suppose that a certain retrofitting technique would strengthen the\nstructures \"by one MMI unit\", meaning that the probability of failure for MMI = I\nafter retrofitting is the same as the probability of failure under MMI = I-1 before\nretrofitting. Re-evaluate the seismic risk of various structural types in Boston after\nsuch retrofitting operation.\nIn some cases, one is not interested in the physical damage to a facility, but in the\nconsequences that such damage might have on the exposed population or the\nenvironment. For example, in the case of a nuclear reactor damaged by an earthquake, the\nconsequences may range widely depending on the amount of radioactive release caused\nby the event, the weather conditions at the time of the earthquake, etc. The risk should in\nthis case be measured through the probability that a consequence C (for example, C =\nnumber of fatalities) exceeds a certain level c* in T years. In a simplified model, one may\nagain ignore all seismic events in T except the one with highest intensity in T. Under this\nsimplifying assumption, the probability that C > c* at least once in T years can be\nevaluated through a second application of the total probability theorem, as follows:\nm\nP[C > c*] =∑ P[C > c* | D = dj] P[D = d j]\n(4)\nj=1\nwhere d1,..., dm are m discretized levels of damage D. The probabilities P[D = dj] are\nevaluated through repeated application of Eq. 3, each time defining \"failure\" as the event\nD = dj, whereas the probabilities P[C > c*|D = dj] are the result of a consequence model.\nConsequence models are usually developed by yet another group of experts.\nProblem 2.2 Suppose that a chemical plant in the Boston area has the following fragility\ncharacteristics:\n\nMMI,I\nP[D=1]\nP[D=2]\nP[D=3]\n0.10\n0.00\n0.00\n0.30\n0.10\n0.00\n0.40\n0.20\n0.10\n0.30\n0.30\n0.20\n0.10\n0.50\n0.30\n0.00\n0.40\n0.60\n0.00\n0.20\n0.80\nwhere D = 1, 2, 3 are three levels of damage, in increasing order of severity. Further\nsuppose that the following consequence model applies:\nD\nP[Nf = 0]\nP[1 ≤ Nf < 10]\nP[Nf ≥ 10]\n0.99\n0.01\n0.00\n0.90\n0.08\n0.02\n0.50\n0.40\n0.10\nwhere Nf = number of fatalities. Consider the event with maximum MMI in the next 100\nyears (this maximum MMI is random; the probability of different values are given on\nPage 3). What is the probability that, as a result of that maximum event, Nf =0, 1 ≤ Nf <\n10, and Nf ≥ 10?"
    },
    {
      "category": "Resource",
      "title": "briefnts2_disdbn.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/bada5e21a3a24f6e95ed8899db5ec884_briefnts2_disdbn.pdf",
      "content": "Brief Notes #2\nRandom Variables: Discrete Distributions"
    },
    {
      "category": "Resource",
      "title": "app3_fedra.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/63362fb1b080e06926bbe58383b87367_app3_fedra.pdf",
      "content": "Application Example 3\n(Bayes' Theorem)\nEXTRA-TERRESTRIAL LIFE AND THE DESIGN OF\nEXPERIMENTS\nThere is much controversy and uncertainty on whether there ever was life on planet\nFedra. To reduce uncertainty, an unmanned experiment is planned. The experiment\nconsists of sending an automatic lab to the surface of Fedra. The lab would conduct\nchemical and biological tests to reveal whether or not life ever existed on that planet. It is\nrecognized, however, that the experiment may not provide definitive information on the\nexistence of life, due to possible malfunctioning of the testing equipment or the\ncommunication system, or the fact that evidence of life may not be present at the\nlocations and depth below the surface accessible by the lab.\nLet A and B be the events\nA = \"there was life on Fedra\"\nB = \"lab says 'there was life on Fedra'\"\n(1)\nand denote by Ac and Bc their complements. For a certain design of the mission\n(equipment, type of tests, communication system, etc.), NASA experts evaluate the\nperformance characteristics of the experiment to be as follows.\n- If there ever was life on Fedra, the probability that the lab will detect it and correctly\nreport the finding is P[B|A] = 0.5. Hence, P[Bc|A] = 0.5;\n\n- If there never was life on Fedra, the probability that the lab will erroneously indicate the\npresence of life is P[B|Ac] = 0.1. Hence, P[Bc|Ac] = 0.9.\nNotice that the probabilities P[Bc|A] and P[B|Ac] are nonzero due to the possibility of\nerrors. In particular, the large value of P[B|Ac] reflects the fact that, in the judgment of\nNASA, many things can go wrong in the detection of early life on Fedra. In fact, it is\nbelieved that only a manned expedition and the retrieval of rock samples for analysis on\nEarth could significantly reduce the probability of this type of errors.\nSuppose that, using currently available information, a fair assessment of the probability\nthat life was ever present on Fedra is P[A] = 0.1. Therefore, P[Ac] = 0.9. These \"prior\"\nprobabilities apply before the experiment is performed. The question is, how will these\nprobabilities change after the experiment is performed and the lab reports either B (\"there\nwas life on Fedra\") or Bc (\"there never was life on Fedra\")? Should the \"posterior\"\nprobabilities P[A|B] and P[A|Bc] be close to the prior probability P[A], little would be\ngained by performing the experiment.\nTo update the probability of A based on (hypothetical) information provided by the lab,\nwe use Bayes' theorem. According to this theorem,\nP[ A | B] = P[A] P[B | A]\n(2)\nP[B]\nUsing the total probability theorem, the probability P[B] in the denominator can be\ncalculated as P[B] = P[A] P[B|A] + P[Ac] P[B|Ac]. In the present case, P[B] = (0.1)(0.5)\n+ (0.9)(0.1) = 0.14 and P[Bc] = 1 - P[B] = 0.86.\nThen, from Eq. 2,\nP[A|B] = (0.1)(0.5)/(0.14) = 0.357\n\nP[Ac|B] = 1 - P[A|B] = 0.643\n(3)\nP[A|Bc] = (0.1)(0.5)/(0.86) = 0.058\nP[Ac|Bc] = 1 - P[A|Bc] = 0.942\nInterestingly, the posterior probability that there ever was life on Fedra does not exceed\n0.5. This is true also in the case when the lab gives a positive indication of life. The\nreason is that the outcome of the experiment is recognized to be quite likely erroneous,\ndue to the high values of the probabilities P[Bc|A] and P[B|Ac].\nProblem 3.1 Calculate and plot the posterior probabilities P[A|B] and P[AC|BC] against\nP[B|A], for P[B|A] between 0 and 1 and P[BC|AC] = 0.5, 0.8, 0.99. Comment on the\nresults.\nGiven the high cost of the experiment, one might question whether the information\ngained from it is worthy of the expense. A conclusion might be that it is preferable to\ninvest more resources in the mission and obtain more definitive information about life on\nFedra. A redesigned experiment might consist of multiple probes (if the likelihood of\nidentical errors is small). Another possibility might be to increase the number and\ndiversity of experiments conducted by the lab to detect past life.\nThe important point here is that, by assessing through Bayes' Theorem the probability of\nc\nA and A under various experimental outcomes, one can compare the informativeness of\nalternative experiments, prior to conducting the experiments.\nFor example, suppose that a modified experiment for life on Fedra consists of making\ntwo separate tests for organic material, each with possible outcomes B (indicating life)\nand Bc (no sign of life). Suppose that the probabilities of various combined outcomes of\nthe two experiments given A or Ac are as follows:\n\n- If there ever was life on Fedra, then\nP[(B∩ B)|A] = 0.4,\nP[(Bc ∩ Bc)|A] = 0.1\n(4a)\n\nP[(B∩ Bc)|A] = P[(Bc ∩ B)|A] = 0.25\n- If there never was life on Fedra, then\nP[(B∩ B)|Ac] = 0.05,\nP[(Bc ∩ Bc)|Ac] = 0.75\n(4b)\n\nP[(B∩ Bc)|Ac] = P[(Bc ∩ B)|Ac] = 0.1\nProblem 3.2\n(a) Using Bayes' theorem, calculate the posterior probabilities P[A|(B∩ B)],\nP[A|(B ∩ Bc)], P[A|(Bc ∩ B)] and P[A|(Bc ∩ Bc)] using P[A] = 0.1 as prior and the\nprobabilities in Eqs. 4a and 4b. Comment on the informativeness of this experiment\nrelative to the experiment in Eq. 3.\n(b) Describe, in one paragraph each, two similar applications of Bayes' theorem to soil\nsampling, material/structural testing, environmental quality monitoring, or any other\narea you are interested in."
    },
    {
      "category": "Resource",
      "title": "briefnts3_contdb.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/27d898923f62e3af09adc336db379869_briefnts3_contdb.pdf",
      "content": "Brief Notes #3\nRandom Variables: Continuous Distributions"
    },
    {
      "category": "Resource",
      "title": "app4_eqk_pred.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/16a1fd5717d31f10283adb1acbcd28c4_app4_eqk_pred.pdf",
      "content": "Application Example 4\n(Bayes' Theorem)\nEARTHQUAKE PREDICTION FROM IMPERFECT\nPREMONITORY SIGNS\nOrdinary people as well as seismologists have observed that, in some cases, major\nearthquakes occur shortly after certain anomalous events, which they then have claimed\ncan be used for earthquake prediction. One of the earliest reported such premonitory\nsigns is the anomalous behavior of animals. Recently, interest has shifted towards more\nobjectively measurable phenomena such as geophysical anomalies, variations in\ngroundwater level, and small changes in the topography near the causative earthquake\nfault. Mathematical models have also been developed, trying to establish theoretical links\nbetween such quantitative observables and the occurrence of large earthquakes.\nThe main issue that determines the practical usefulness of these premonitory events is the\naccuracy with which predictions can be made. Accuracy can be quantified in terms of the\nfollowing probabilities\nP1|1 = P[earthquake occurs|earthquake is predicted]\nP0|1 = P[earthquake does not occur|earthquake is predicted] = 1 - P1|1\n(1)\nP0|0 = P[earthquake does not occur |earthquake is not predicted]\nP1|0 = P[earthquake occurs|earthquake is not predicted] = 1 - P0|0\nFor a perfect prediction system, P1|1 = P0|0 = 1 and P0|1 = P1|0 = 0.\n\nThe probabilities in Eq. 1 depend on the strength of the association between the\npremonitory event and the occurrence of earthquakes. Unfortunately, this association is\noften weak. To make a quantitative analysis, define the following events:\nE = earthquake occurs in a given day\nEC = earthquake does not occur in a given day\n(2)\nA, B, C, ... = a premonitory event of type a, b, c, .... occurs in\n\na given day\nAC, BC, CC, ... = premonitory event of type a, b, c, .... does not\n\noccur in a given day\nA typical daily probability for a major earthquake might be P[E] = 10-5 (hence P[EC] = 1-\n10-5), meaning that at a given location large earthquakes might occur on average every\nabout 300 years. Also, a typical association between a premonitory event A and large\nearthquakes might be\nP[A|E] = 0.1 (meaning that event A occurs in only 10% of the days\nthat preceed major earthquakes)\n(3)\nP[A|EC] = 0.001 (meaning that A occurs on average once every\n1000 of the days that are not followed by an earthquake)\nNotice that, for prediction purposes, one looks at the probability of A in the 24 hours that\npreceed a major earthquake. Applying Bayes' theorem to this case gives\nP1|1 = P[E|A] = P[E] P[A|E]/P[A]\n= 10-5 (0.1)/[(0.1)(10-5)+(0.001)(1-10-5)]\n= 10-3\n(4)\nNotice that the probability of a major earthquake, which for a generic day is 10-5,\nincreases 100-fold, to 10-3, after observation of the premonitory event A. This increase\nshould be considered significant in a scientific sense, but may not be sufficient to issue\nwarnings of an impending earthquake. After all, only once every 1000 such warnings, an\nearthquake would actually occur. Also consider that issuing false earthquake warnings is\n\nvery costly and that, following two or three such erroneous calls, people would lose\nconfidence in the predictions.\nAdvocates of earthquake warning have observed that, although single premonitory signs\nare seldom useful as a basis for issuing warnings, the use of several such signs in\ncombination may lead to more accurate predictions. Suppose for example that two\ndiagnostic events, A and B, are being monitored. For simplicity, assume that, when taken\nin isolation, A and B have the same association with E, i.e.\nP[A|E] = P[B|E] = 0.1\nP[A|EC] = P[B|EC] = 0.001\n(5)\nand that, given E or EC, A and B are independent. Such conditional independence implies\nP[A∩B|E] = P[A|E] P[B|E] = (0.1)(0.1) = 0.01\nP[A∩B|EC] = P[A|EC] P[B|EC] = (0.001)(0.001) = 10-6\n\n(6)\nSuppose now that an earthquake warning is issued when both A and B occur\nsimultaneously. The probability that the warning is followed by an earthquake is now\nP1|1 = P[E|A∩B] = P[E] P[A∩B|E]/P[A∩B]\n= 10-5 (0.01)/[(0.01)(10-5)+(10-6)(1-10-5)]\n= 0.09\n(7)\nHence, the combined use of two independent premonitory events increases the likelihood\nof issuing correct warnings by a factor of 100, from 0.001 to 0.1. However, Eq. 6 gives\nP[A∩B|E] = 0.01, meaning that 99% of the earthquakes occur without the combined\npremonitory sign (A∩B)!\n\nProblem 4.1\n(a) What do you conclude from the previous example?\n(b) Repeat the calculations in Eqs. 6 and 7 for the case of 1, 2, 3, 4 premonitory events,\nunder the following conditions:\n1. all events A, B, C, D have the same probabilities P[event occurs|E] and P[event\noccurs|EC]\n2. all events are conditionally independent, given E or EC\n3. repeat the analysis for the following alternative sets of probabilities:\n(i) P[event occurs|E] = 0.1, P[event occurs|EC] = 0.001 (same as in the\nprevious examples)\n(ii) P[event occurs|E] = 0.1, P[event occurs|EC] = 0.00001\n(iii) P[event occurs|E] = 1, P[event occurs|EC] = 0.01\nComment on the results."
    },
    {
      "category": "Resource",
      "title": "briefnts4_randvt.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/c9dde95134bd6113e5a5186bc9541a29_briefnts4_randvt.pdf",
      "content": "Brief Notes #4\nRandom Vectors\nA set of 2 or more random variables constitutes a random vector. For example, a random\n⎡X1 ⎤\nvector with two components, X = ⎢\n⎥, is a function from the sample space of an\n⎣X 2 ⎦\nexperiment to the (x1, x2) plane.\n- Discrete Random Vectors\n- Characterization\n- Joint PMF of X1 and X2:\nPX (x) = PX X\n,\n(x 1 x\n,\n) =\nX\n[(\nP\n= x 1) ∩(X = x 2 )]\n- Joint CDF of X1 and X2:\nFX (x) = F\nX\n,\nX\n2 (\nx\n,\nx\n) =\nX\n[(\nP\n≤x1) ∩(X ≤x 2)]\n= ∑∑P\nX\n,\nX\n(\nu\n,\nu\n)\nu1 ≤x1 u2 ≤x2\n- Marginal Distribution\n- Marginal PMF of X1:\nPX1 (x ) = P[X = x1] = ∑\nX\n[(\nP\n= x1) ∩(X = x 2)] = ∑P\nX\n,\nX\n(\nx\n,\nx\n)\nx\nall\nx\nall\n- Marginal CDF of X1:\nFX1 (x ) = P[X ≤x1] =\nX\n[(\nP\n≤x1) ∩(X\ninf\n< )] = F\nX\n,\nX\n(\n,\nx\n=\ninf\n∑∑P\nX\n,\nX\n(\nx\n,\nu\n)\nx\nall\n2 u≤x1\n)\n\n- Continuous Random Vectors\n- Characterization\n- Joint CDF F\nX\n,\nX\n2 (\nx\n,\nx\n) : same as for discrete vectors.\n- Joint Probability Density Function (JPDF) of X = ⎡ X1 ⎤ , f\nX\n,\nX\n2 (\nx\n,\nx\n) :\n⎢\n⎣ X 2 ⎦⎥\nThis function is defined such that:\nf X X\n,\n(\nx\n,\nx\n)\ndx\ndx\n=\nx\n[(\nP\n≤ X 1 < x 1 + dx 1) ∩(x ≤ X 2 < x 2 + dx 2 )]\nRelationships between f\nX\n,\nX\nand F\nX\n,\nX\n:\nf\n∂ 2FX\nX\n,\n(\nx\n,\nx\n)\nX\nX\n,\n(\nx\n,\nx\n) =\n∂ x 1∂ x 2\nx 2\nFX\nX\n,\n(\nx\n,\nx\n) =\nx1\n2 (\nu\n,\nu\n)du du 2\n∫∫\ninf\n-\ninf\n\n- f X X\n,\n- Marginal distribution of X1\n- CDF:\nFX1 (x1) = F\nX\n,\nX\n2 (\n,\nx inf )\n∂FX1 X\n,\n2 (\n,\nx inf )\n- PDF:\nf X1 (x ) = dFX1 (x ) =\n∂ x1\ndx 1\nx1\n= ∂\n∂\nx 1\n⎛⎜⎝∫ inf\n-\ninf\ndu 1 ∫ inf\n- f X X\n,\n(\nu\n,\nu\n)du 2 ⎟⎞\n⎠\ninf\n= ∫ inf\n- f X\nX\n,\n(\nu\n,\nx\n)du\nf\n- Conditional PDF of (X1 | X2 = x2)\nf\nX\nX\n,\n(\nx\n,\nx\n)\n(X1|X 2 = x 2 ) (x 1) =\nf X 2 (x\n)\nf\n∝\nX\n,\nX\n2 (\nx\n,\nx\n) ,\nf\nfor X2 (x ) =0\n\n- Conditional Distribution\n- Conditional PMF of (X1 | X2 = x2):\nPX\nX\n,\n(\nx\n,\nx\n)\nP(X1|X 2 = x 2 ) (x 1) = P[X 1 = x 1 | X = x 2 ] =\nPX 2 (x\n)\nP\n∝\nX\n,\nX\n2 (\nx\n,\nx\n)\nExample of discrete joint distribution: joint PMF of traffic at remote location\n(X in cars/30 sec. interval) and traffic recorded by some imperfect traffic counter (Y)\n(note: X and Y are the random variables X1 and X2 in our notation).\nExample of discrete joint distribution: marginal distributions.\n(a) Marginal PMF of actual traffic X, and (b) marginal counter response Y.\n\n- Independent Random Variables\nF\nX1 and X2 are independent variables if:\nX\n,\nX\n2 (\nx\n,\nx\n) = FX1 (x ) F\n.\n(x )\nX2\nf\nEquivalent conditions for continuous random vectors are:\nX\n,\nX\n(\nx\n,\nx\n) = f X1 (x ) f\n. X2 (x 2)\nor:\nf(X1|X2 =x2 )(x1) = f X1 (x1)\nand for discrete random vectors:\nP\nX\n,\nX\n2 (\nx\n,\nx\n) = PX1 (x ) P\n.\n(x )\nX2\nor:\nP(X1|X2 =x2 ) (x1) = PX1 (x1)\nExample of continuous joint distribution:\njoint and marginal PMF of random variables X and Y.\n(Note: X and Y are the random variables X1 and X2 in our notation)"
    },
    {
      "category": "Resource",
      "title": "app5_rain_norain.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/0ee92b3cf4331b9dac9ac0fbe1ea53da_app5_rain_norain.pdf",
      "content": "Application Example 5\n(Bernoulli Trial Sequence and Dependence in Binary Time Series)\nIS THE SERIES OF RAINY/NON-RAINY DAYS A BERNOULLI\nTRIAL SEQUENCE?\nNote: The shaded text in this note involves the concept of correlation function for a random\nsequence. This concept will be encountered later in the course. In a fist reading, you may skip\nthat text.\nThe concept of dependent random variables finds an important application in so-called time\nseries, which are models of how a random quantity varies in time. In the case when time is\ndiscrete or discretized, as for example happens when one considers variables with daily, monthly\nor annual values (daily close of the stock market, monthly average temperatures, annual sales,\nscore of ith baseball game, etc.), the time series is simply a discrete sequence of random variables\nXi. An important issue in modeling such sequences is the probabilistic dependence among\ndifferent variables.\nHere we illustrate the concepts of dependence in time series by considering the simplest case,\nwhich is a series of indicator variables {Ii, i = 0, ± 1, ±2, ...}. Such variables can be used to\nindicate whether or not an event of interest occurs (Ii = 1) or does not occur (Ii = 0) at \"time\" i.\nFor example, we can take the event of interest to be the fact that day i is rainy. Again to keep the\nillustration simple, we consider the case when the sequence of rainy/non-rainy days is stationary.\nStationarity means that the sequence has everywhere the same statistical properties. Hence, the\nprobability P[Ii = 1] does not depend on i, the probability P[(Ii = 1)∩ (Ij = 1)] depends only on the\nseparating distance |i - j|, and so on. The assumption of stationarity is realistic in many cases and\ngreatly simplifies the characterization of a time series.\ni, i = 0, ± 1, ±2, ...} is that the correlation\nfunction ρij\nAn implication of stationarity for a random sequence {I\ndepends only on the time lag |i-j|.\n\nThe joint distribution of the daily rain/no-rain indicators Ii and Ij has 4 probability masses:\n- a probability mass p00 at (0,0), which gives the probability that both days are dry,\n- a probability mass p11 at (1,1), which gives the probability that both days are wet,\n- probability masses p01 and p10 at (0,1) and (1,0), which give the probability that day i is dry\nand day j is wet and, viceversa, that day i is wet and day j is dry.\nThese four probabilities must add to unity. Moreover, due to stationarity, p01 = p10, meaning that\nthe relative frequency of the two \"transitions\" (dry → wet and wet → dry) must be the same.\nThis means that the joint distribution of Ii and Ij is completely specified by just two probabilities,\nwhich we take to be p00 and p11. The other probabilities must be p01 = p10 = (1 - p00 - p11)/2.\nSince p00 and p11 determine the joint distribution of Ii and Ij, they also determine the marginal\ndistribution of Ii (which, due to stationarity, does not depend on i) and the conditional\ndistributions of (Ii|Ij) and (Ij|Ii) (which, due to stationarity, are the same and depend only on the\ntime lag |i - j|). In fact,\nP[Ii = 0] = p0 = p00 + p01\nP[Ii = 1] = p1 = 1 - p0 = p11 + p01\n\nP[Ii = 0| Ij = 0] = p00/( p00 + p01)\nP[Ii = 1| Ij = 0] = 1 - P[Ii = 0| Ij = 0]\n(1)\nP[Ii = 0| Ij = 1] = p01/( p11 + p01)\nP[Ii = 1| Ij = 1] = 1 - P[Ii = 0| Ij = 1]\nNotice the following:\n- The marginal probabilities p0 and p1 = 1 - p0 describe the overall dryness/wetness of the region.\nIn fact, these probabilities give the long-term fraction of days when it rains or does not rain.\nHowever, they say nothing about the pattern of rain. For example, for a given fraction p1 of\nrainy days, such days might in some regions come as long runs of uninterrupted rain followed\nby long dry spells, whereas in other regions dry and wet day may be much more \"mixed\". The\nfollowing are examples of rain/no-rain patterns with the same values of p0 and p1 but very\ndifferent \"clustering characteristics\":\n\n50-day record from Climate 1:\n(2)\n50-day record from Climate 2:\nIn both cases, there are 10 rainy days out of 50 and reasonable estimates of p0 and p1 are p0 =\n40/50 = 0.8 and and p1 = 10/50 = 0.2.\n- To understand how the differences in the patterns of Eq. 2 are reflected in our indicator model,\nconsider the joint distribution of rain/no-rain in two consecutive days, i and j = i + 1. We\nestimate the probabilities p00 and p11 of the joint distribution as the relative frequencies in the\nsamples of pairs of consecutive dry (00) and consecutive wet (11) days, respectively. This\ngives:\nfor Climate 1: p00 = 37/49 = 0.7551,\np11 = 8/49 = 0.1633\np01 = p10 = (1 - p00 - p11)/2 = 0.0408\n(3)\nfor Climate 2: p00 = 31/49 = 0.6327,\np11 = 2/49 = 0.0407\np01 = p10 = (1 - p00 - p11)/2 = 0.1633\nNotice that the marginal probabilities p0 and p1, obtained using Eq. 1, are the same in the two\ncases. What is different is that these probabilities are contributed in different amounts by the\n\"diagonal terms\" p00 and p11 and the \"off-diagonal terms\" p01 and p10: in Climate 1, the off-\ndiagonal terms are nearly zero, meaning that the probability of the weather changing from one\nday to the next is very small (this is consistent with the observed long spells of wet and dry\nperiods), whereas in Climate 2 the probability of a weather change is much higher.\nLimiting cases with respect to weather variability are joint distributions of the following types:\n\n- extreme permanence of weather conditions: p11 = 1 - p00 and p01 = p10 = 0. In this case,\nextremely long dry periods alternate with extremely long wet periods. The ratio between\nthe average lengths of dry and wet periods equals p00/p11.\n- extreme variability of weather conditions: either p11 or p00 or both are zero and p01 = p10 = 0.\nFor example, suppose that p11 = p00 = 0 and p01 = p10 = 0.5. This means that weather\nalternates in a perfectly predictable manner between rainy and non-rainy days, as\n01010101...\nIn both cases, the weather can be deterministically predicted from one day to the next. In fact, the\nconditional distribution of (Ii+1|Ii) has in both cases a unit mass at 0 or at 1. This is consistent\nwith the intuitive notion that, in the first case, the weather tomorrow is with probability 1 the\nsame as the weather today and, in the second case, the weather tomorrow is with probability one\nopposite to the weather today. An intermediate case between these two extremes is when the\nweather in different days is independent. The condition of independence is that\npij = pi pj, for all i,j = 0,1\n(4)\nIn this case of independence, it is easy to verify that the conditional distributions are identical to\nthe marginal distribution. In a sense, this is the case of maximum prediction uncertainty, because\ninformation from weather in the past is useless to predict future weather conditions.\nThe previous examples illustrate the limitation of providing only the marginal distribution of\nvariables that form dependent time series - or for that matter any set of dependent variables - and\nthe additional information provided by the joint distributions. Now we turn to the calculation of\nfirst and second-moment properties, i.e. mean values, variances, and covariance and correlation\nfunctions.\ni\ni = 1] + (1)P[Ii = 1] = P[Ii = 1] = p1\nThe mean value and variance of I can be calculated from the marginal distribution and are:\nm = (0)P[I\n\nσ2 = E[Ii\n2] - m2 = p1 - p1\n(5)\nThe covariance may be found using the relation Cov[Ii,Ij] = E[IiIj] - E[Ii] E[Ij]. This gives\nCov[Ii,Ij] = p11 - p1\n(6)\nTherefore, the correlation function is given by\nρij = (p11 - p1\n2)/( p1 - p1\n2)\n(7)\nThis correlation is zero for p11 = p1\n2, which for the indicator variables Ij and Ij is also a condition\nof independence (see Eq. 4).\nA first key issue when modeling an indicator time series {Ii} is whether the series satisfies the\nconditions of stationarity and independence, i.e. whether it may be regarded as a Bernoulli Trial\nSequences (BTS). To illustrate, we consider a series of 84 daily rain/no-rain indicators collected\nat a station in Illinois during the summer season. The recorded series is\nThe marginal probabilities of rainy and non-rainy conditions are estimated to be p1 = P[Ii =1] =\n30/84 = 0.36 and p0 = P[Ii = 0] = 54/84 = 0.64.\nIn order to determine whether the sequence is independent or not, we estimate the probabilities\np00 and p11 for different time lags |i-j|, the correlation function ρ|i-j| = (p11-p1\n2)/(p1-p1\n2), and the\none-day-lag conditional probabilities\np0|0 = P[Ii+1 = 0|Ii = 0].\np1|0 = P[Ii+1 = 1|Ii = 0]\np0|1 = P[Ii+1 = 0|Ii = 1].\np11 = P[Ii+1 = 1|Ii = 1]\n(8)\n\nResults are as follows:\n|i-j|\np00\np11\nρij\np\np\n0.50\n0.20\n0.40\n0.78\n0.40\n0.48\n0.20\n0.29\n0.75\n0.47\n0.42\n0.14\n0.03\n0.65\n0.62\n0|0\n0|1\nProblem 5.1 Based on the above statistics and on direct inspection of the rain/no-rain record,\ndiscuss whether the BTS assumption is realistic or not.\nFrom the previous analysis, you have probably concluded that the assumption of independence is\nnot tenable. Then the problem is to formulate a suitable model with dependence. Perhaps the\nsimplest random sequences {Ii} with dependence are so-called Markov chains. The Markov\nproperty is a limited-memory property, which in our case says that the weather in the future\ndepends on the weather in the past only through the most recent (the present) weather conditions.\nTherefore, in predicting whether tomorrow it will rain or shine, one needs only consider whether\nit rains or shines today. While such an assumption may not be entirely verified by actual weather\npatterns, it provides a convenient first step towards modeling dependence.\nA way to appreciate the simplicity of Markov models is to set up a weather simulation procedure.\nFrom the rain/shine record above, you have estimated the marginal probabilities p0 and p1 and the\none-day conditional probabilities in Eq. 8. This is all one needs to simulate Markov sequences of\ndry/wet weather patterns. Start by simulating the weather state (rain or shine) in day 1 by\nrandomly drawing from the marginal distribution. Then, for day 2, draw a random variable from\nthe conditional distribution given the state in day 1. Continue this operation for successive days.\nNotice that this is analogous to an \"urn model\" in which there are two urns with different\nproportions of white and black balls. White balls signify shine and black balls signify rain. The\n\nproportions of black and white balls in the two urns correspond to the conditional probabilities of\nrain and shine given that the previous day was sunny (urn 1) or rainy (urn 2). To generate\nweather sequences, one draws randomly, with replacement, from the urn that corresponds to the\nweather of the preceding day.\nProblem 5.2 Use the above Markov (urn) model and the marginal and conditional probabilities\nextracted from the Illinois sequence to produce a long synthetic weather record. Compare\nstatistics of the record with those of the actual weather sample."
    },
    {
      "category": "Resource",
      "title": "briefnts5_funct.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/1-151-probability-and-statistics-in-engineering-spring-2005/07f7c4336039bf4aa6526d711ba1e4e2_briefnts5_funct.pdf",
      "content": "Brief Notes #5\nFunctions of Random Variables and Vectors\n\nExamples of Monotonic Transformations\n\nConsider an exponential variable X ~\n)\n(\nEX λ with cumulative distribution function\n,\n.\nx\nX\ne\n)\nx\n(\nF\nλ\n-\n-\n=\nx ≥\n\nExponential, Power and Log Functions\n\nExponential Functions\nSuppose\n,\n\n,\n. This is a monotonic increasing function, and\n. This distribution is known as the (strict) Pareto\nDistribution.\nX\ne\nY =\n⇒\nY\nln\nX =\ny ≥\nλ\n-\nλ\n-\n-\n=\n-\n=\n=\ny\ne\n))\ny\n(\nx\n(\nF\n)\ny\n(\nF\ny\nln\nX\nY\n\nPower Functions\nSuppose\nα\n=\nX\nY\n,\n\n,\n. This is a monotonic increasing function,\nand\n. This distribution is known as the Weibull (Extreme\nType III) Distribution.\n>\nα\n⇒\nY\nln\nX =\ny ≥\nα\nλ\n-\n-\n=\n=\ny\nX\nY\ne\n))\ny\n(\nx\n(\nF\n)\ny\n(\nF\n\nLog Functions\nSuppose\n,\n\n,\nX\nln\nY\n-\n=\n⇒\nY\ne\nX\n-\n=\ninf\n≤\n≤\ninf\n-\ny\n. This is a monotonic decreasing function,\nand\n. This distribution is known as the Gumbel (Extreme\nType I) Distribution.\ny\ne\nX\nY\ne\n))\ny\n(\nx\n(\nF\n)\ny\n(\nF\n-\nλ\n-\n=\n-\n="
    }
  ]
}