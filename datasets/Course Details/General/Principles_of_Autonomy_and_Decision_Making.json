{
  "course_name": "Principles of Autonomy and Decision Making",
  "course_description": "This course surveys a variety of reasoning, optimization and decision making methodologies for creating highly autonomous systems and decision support aids. The focus is on principles, algorithms, and their application, taken from the disciplines of artificial intelligence and operations research.\nReasoning paradigms include logic and deduction, heuristic and constraint-based search, model-based reasoning, planning and execution, and machine learning. Optimization paradigms include linear programming, integer programming, and dynamic programming. Decision-making paradigms include decision theoretic planning, and Markov decision processes.",
  "topics": [
    "Engineering",
    "Computer Science",
    "Algorithms and Data Structures",
    "Artificial Intelligence",
    "Systems Engineering",
    "Systems Optimization",
    "Science",
    "Cognitive Science",
    "Social Science",
    "Game Theory",
    "Engineering",
    "Computer Science",
    "Algorithms and Data Structures",
    "Artificial Intelligence",
    "Systems Engineering",
    "Systems Optimization",
    "Science",
    "Cognitive Science",
    "Social Science",
    "Game Theory"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nRecitations: 1 session / week, 1 hour / session\n\nCourse Description\n\nThis course provides a survey of reasoning, learning, and optimal decision making methodologies for creating highly autonomous systems and decision support aids. It focuses on principles, algorithms, and their application, taken from the disciplines of artificial intelligence and operations research.\n\nReasoning paradigms include uninformed, informed and game search, logic and deduction, constraint modeling, model-based diagnosis, planning and execution, and reasoning under uncertainty. Machine learning paradigms include expectation maximization and reinforcement learning. Optimal decision making paradigms include linear and integer programming, dynamic programming and Markov decision processes.\n\nThe graduate subject 16.413 meets with undergraduate subject 16.410, but requires more advanced programming and written assignments, including an advanced tutorial in Java.\n\nPrerequisites\n\n6.01\nor\n1.00\n.\n\nAdditional Information\n\nLearning Objectives and Assessment\n\nCourse Policies\n\nReadings\n\n[AIMA] = Russell, Stuart, and Peter Norvig.\nArtificial Intelligence: A Modern Approach\n. 3rd ed. Prentice Hall, 2009. ISBN: 9780136042594.\n\n[IOR] = Hillier, Frederick, and Gerald Lieberman.\nIntroduction to Operations Research\n. 9th ed. McGraw-Hill, 2009. ISBN: 9780077298340.\n\n[PA] = LaValle, Steven.\nPlanning Algorithms\n. Cambridge University Press, 2006. ISBN: 9780521862059.\n\n[JINS] = Flanagan, David.\nJava in a Nutshell\n. 5th ed. O'Reilly, 2005. ISBN: 9780596007737.\n\nGrades\n\nYour grade in 16.410 or 16.413 will be determined by the following approximate weighting.\n\n16.410\n\nACTIVITIES\n\nPERCENTAGES\n\nMid-term quiz\n\n25%\n\nFinal exam\n\n40%\n\nProblem sets\n\n35%\n\n16.413\n\nACTIVITIES\n\nPERCENTAGES\n\nMid-term quiz\n\n20%\n\nFinal exam\n\n35%\n\nProject\n\n15%\n\nProblem sets\n\n30%\n\nHowever, you must do all problem sets to pass the course; a passing grade based on the other parts may be converted to a failing grade if you do not turn in all the problem sets, where turning in a problem set means including a serious attempt to complete each problem set.\n\nHomework: You are expected to do all the homework. While performance on exams is an indication of basic competence, performance on homework is your major opportunity to demonstrate outstanding achievement in 16.410-13. Mediocre homework performance will result in a lower grade, even if performance on exams is good. It is virtually impossible to get an A in 16.410-13 unless all homework assignments have been turned in. Missing more than a couple of the homework assignments may result in a failing grade for the semester, regardless of performance on exams, and in class participation. This applies to the weekly problem sets and to the final project.\n\nParticipation in class: You are expected to participate actively in lecture discussions, and to read assigned material before class.",
  "files": [
    {
      "category": "Resource",
      "title": "MIT16_410F10_final_sol.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/82acd4842b47ba08f6456dbe373b97d1_MIT16_410F10_final_sol.pdf",
      "content": "Name\nE-mail\nNote: Budget your time wisely. Some parts of this exam could take you\nmuch longer than others. Move on if you are stuck and return to the\nproblem later.\nProblem\nNumber\nMax\nScore\nGrader\nProblem 1\n(optional)\nProblem 2\nProblem 3\nProblem 4\nProblem 5\nProblem 6\nProblem 7\nTotal\n(not including\nProblem 1)\n16.410-13: Principles of Autonomy\nand Decision Making\nFinal Exam Solutions\nDecember 14th, 2010\n\nProblem 1 - Activity Planning (20 points)\nNote that this is an optional problem, which you can use to replace your\nscore on the planning problem (Question 4A & C) from the mid-term.\nWe will take the max of your score from the midterm and the final for\nthe respective part of this question in your final grade.\nIn this problem we consider the formulation of an activity planning problem, to be\nencoded as atomic actions in PDDL, as well as the soundness/completeness properties of\nGraphPlan.\nPart 1.A Formulating Planning Problems (10 points)\nNASA is planning a Mars sample return mission with the objective of returning rock\nsamples back to Earth. The mission involves sending out two Mars rovers to the Mars\nsurface, which will collect samples for years. Other space vehicles will subsequently be\nsent to Mars to meet the rovers and take rocks to Mars orbit. They will rendezvous with\norbiters, which will return the rocks to Earth.\nPlease describe this problem as an activity planning problem using PDDL.\nPart 1.A.1 (3 points)\nList and describe your predicates, actions, initial condition, and goal predicates.\n\nPart 1.A.2 (3 points)\nState any assumptions that you make, and justify why your representation is at the right\nlevel of abstraction.\nPart 1.A.3 (4 points)\nPoint out one limitation of atomic actions in PDDL (as presented in class) that limits the\neffectiveness of your solution. Augment PDDL with a new syntax that remedies this\nlimitation. Explain the meaning of this augmentation and give one example action\ndescription.\n\nPart 1.C Proving completeness of Graph Plan (10 points)\nGive an inductive proof for the fact that the Graph Plan algorithm finds any plan of\nlength N that is complete and consistent.\nWhat is the induction on?\nFormulate and prove the base case:\nFormulate and prove the induction step:\n\nProblem 2 - Model-based Diagnosis (20 points)\nYou are part of a team that is developing a spacecraft for deep space exploration. Your\ntask is to monitor and diagnosis the electrical subsystem of the spacecraft, shown in the\nfigure below.\nPart 2.A (6 points)\nA solar panel provides power to three electrical busses. The first bus is directly connected\nto the power source, the second bus is connected to the power source with a switch\n(Switch 1), and the third bus is connected to the second bus with another switch (Switch\n2). A heater unit is connected to the first bus, a wheel motor is connected to the second\nbus, and a star tracker is connected to the third bus.\n\nThe star tracker, wheel motor, and heater each have a power indicator, which outputs 1 if\nthe device is receiving power and 0 otherwise. Assume that these three devices and\ntheir indicators are working correctly; the solar panel is exposed to the sun, and the star\ntracker and heater are powered, but the wheel motor is not powered, as indicated on the\nfigure below.\nWrite down all minimal conflicts (do not provide conflicts that are not minimal). Write\ndown the corresponding constituent kernels and the kernel diagnoses, using the minimal\nset-covering algorithm. Show your work below.\nThere are two minimal conflicts: {S1 = G} and {S2 = G}. See the figure below.\nThe corresponding constituent kernels are {S1 = U} and {S2 = U} respectively.\nThere is only one kernel diagnosis: {S1 = U, S2 = U}.\n2 pts each for conflicts, constitutent kernels, kernels.\n-2 missing answer.\n-1 if conflicts not minimal.\n-1 for missing conflicts, kernels, or constitutents\n\nPart 2.B (14 points)\nThis time consider the circuit shown below. In this case, Bus 1 has no load. There are two\nwheel motors connected to Bus 2. And there is a star tracker connected to Bus 3.\n\nPart 2.B.1 (7 points)\nAssume that the three devices connected to the bus can fail, that is, the star tracker and\nthe two motors. Assume that the indicators cannot fail; they indicate that the star tracker\n(component M1) and the second wheel motor (component M3) are powered, and the first\nwheel motor (component M2) is not powered. See the figure below.\nWrite down all minimal conflicts (do not provide conflicts that are not minimal). Write\ndown the corresponding constituent kernels, and the kernel diagnoses, using the minimal\nset-covering algorithm. Show your work below.\nThere are three minimal conflicts:\n{M2 = G, M3 = G},\n{M1 = G, M2 = G, S2 = G},\n{P1 = G, S1 = G, M2=G}.\nThe corresponding constituent kernels are\n{M2 = U, M3 = U},\n{M1 = U, M2 = U, S2 = U}, and\n{P1 = U, S1 = U, M2 = U}, respectively.\nThe kernel diagnoses are:\n{M2 = U},\n{M3 = U, M1 = U, P1 = U},\n{M3 = U, M1 = U, S1 = U},\n{M3 = U, S2 = U, P1 = U}, and\n{M3 = U, S2 = U, S1 = U}.\nThe corresponding constituent kernels are {S1 = U} and {S2 = U} respectively.\nThere is only one kernel diagnosis: {S1 = U, S2 = U}.\n-1 if conflicts not minimal.\n-1 for incorrect conflicts.\n-1 for each missing conflicts, kernels, or constitutents.\n-1 for missing constitutent kernels (already penalized on part A).\n\nPart 2.B.2 (7 Points)\nConsider again the circuit introduced at the start of Part B. This time assume that the\nsensors indicate that the star tracker (component M1) and the first wheel motor\n(component M2) are not powered. But the second wheel motor (M3) is powered.\nWrite down all minimal conflicts (do not provide conflicts that are not minimal). Write\ndown the corresponding constituent kernels, and the kernel diagnoses, using the minimal\nset-covering algorithm. Show your work below.\nThere are four minimal conflicts\n{M2 = G, M3 =G},\n{M1 = G, M3 = G, S2 = G},\n{P1 = G, S1 = G, S2 = G, M1 = G}, and\n{P1 = G, S1 = G, M2 = G}.\nSee the figures on the next page for derivations.\nThe corresponding constituent kernels are\n{M2 = U, M3 = U},\n{M1 = U, M3 = U, S2 = U},\n{P1 = U, S1 = U, S2 = U, M1 = U}, and\n{P1 = U, S1 = U, M2 = U}, respectively.\nThere are four kernel diagnoses:\n{M3 = U, P1 = U},\n{M3 = U, S1 = U},\n{M3 = U, S2 = U, P1 = U}, (not minimal)\n{M3 = U, S1 = U, S2 = U}, (not minimal)\n{M2 = U, S2 = U}, and\n{M3 = U, M1 = U, P1 = U}, (not minimal)\n{M3 = U, M1 = U, S1 = U}, (not minimal)\n{M1 = U, M2 = U}.\n\nProblem 3 - Optimal Search (20 points)\nConsider a shortest path problem in the following planar environment, with polytopic\nobstacles.\nPart 3.A (8 points) Using Dijsktra's algorithm, compute the length of the shortest\ncollision-free paths from each vertex of the obstacles to the origin. Mark clearly the order\nin which you compute such shortest path lengths.\n\nPart 3.B (8 points) Use the information above to design an algorithm to find the shortest\ncollision-free path to the origin starting from any point in the plane. State the algorithm,\nand compute the lenght of the shortest collision-free path to the origin starting from the\npoint (5,5).\nPart 3.C (4 points) Would such an algorithm be applicable to shortest-path problems in\nthree dimensions? Why or why not?\n\nProblem 4 - Linear Programming (20 points)\nConsider the following problem: Given a polyhedron, find the center and the radius of the\nlargest ball contained within the polyhedron. In other words, what is the point that is\nfurthest away from all the boundaries of the polyhedron, and what is its distance from the\nclosest boundary?\nPart 4.A (10 points) Show that this problem can be formulated as a linear program.\nRemember that a polyhedron is defined by a number of inequalities of the form ai\nTx <=\nbi.\n\nPart 4.B (10 points) Use the simplex algorithm on the linear program model you just\nderived to compute the center and the radius of the largest ball within the polyhedron\ndescribed by the following inequalities:\n-x2 < 0\nsqrt(3) x1 + x2 < sqrt(3)\n-sqrt(3) x1 + x2<sqrt(3)\n\nProblem 5 - Probabilistic Inference (20 points)\nTwo astronomers, in different parts of the world, make measurements M1 and M2 of the\nnumber of stars N in some small region of the sky, using their telescopes 1 and 2. There is\na small probability of an error in N, up to a few stars. Also, there is a slight chance that\nthe telescopes can be badly out of focus, which influences the measurement error. The\nproposition that Telescope 1 is out of focus is denoted by F1. Similarly, the proposition\nthat Telescope 2 is out of focus is denoted by F2.\nPart 5.A (5 points)\nWhich of the following Bayesian network models best represents the information given\nabove? Why?\n1.\n2.\n3. (i)\n4. (ii)\nThe first model better represents the information, since measurements M1 and M2 are\nthe outputs of the telescopes, and the inputs are the number of stars and whether each\ntelescope is out of focus. In addition, the measurement obtained using the first\ntelescope is directly influenced by whether the first telescope is out of focus and the\nnumber of stars, but not the measurement of the second telescope and whether it is out\nof focus. The same holds for the second telescope. The model describes each of\nthese propositions well.\n\nPart 5.B (5 points)\nFor both of the Bayesian networks provided in the figure above, write down the joint\nprobability distribution P(M1, M2, F1, F2, N) using the Chain Rule for Bayesian\nnetworks.\nSolution for Model (i):\nP(M1, M2, F1, F2, N) = P(M1 | F1, N) P(M2 | F2, N) P(F1) P(F2) P(N)\n-1 If missing unconditioned probabilities\n-1 Mission variables in conditional probabilities.\nSolution for Model (ii):\nP(M1, M2, F1, F2, N)\n= P(F1 | N, M1) P(F2 | N, M2) P(N | M1, M2) P(M2 | M1) P(M1)\n\nPart 5.C (5 points)\nFor both of the Bayesian network models provided in the figure above, write down P(M1,\nF1) using marginalization. Make careful use of the order of summations to reduce the\ntime complexity.\nSolution for Model (i)\nP(M1, F1) = Sum_(M2, F2, N) P(M1 | F1, N) P(M2 | F2, N) P(F1) P(F2) P(N)\n= P(F1) Sum_(N) P(M1 | F1, N) P(N) Sum_(F2) P(F2) Sum_(M2) P(M2| F2, N).\nSum_(M2) P(M2| F2, N) = 1 and Sum_(F2) P(F2) = 1,\nHence this simplifies further to:\nP(M1, F1) = P(F1) Sum_(N) P(M1 | F1, N) P(N).\nAccept any variable ordering, as long as summations are pushed in as far as possible.\n+1 if some attempt made.\n+2 If stated marginalization, but didn't instantiate Bayes net chain rule.\n-1 If summations not fully reduced, or -2 if systematic problem.\n-2 Assumes false independence. (Note: 16.410 should teach independence).\nOr missing terms.\n-1 Summation over wrong variables.\n-1 Summation is in too far.\nSolution for Model (ii):\nP(M1, F1)\n= Sum(M2, F2, N) P(F1 | N, M1) P(F2 | N, M2) P(N | M1, M2) P(M2 | M1) P(M1)\n= P(M1) Sum(M2) P(M2 | M1) Sum(N) P(F1 | N, M1) P(M2 | N)\nSum(F2) P(F2 | N, M2).\n\nPart 5.D (5 points)\nNext, we would like to estimate the probability of a particular number of stars N, given\nmeasurements M1 and M2, that is P(N | M1, M2). Write down this probability for both\nmodels.\nSolution for Model (i):\nP(M1, M2, N) / P(M1, M2) where\nP(M1, M2, N) = Sum_(F1, F2) P(M1 | F1, N) P(M2 | F2, N) P(F1) P(F2) P(N)\n= P(N) Sum_(F1) P(M1 | F1, N) P(F1) Sum_(F2) P(M2, F2, N) P(F2).\nand\nP(M1, M2) = Sum_(N) P(M1, M2, N)\nstate P(M1, M2, N) / P(M1, M2)\nif fully instantiated.\nif deadend based on Bayes rule.\nrandom attempt.\nSolution for Model (ii):\nP(M1, M2, N) / P(M1, M2) where\nP(M1, M2, N)\n= Sum(F1, F2) P(F1 | N, M1) P(F2 | N, M2) P(N | M1, M2) P(M2 | M1) P(M1)\n= P(M1) P(M2 | M1) P(M2 | N) Sum(F1) Sum(F1) P(F1 | N, M1)\nSum(F2) P(F2 | N, M2).\nand\nP(M1, M2) = Sum_(N) P(M1, M2, N)\n\nProblem 6 - Hidden Markov Models (20 points)\nConsider the following simplified model of a human operator's performance while\nperforming a series of tasks sequentially.\nThe human operator can be in one of these states: distracted, focused, or stressed.\nTasks can either be easy or hard.\nEach new task assigned to the operator has the same difficulty as the last one with\nprobability 0.6, and has different difficulty with probability 0.4.\nAt the beginning of his/her shift, the operator is focused. The probability that the operator\ntransitions to a different state depends on its current state, and the difficulty of the task,\naccording to the following table, where the first number is the transition probability for\neasy tasks, and the second is the transition probability for hard tasks :\nto Distracted\nto Focused\nto Stressed\nfrom\nDistracted\n0.4/0.2\n0.6/0.4\n0/0.4\nfrom Focused\n0.6/0.3\n0.4/0.4\n0/0.3\nfrom Stressed\n0.1/0\n0.3/0.1\n0.6/0.9\nAssume that the time to complete each task is observable. The time that the operator\nneeds to complete a task is a random variable that depends on the operator's state and the\ndifficulty of the task, according to the following table.\nEasy\nHard\nDistracted\nlong\nlong\nFocused\nshort\nlong\nStressed\nlong\nvery long\nFormulate the problem of inferring the state of the operator and the difficulty of each task\nas a Hidden Markov Model. In particular, find the best estimate at each time step of the\nstate of the operator and of the types of tasks, and of the most likely trajectory, given the\nfollowing sequence of observation:\n(long, short, short, long, long, very long)\n\nProblem 7 - Markov Decision Processes (20 points)\nConsider the following abstract model of a CAP (combat air patrol) mission.\nAn aircraft can be at one of two locations: the home base or the objective.\nTransitions\nbetween these locations are deterministic. However, fuel consumption is not\ndeterministic. In particular, whenever the airplane leaves the home base, it has a full tank\nwith 10 units of fuel. At each time step, the airplane burns 1 unit of fuel with probability\n0.5, 2 units with probability 0.3, and 3 units with probability 0.2, and can either stay at\nthe current location, or move to the other location (i.e., return to base, or go to the\nobjective). Should the on-board fuel become zero or negative, the aircraft crashes and is\nlost (i.e., it remains \"crashed\" for all future times).\nThe aircraft gets a unit reward for each time unit they spend at the objective, with a\ndiscount factor equal to 0.8. The aircraft gets zero reward if crashed.\nConsider the following policy: go to the objective, or stay at the objective, if the on-board\nfuel is greater than 2 units, otherwise return to base.\nPart 7.A (10 points) Compute the expected reward (starting from the home base) under\nthis policy.\n\nPart 7.B (10 points) Compute an improved policy, if one exists, and compute its\nexpected reward.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "MIT16_410F10_final.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/006bb6815e138480553a438c59d86c15_MIT16_410F10_final.pdf",
      "content": "16.410-13: Principles of Autonomy\nand Decision Making\nFinal Exam\nDecember 14th, 2010\nName\nE-mail\nNote: Budget your time wisely. Some parts of this exam could take you\nmuch longer than others. Move on if you are stuck and return to the\nproblem later.\nProblem\nNumber\nMax\nScore\nGrader\nProblem 1\n(optional)\nProblem 2\nProblem 3\nProblem 4\nProblem 5\nProblem 6\nProblem 7\nTotal\n(not including\nProblem 1)\n\nProblem 1 - Activity Planning (20 points)\nNote that this is an optional problem, which you can use to replace your\nscore on the planning problem (Question 4A & C) from the mid-term.\nWe will take the max of your score from the midterm and the final for\nthe respective part of this question in your final grade.\nIn this problem we consider the formulation of an activity planning problem, to be\nencoded as atomic actions in PDDL, as well as the soundness/completeness properties of\nGraphPlan.\nPart 1.A Formulating Planning Problems (10 points)\nNASA is planning a Mars sample return mission with the objective of returning rock\nsamples back to Earth. The mission involves sending out two Mars rovers to the Mars\nsurface, which will collect samples for years. Other space vehicles will subsequently be\nsent to Mars to meet the rovers and take rocks to Mars orbit. They will rendezvous with\norbiters, which will return the rocks to Earth.\nPlease describe this problem as an activity planning problem using PDDL.\nPart 1.A.1 (3 points)\nList and describe your predicates, actions, initial condition, and goal predicates.\n\nPart 1.A.2 (3 points)\nState any assumptions that you make, and justify why your representation is at the right\nlevel of abstraction.\nPart 1.A.3 (4 points)\nPoint out one limitation of atomic actions in PDDL (as presented in class) that limits the\neffectiveness of your solution. Augment PDDL with a new syntax that remedies this\nlimitation. Explain the meaning of this augmentation and give one example action\ndescription.\n\nPart 1.C Proving completeness of Graph Plan (10 points)\nGive an inductive proof for the fact that the Graph Plan algorithm finds any plan of\nlength N that is complete and consistent.\nWhat is the induction on?\nFormulate and prove the base case:\nFormulate and prove the induction step:\n\nProblem 2 - Model-based Diagnosis (20 points)\nYou are part of a team that is developing a spacecraft for deep space exploration. Your\ntask is to monitor and diagnosis the electrical subsystem of the spacecraft, shown in the\nfigure below.\nPart 2.A (6 points)\nA solar panel provides power to three electrical busses. The first bus is directly connected\nto the power source, the second bus is connected to the power source with a switch\n(Switch 1), and the third bus is connected to the second bus with another switch (Switch\n2). A heater unit is connected to the first bus, a wheel motor is connected to the second\nbus, and a star tracker is connected to the third bus.\n\nThe star tracker, wheel motor, and heater each have a power indicator, which outputs 1 if\nthe device is receiving power and 0 otherwise. Assume that these three devices and\ntheir indicators are working correctly; the solar panel is exposed to the sun, and the star\ntracker and heater are powered, but the wheel motor is not powered, as indicated on the\nfigure below.\nWrite down all minimal conflicts (do not provide conflicts that are not minimal). Write\ndown the corresponding constituent kernels and the kernel diagnoses, using the minimal\nset-covering algorithm. Show your work below.\n\nPart 2.B (14 points)\nThis time consider the circuit shown below. In this case, Bus 1 has no load. There are two\nwheel motors connected to Bus 2. And there is a star tracker connected to Bus 3.\n\nPart 2.B.1 (7 points)\nAssume that the three devices connected to the bus can fail, that is, the star tracker and\nthe two motors. Assume that the indicators cannot fail; they indicate that the star tracker\n(component M1) and the second wheel motor (component M3) are powered, and the first\nwheel motor (component M2) is not powered. See the figure below.\nWrite down all minimal conflicts (do not provide conflicts that are not minimal). Write\ndown the corresponding constituent kernels, and the kernel diagnoses, using the minimal\nset-covering algorithm. Show your work below.\n\nPart 2.B.2 (7 Points)\nConsider again the circuit introduced at the start of Part B. This time assume that the\nsensors indicate that the star tracker (component M1) and the first wheel motor\n(component M2) are not powered. But the second wheel motor (M3) is powered.\nWrite down all minimal conflicts (do not provide conflicts that are not minimal). Write\ndown the corresponding constituent kernels, and the kernel diagnoses, using the minimal\nset-covering algorithm. Show your work below.\n\nProblem 3 - Optimal Search (20 points)\nConsider a shortest path problem in the following planar environment, with polytopic\nobstacles.\nPart 3.A (8 points) Using Dijsktra's algorithm, compute the length of the shortest\ncollision-free paths from each vertex of the obstacles to the origin. Mark clearly the order\nin which you compute such shortest path lengths.\n\nPart 3.B (8 points) Use the information above to design an algorithm to find the shortest\ncollision-free path to the origin starting from any point in the plane. State the algorithm,\nand compute the lenght of the shortest collision-free path to the origin starting from the\npoint (5,5).\nPart 3.C (4 points) Would such an algorithm be applicable to shortest-path problems in\nthree dimensions? Why or why not?\n\nProblem 4 - Linear Programming (20 points)\nConsider the following problem: Given a polyhedron, find the center and the radius of the\nlargest ball contained within the polyhedron. In other words, what is the point that is\nfurthest away from all the boundaries of the polyhedron, and what is its distance from the\nclosest boundary?\nPart 4.A (10 points) Show that this problem can be formulated as a linear program.\nRemember that a polyhedron is defined by a number of inequalities of the form ai\nTx <=\nbi.\n\nPart 4.B (10 points) Use the simplex algorithm on the linear program model you just\nderived to compute the center and the radius of the largest ball within the polyhedron\ndescribed by the following inequalities:\n-x2 < 0\nsqrt(3) x1 + x2 < sqrt(3)\n-sqrt(3) x1 + x2<sqrt(3)\n\nProblem 5 - Probabilistic Inference (20 points)\nTwo astronomers, in different parts of the world, make measurements M1 and M2 of the\nnumber of stars N in some small region of the sky, using their telescopes 1 and 2. There is\na small probability of an error in N, up to a few stars. Also, there is a slight chance that\nthe telescopes can be badly out of focus, which influences the measurement error. The\nproposition that Telescope 1 is out of focus is denoted by F1. Similarly, the proposition\nthat Telescope 2 is out of focus is denoted by F2.\nPart 5.A (5 points)\nWhich of the following Bayesian network models best represents the information given\nabove? Why?\n1.\n2.\n3. (i)\n4. (ii)\n\nPart 5.B (5 points)\nFor both of the Bayesian networks provided in the figure above, write down the joint\nprobability distribution P(M1, M2, F1, F2, N) using the Chain Rule for Bayesian\nnetworks.\nSolution for Model (i):\nSolution for Model (ii):\n\nPart 5.C (5 points)\nFor both of the Bayesian network models provided in the figure above, write down P(M1,\nF1) using marginalization. Make careful use of the order of summations to reduce the\ntime complexity.\nSolution for Model (i)\nSolution for Model (ii):\n\nPart 5.D (5 points)\nNext, we would like to estimate the probability of a particular number of stars N, given\nmeasurements M1 and M2, that is P(N | M1, M2). Write down this probability for both\nmodels.\nSolution for Model (i):\nSolution for Model (ii):\n\nProblem 6 - Hidden Markov Models (20 points)\nConsider the following simplified model of a human operator's performance while\nperforming a series of tasks sequentially.\nThe human operator can be in one of these states: distracted, focused, or stressed.\nTasks can either be easy or hard.\nEach new task assigned to the operator has the same difficulty as the last one with\nprobability 0.6, and has different difficulty with probability 0.4.\nAt the beginning of his/her shift, the operator is focused. The probability that the operator\ntransitions to a different state depends on its current state, and the difficulty of the task,\naccording to the following table, where the first number is the transition probability for\neasy tasks, and the second is the transition probability for hard tasks :\nto Distracted\nto Focused\nto Stressed\nfrom\nDistracted\n0.4/0.2\n0.6/0.4\n0/0.4\nfrom Focused\n0.6/0.3\n0.4/0.4\n0/0.3\nfrom Stressed\n0.1/0\n0.3/0.1\n0.6/0.9\nAssume that the time to complete each task is observable. The time that the operator\nneeds to complete a task is a random variable that depends on the operator's state and the\ndifficulty of the task, according to the following table.\nEasy\nHard\nDistracted\nlong\nlong\nFocused\nshort\nlong\nStressed\nlong\nvery long\nFormulate the problem of inferring the state of the operator and the difficulty of each task\nas a Hidden Markov Model. In particular, find the best estimate at each time step of the\nstate of the operator and of the types of tasks, and of the most likely trajectory, given the\nfollowing sequence of observation:\n(long, short, short, long, long, very long)\n\nProblem 7 - Markov Decision Processes (20 points)\nConsider the following abstract model of a CAP (combat air patrol) mission.\nAn aircraft can be at one of two locations: the home base or the objective.\nTransitions\nbetween these locations are deterministic. However, fuel consumption is not\ndeterministic. In particular, whenever the airplane leaves the home base, it has a full tank\nwith 10 units of fuel. At each time step, the airplane burns 1 unit of fuel with probability\n0.5, 2 units with probability 0.3, and 3 units with probability 0.2, and can either stay at\nthe current location, or move to the other location (i.e., return to base, or go to the\nobjective). Should the on-board fuel become zero or negative, the aircraft crashes and is\nlost (i.e., it remains \"crashed\" for all future times).\nThe aircraft gets a unit reward for each time unit they spend at the objective, with a\ndiscount factor equal to 0.8. The aircraft gets zero reward if crashed.\nConsider the following policy: go to the objective, or stay at the objective, if the on-board\nfuel is greater than 2 units, otherwise return to base.\nPart 7.A (10 points) Compute the expected reward (starting from the home base) under\nthis policy.\n\nPart 7.B (10 points) Compute an improved policy, if one exists, and compute its\nexpected reward.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "MIT16_410F10_mid_sol.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/976a1098b2a4cff73263fe926e251119_MIT16_410F10_mid_sol.pdf",
      "content": "16.410-13: Principles of Automated Reasoning\nand Decision Making\nSample Midterm\nOctober 20th, 2010\nName\nE-mail\nNote: Budget your time wisely. Some parts of this quiz could take you\nmuch longer than others. Move on if you are stuck and return to the\nproblem later.\nProblem\nNumber\nMax\nScore\nGrader\nProblem 1\n16.41x 37\n16.413 15\nProblem 2\nProblem 3\nProblem 4\nTotal\n16.410 112\n16.413 127\n\nProblem 1 Uninformed Search (X points)\nYou are given the task of finding a path from state S to state G in the following directed\ngraph, using the three uninformed search algorithms introduced in class - depth-first,\nbreadth-first and iterative-deepening search:\nS\nB\nA\nC\nE\nD\nG\nMake the following assumptions:\nDepth and breadth-first search explore a node's children in alphabetical order.\nThe depth-limited search called by iterative deepening search also explores a\nnode's children in alphabetical order.\nEach search algorithm uses a visited list to prune nodes, unless otherwise stated.\nThe search stops as soon as the goal is expanded (not when it is first visited).\nIn the following, recall that a node is expanded when the search algorithm takes a path\nto that node off the queue, and attempts to create its children. A node is visited when a\npath to that node is first placed on the queue.\n\nPart 1.A Depth-first Search with a Visited List (12 points)\nThe above graph is repeated here for your convenience:\nS\nB\nA\nC\nE\nD\nG\nFor each iteration of depth-first search, fill in the path being expanded, the state if the\nsearch queue and the visited list after expansion. Search begins with the path (S) on the\nqueue and node S on the visited list. Remember to use a visited list. Stop if search does\nnot terminate after 6 steps.\nPath being expanded\nQueue after expansion\nVisited list after expansion\n(S)\nS\n(S)\n(A,S)(B,S)\nSAB\n(A,S)\n(C,A,S)(D,A,S)(B,S)\nSABCD\n(C,A,S)\n(E,C,A,S)(D,A,S)(B,S)\nSABCDE\n(E,C,A,S)\n(D,A,S)(B,S)\nSABCDE\n(D,A,S)\n(G,D,A,S)(B,S)\nSABCDEG\n\nPart 1.B Search Issues (6 Points)\nIn each of the following, circle T if the statement is True, and F, otherwise:\na. T F\nAssuming an edge cost of 1, breadth-first search with a visited list is\nguaranteed to find a shortest path to the goal if one exists.\nb. T F\nAssuming an edge cost of 1, depth-first search with a visited list is\nguaranteed to find a shortest path to the goal if one exists.\nc. T F\nBreadth-first search without a visited list is guaranteed to find a path to\nthe goal if one exists.\nd. T F\nDepth-first search without a visited list is guaranteed to find a path to the\ngoal if one exists.\nThe following are all statements about Iterative Deepening search. For each statement,\ncircle T if the statement is True, and F, otherwise.\nIterative Deepening Search...\ne. T F\nwill typically require much less memory than breadth-first search.\nf. T F\nhas a smaller worst case run-time overhead for search trees with a small\nbranching factor, when compared to search trees with a larger branching\nfactor.\nThis is true if just the run-times of the over head is compared. If the ratio of\n(overhead runtime of iterative deepening)/(breadth-first runtime) is\n\nPart 1.C Complexity Analysis (12 points)\nIn this problem we consider the complexity of searching a tree of depth d, in which the\nbranching factor is not constant, but varies as a function of node level i. In particular,\nthe branching factor bi of each node at level i is bi = d - i, with the root node appearing at\nlevel 0. For example, the root has d children, all nodes at level 2 have d-1 children,\nnodes at level 3 have d-2 children, and so on; at level d, the tree dies out and no node at\nlevel d has a child node).\nPart 1.C.1 Number of nodes in the tree (6 points)\nGiven a tree of depth d, write down an expression for the number of nodes at each level\nof the tree, up to d. This expression must be a function of the level number m and the\ndepth of the tree d.\nNumber of nodes in level m is d(d-1)(d-2) ... (d-(m-1)) = d! / (d-m)!\nWrite an expression for the total number of number of nodes in the tree for a tree with\ndepth d. This expression must be a function of the depth of the tree d. (You do not need to\nsolve the recursion in this step).\nTotal number of nodes in the tree is the sum:\nT(d) = 1 + d + d(d-1) + d(d-1)(d-2) + ... + d!\nLet T(d) denote the total number of nodes in the tree. Write an equation for the total\nnumber of nodes in the tree in a recursive form. That is, write an equation for T(d) in\nterms of T(d-1) (the number of nodes in a tree that has depth d-1). (You do not need to\nsolve the recursion in this step).\nNote that:\nT(d) = 1 + d + d(d-1) + d(d-1)(d-2) + ... + d!\nT(d-1) = 1 + (d-1) + (d-1)(d-2) + (d-1)(d-2)(d-3) + ... + (d-1)!\nThen, write T(d) as\nT(d) = 1 + d ( 1 + (d-1) + (d-1)(d-2) + ... + (d-1)!) = 1 + d T(d-1).\nHence, T(d) = 1 + d T(d-1).\n\nPart 1.C.2 Worst Case Run-time of Breadth First Search (6 points)\nNext consider runtime. What is the maximum number of nodes that might be generated\n(visited) during breadth-first search, in order to reach a goal that is placed on level d?\nYou can write your answer in terms of the depth of the tree (denoted as d) and the total\nnumber of nodes in the tree (denoted as T(d)).\nIn the worst case, all the nodes are visited. The answer is\nT(d).\nFor full credit you must explain your derivation below:\nMust draw that all the nodes are visited, and show where the goal is located in the\nworst case.\n\nProblem 2 Formulating Roadmaps (20 points)\nIn this problem we considered the mapping of a path-planning problem with obstacles to\na road map, using the concepts of configuration spaces and visibility graphs. A robot\nhas dimensions 2 feet by 4 feet (it's a rectangle) and is positioned so that its center is at\nlocation [10, 10] (all dimensions in feet). It must reach a goal position at location [30,\n30], while avoiding all obstacles. There are two rectangular obstacles, which are five by\nten foot, and centered at [20, 20] and [20, 10]. The robot can translate along any vector,\nas long as it doesn't collide with an obstacle, but can not rotate.\nPart 2.A - Drawing the Configuration Space (10 points)\nFirst consider mapping the problem above to an equivalent C-space. In the space below,\nplease draw the C-space map for the problem. As stated earlier, when the robot changes\ndirection, assume it does not rotate, hence the orientations of the robot's boundaries do\nnot change.\nstart\ngoal\n\nPart 2.B Visibility Graph (10 points)\nConsider the problem instance with two obstacles in the following figure. Draw the\ncorresponding visibility graph on the figure.\ngoal\nsta\nrt\n\nProblem 3 Constraint Programming (35 points)\nIn this problem we consider the two essential elements of constraint programming,\nconstraint modeling, and constraint satisfaction.\nPart 3.A Constraint Modeling (12 points)\nBetty, John and Alfredo are about to order their dinner at a fine restaurant. Your job is\nto design a robot Waiter who will recommend what they should order.\nYou will\naccomplish this be formulating the decision problem as a constraint satisfaction problem.\nYou know that the menu is comprised of the following:\nMain Courses\nWines\nBeef Bourguignon (BB)\nRed\nCabernet (Ca)\nChicken Kiev (CK)\nMerlot (M)\nGlazed Salmon (GS) (Fish)\nWhite Chardonnay (Ch)\nPasta Primavera (PP) (Vegetarian)\nPinot Grigio (PG)\nMushroom Risotto (MR) (Vegetarian)\nIn addition, Betty, John and Alfredo tell you that your recommendation must satisfy the\nfollowing constraints:\n- Each of the three diners will order a main course and a suitable wine.\n- Betty is a vegetarian, and will not eat a course with chicken, beef, or fish.\n- John wants to impress Betty, and will order the same main course.\n- To show individuality, John will order a different wine from Betty.\n- White wine can be ordered with chicken, fish and vegetarian food, but not beef.\n- Red wine can be ordered with beef or fish, but not chicken or vegetarian courses.\n- Alfredo is rebellious and will not select a wine that either Betty or John has\nordered.\nPlease formulate this problem as a constraint satisfaction problem.\nList all variables and their corresponding domains. Denote the menu items by using\ntheir short form (e.g., BB for Beef Bourguignon).\nDefine 6 variables, two for each person denoting their choice of the main course and\nthe wine: B-M and B-W for Betty; J-M and J-W for John; and A-M and A-W for\nAlfredo.\nThe domains of B-M, J-M, A-M are {BB, CV, GS, PP, MR}.\nThe domains of B-W, J-W, A-W are {Ca, M, Ch, PG}.\n\nDraw a constraint graph for your encoding of this problem. Label the vertices and edges\nwith a symbol for each corresponding variable and constraint.\nWrite a description for each constraint, consisting of its scope and relation. Describe the\n\nrelation by enumerating allowed assignments to the variables in the scope.\n2) Betty is a vegetarian: C1 constrains the domain:\nD_{B-W} = {PP, MR}\n3) John wants to impress Betty: C2 constrains B-M J-M:\nR_{B-M, J-M} = {(BB,BB), (CV,CV), (GS,GS), (PP,PP), (MR,MR)}\n4) John has individuality: C3 constrains B-W and J-W:\nR_{B-W, J-W} = {(Ca, M), (Ca, Ch), (Ca, PG),\n(M, Ca), (M, Ch), (M, PG),\n(Ch, Ca), (Ch, M), (Ch, PG),\n(PG, Ca), (PG, M), (PG, Ch)}.\n5) White goes well with chicken, fish, and veggies: C4 constrains B-M and B-W, C5\nconstrains J-M and J-W, C6 constrains A-M and A-W.\nR_{B-M, B-W} = {(CV, Ch), (CV,PG), (GS, Ch), (GS, Ch),\n(PP, Ch), (PP, PG), (MR, Ch), (MR, PG)}. (C5 and C6 are same).\n6) Red goes well with beef and fish: will be merged with constraints C4, C5, and C6.\nR_{B-M, B-W} = {(BB, Ca), (BB, M), (GS, Ca), (GS, M)} (C5 and C6 are same).\n7) Alfredo is rebellious: C7 constrains A-W and J-W, C8 constrains A-W and B-W\nR_{A-W, J-W} = R_{A-W, B-W} = R_{B-W, J-W} (from item 4).\n\nPart 3.B Constraint Satisfaction (23 points)\nA: {A1, A2}\nB: {B1, B2}\nC: {C1, C2}\nB: B1,\nB2\nD: {D1, D2}\nAnd constraints:\nA-B: <A1, B1> or <A2,B1>\nA-C: <A1, C1> or <A2,C2>\nB-D: <B1, D1> or <B1,D2>\nC-D: <C2, D1> or <C2, D2>\nD: D1,\nB-C: <B1, C2>\nD2\nA-D: <A2, D2>\nPart 3.B.1 Constraint Propagation (10 points)\n3.B.1.a Pruned Domains (4 points)\nOn the following copy of the constraint graph, cross out each domain element that is\nConsider a constraint satisfaction problem consisting of four variables:\nA: A1,\nA2\nC: C1,\nC2\neliminated by constraint propagation:\n3.B.1.b Examined Arcs (6 points)\nList the arcs examined by constraint propagation, in the order in which they are\nexamined. For each arc, list its pair of variables, and use \">\" to indicate the direction\nin which arc consistency is tested (similar to the lecture notes):\nA: A1, A2\nB: B1, B2\nD: D1, D2\nC: C1, C2\n\nPart 3.B.2 Backtrack Search and Forward Checking (13 points)\nIn this part we search for the first consistent solution to the constraint problem described\nabove, stopping when found. Variables are ordered alphabetically, and values are\nordered numerically.\nfirst assignment. Circle the first consistent assignment. Cross-out assignments pruned.\n3.B.2.a Backtrack Search (no Forward Checking) (5 points)\nA-B: <A1, B1> or <A2,B1>\nA-C: <A1, C1> or <A2,C2>\nB-D: <B1, D1> or <B1,D2>\nC-D: <C2, D1> or <C2, D2>\nB-C: <B1, C2>\nA-D: <A2, D2>\nIndicate which assignments are made and the order of those assignments, by writing a\nnumber under each assignment made, on the copy below. We have written \"1\" under the\nA: A1, A2\nB: B1, B2\nD: D1, D2\nC: C1, C2\nD1\nD2\nC1\nD1\nD2\nC2\nD1\nD2\nC1\nD1\nD2\nC2\nD1\nD2\nC1\nD1\nD2\nC2\nD1\nD2\nC1\nD1\nD2\nC2\nB1\nB2\nB1\nB2\nA1\nA2\n()\nSpace available to make comments or show your work:\nA:\nB:\nC:\nD:\n\nPart 3.B.2 Backtrack Search with Forward Checking (8 points)\nA-B: <A1, B1> or <A2,B1>\nA-C: <A1, C1> or <A2,C2>\nB-D: <B1, D1> or <B1,D2>\nC-D: <C2, D1> or <C2, D2>\nB-C: <B1, C2>\nA-D: <A2, D2>\nIndicate which assignments are made and the order of those assignments, by writing a\nnumber under each assignment made on, the copy of the search tree below. We have\nA: A1, A2\nB: B1, B2\nD: D1, D2\nC: C1, C2\nwritten 1 under the first assignment. Circle the first consistent assignment. Cross out the\nassignments that are pruned.\nD1\nD2\nC1\nD1\nD2\nC2\nD1\nD2\nC1\nD1\nD2\nC2\nD1\nD2\nC1\nD1\nD2\nC2\nD1\nD2\nC1\nD1\nD2\nC2\nB1\nB2\nB1\nB2\nA1\nA2\n()\nSpace available to make comments or show your work:\n(Please indicate the pruned domain values for each step)\n\nProblem 4 - Planning (35 points)\nIn this problem we consider the formulation of activity planning problems as atomic\nactions in PDDL, the construction of planning graphs, and properties of solution\nextraction from the planning graph.\nPart 4.A Formulating Planning Problems (10 points)\nRecently the elevators in the Stata center have been running very slow. Sertac, who sits\non the seventh floor, is busy delivering his paper on time, but needs to get the exam\npapers to Brian's office, which is on the 1st floor. In order not to waste time, Sertac has\ndecided to use one of his robots to carry the exam papers from the 7th floor to the 1st\nfloor. Luckily, his robot already has a built-in activity planner, which takes a problem\ndescription in the PDDL format, and generates and executes a plan that satisfies the\nPDDL description. Please help Sertac formulate this problem using atomic operators in\nPDDL.\nPart 4.A.1 (3 points)\nList and describe your predicates, actions, initial condition, and goal predicates.\n(:objects robot, elevator, floor1, floor7)\n(:predicate (IN ?robot ?elevator) (ELEV-AT ?elevator ?floor) (ROBOT-AT ?robot ?floor))\n(:action GET-IN :parameters (?robot ?elevator ?floor)\n:precondition (and (ROBOT-AT robot floor) (ELEV-AT elevator floor)\n:effect (IN robot elevator) )\n(:action GET_OUT :parameters (?robot ?elevator ?floor)\n:precondition (and (IN robot elevator) (AT elevator floor))\n:effect (not (IN robot elevator)) )\n(:action PUSH-CALL-BUTTON :parameters (?robot ?elevator ?floor)\n:precondition (and (not (IN robot elevator))\n(ROBOT-AT robot floor) (not (ELEV-AT elevator floor)))\n:effects (ELEV-AT elevator floor) )\n(:action PUSH-GO-BUTTON :parameters (?robot ?elevator ?floorAt ?floorTo)\n:precondition (and (IN robot elevator) (ELEV-AT elevator floorAt))\n:effect (and (ELEV-AT elevator floorTo) (ROBOT-AT robot floorTo)) )\n(:init (ROBOT-AT robot floor7), (ELEV-AT elevator floor1))\n(:goal (and (ROBOT-AT robot floor1) (not (IN robot elevator)) )\n\nPart 4.A.2 (3 points)\nState any assumptions that you make, and justify why your representation is at the right\nlevel of abstraction.\nWe had assumed that the robot can\ni)\npush the call button and wait for the elevator until it gets to the floor that\nthe robot is at and the elevator door opens\nii)\nget inside the elevator, once the elevator door is open\niii)\npush the button to its destination and wait until the elevator gets to the\ndestination and the elevator door opens\niv)\nget outside the elevator\nThis level of abstraction provides the basic set of activities as the primitives.\nPart 4.A.3 (4 points)\nPoint out one limitation of atomic actions in PDDL (as presented in class) that limits the\neffectiveness of your solution. Augment PDDL with a new syntax that remedies this\nlimitation. Explain the meaning of this augmentation and give one example action\ndescription.\nOne limitation is the inability to handle metric time. For instance, we may want the\ngoal predicate to be true at some time interval. PDDL can be extended to support\npropositions with metric time intervals, e.g.,\n(and (or (IN robot elevator1):[10, 20] (IN robot elevator2):[30, 50])\n(ELEV-AT elevator1 floor2)):[40,50]\nThis formula states that either the robot has to be in elevator1 in the interval [10,20]\ntime units, or it should be in elevator2 in the interval [30,50]. Moreover, elevator1\nshould be in floor2. And all these should be true during the interval [40,50].\nA second limitation is the inability to handle sensing, and nondeterministic action. To\nremedy this one can introduce a conditional effect operator, in which the effect\ndepends on the sensor readings after execution of the particular action.\n\nPart 4.B Constructing Planning Graphs (15 points)\nConsider the plan graph for the following problem. The Smith residence is a small house\nconsisting of three rooms, A, B, and C, arranged as shown below:\nDr. Smith is away, but he has left two robots, R1 and R2, in charge of the house. Dr. Smith asked\nthem to move two boxes, B1 and B2, from room C to room A. R2 is initially in C, and R1 is\ninitially in A. Let's help the robots figure out the best way to do this.\nTo generate a plan for the robots, we formulate the problem in PDDL and give the description to\nGraph Plan, as follows (note that for the :parameters field of :action, an expression like (Robot\n?R) specifies that there is a parameter ?R that is of type \"Robot\"):\nOperators:\n(:action move-left\n:parameters ((Robot ?R) (Room ?From) (Room ?To))\n:preconditions (:and\n(left-of ?To ?From)\n(in ?R ?From))\n:effects\n(:and\n(in ?R ?To)\n(del in ?R ?From)))\n(:action move-right\n:parameters ((Robot ?R) (Room ?From) (Room ?To))\n:preconditions (:and\n(right-of ?To ?From)\n(in ?R ?From))\n:effects\n(:and\n(in ?R ?To)\n(del in ?R ?From)))\n(:action carry-left\n:parameters ((Robot ?R) (Box ?Box) (Room ?From) (Room ?To)\n:preconditions (:and\n(left-of ?To ?From)\n(in ?R ?From)\n(in ?Box ?From))\n:effects (:and\n(in ?R ?To)\n(in ?Box ?To)\n(del in ?R ?From)\n(del in ?Box ?From)))\n\n(:action carry-right\n:parameters ((Robot ?R) (Box ?Box) (Room ?From) (Room ?To)\n:preconditions (:and\n(right-of ?To ?From)\n(in ?R ?From)\n(in ?Box ?From))\n:effects\n(:and\n(in ?R ?To)\n(in ?Box ?To)\n(del in ?R ?From)\n(del in ?Box ?From)))\nInitial State Facts:\n(:init\n(Robot R1)\n(in R1 A)\n(Robot R2)\n(in R2 C)\n(Room A)\n(in B1 C)\n(Room B)\n(in B2 C)\n(Room C)\n(left-of A B)\n(Box B1)\n(left-of B C)\n(Box B2)\n(right-of B A)\n(right-of C B)\n)\nGoal State Facts:\n(:goal\n(in B1 A)\n(in B2 A)\n)\n\nPart 4.B.1 Plan Graph Minus Mutex (10 points)\n\nFor the PDDL description above, fill in the following plan graph for the first level. Show Level 1\noperators and Level 2 facts. Do not show mutex relations:\n\nPart 4.B.2 Mutex for the Plan Graph (5 points)\n\nIn the following table, list three pairs of mutex actions for the Level 1 actions in Part 4.B.1. For\neach pair, specify the type of mutex relation (\"deletes precondition,\" \"deletes effect,\" or\n\"inconsistent preconditions\"). Note that you may not need all of the entries shown in this table:\n\nAvailable mutex types are:\n1. Inconsistent effects\n2. Effect interferes with precondition\n3. Competing needs\n\nAction Mutex Pair\nMutex Type\n\nMutex operators - (move-left R2 C B) (carry-left R2 B1 C B) (carry-left R2 B2 C B)\n\nare all mutex with each other (three mutex relations). They are all mutex because they\nundo each other's precondition that R2 is in C. This makes up three pairs.\n\nPart 4.C Proving completeness of Graph Plan (10 points)\nGive an inductive proof for the fact that the Graph Plan algorithm finds any plan of\nlength N that is complete and consistent.\nWhat is the induction on?\nThe number of levels in the plan graph.\nFormulate and prove the base case:\nIn the base case, the number of levels in the graph is zero. Hence, we only have the\npropositions that are initially true. In this case, trivial (and only) plan of length zero is\nto do nothing. Hence, the algorithm will find only this plan guaranteeing completeness\nfor plan graphs of length zero.\nFormulate and prove the induction step:\nAssume that the hypothesis holds for plan graphs with number of levels N. Let us\nshow that it holds for plan graphs with number of levels equal to N+1.\nNote that if there exists a consistent plan of length N+1, then the prefix of length N\nappears in the previous plan graph level, i.e., at level N. Then, by the induction\nhypothesis, our algorithm can find this prefix, since it is a consistent plan of length N.\nWhen investigating level N+1, all consistent plans of length N will be completed to all\nits consistent extensions of length N+1, since the search at level is complete (for\ninstance, carried out with a complete CSP algorithm).\nHence, assuming that all consistent plans of length N can be found, all consistent\nplans of length N+1 can also be found by the algorithm.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "MIT16_410F10_mid.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/0a4305d13d7907dde1651d2d5cba33a9_MIT16_410F10_mid.pdf",
      "content": "16.410-13: Principles of Automated Reasoning\nand Decision Making\nMidterm\nOctober 20th, 2010\nName\nE-mail\nNote: Budget your time wisely. Some parts of this quiz could take you\nmuch longer than others. Move on if you are stuck and return to the\nproblem later.\nProblem\nNumber\nMax\nScore\nGrader\nProblem 1\nProblem 2\nProblem 3\nProblem 4\nTotal\n\nProblem 1 Uninformed Search (30 points)\nIn this problem we exercise your understanding of the uninformed search algorithms\nintroduced in class - depth-first, breadth-first and iterative-deepening. We start by\nexploring the task of finding a path from state S to state G in the following directed graph\nusing uninformed search:\nS\nB\nA\nC\nE\nD\nG\nMake the following assumptions:\nDepth and breadth-first search explore a node's children in alphabetical order.\nThe depth-limited search called by iterative deepening search also explores a\nnode's children in alphabetical order.\nEach search algorithm uses a visited list to prune nodes, unless otherwise stated.\nThe search stops as soon as the goal is expanded (not when it is first visited).\nIn the following, recall that a node is expanded when the search algorithm takes a path to\nthat node off the queue, and attempts to create its children. A node is visited when a path\nto that node is first placed on the queue.\n\nPart 1.A Depth-first Search with a Visited List (12 points)\nThe above graph is repeated here for your convenience:\nS\nB\nA\nC\nE\nD\nG\nFor each iteration of depth-first search, fill in the path being expanded, the state in the\nsearch queue and the visited list after expansion. Search begins with the path (S) on the\nqueue and node S on the visited list. Remember to use a visited list. Stop if search does\nnot terminate after 6 steps.\nPath being expanded\nQueue after expansion\nVisited list after expansion\n(S)\nS\n\nPart 1.B Search Issues (6 Points)\nIn each of the following, circle T if the statement is True, and F, otherwise:\na. T F\nAssuming an edge cost of 1, breadth-first search with a visited list is\nguaranteed to find a shortest path to the goal if one exists.\nb. T F\nAssuming an edge cost of 1, depth-first search with a visited list is\nguaranteed to find a shortest path to the goal if one exists.\nc. T F\nBreadth-first search without a visited list is guaranteed to find a path to\nthe goal if one exists.\nd. T F\nDepth-first search without a visited list is guaranteed to find a path to the\ngoal if one exists.\nThe following are all statements about Iterative Deepening search. For each statement,\ncircle T if the statement is True, and F, otherwise.\nIterative Deepening Search...\ne. T F\nwill typically require much less memory than breadth-first search.\nf. T F\nhas a smaller worst case run-time overhead for search trees with a small\nbranching factor, when compared to search trees with a larger branching\nfactor.\n\nPart 1.C Complexity Analysis (12 points)\nIn this problem we consider the complexity of searching a tree of depth d, in which the\nbranching factor is not constant, but varies as a function of node level i. In particular,\nthe branching factor bi of each node at level i is bi = d - i, with the root node appearing at\nlevel 0. For example, the root has d children, all nodes at level 2 have d-1 children,\nnodes at level 3 have d-2 children, and so on; at level d, the tree dies out and no node at\nlevel d has a child node).\nPart 1.C.1 Number of nodes in the tree (6 points)\nGiven a tree of depth d, write down an expression for the number of nodes at each level\nof the tree, up to d. This expression must be a function of the level number m and the\ndepth of the tree d.\nWrite an expression for the total number of number of nodes in the tree for a tree with\ndepth d. This expression must be a function of the depth of the tree d. (You do not need\nto solve the recursion in this step).\nLet T(d) denote the total number of nodes in the tree. Write an equation for the total\nnumber of nodes in the tree in a recursive form. That is, write an equation for T(d) in\nterms of T(d-1) (the number of nodes in a tree that has depth d-1). (You do not need to\nsolve the recursion in this step).\n\nPart 1.C.2 Worst Case Run-time of Breadth First Search (6 points)\nNext consider runtime. What is the maximum number of nodes that might be generated\n(visited) during breadth-first search, in order to reach a goal that is placed on level d?\nYou can write your answer in terms of the depth of the tree (denoted as d) and the total\nnumber of nodes in the tree (denoted as T(d)).\nFor full credit you must explain your derivation below:\n\nProblem 2 Formulating Roadmaps (20 points)\nIn this problem we considered the mapping of a path-planning problem with obstacles to\na road map, using the concepts of configuration spaces and visibility graphs. A robot has\ndimensions 2 feet by 4 feet (it's a rectangle) and is positioned so that its center is at\nlocation [10, 10] (all dimensions in feet). It must reach a goal position at location [30,\n30], while avoiding all obstacles. There are two rectangular obstacles, which are five by\nfive foot, and centered at [20, 30] and [20, 10]. The robot can translate along any vector,\nas long as it doesn't collide with an obstacle, but can not rotate.\nPart 2.A - Drawing the Configuration Space (10 points)\nFirst consider mapping the problem above to an equivalent C-space. In the space below,\nplease draw the C-space map for the problem. As stated earlier, when the robot changes\ndirection, assume it does not rotate, hence the orientations of the robot's boundaries do\nnot change.\nstart\ngoal\n\nPart 2.B Visibility Graph (10 points)\nConsider the problem instance with two obstacles in the following figure. Draw the\ncorresponding visibility graph on the figure.\ngoal\nsta\nrt\n\nProblem 3 Constraint Programming (35 points)\nIn this problem we consider the two essential elements of constraint programming,\nconstraint modeling, and constraint satisfaction.\nPart 3.A Constraint Modeling (12 points)\nBetty, John and Alfredo are about to order their dinner at a fine restaurant. Your job is to\ndesign a robot Waiter who will recommend what they should order. You will accomplish\nthis be formulating the decision problem as a constraint satisfaction problem.\nYou know that the menu is comprised of the following:\nMain Courses\nWines\nBeef Bourguignon (BB)\nRed\nCabernet (Ca)\nChicken Kiev (CK)\nMerlot (M)\nGlazed Salmon (GS) (Fish)\nWhite Chardonnay (Ch)\nPasta Primavera (PP) (Vegetarian)\nPinot Grigio (PG)\nMushroom Risotto (MR) (Vegetarian)\nIn addition, Betty, John and Alfredo tell you that your recommendation must satisfy the\nfollowing constraints:\n- Each of the three diners will order a main course and a suitable wine.\n- Betty is a vegetarian, and will not eat a course with chicken, beef, or fish.\n- John wants to impress Betty, and will order the same main course.\n- Red wine can be ordered with beef or fish, but not chicken or vegetarian courses.\n- Alfredo is rebellious and will not select wine that either Betty or John has\nordered.\nPlease formulate this problem as a constraint satisfaction problem.\nList all variables and their corresponding domains. Denote the menu items by using their\nshort form (e.g., BB for Beef Bourguignon).\n\nDraw a constraint graph for your encoding of this problem. Label the vertices and edges\nwith a symbol for each corresponding variable and constraint.\nWrite a description for each constraint, consisting of its scope and relation. Describe the\nrelation by enumerating allowed assignments to the variables in the scope.\n\nPart 3.B Constraint Satisfaction (23 points)\nConsider a constraint satisfaction problem consisting of four variables:\nA: {A1, A2}\nB: {B1, B2}\nC: {C1, C2}\nB: B1,\nB2\nAnd constraints:\nA-B: <A1, B1> or <A2,B1>\nA-C: <A1, C1> or <A2,C2>\nB-D: <B1, D1> or <B1,D2>\nC-D: <C2, D1> or <C2, D2>\nD: {D1, D2}\nD: D1,\nB-C: <B1, C2>\nD2\nA-D: <A2, D2>\nPart 3.B.1 Constraint Propagation (10 points)\n3.B.1.a Pruned Domains (4 points)\nOn the following copy of the constraint graph, cross out each domain element that is\nA: A1,\nA2\nC: C1,\nC2\neliminated by constraint propagation:\n3.B.1.b Examined Arcs (6 points)\nList the arcs examined by constraint propagation, in the order in which they are\nexamined. For each arc, list its pair of variables, and use \">\" to indicate the direction in\nwhich arc consistency is tested (similar to the lecture notes):\nA: A1, A2\nB: B1, B2\nD: D1, D2\nC: C1, C2\n\nPart 3.B.2 Backtrack Search and Forward Checking (13 points)\nIn this part we search for the first consistent solution to the constraint problem described\nabove, stopping when found.\nVariables are ordered alphabetically, and values are\nordered numerically.\nfirst assignment. Circle the first consistent assignment. Cross-out assignments pruned.\n3.B.2.a Backtrack Search (no Forward Checking) (5 points)\nA-B: <A1, B1> or <A2,B1>\nA-C: <A1, C1> or <A2,C2>\nB-D: <B1, D1> or <B1,D2>\nC-D: <C2, D1> or <C2, D2>\nB-C: <B1, C2>\nA-D: <A2, D2>\nIndicate which assignments are made and the order of those assignments, by writing a\nnumber under each assignment made, on the copy below. We have written \"1\" under the\nA: A1, A2\nB: B1, B2\nD: D1, D2\nC: C1, C2\nD1\nD2\nC1\nD1\nD2\nC2\nD1\nD2\nC1\nD1\nD2\nC2\nD1\nD2\nC1\nD1\nD2\nC2\nD1\nD2\nC1\nD1\nD2\nC2\nB1\nB2\nB1\nB2\nA1\nA2\n()\nSpace available to make comments or show your work:\nA:\nB:\nC:\nD:\n\nPart 3.B.2 Backtrack Search with Forward Checking (8 points)\nA-B: <A1, B1> or <A2,B1>\nA-C: <A1, C1> or <A2,C2>\nB-D: <B1, D1> or <B1,D2>\nC-D: <C2, D1> or <C2, D2>\nB-C: <B1, C2>\nA-D: <A2, D2>\nIndicate which assignments are made and the order of those assignments, by writing a\nnumber under each assignment made on, the copy of the search tree below. We have\nA: A1, A2\nB: B1, B2\nD: D1, D2\nC: C1, C2\nwritten 1 under the first assignment. Circle the first consistent assignment. Cross out the\nassignments that are pruned.\nD1\nD2\nC1\nD1\nD2\nC2\nD1\nD2\nC1\nD1\nD2\nC2\nD1\nD2\nC1\nD1\nD2\nC2\nD1\nD2\nC1\nD1\nD2\nC2\nB1\nB2\nB1\nB2\nA1\nA2\n()\nSpace available to make comments or show your work:\n(Please indicate the pruned domain values for each step)\n\nProblem 4 - Planning (35 points)\nIn this problem we consider the formulation of activity planning problems as atomic\nactions in PDDL, the construction of planning graphs, and properties of solution\nextraction from the planning graph.\nPart 4.A Formulating Planning Problems (10 points)\nRecently the elevators in the Stata center have been running very slow. Sertac, who sits\non the seventh floor, is busy delivering his paper on time, but needs to get the exam\npapers to Brian's office, which is on the 1st floor. In order not to waste time, Sertac has\ndecided to use one of his robots to carry the exam papers from the 7th floor to the 1st\nfloor. Luckily, his robot already has a built-in activity planner, which takes a problem\ndescription in the PDDL format, and generates and executes a plan that satisfies the\nPDDL description. Please help Sertac formulate this problem using atomic operators in\nPDDL.\nPart 4.A.1 (3 points)\nList and describe your predicates, actions, initial condition, and goal predicates.\n\nPart 4.A.2 (3 points)\nState any assumptions that you make, and justify why your representation is at the right\nlevel of abstraction.\nPart 4.A.3 (4 points)\nPoint out one limitation of atomic actions in PDDL (as presented in class) that limits the\neffectiveness of your solution. Augment PDDL with a new syntax that remedies this\nlimitation. Explain the meaning of this augmentation and give one example action\ndescription.\n\nPart 4.B Constructing Planning Graphs (15 points)\nConsider the plan graph for the following problem. The Smith residence is a small house\nconsisting of three rooms, A, B, and C, arranged as shown below:\nDr. Smith is away, but he has left two robots, R1 and R2, in charge of the house. Dr. Smith asked\nthem to move two boxes, B1 and B2, from room C to room A. R2 is initially in C, and R1 is\ninitially in A. Let's help the robots figure out the best way to do this.\nTo generate a plan for the robots, we formulate the problem in PDDL and give the description to\nGraph Plan, as follows (note that for the :parameters field of :action, an expression like (Robot\n?R) specifies that there is a parameter ?R that is of type \"Robot\"):\nOperators:\n(:action move-left\n:parameters ((Robot ?R) (Room ?From) (Room ?To))\n:preconditions (:and\n(left-of ?To ?From)\n(in ?R ?From))\n:effects\n(:and\n(in ?R ?To)\n(del in ?R ?From)))\n(:action move-right\n:parameters ((Robot ?R) (Room ?From) (Room ?To))\n:preconditions (:and\n(right-of ?To ?From)\n(in ?R ?From))\n:effects\n(:and\n(in ?R ?To)\n(del in ?R ?From)))\n(:action carry-left\n:parameters ((Robot ?R) (Box ?Box) (Room ?From) (Room ?To)\n:preconditions (:and\n(left-of ?To ?From)\n(in ?R ?From)\n(in ?Box ?From))\n:effects (:and\n(in ?R ?To)\n(in ?Box ?To)\n(del in ?R ?From)\n(del in ?Box ?From)))\n\n(:action carry-right\n:parameters ((Robot ?R) (Box ?Box) (Room ?From) (Room ?To)\n:preconditions (:and\n(right-of ?To ?From)\n(in ?R ?From)\n(in ?Box ?From))\n:effects\n(:and\n(in ?R ?To)\n(in ?Box ?To)\n(del in ?R ?From)\n(del in ?Box ?From)))\nInitial State Facts:\n(:init\n(Robot R1)\n(in R1 A)\n(Robot R2)\n(in R2 C)\n(Room A)\n(in B1 C)\n(Room B)\n(in B2 C)\n(Room C)\n(left-of A B)\n(Box B1)\n(left-of B C)\n(Box B2)\n(right-of B A)\n(right-of C B)\n)\nGoal State Facts:\n(:goal\n(in B1 A)\n(in B2 A)\n)\n\nPart 4.B.1 Plan Graph Minus Mutex (10 points)\nFor the PDDL description above, fill in the following plan graph for the first level. Show Level 1\noperators and Level 2 facts. Do not show mutex relations:\nPart 4.B.2 Mutex for the Plan Graph (5 points)\nIn the following table, list three pairs of mutex actions for the Level 1 actions in Part 4.B.1. For\neach pair, specify the type of mutex relation (\"deletes precondition,\" \"deletes effect,\" or\n\"inconsistent preconditions\"). Note that you may not need all of the entries shown in this table:\nAction Mutex Pair\nMutex Type\n\nPart 4.C Proving completeness of Graph Plan (10 points)\nGive an inductive proof for the fact that the Graph Plan algorithm finds any plan of\nlength N that is complete and consistent.\nWhat is the induction on?\nFormulate and prove the base case:\nFormulate and prove the induction step:\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "MIT16_410F10_lec01a.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/39c5b189edc1d3e0d6e8124d6cb4c52c_MIT16_410F10_lec01a.pdf",
      "content": "16.410 and 16.412:\nPrinciples of Autonomy\nand Decision Making\nProf Brian Williams, Prof Emilio Frazzoli and Sertac Karaman\nSeptember, 8th, 2010\nBrian Williams, Fall 10\nBrian Williams, Fall 10\nAssignments\n- Homework:\n- Class signup, return at end of class;\n- Problem Set #1: Java warm up\nOut Today,\nDue next Wednesday, September 15th\n- Reading:\n- Today: [AIMA] Ch. 2, [JINS] Ch. 1-3,5\n- Monday: search [AIMA] Ch. 3.1-4\n\nOutline\n1. Trends in Computing\n2. Examples of autonomous systems - Williams\n3. Autonomous systems architectures\n4. Principles = modeling + inference + search\n5. More examples - Frazzoli\n6. Course logistics and schedule\n7. Projects and programming\nBrian Williams, Fall 10\nHuman Brain\n- 100 Billion neurons\n- On average, connected to 1 K others\n- Neurons are slow. Firing rates < 100 Hz.\n- Can be classified into\n- Sensory\n- Motor\n- Central\n- (reasoning,\nproblem solving,\nlanguage..)\nBrian Williams, Fall 10\nImages of brain activity removed due\nto copyright restrictions.\n\nTrends in Biological and\nMachine Evolution - Moravec\n- 1 neuron = 1000 instructions/sec\n- Human brain then processes 10^14 IPS\n- 1 synapse = 1 byte of information\n- Human brain then has 10^14 bytes of storage\n- In 2000, we had10^9 IPS and 10^9 bytes on a\ndesktop machine\n- In 25 years, assuming Moore's law we obtain\nhuman level computing power\nBrian Williams, Fall 10\nOutline\n1. Trends in Computing\n2. Examples of autonomous systems - Williams\n3. Autonomous systems architectures\n4. Principles = modeling + inference + search\n5. More examples - Frazzoli\n6. Course logistics and schedule\n7. Projects and programming\nBrian Williams, Fall 10\n\nWilliams Research: Model-based\nProgramming of Autonomous Systems\nRobust, mission-directed agents:\n1. Self-repairing agents\n2. Agents that are agile\n3. Science explorers\nBrian Williams, Fall 10\nCassini Maps Titan\n\n- 7 year cruise\n- ~ 150 - 300\nground operators\n-~ 1 billion $\n- 7 years to build\n1. Self-Repairing Agents\n-150 million $\n-2 year build\n- 0 ground ops\nAffordable Missions\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/fairuse.\n\nRemote Agent on Deep Space One\n1.\nCommanded by giving goals\n2.\nReasoned from\ncommonsense models\n3.\nClosed loop on goals\nDiagnosis\n& Repair\nMission\nManager\nExecutive\nPlanner/\nScheduler\nRemote Agent\n[Williams & Nayak, AAAI 95;\nMuscettola et al, AIJ 00]\nBrian Williams, Fall 10\nA Goal sets engine A state to thrusting, and\nthe agent . . .\nExec: determines that valves on\nengine B will achieve thrust,\nand plans needed actions.\nDeduces that a valve\nfailed - stuck closed\nPlans actions\nto open\nsix valves\nDeduces that\nthrust is off, and\nthe engine is healthy\nEstimates Modes\nEstimates Modes\nReconfigures Modes\nReconfigures Modes\nA new Goal:\nSets engine B to thrust,\n\nCourtesy JPL\n2. Agile Agents\nBrian Williams, Fall 10\nBrian Williams, Fall 10\nImage credit: NASA.\n\nCourtesy JPL\nDescribe Tasks as\nTemporal Plans over Qualitative Poses\nInput:\nQualitative\nState Plan\nHofmann PhD - Chekov\nBrian Williams, Fall 10\nCourtesy of Andreas Hofmann. Used with permission.\nImage of hilly terrain removed due to copyright restrictions.\n\nBrian Williams, Fall 10\nMaintaining\nTemporal Synchronization\nDisturbance without\ntemporal coordination\nDisturbance with\ntemporal coordination\nHofmann\nPhD - Chekov\nBrian Williams, Fall 10\nCourtesy of Andreas Hofmann. Used with permission.\nCourtesy of Andreas Hofmann. Used with permission.\n\nCDIO Capstone:\nMoretta\nHofmann\nPhD - Chekov\nBrian Williams, Fall 10\nMBARI Dorado-class AUV:\n- 6000m rated\n- 20 hour operation\n- Multibeam Sonars\n- 3+ knots speed\nChallenges:\n- Long mission duration\n- Limited communication\n- GPS unavailable\n- Uncertainty\n- tides and currents\n- estimation error\n3. Science Explorers\nBrian Williams, Fall 10\nCourtesy of Andreas Hofmann. Used with permission.\nGraph (c) source unknown. All rights reserved. This content\nis excluded from our Creative Commons license. For more\ninformation, see http://ocw.mit.edu/fairuse.\n\nRobust, Goal-directed\nDeep Sea Exploration\nCommand script\n00:00 Go to x1,y1\n00:20 Go to x2,y2\n00:40 Go to x3,y3\n...\n04:10 Go to xn,yn\nPlant\nCommands\nLeaute & Williams, AAAI 05\nBrian Williams, Fall 10\nRobust, Goal-directed\nDeep Sea Exploration\nModel-based Executive\nObservations\nCommands\n\"Remain in mapping region for at least\n100s, then remain in bloom region for at\nleast 50s, then return to pickup region.\nAvoid obstacles at all times\"\nQualitative State Plan\nPlant\nLeaute & Williams, AAAI 05\nOptimal\nRobust\nBrian Williams, Fall 10\n\nExample Execution\nRemain in [safe region]\nRemain in\n[bloom region]\ne1\ne5\nRemain in\n[mapping region]\ne2\ne3\ne4\nEnd in\n[pickup region]\n[50,70]\n[40,50]\n[0,300]\nT(e1)=0\nT(e2)=70\nT(e3)=110\nT(e4)=150\nT(e5)=230\nBlackmore PhD\nBrian Williams, Fall 10\nCourtesy of Lars Blackmore. Used with permission.\nImage of NASA Athlete rover removed due to copyright restrictions.\n\nRemove one ball from red bin\nRemove one ball from blue bin\nRemove one ball from green bin\nRemove one ball from pink bin\nSwap black striped ball\n- Right Robot picks up and\noffers ball.\n- Robots perform hand-to-hand\nswap.\nSwap red striped ball\n- Left Robot picks up and offers\nball.\n- Robots perform hand-to-hand\nswap.\ntstart\ntfinish\n(Someone) Remove one ball from red bin\nRemove one ball from red bin\nL[32,39] V R[42,55]\nOR\nAgents choose and\nschedule activities\nBrian Williams, Fall 10\n\n-\n\n-\n\nBrian Williams, Fall 10\n\nVecna Bear\nBrian Williams, Fall 10\nOutline\n1. Trends in Computing\n2. Examples of autonomous systems\n3. Autonomous systems architectures\n4. Principles = modeling + inference + search\n5. More examples\n6. Course logistics and schedule\n7. Projects and programming\nBrian Williams, Fall 10\nImage of Vecna's Bear Robot removed due to copyright restrictions.\n\nAgent Paradigms\nBrian Williams, Fall 10\nGoal-Oriented Agents\nCourtesy of Stuart Russell and Peter Norvig. Used with permission.\n\nUtility-Based Agents\nDeliberative Agents\nWorld Model\nCourtesy of Stuart Russell and Peter Norvig. Used with permission.\n\nReflexive Agents\nPlan\nExecute\nMonitor &\nDiagnosis\nLocate in\nWorld\nPlan Routes\nMap\n16.410/13 Canonical\nAgent Architecture\nManeuver and Track\nCommunicate and Interpret Goals\nBrian Williams, Fall 10\nCourtesy of Stuart Russell and Peter Norvig. Used with permission.\n\nOutline\n1. Trends in Computing\n2. Examples of autonomous systems\n3. Autonomous systems architectures\n4. Principles = modeling + inference + search\n5. More examples\n6. Course logistics and schedule\n7. Projects and programming\nBrian Williams, Fall 10\nModeling Example:\nRobust, Goal-directed\nDeep Sea Exploration\nModel-based Executive\nObservations\nCommands\n\"Remain in mapping region for at least\n100s, then remain in bloom region for at\nleast 50s, then return to pickup region.\nAvoid obstacles at all times\"\nQualitative State Plan\nPlant\nLeaute & Williams, AAAI 05\nOptimal\nRobust\nBrian Williams, Fall 10\n\nModeling Goal Behavior\nusing Qualitative State Plans\nRemain in [safe region]\nRemain in\n[bloom region]\ne1\ne5\nRemain in\n[mapping region]\ne2\ne3\ne4\nEnd in\n[pickup region]\n[50,70]\n[40,50]\n[0,300]\nObstacle 1\nObstacle 2\nMapping\nRegion\nBloom\nRegion\nPickup\nRegion\n\"Remain in bloom region for between 50 and\n70 seconds. Afterwards, remain in mapping\nregion for between 40s and 50s. End in the\npickup region. Avoid obstacles at all times.\nComplete the mission within 300s\"\nApproach: Frame as Model-Predictive Control\nusing Mixed Logic or Integer / Linear Programming.\nLeaute & Williams, AAAI 05\nA qualitative state plan is a model-based program that is\nunconditional, timed, and hybrid and\nprovides flexibility in state and time.\nBrian Williams, Fall 10\nModeling Goal-directed Planning\nas a Mathematical Program\nmin\nU J(X,U) + H(xT )\ns.t.\n\nt= 0\nT\n\ni= 0\nN\n\nj= 0\nM\nht\niT xt gt\nij\nConstraints\nDynamics\n(Discrete time)\nCost function (e.g. fuel consumption)\nState vector (e.g. position of vehicle)\nControl inputs\nMixed Logic or Integer\nBrian Williams, Fall 10\n\nSpecify Building Blocks using\nDeclarative Programming\n- Mathematical Programming\n- Constraint Programming\n- Logic Programming\n- Agent Programming\n- Model-based programming\n- Timed concurrent constraint programming\n- Golog\n- Temporal logic programming\nBrian Williams, Fall 10\nSolve Declarative Programs using:\nSearch + Inference\nSearch:\ntry taking the subway, or\ntry taking the bus.\nInference: It takes 35 minutes to get to MIT,\n20 min subway + 15 min walking.\nBrian Williams, Fall 10\n\nOutline\n1. Trends in Computing\n2. Examples of autonomous systems\n3. Autonomous systems architectures\n4. Principles = modeling + inference + search\n5. More examples\n6. Course logistics and schedule\n7. Projects and programming\nBrian Williams, Fall 10\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "MIT16_410F10_lec01b.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/a0d6b74187b73ab14ce7f5d93d149a5f_MIT16_410F10_lec01b.pdf",
      "content": "16.410/413\nPrinciples of Autonomy and Decision Making\nLecture 1: Introduction to the course\nEmilio Frazzoli and Brian Williams\nAeronautics and Astronautics,\nMassachusetts Institute of Technology\nSeptember 8, 2010\nWednesday, September 8, 2010\n\nOutline\n- Introduction\n- Examples of autonomy in aerospace systems and robotics\n- Syllabus\n- Course Objectives\n- Course Staff\n- Logistics\n- Assignments and Grading\n- Course Overview\nWednesday, September 8, 2010\n\nTextbooks and programming languages\n- Primary textbook:\n- [AIMA] \"Artificial Intelligence: A Modern Approach,\" by S. Russell and P. Norvig\n(Prentice Hall), 3nd Edition\n- Other recommended textbooks:\n- [PA] \"Planning Algorithms,\" by S. LaValle (Cambridge Press), available at\nhttp://planning.cs.uiuc.edu/\n- [IOR] \"Introduction to Operations Research,\" by F. S. Hillier and G. J. Lieberman\n(McGraw-Hill).\n- Programming:\n- All programming in this course will be done in Java.\n- A good Java reference is\n[JINS] \"Java in a Nutshell\" by D. Flanagan (O'Reilly).\nWednesday, September 8, 2010\n\nAssignments and Grading\n- Reading assignments\n- We highly recommend reading the assigned material before the lecture in which\nit will be covered\n- Problem sets:\n- Problem sets are released weekly, and will include\n- modeling/analysis problems;\n- programming assignments;\n- Problem sets are due in class, or to the course administrator by 4:45pm of the\ndue date, unless otherwise indicated, or arranged in advance with the\ninstructors.\n- Exams:\n- There will be a mid-term exam on Oct 20 (mark the date), and a final exam\nWednesday, September 8, 2010\n\nAssignments and grading (cont'd)\n- Term project:\n- Students in 16.413 will be required to complete a project (to be discussed)\n- Grading schemes:\n- Your grade in 16.410 or 16.413 will be determined according to the following\napproximate weights (adjustments may be made based on factors such as, e.g.,\nclass participation):\n- 16.410: mid-term (25%), final (40%), and psets (35%)\n- 16.413: mid-term (20%), final (35%), project (20%), and psets (25%)\n- Furthermore:\n- Must complete all assignments for a passing grade.\n- Late assignments lose 20% per day (or fraction) after the deadline.\n- Exams will be closed-book, with one sheet of handwritten notes allowed\nWednesday, September 8, 2010\n\nTentative Schedule\n- Introduction:\n- 9/8,W: Course objectives, logistics, and overview\n- State-space search:\n- 9/13,M: Formulating problem solving as state-space search\n- 9/15,W: Analysis of uninformed search\n- Global path planning:\n- 9/21, M: Formulating Path Planning using Roadmaps.\n- Constraint Programming\n- 9/22, W: Visual interpretation and scheduling\n- 9/27, M: Constraint satisfaction\nWednesday, September 8, 2010\n\nTentative schedule\n- Propositional Logic\n- 9/29, W: Propositional Formulas, Models and Propositional Satisfiability,\nPropositional Inference and Entailment\n- Activity Planning and Execution\n- 10/4, M: Operator-based Planning Problems and Plan Graphs, Plan Generation\nusing Plan Graphs.\n- 10/6, W: Planning and Execution in a Changing World.\n- Autonomy architecture and case studies\n- 10/13, W: Space probes, vehicles and human-robot coordination\n- 10/18, M: TBD\n- 10/20, W: Midterm Exam\nWednesday, September 8, 2010\n\nTentative schedule\n- Constraint Optimization\n- 10/25, M: Finite-domain constraint optimization, Conflict learning.\n- 10/27, W: Consistency-based diagnosis, Multiple-fault diagnosis, Mode\nestimation and active probing\n- Global Path Planning (cont'd)\n- 11/1, M: Exploring Roadmaps using Informed Search. Weighted graphs; shortest\npath problems; DP, A*, B&B.\n- 11/3, W: Incremental sampling methods, PRM/RRT/RRT*\n- Mathematical Programming\n- 11/8, M: Formulating planning, scheduling, and resource allocation problems as\nmathematical programs\n- 11/10, W: Linear Programs (LPs): The simplex algorithm.\n- 11/15, M: Mixed-Integer Linear Programs (MILPs)\nWednesday, September 8, 2010\n\nTentative schedule\n- Reasoning in an uncertain world\n- 11/17, W: Probabilistic Inference, graphical models.\n- Sensing in an uncertain world\n- 11/22, M: Hidden Markov Models (HMMs): robot localization and mapping\n- 11/24, W: HMMs: algorithms\n- Acting in an uncertain world\n- 11/29, M: Dynamic programming and stochastic control, Markov Decision\nProcesses (MDPs)\n- Acting in an adversarial world\n- 12/6, M: Matrix and sequential games, alpha-beta pruning\n- 12/8, W: Mechanism design and auctions. Introduction to differential games,\npursuit-evasion, and collision avoidance.\nWednesday, September 8, 2010\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "MIT16_410F10_lec02.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/c58c480f620f23379260bc969f4c5dc2_MIT16_410F10_lec02.pdf",
      "content": "Brian Williams, Fall 10\nProblem Solving\nas State Space Search\nBrian C. Williams\n16.410-13\nSept 13th, 2010\nSlides adapted from:\n6.034 Tomas Lozano Perez,\nRussell and Norvig AIMA\nBrian Williams, Fall 10\nAssignments\n- Remember:\nProblem Set #1: Java warm up\nOut last Wednesday,\nDue this Wednesday, September 15th\n- Reading:\n- Today: Solving problems through search [AIMA] Ch. 3.1-4\n- Wednesday: Asymptotic Analysis Lecture 2 Notes of 6.046J;\nRecurrences, Lecture 12 Notes of 6.042J.\n\nBrian Williams, Fall 10\nRecap - Course Objectives\n1. Understand the major types of agents and\narchitectures:\n- goal-directed vs utility-based\n- deliberative vs reactive\n- model-based vs model-free\n2. Learn the modeling and algorithmic building\nblocks for creating agents:\n-\nModel problem in an appropriate\nformal representation.\n-\nSpecify, analyze, apply and implement reasoning\nalgorithms to solve the problem formulations.\nBrian Williams, Fall 10\nPlan\nExecute\nMonitor &\nDiagnosis\nLocate in\nWorld\nPlan Routes\nMap\nManeuver and Track\nMission Goals\nRecap - Agent Architectures\nFunctions: Robust, coordinated operation + mobility\nIt Begins with State Space Search!\n\nBrian Williams, Fall 10\nProblem Solving as\nState Space Search\n- Problem Formulation (Modeling)\n- Problem solving as state space search\n- Formal Representation\n- Graphs and search trees\n- Reasoning Algorithms\n- Depth and breadth-first search\nBrian Williams, Fall 10\nMost Agent Building Block\nImplementations Use Search\nRobust Operations:\n- Activity Planning\n- Diagnosis\n- Repair\n- Scheduling\n- Resource Allocation\nMobility:\n- Path Planning\n- Localization\n- Map Building\n- Control Trajectory\nDesign\n\nBrian Williams, Fall 10\nExample: Outpost\nLogistics Planning\nBrian Williams, Fall 10\nEarly AI: What are the universal problem solving methods?\nAstronaut\nGoose\nGrain\nFox\nRover\nCan the astronaut get its supplies\nsafely across a Lunar crevasse?\n- Astronaut + 1 item\nallowed in the rover.\n- Goose alone eats Grain\n- Fox alone eats Goose\nSimple\nTrivial\nImage produced for NASA by John Frassanito and Associates.\n\nBrian Williams, Fall 10\nProblem Solving as\nState Space Search\n- Formulate Goal\n- State\n- Astronaut, Fox, Goose & Grain below crevasse.\n- Formulate Problem\n- States\n- Astronaut, Fox, Goose & Grain\nabove or below the crevasse.\n- Operators\n- Move: Astronaut drives rover and 1 or 0 items\nto other side of crevasse.\n- Initial State\n- Astronaut, Fox, Goose & Grain above crevasse.\n- Generate Solution\n- Sequence of Operators (or States)\n- Move(goose,astronaut), Move(astronaut), . . .\nBrian Williams, Fall 10\nAstronaut\nGoose\nGrain\nFox\nAstronaut\nGoose\nGrain\nFox\nGrain\nFox\nAstronaut\nGoose\nGoose\nGrain\nAstronaut\nFox\nGoose\nFox\nAstronaut\nGrain\nGoose\nGrain\nFox\nAstronaut\n\nBrian Williams, Fall 10\nAstronaut\nGoose\nGrain\nFox\nGrain\nFox\nAstronaut\nGoose\nAstronaut\nGoose\nGrain\nFox\nGoose\nFox\nAstronaut\nGrain\nAstronaut\nGrain\nFox\nGoose\nAstronaut\nGoose\nGrain\nFox\nGoose\nGrain\nAstronaut\nFox\nAstronaut\nGoose\nFox\nGrain\nGrain\nAstronaut\nGoose\nFox\nFox\nAstronaut\nGoose\nGrain\nGoose\nAstronaut\nFox\nGrain\nGoose\nGrain\nFox\nAstronaut\nAstronaut\nGrain\nGoose\nFox\nAstronaut\nFox\nGoose\nGrain\nAstronaut\nGoose\nGrain\nFox\nAstronaut\nGoose\nGrain\nFox\nBrian Williams, Fall 10\nAstronaut\nGoose\nGrain\nFox\nGrain\nFox\nAstronaut\nGoose\nAstronaut\nGrain\nFox\nGoose\nGoose\nAstronaut\nFox\nGrain\nAstronaut\nGoose\nGrain\nFox\nAstronaut\nGoose\nGrain\nFox\nGrain\nAstronaut\nGoose\nFox\nFox\nAstronaut\nGoose\nGrain\nGoose\nFox\nAstronaut\nGrain\nGoose\nGrain\nAstronaut\nFox\nAstronaut\nGoose\nFox\nGrain\nAstronaut\nGrain\nGoose\nFox\nAstronaut\nFox\nGoose\nGrain\nGoose\nGrain\nFox\nAstronaut\nAstronaut\nGoose\nGrain\nFox\nAstronaut\nGoose\nGrain\nFox\n\nBrian Williams, Fall 10\n\n- Swaggert & Lovell assemble\nemergency rig for Apollo 13\nlithium hydroxide unit.\nLanguages for Expressing\nStates and Operators for Complex Tasks\nImage source: NASA.\nBrian Williams, Fall 10\nFormulation Example: 8-Puzzle\n- States:\n- Operators:\n- Initial and\nGoal States:\nStart\nGoal\ninteger location for each tile AND ...??\nmove empty square up, down, left, right\nas shown above\n\nBrian Williams, Fall 10\nExample: STRIPS Planning Language\nInitial state:\n(and (hose a) !\n(clamp b)!\n(hydroxide-unit c) !\n(on-table a) !\n(on-table b)\n(on-table c) !\n(clear a) !\n(clear b) !\n(clear c) !\n(empty arm))\ngoal (partial state):\n(and (connected a b) !\n(connected b c)))\nprecondition: (and (clear hose)\n\n(on-table hose)\n(empty arm))\neffect: (and (not (clear hose))\n(not (on-table hose))\n(not (empty arm))\n(holding arm hose)))\nOperators\nProblem:\nFind a Route from home to MIT\nStates? Operators?, Initial and Goal State?\n(c) MapQuest, Navigation Technologies. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/fairuse.\npickup hose\n\nBrian Williams, Fall 09\nProblem: Compensating for Error Online\n- Policy, π(v) → e, dictates how to act in all states.\n- Policy π corresponds to a shortest path tree from all vertices to the destination.\nHow do we Map Path Planning to\nState Space Search?\nStart\nposition\nGoal\nposition\nVehicle translates,\nbut no rotation\n\n1. Create Configuration Space\nIdea: Transform to equivalent\nproblem of navigating a point.\nStart\nposition\nGoal\nposition\nVehicle translates,\nbut no rotation\n2. Map From Continuous Problem to\nGraph Search: Create Visibility Graph\nStart\nposition\nGoal\nposition\n\nStart\nposition\nGoal\nposition\n2. Map From Continuous Problem to\nGraph Search: Create Visibility Graph\n3. Find Shortest Path (e.g., A*)\nStart\nposition\nGoal\nposition\n\nStart\nposition\nGoal\nposition\nResulting Solution\nA Visibility Graph is a Kind of Roadmap\nStart\nposition\nGoal\nposition\nWhat are the strengths / weaknesses of roadmaps?\nWhat are some other types of roadmaps?\n\nVoronoi Diagrams\nLines equidistant from CSpace obstacles\nBrian Williams, Fall 03\nRoadmaps: Approximate Fixed Cell\n\nBrian Williams, Fall 03\nRoadmaps: Approximate Fixed Cell\nBrian Williams, Fall 03\nRoadmaps: Approximate Variable Cell\n\nBrian Williams, Fall 03\nRoadmaps: Exact Cell Decomposition\nBrian Williams, Fall 03\nHow do we handle large state spaces?\nStart\nposition\nGoal\nposition\nRRT,\nTa\nRRT,\nTb\nRapid exploring Random Trees\n\nBrian Williams, Fall 10\nProblem Solving as\nState Space Search\n- Problem Formulation (Modeling)\n- Problem solving as state space search\n- Formal Representation\n- Graphs and search trees\n- Reasoning Algorithms\n- Depth and breadth-first search\nBrian Williams, Fall 10\nProblem Formulation: A Graph\nOperator\nEdge\nState\nVertex\nDirected\nGraph\n(one-way streets)\nUndirected\nGraph\n(two-way streets)\nneighbors\n(adjacent)\nTail Vertex\nof Edge\nHead Vertex\nof Edge\nh\nt\n\nBrian Williams, Fall 10\nProblem Formulation: A Graph\nIn Degree (2)\nOut Degree (1)\nDirected\nGraph\n(one-way streets)\nb\nUndirected\nGraph\n(two-way streets)\nb\nDegree (3)\nBrian Williams, Fall 10\nProblem Formulation: A Graph\nDirected\nGraph\n(one-way streets)\na\nc\nd\ne\nb\nUndirected\nGraph\n(two-way streets)\na\nc\ne\nd\nb\nConnected graph\nPath between all vertices.\nComplete graph\nAll vertices are adjacent.\nSub graph\nSubset of vertices\nedges between vertices in Subset\nClique\nA complete subgraph\n(All vertices are adjacent).\nStrongly connected graph\nDirected path between all vertices.\n\nBrian Williams, Fall 10\nSpecifying a Graph: G = <V, E>\na\nc\nd\ne\nb\nVertices V = {a, b, c, d, e}\nEdges E = {<a, b>, <a, c>,\n<b, e>,\n<c, b>, <c,d>,\n<e, d>}\nNotation:\n<a, b, ... n> an ordered list of elements a, b ...\n{a, b, ... n} an unordered set of distinguished elements.\nBrian Williams, Fall 10\nExamples of Graphs\nSan Fran\nBoston\nLA\nDallas\nWash DC\nRoadmap\nA\nB\nC\nA\nB\nC\nA\nB\nC\nA\nB\nC\nPut C on B\nPut C on A\nPut B on C\nPut C on A\nA\nB\nC\nPut A on C\nPlanning Actions\n(graph of possible\nstates of the world)\n\nBrian Williams, Fall 10\nFormalizing State Space Search\nC\nS\nB\nG\nA\nD\nInput: A search problem S = <g, S, G> where\n- graph g = <V, E>,\n- start vertex S in V, and\n- goal vertex G in V.\nOutput: A simple path P = <S, v2, ... G> in g from S to G.\nBrian Williams, Fall 10\nSimple Paths of Graph g = <V, E>\nC\nS\nB\nG\nA\nD\nA simple path is a path that has no cycles.\nA cycle is a subpath where start = end (i.e., repeated vertices).\nA (directed) path P of graph g is\na sequence of vertices <v1, ... vn> in V\n\nsuch that each successive pair <vi,vi+1> is a (directed) edge in E\nstart\nend\n<S, A, D, C>\n\nBrian Williams, Fall 10\nA Problem Solver Searches\nthrough all Simple Paths\nC\nS\nB\nG\nA\nD\nS\nD\nA\nC\nG\nBrian Williams, Fall 10\nA Search Tree Denotes All Simple Paths\nC\nS\nB\nG\nA\nD\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nEnumeration is:\n- Complete\n- Systematic\n- Sound\n\nBrian Williams, Fall 10\nSearch Trees\nA tree T is a directed graph, such that\n- there exists exactly one undirected path between any\npair of vertices.\n- In degree of each vertex is 1\nthink of a tree as a \"family\" tree\nBrian Williams, Fall 10\nSearch Trees\nRoot\nBranch\n(Edge)\nNode\n(Vertex)\nLeaf\nthink of a tree as a \"family\" tree\n\nBrian Williams, Fall 10\nSearch Trees\nParent\nChild\nSiblings\nthink of a tree as a \"family\" tree\nBrian Williams, Fall 10\nSearch Trees\nAncestors\nthink of a tree as a \"family\" tree\n\nBrian Williams, Fall 10\nSearch Trees\nDescendants\nthink of a tree as a \"family\" tree\nBrian Williams, Fall 10\nProblem Solving as\nState Space Search\n- Problem Formulation (Modeling)\n- Problem solving as state space search\n- Formal Representation\n- Graphs and search trees\n- Reasoning Algorithms\n- Depth and breadth-first search\n\nBrian Williams, Fall 10\nClasses of Search\nBlind\n\nDepth-First\nSystematic exploration of whole tree\n(uninformed)\nBreadth-First\nuntil the goal is found.\n\nIterative-Deepening\nHeuristic\nHill-Climbing\nUse heuristic measure of goodness\n(informed)\nBest-First\nof a node.\n\nBeam\n\nOptimal\nA*\n\nUse path \"length\" measure. Find\n(informed)\nBranch&Bound \"shortest\" path.\nBrian Williams, Fall 10\nDepth First Search (DFS)\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nLocal Rule: After visiting node...\n- Visit its children before its siblings\n- Visit its children left to right\nS\nA\nD\nC\nG\nC\nB\nD\nC\nG\nG\n\nBrian Williams, Fall 10\nBreadth First Search (BFS)\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nLocal Rule: After visiting node...\n- Visit its siblings, before its children\n- Visit its children left to right\nS\nA\nD\nC\nG\nC\nB\nD\nC\nG\nG\nBrian Williams, Fall 10\nElements of Algorithm Design\nAlgorithm Description: (Today)\n- stylized pseudo code, sufficient to analyze and implement the algorithm\n(implementation next Wednesday).\nAlgorithm Analysis: (Wednesday & Monday)\n- Time complexity:\n- how long does it take to find a solution?\n- Space complexity:\n- how much memory does it need to perform search?\n- Soundness:\n- when a solution is returned, is it guaranteed to be correct?\n- Completeness:\n- is the algorithm guaranteed to find a solution when there is one?\n\nBrian Williams, Fall 10\nProblem Solving as\nState Space Search\n- Problem Formulation (Modeling)\n- Formal Representation\n- Reasoning Algorithms\n- A generic search algorithm description\n- Depth-first search example\n- Handling cycles\n- Breadth-first search example\nBrian Williams, Fall 10\nSolve <g = <V, E>, S, G>\nusing State Space Search\nSearch States:\n- All simple paths <S, ...v> in g starting at S\nInitial State:\n- <S>\nOperator:\n- Extend a path <S, ... v> to <S, ... v, u>\nfor each <v, u> in E\n- call u a child of v\nGoal:\n- A simple path <S, ..., G> in g\n\nBrian Williams, Fall 10\nSolve <g = <V, E>, S, G>\nusing State Space Search\nHow do we maintain the search state?\n-\nAn ordering on partial paths yet to be expanded\n(called a queue Q).\nHow do we perform search?\n-\nRepeatedly:\n1. Select next partial path from Q.\n2. Expand it.\n3. Add expansions to Q.\n-\nTerminate when goal G is found.\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nBrian Williams, Fall 10\nSimple Search Algorithm: Preliminaries\n- A partial path from S to D is listed in reverse order,\n- e.g., <D, A, S>\n- The head of a partial path is its most recent visited node,\n- e.g., D.\n- The Q is a list of partial paths,\n- e.g. (<D, A, S>, <C, A, S> ...>.\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\n\nBrian Williams, Fall 10\nSimple Search Algorithm\nLet Q be a list of partial paths,\nS be the Start node and\nG be the Goal node.\n1. Initialize Q with partial path <S>\n2. If Q is empty, fail. Else, pick a partial path N from Q\n3. If head(N) = G, return N\n\n(goal reached!)\n4. Else:\na) Remove N from Q\nb) Find all children of head(N) and\ncreate a one-step extension of N to each child\nc) Add all extended paths to Q\nd) Go to step 2\nBrian Williams, Fall 10\nProblem Solving as\nState Space Search\n- Problem Formulation (Modeling)\n- Formal Representation\n- Reasoning Algorithms\n- A generic search algorithm description\n- Depth-first search example\n- Handling cycles\n- Breadth-first search example\n\nBrian Williams, Fall 10\nDepth First Search (DFS)\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nS\nA\nD\nC\nG\nC\nB\nD\nC\nG\nG\nAssume we remove the first element of Q,\nWhere to Q do we add the path extensions?\nIdea: After visiting node\n- Visit its children left to right (or top to bottom)\n- Visit its children before its siblings\nBrian Williams, Fall 10\nSimple Search Algorithm\nLet Q be a list of partial paths,\nS be the start node and\nG be the Goal node.\n1. Initialize Q with partial path <S>\n2. If Q is empty, fail. Else, pick a partial path N from Q\n3. If head(N) = G, return N\n\n(goal reached!)\n4. Else:\na) Remove N from Q\nb) Find all children of head(N) and\ncreate a one-step extension of N to each child\nc) Add all extended paths to Q\nd) Go to step 2\n\nBrian Williams, Fall 10\nDepth-First\nPick first element of Q; Add path extensions to front of Q\nC\nS\nB\nG\nA\nD\nQ\n(S)\nBrian Williams, Fall 10\nSimple Search Algorithm\nLet Q be a list of partial paths,\nS be the Start node and\nG be the Goal node.\n1. Initialize Q with partial path <S>\n2. If Q is empty, fail. Else, pick a partial path N from Q\n3. If head(N) = G, return N\n\n(goal reached!)\n4. Else:\na) Remove N from Q\nb) Find all children of head(N) and\ncreate a one-step extension of N to each child\nc) Add all extended paths to Q\nd) Go to step 2\n\nBrian Williams, Fall 10\nC\nS\nB\nG\nA\nD\nQ\n(S)\nDepth-First\nPick first element of Q; Add path extensions to front of Q\nBrian Williams, Fall 10\nC\nS\nB\nG\nA\nD\nQ\n(S)\n(A S)\nAdded paths in blue\nDepth-First\nPick first element of Q; Add path extensions to front of Q\n\nBrian Williams, Fall 10\nC\nS\nB\nG\nA\nD\nQ\n(S)\n(A S) (B S)\nAdded paths in blue\nDepth-First\nPick first element of Q; Add path extensions to front of Q\nBrian Williams, Fall 10\nSimple Search Algorithm\nLet Q be a list of partial paths,\nLet S be the start node and\nLet G be the Goal node.\n1. Initialize Q with partial path <S>\n2. If Q is empty, fail. Else, pick a partial path N from Q\n3. If head(N) = G, return N\n\n(goal reached!)\n4. Else:\na) Remove N from Q\nb) Find all children of head(N) and\ncreate a one-step extension of N to each child\nc) Add all extended paths to Q\nd) Go to step 2\n\nBrian Williams, Fall 10\nC\nS\nB\nG\nA\nD\nQ\n(S)\n(A S) (B S)\nAdded paths in blue\nDepth-First\nPick first element of Q; Add path extensions to front of Q\nBrian Williams, Fall 10\nC\nS\nB\nG\nA\nD\nQ\n(S)\n(A S) (B S)\n(C A S) (D A S) (B S)\nDepth-First\nPick first element of Q; Add path extensions to front of Q\nAdded paths in blue\n\nBrian Williams, Fall 10\nC\nS\nB\nG\nA\nD\nQ\n(S)\n(A S) (B S)\n(C A S) (D A S) (B S)\nDepth-First\nPick first element of Q; Add path extensions to front of Q\nAdded paths in blue\nBrian Williams, Fall 10\nC\nS\nB\nG\nA\nD\nQ\n(S)\n(A S) (B S)\n(C A S) (D A S) (B S)\n(D A S) (B S)\nDepth-First\nPick first element of Q; Add path extensions to front of Q\nAdded paths in blue\n\nBrian Williams, Fall 10\nC\nS\nB\nG\nA\nD\nQ\n(S)\n(A S) (B S)\n(C A S) (D A S) (B S)\n(D A S) (B S)\nDepth-First\nPick first element of Q; Add path extensions to front of Q\nAdded paths in blue\nBrian Williams, Fall 10\nC\nS\nB\nG\nA\nD\nQ\n(S)\n(A S) (B S)\n(C A S) (D A S) (B S)\n(D A S) (B S)\n(C D A S)(G D A S)\n(B S)\nDepth-First\nPick first element of Q; Add path extensions to front of Q\n\nBrian Williams, Fall 10\nC\nS\nB\nG\nA\nD\nQ\n(S)\n(A S) (B S)\n(C A S) (D A S) (B S)\n(D A S) (B S)\n(C D A S)(G D A S)\n(B S)\nDepth-First\nPick first element of Q; Add path extensions to front of Q\nBrian Williams, Fall 10\nC\nS\nB\nG\nA\nD\nQ\n(S)\n(A S) (B S)\n(C A S) (D A S) (B S)\n(D A S) (B S)\n(C D A S)(G D A S)\n(B S)\n(G D A S)(B S)\nDepth-First\nPick first element of Q; Add path extensions to front of Q\n\nBrian Williams, Fall 10\nC\nS\nB\nG\nA\nD\nQ\n(S)\n(A S) (B S)\n(C A S) (D A S) (B S)\n(D A S) (B S)\n(C D A S)(G D A S)\n(B S)\n(G D A S)(B S)\nDepth-First\nPick first element of Q; Add path extensions to front of Q\nBrian Williams, Fall 10\nSimple Search Algorithm\nLet Q be a list of partial paths,\nLet S be the start node and\nLet G be the Goal node.\n1. Initialize Q with partial path <S>\n2. If Q is empty, fail. Else, pick a partial path N from Q\n3. If head(N) = G, return N\n\n(goal reached!)\n4. Else:\na) Remove N from Q\nb) Find all children of head(N) and\ncreate a one-step extension of N to each child\nc) Add all extended paths to Q\nd) Go to step 2\n\nBrian Williams, Fall 10\nProblem Solving as\nState Space Search\n- Problem Formulation (Modeling)\n- Formal Representation\n- Reasoning Algorithms\n- A generic search algorithm description\n- Depth-first search example\n- Handling cycles\n- Breadth-first search example\nBrian Williams, Fall 10\nC\nS\nB\nG\nA\nD\nIssue: Starting at S and moving top to bottom,\nwill depth-first search ever reach G?\n\nBrian Williams, Fall 10\nC\nS\nB\nG\nA\nD\nQ\n(S)\n(A S) (B S)\n(C A S) (D A S) (B S)\n(D A S) (B S)\n(C D A S)(G D A S)\n(B S)\n(G D A S)(B S)\nDepth-First\n- C visited multiple times\n- Multiple paths to C, D & G\nHow much wasted effort can be incurred in the worst case?\nEffort can be wasted in more mild cases\nBrian Williams, Fall 10\nHow Do We Avoid Repeat Visits?\nIdea:\n- Keep track of nodes already visited.\n- Do not place expanded path on Q if head is a visited node.\nDoes this maintain correctness?\n- Any goal reachable from a node that was visited a second\ntime would be reachable from that node the first time.\nDoes this always improve efficiency?\n- Visits only a subset of the original paths, such that\neach node appears at most once at the head of a visited path.\n\nBrian Williams, Fall 10\nHow Do We Modify The\nSimple Search Algorithm?\nLet Q be a list of partial paths,\nLet S be the Start node and\nLet G be the Goal node.\n1. Initialize Q with partial path <S> as only entry;\n2. If Q is empty, fail. Else, pick some partial path N from Q\n3. If head(N) = G, return N\n\n(goal reached!)\n4. Else\na) Remove N from Q\nb) Find all children of head(N) and\ncreate a one-step extension of N to each child\nc) Add to Q all the extended paths\nd) Go to step 2\nBrian Williams, Fall 10\nSimple Search Algorithm\nLet Q be a list of partial paths,\nLet S be the start node and\nLet G be the Goal node.\n1. Initialize Q with partial path <S> as only entry; set Visited = {}\n2. If Q is empty, fail. Else, pick some partial path N from Q\n3. If head(N) = G, return N\n\n(goal reached!)\n4. Else\na) Remove N from Q\nb) Find all children of head(N) not in Visited and\ncreate a one-step extension of N to each child\nc) Add to Q all the extended paths\nd) Add children of head(N) to Visited\ne) Go to step 2\n\nBrian Williams, Fall 10\nTesting for the Goal\n- This algorithm stops (in step 3) when head(N) = G.\n- We could have performed this test in step 6 as each\nextended path is added to Q. This would catch\ntermination earlier and be perfectly correct for all the\nsearches we have covered so far.\n- However, performing the test in step 6 will be\nincorrect for the optimal search algorithms that we\nlook at later. We have chosen to leave the test in step 3\nto maintain uniformity with these future searches.\nBrian Williams, Fall 10\nProblem Solving as\nState Space Search\n- Problem Formulation (modeling)\n- Formal Representation\n- Reasoning Algorithms\n- A generic search algorithm description\n- Depth-first search example\n- Handling cycles\n- Breadth-first search example\n\nBrian Williams, Fall 10\nBreadth First Search (BFS)\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nS\nA\nD\nC\nG\nC\nB\nD\nC\nG\nG\nIdea: After visiting node\n- Visit its children left to right\n- Visit its siblings, before its children\nAssume we remove the first element of Q,\nWhere to Q do we add the path extensions?\nBrian Williams, Fall 10\nBreadth-First with Visited List\nPick first element of Q; Add path extensions to end of Q\nC\nS\nB\nG\nA\nD\nQ\nVisited\n(S)\nS\n\nBrian Williams, Fall 10\nBreadth-First with Visited List\nPick first element of Q; Add path extensions to end of Q\nC\nS\nB\nG\nA\nD\nQ\nVisited\n(S)\nS\nBrian Williams, Fall 10\nBreadth-First with Visited List\nPick first element of Q; Add path extensions to end of Q\nC\nS\nB\nG\nA\nD\nQ\nVisited\n(S)\nS\n(A S) (B S)\nA,B,S\n\nBrian Williams, Fall 10\nBreadth-First with Visited List\nPick first element of Q; Add path extensions to end of Q\nC\nS\nB\nG\nA\nD\nQ\nVisited\n(S)\nS\n(A S) (B S)\nA,B,S\nBrian Williams, Fall 10\nBreadth-First with Visited List\nPick first element of Q; Add path extensions to end of Q\nC\nS\nB\nG\nA\nD\nQ\nVisited\n(S)\nS\n(A S) (B S)\nA,B,S\n(B S) (C A S) (D A S)\nC,D,B,A,S\n\nBrian Williams, Fall 10\nBreadth-First with Visited List\nPick first element of Q; Add path extensions to end of Q\nC\nS\nB\nG\nA\nD\nQ\nVisited\n(S)\nS\n(A S) (B S)\nA,B,S\n(B S) (C A S) (D A S)\nC,D,B,A,S\nBrian Williams, Fall 10\nBreadth-First with Visited List\nPick first element of Q; Add path extensions to end of Q\nC\nS\nB\nG\nA\nD\nQ\nVisited\n(S)\nS\n(A S) (B S)\nA,B,S\n(B S) (C A S) (D A S)\nC,D,B,A,S\n(C A S) (D A S) (G B S)*\nG,C,D,B,A,S\n* We could stop here, when the first path to the goal is generated.\n\nBrian Williams, Fall 10\nBreadth-First with Visited List\nPick first element of Q; Add path extensions to end of Q\nC\nS\nB\nG\nA\nD\nQ\nVisited\n(S)\nS\n(A S) (B S)\nA,B,S\n(B S) (C A S) (D A S)\nC,D,B,A,S\n(C A S) (D A S) (G B S)*\nG,C,D,B,A,S\n* We could stop here, when the first path to the goal is generated.\nBrian Williams, Fall 10\nBreadth-First with Visited List\nPick first element of Q; Add path extensions to end of Q\nC\nS\nB\nG\nA\nD\nQ\nVisited\n(S)\nS\n(A S) (B S)\nA,B,S\n(B S) (C A S) (D A S)\nC,D,B,A,S\n(C A S) (D A S) (G B S)*\nG,C,D,B,A,S\n(D A S) (G B S)\nG,C,D,B,A,S\n\nBrian Williams, Fall 10\nBreadth-First with Visited List\nPick first element of Q; Add path extensions to end of Q\nC\nS\nB\nG\nA\nD\nQ\nVisited\n(S)\nS\n(A S) (B S)\nA,B,S\n(B S) (C A S) (D A S)\nC,D,B,A,S\n(C A S) (D A S) (G B S)*\nG,C,D,B,A,S\n(D A S) (G B S)\nG,C,D,B,A,S\n(G B S)\nG,C,D,B,A,S\nBrian Williams, Fall 10\nBreadth-First with Visited List\nPick first element of Q; Add path extensions to end of Q\nC\nS\nB\nG\nA\nD\nQ\nVisited\n(S)\nS\n(A S) (B S)\nA,B,S\n(B S) (C A S) (D A S)\nC,D,B,A,S\n(C A S) (D A S) (G B S)*\nG,C,D,B,A,S\n(D A S) (G B S)\nG,C,D,B,A,S\n(G B S)\nG,C,D,B,A,S\n\nBrian Williams, Fall 10\nDepth-first with Visited List\nPick first element of Q; Add path extensions to front of Q\nC\nS\nB\nG\nA\nD\nQ\nVisited\n(S)\nS\n(A S) (B S)\nA, B, S\n(C A S) (D A S) (B S)\nC,D,B,A,S\n(D A S) (B S)\nC,D,B,A,S\n(G D A S) (B S)\nG,C,D,B,A,S\nBrian Williams, Fall 10\nDepth First Search (DFS)\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nBreadth First Search (BFS)\nFor each search type, where do we place the children on the queue?\nDepth-first:\nAdd path extensions to front of Q\nPick first element of Q\nBreadth-first:\nAdd path extensions to back of Q\nPick first element of Q\n\nBrian Williams, Fall 10\nWhat You Should Know\n- Most problem solving tasks may be\nformulated as state space search.\n- State space search is formalized using\ngraphs, simple paths, search trees, and\npseudo code.\n- Depth-first and breadth-first search are\nframed, among others, as instances of a\ngeneric search strategy.\n- Cycle detection is required to achieve\nefficiency and completeness.\nBrian Williams, Fall 10\nAppendix\n\nBrian Williams, Fall 10\nBreadth-First (without Visited list)\nPick first element of Q; Add path extensions to end of Q\nC\nS\nB\nG\nA\nD\nQ\n(S)\nBrian Williams, Fall 10\nBreadth-First (without Visited list)\nPick first element of Q; Add path extensions to end of Q\nC\nS\nB\nG\nA\nD\nQ\n(S)\n(A S) (B S)\nAdded paths in blue\n\nBrian Williams, Fall 10\nBreadth-First (without Visited list)\nPick first element of Q; Add path extensions to end of Q\nC\nS\nB\nG\nA\nD\nQ\n(S)\n(A S) (B S)\n(B S) (C A S) (D A S)\nAdded paths in blue\nBrian Williams, Fall 10\nBreadth-First (without Visited list)\nPick first element of Q; Add path extensions to end of Q\nC\nS\nB\nG\nA\nD\nQ\n(S)\n(A S) (B S)\n(B S) (C A S) (D A S)\n(C A S) (D A S) (D B S) (G B S)*\nAdded paths in blue\nRevisited nodes in pink\n* We could have stopped here, when the first path to the goal was generated.\n\nBrian Williams, Fall 10\nBreadth-First (without Visited list)\nPick first element of Q; Add path extensions to end of Q\nC\nS\nB\nG\nA\nD\nQ\n(S)\n(A S) (B S)\n(B S) (C A S) (D A S)\n(C A S) (D A S) (D B S) (G B S)*\n(D A S) (D B S) (G B S)\nBrian Williams, Fall 10\nBreadth-First (without Visited list)\nPick first element of Q; Add path extensions to end of Q\nC\nS\nB\nG\nA\nD\nQ\n(S)\n(A S) (B S)\n(B S) (C A S) (D A S)\n(C A S) (D A S) (D B S) (G B S)*\n(D A S) (D B S) (G B S)\n(D B S) (G B S) (C D A S) (G D A S)\n\nBrian Williams, Fall 10\nBreadth-First (without Visited list)\nPick first element of Q; Add path extensions to end of Q\nC\nS\nB\nG\nA\nD\nQ\n(S)\n(A S) (B S)\n(B S) (C A S) (D A S)\n(C A S) (D A S) (D B S) (G B S)*\n(D A S) (D B S) (G B S)\n(D B S) (G B S) (C D A S) (G D A S)\n(G B S) (C D A S) (G D A S)(C D B S)(G D B S)\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "MIT16_410F10_lec03.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/ee43f99f8c4b82c4aab96e8d8d294f30_MIT16_410F10_lec03.pdf",
      "content": "Analysis of Uninformed\nSearch Methods\nBrian Williams, Fall 10\nBrian C.\nWilliams\nDraws from materials in:\n16.410-13\n6.034 Tomas Lozano Perez,\nRussell and Norvig AIMA\nSep 15th, 2010\n6.046J Charles E. Leiserson\nAssignments\n- Assignment:\n- Problem Set #1 due today, Wed Sept 15th, 2010.\n- Problem Set #2: Uninformed Search out today,\ndue Wednesday, September 22nd, 20010.\n- Reading:\n- Today: Asymptotic Analysis, Lecture 2 Notes of 6.046J\nRecurrences, Lecture 12 Notes of 6.042J.\n- Monday: Proofs & Induction, Lectures 2 and 3 of 6.042J.\nBrian Williams, Fall 10\n\nOutline\n- Review\n- Analysis\n- Depth-first search\n- Breadth-first search\n- Iterative deepening\nBrian Williams, Fall 10\nAutonomous Systems:\n- Plan complex sequences of actions\n- Schedule tight resources\n- Monitor and diagnose behavior\n- Repair or reconfigure hardware.\nformulate as state space search.\nBrian Williams, Fall 10\n\nFormalizing Graph Search\nInput: A search problem SP = <g, S, G> where\n-graph g = <V, E>,\n-start vertex S in V, and\n-goal vertex G in V.\nOutput: A simple path P = <S, v2, ... G> in g from S to G.\n(i.e., <vi,vi+1> E, and vi vj if i j ).\nC\nS\nB\nG\nA\nD\nBrian Williams, Fall 10\nBrian Williams, Fall 10\nS\nB\nG\nA\n<S>\n<B, S>\n<A, S>\n<G, B, S>\n< A, B, S>\nGraph Search is a Kind\nof State Space Search\nS\nB\nA\nG\nB\nGraph Search is a Kind\nOf Tree Search\n\nSolution: Depth First Search (DFS)\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nSolution: Breadth First Search (BFS)\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nBrian Williams, Fall 10\nBrian Williams, Fall 10\nS\nB\nG\nA\n<S>\nGenerate (Q)\nTest\n<A, S>\n<B, S>\nVisited\nS\n\nPseudo Code For Simple Search\nLet g be a Graph\nG be the Goal vertex of g.\nS be the Start vertex of g\nQ be a list of simple partial paths in GR,\n1. Initialize Q with partial path (S) as only entry; set Visited = ( );\n2. If Q is empty, fail. Else, pick some partial path N from Q;\n3. If head(N) = G, return N;\n(goal reached!)\n4. Else\na) Remove N from Q;\nb) Find all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc) Add to Q all the extended paths;\nd) Add children of head(N) to Visited;\nBrian Williams, Fall 10\ne) Go to step 2.\nSolution: Depth First Search (DFS)\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nDepth-first:\nAdd path extensions to front of Q\nPick first element of Q\nSolution: Breadth First Search (BFS)\nS\nD\nA\nC\nC\nG\nD\nC\nB\nBreadth-first:\nAdd path extensions to back of Q\nG\nPick first element of Q\nG\nBrian Williams, Fall 10\n\nOutline\n- Review\n- Analysis\n- Depth-first search\n- Breadth-first search\n- Iterative deepening\nBrian Williams, Fall 10\nElements of Algorithm Design\nDescription: (last Monday)\n- Problem statement.\n- Stylized pseudo code, sufficient to analyze and implement the\nalgorithm.\n- Implementation (last Wednesday).\nAnalysis: (today)\n- Performance:\n- Time complexity:\n- how long does it take to find a solution?\n- Space complexity:\n- how much memory does it need to perform search?\n- Correctness: (next Monday)\n- Soundness:\n- when a solution is returned, is it guaranteed to be correct?\n- Completeness:\n- is the algorithm guaranteed to find a solution when there is one?\nBrian Williams, Fall 10\n\nE.g., a search tree with\na Goal to the left is easier than one to the right.\nGenerally gets harder\nwith increased size.\nEveryone likes a guarantee.\nPerformance Analysis\nAnalysis of run-time and resource usage:\n- Helps to understand scalability.\n- Draws line between feasible and impossible.\n- A function of program input.\n- Parameterized by input size.\n- Seeks upper bound.\nBrian Williams, Fall 10\nTypes of Analyses\nWorst-case:\n- T(n) = maximum time of algorithm on any input\nof size n.\nAverage-case:\n- T(n) = expected time of algorithm over all inputs\nof size n.\n- Requires statistical distribution on inputs.\nBest-case:\n- T(n) = minimum time of algorithm on any input.\nBrian Williams, Fall 10\n\nAnalysis uses Machine-independent\nTime and Space\nPerformance depends on computer speed:\n-\nRelative speed (run on same machine)\n-\nAbsolute speed (on different machines)\nBig idea:\n-\nIgnore machine-dependent constraints\n-\nLook at growth of T(n) as n\n\"Asymptotic Analysis\"\nBrian Williams, Fall 10\nAsymptotic notation\nO-notation (upper bounds):\n- 2n2 = O(n3)\nmeans 2n2 cn3 for sufficiently large c & n\n- f(n) = O( g(n) )\nif there exists constants c > 0, n0 > 0\nsuch that 0 f(n) c g(n) for all n n .\no\nBrian Williams, Fall 10\n\nWorst case time is proportional to number of vertices visited\nWorst case space is proportional to maximum length of Q\nSet definition of O-notation\nO(n3) = { all functions bounded by cn3 }\n2n2 O(n3)\nO(g(n)) = {f(n) | there exists constants\nc > 0, n0 > 0 such that\n0 f(n) c g(n) for all n no}\nBrian Williams, Fall 10\nPerformance and Resource Usage\nWhich is better, depth-first or breadth-first?\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nC\nS\nB\nG\nA\nD\nSearch\nMethod\nWorst\nTime\nWorst\nSpace\nShortest\nPath?\nGuaranteed to\nfind path?\nDepth-first\nBreadth-first\nBrian Williams, Fall 10\n\nAnalyzing Time and Space Complexity\nof Search in Terms of Trees\nb = 3\nd = 1\nLevel 1\nLevel 2\nLevel 0\nm = 2\nb = maximum branching factor, number of children\nd = depth of the shallowest goal node\nm = maximum length of any path in the state space\nBrian Williams, Fall 10\nWorst Case Time for Depth-first\nWorst case time T is proportional to number of nodes visited\nLevel 1\nLevel 2\nLevel 0\nb*1\nb*b\nb*bm-1\n. . .\nLevel m\nBrian Williams, Fall 10\nTdfs\nb * Tdfs\n[b - 1] * Tdfs = [bm+1 - 1]*cdfs\nTdfs = [bm+1 - 1] / [b - 1] *cdfs\nwhere cdfs is time per node\nSolve recurrence\n=\n[bm + ... b + 1]*cdfs\n= [bm+1 + bm + ... b + 0]*cdfs\n\nCost Using Order Notation\nWorst case time T is proportional to number of nodes visited\nLevel 1\nLevel 2\nLevel 0\nb*1\nb*b\nb*bm-1\n. . .\nOrder Notation\n- T(n) = O(e(n)) if T c * e for sufficiently large c & n\nTdfs = [bm+1 - 1] / [b - 1] *cdfs\n= O(bm+1)\n~ O(bm)\nas b\n(used in some texts)\nBrian Williams, Fall 10\nPerformance and Resource Usage\nWhich is better, depth-first or breadth-first?\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nC\nS\nB\nG\nA\nD\nSearch\nMethod\nWorst\nTime\nWorst\nSpace\nShortest\nPath?\nGuaranteed to\nfind path?\nDepth-first\n~ bm\nBreadth-first\nWorst case time is proportional to number of nodes visited\nWorst case space is proportional to maximal length of Q\nBrian Williams, Fall 10\n\nWorst Case Space for Depth-first\nWorst case space Sdfs is proportional to maximum length of Q\n- If a node is queued its parent and siblings have been queued,\nand its parent dequeued.\nBrian Williams, Fall 10\nLevel 1\nLevel m\nLevel 0\nWorst Case Space for Depth-first\nWorst case space Sdfs is proportional to maximuml length of Q\n- If a node is queued its parent and siblings have been queued,\nand its parent dequeued.\nSdfs [(b-1)*m+1] *cdfswhere cdfs is space per node.\n- At most one sibling of a node has its children queued.\nSdfs = [(b-1)*m+1] *cdfs\n-\nSdfs = O(b*m)\n+ add visited list\nLevel 1\nLevel m\nLevel 0\nb-1\nb-1\nb\n. . .\nBrian Williams, Fall 10\n\nPerformance and Resource Usage\nWhich is better, depth-first or breadth-first?\nC\nG\nA\nD\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nS\nB\nSearch\nMethod\nWorst\nTime\nWorst\nSpace\nShortest\nPath?\nGuaranteed to\nfind path?\nDepth-first\n~bm\nb*m\nBreadth-first\nWorst case time is proportional to number of nodes visited\nWorst case space is proportional to maximal length of Q\nBrian Williams, Fall 10\nPerformance and Resource Usage\nWhich is better, depth-first or breadth-first?\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nC\nS\nB\nG\nA\nD\nSearch\nMethod\nWorst\nTime\nWorst\nSpace\nShortest\nPath?\nGuaranteed to\nfind path?\nDepth-first\n~bm\nb*m\nNo\nBreadth-first\nWorst case time is proportional to number of nodes visited\nWorst case space is proportional to maximal length of Q\nBrian Williams, Fall 10\n\nPerformance and Resource Usage\nWhich is better, depth-first or breadth-first?\nC\nG\nA\nD\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nS\nB\nSearch\nMethod\nWorst\nTime\nWorst\nSpace\nShortest\nPath?\nGuaranteed to\nfind path?\nDepth-first\n~bm\nb*m\nNo\nYes for finite graph\nBreadth-first\nWorst case time is proportional to number of nodes visited\nWorst case space is proportional to maximal length of Q\nBrian Williams, Fall 10\nPerformance and Resource Usage\nWhich is better, depth-first or breadth-first?\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nC\nS\nB\nG\nA\nD\nSearch\nMethod\nWorst\nTime\nWorst\nSpace\nShortest\nPath?\nGuaranteed to\nfind path?\nDepth-first\n~bm\nb*m\nNo\nYes for finite graph\nBreadth-first\nWorst case time is proportional to number of nodes visited\nWorst case space is proportional to maximal length of Q\nBrian Williams, Fall 10\n\nWorst Case Time for Breadth-first\nWorst case time T is proportional to number of nodes visited\nLevel 1\nLevel d\nLevel 0\nLevel d+1\nLevel m\n. . .\nConsider case where solution is at level d (absolute worst is m):\nBrian Williams, Fall 10\nWorst Case Time for Breadth-first\nWorst case time T is proportional to number of nodes visited\nLevel 1\nLevel d\nLevel 0\nLevel d+1\nbd+1- b\nb\n. . .\nbd\nLevel m\n. . .\nConsider case where solution is at level d (absolute worst is m):\nTbfs = [bd+1 + bd + ... b + 1 - b] * cbfs\n= [bd+2 - b2 + b - 1] / [b - 1] * cbfs\n= O[bd+2]\n~ O(bd+1)\nfor large b\nBrian Williams, Fall 10\n\nPerformance and Resource Usage\nWhich is better, depth-first or breadth-first?\nS\nC\nA\nB\nG\nA\nD\nC\nD\nG\nD\nC\nG\nC\nG\nS\nB\nSearch\nMethod\nWorst\nTime\nWorst\nSpace\nShortest\nPath?\nGuaranteed to\nfind path?\nDepth-first\n~bm\nb*m\nNo\nYes for finite graph\nBreadth-first\n~bd+1\nWorst case time is proportional to number of nodes visited\nWorst case space is proportional to maximal length of Q\nBrian Williams, Fall 10\nWorst Case Space for Breadth-first\nWorst case space Sdfs is proportional to maximum length of Q\nLevel 1\nLevel d\nLevel 0\nLevel d+1\nBrian Williams, Fall 10\n\nWorst Case Space for Breadth-first\nWorst case space Sdfs is proportional to maximum length of Q\nLevel 1\nLevel d\nLevel 0\nLevel d+1\nb\nbd+1- b\n. . .\nbd\nSbfs = [bd+1- b + 1]*cbfs\n= O(bd+1)\nBrian Williams, Fall 10\nPerformance and Resource Usage\nWhich is better, depth-first or breadth-first?\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nC\nS\nB\nG\nA\nD\nSearch\nMethod\nWorst\nTime\nWorst\nSpace\nShortest\nPath?\nGuaranteed to\nfind path?\nDepth-first\n~bm\nb*m\nNo\nYes for finite graph\nBreadth-first\n~bd+1\nbd+1\nWorst case time is proportional to number of nodes visited\nWorst case space is proportional to maximal length of Q\nBrian Williams, Fall 10\n\nBreadth-first Finds Shortest Path\nNodes visited earlier\nLevel 0\nLevel 1\nreached\nLevel d\nLevel d+1\nG\nG\nFirst\ncan't include G\nAssuming each edge is length 1,\nother paths to G must be at least as long as first found\nBrian Williams, Fall 10\nPerformance and Resource Usage\nWhich is better, depth-first or breadth-first?\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nC\nS\nB\nG\nA\nD\nSearch\nMethod\nWorst\nTime\nWorst\nSpace\nShortest\nPath?\nGuaranteed to\nfind path?\nDepth-first\n~bm\nb*m\nNo\nYes for finite graph\nBreadth-first\n~bd+1\nbd+1\nYes unit lngth\nWorst case time is proportional to number of nodes visited\nWorst case space is proportional to maximal length of Q\nBrian Williams, Fall 10\n\nPerformance and Resource Usage\nWhich is better, depth-first or breadth-first?\nS\nC\nA\nB\nG\nA\nD\nC\nD\nG\nD\nC\nG\nC\nG\nS\nB\nSearch\nMethod\nWorst\nTime\nWorst\nSpace\nShortest\nPath?\nGuaranteed to\nfind path?\nDepth-first\n~bm\nb*m\nNo\nYes for finite graph\nBreadth-first\n~bd+1\nbd+1\nYes unit lngth\nYes\nWorst case time is proportional to number of nodes visited\nWorst case space is proportional to maximal length of Q\nBrian Williams, Fall 10\nThe Worst of The Worst\nWhich is better, depth-first or breadth-first?\nC\nG\nA\nD\nS\nB\n-Assume d = m in the worst case, and call both m.\n- Best-first can't expand to level m+1, just m.\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nSearch\nMethod\nWorst\nTime\nWorst\nSpace\nShortest\nPath?\nGuaranteed to\nfind path?\nDepth-first\n~bm\nb*m\nNo\nYes for finite graph\nBreadth-first\n~bm\nbm\nYes unit lngth\nYes\nWorst case time is proportional to number of nodes visited\nWorst case space is proportional to maximal length of Q\nBrian Williams, Fall 10\n\nFor best first search, which runs out first - time or memory?\nGrowth for Best First Search\nb = 10; 10,000 nodes/sec; 1000 bytes/node\nDepth\nNodes\nTime\nMemory\n1,100\n.11 seconds\n1 megabyte\n111,100\n11 seconds\n106 megabytes\n19 minutes\n10 gigabytes\n31 hours\n1 terabyte\n129 days\n101 terabytes\n35 years\n10 petabytes\n3,523 years\n1 exabyte\nBrian Williams, Fall 10\nHow Do We Get The\nBest of Both Worlds?\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nC\nS\nB\nG\nA\nD\nSearch\nMethod\nWorst\nTime\nWorst\nSpace\nShortest\nPath?\nGuaranteed to\nfind path?\nDepth-first\n~bm\nb*m\nNo\nYes for finite graph\nBreadth-first\n~bd+1\nbd+1\nYes unit lngth\nYes\nWorst case time is proportional to number of nodes visited\nWorst case space is proportional to maximal length of Q\nBrian Williams, Fall 10\n\nOutline\n- Analysis\n- Iterative deepening\nBrian Williams, Fall 10\nIterative Deepening (IDS)\nIdea:\n-Explore tree in breadth-first order, using depth-first search.\nSearch tree to depth 1, ....\ncalled depth-limited search\nLevel 0\nLevel 1\nLevel 2\nLevel 3\nC\nG\nS\nD\nB\nA\nC\nG\nC\nG\nD\nBrian Williams, Fall 10\n\nIterative Deepening (IDS)\nIdea:\n-Explore tree in breadth-first order, using depth-first search.\nSearch tree to depth 1, then 2, ....\ncalled depth-limited search\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nLevel 1\nLevel 2\nLevel 0\nLevel 3\nBrian Williams, Fall 10\nIterative Deepening (IDS)\nIdea:\n-Explore tree in breadth-first order, using depth-first search.\nSearch tree to depth 1, then 2, then 3....\ncalled depth-limited search\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nLevel 1\nLevel 2\nLevel 0\nLevel 3\nBrian Williams, Fall 10\n\nSpeed of Iterative Deepening\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nd*b\n1*bd\n. . .\nd+1\n2*bd-1\nLevel 1\nLevel d-1\nLevel 0\nLevel d\nCompare speed of BFS vs IDS:\n- Tbfs = 1 + b +\nb2 + . . . bd + (bd+1 - b) ~ O(bd+1)\n- Tids = (d + 1)1 + (d)b + (d - 1)b2 +. . . 2bd-1+ bd\n= [bd+2 + d(b-1) + 1)] / [b - 1]2\n~ O(bd) for lrg b\nIterative deepening performs better than breadth-first!\nBrian Williams, Fall 10\nSpeed of Iterative Deepening\nTids\n= (d + 1)1 + (d)b + (d - 1)b2 + . . . 2bd-1+ bd\nbTids\n=\n(d + 1)b + (d)b2 + (d - 1)b3 +. . . 2bd+ bd+1\n(b-1)Tids = (d + 1) + b +b2 + b3 +. . . bd+ bd+1\n(b-1)Tids = d + {[bd+2 + 1)] / [b - 1]}\n= [bd+2 + d(b-1) + 1)] / [b - 1]2\n~ O(bd) for lrg b\nIterative deepening performs better than breadth-first!\nBrian Williams, Fall 10\n\nSoundness and Completeness\n(next Monday)\nSoundness:\n- All returned solutions are correct.\n- Returns only simple paths from S to G.\nCompleteness:\n- Always returns a solution if one exists.\n- Returns a simple path from S to G whenever S is\nconnected to G.\nBrian Williams, Fall 10\nSummary\n- Most problem solving tasks may be encoded as state space\nsearch.\n- Basic data structures for search are graphs and search trees.\n- Depth-first and breadth-first search may be framed,\nas instances of a generic search strategy.\n- Cycle detection is required to achieve efficiency and\ncompleteness.\n- Complexity analysis shows that breadth-first is preferred in\nterms of optimality and time, while depth-first is preferred\nin terms of space.\n- Iterative deepening draws the best from depth-first and\nbreadth-first search.\nBrian Williams, Fall 10\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "MIT16_410F10_lec04.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/424d8d65875c903d9470a191d43ee277_MIT16_410F10_lec04.pdf",
      "content": "7/2/11\nSoundness and Completeness of\nState Space Search\nSertac Karaman\n16.410‐13\nSept 20th, 2010\nAssignments\n- Remember:\nProblem Set #2: Uninformed search\nOut last Wednesday,\nDue this Wednesday, September 22nd\n\n- Reading:\n- Today: Proofs and InducNon: Lecture 2 and 3 Notes of 6.042.\n- Wednesday: [AIMA] Ch. 6.1; 24.3‐5 Constraint SaNsfacNon.\n- To learn more: Constraint Processing, by Rina Dechter\n- Chapter 2: Constraint Networks\n- Chapter 3: Consistency Enforcing and PropagaNon\n\n9/20/1\nAutonomous Systems: \n-  Plan complex sequences of acVons \n-  Schedule Vght resources \n-  Monitor and diagnose behavior \n-  Repair or reconfigure hardware. \nformulate as state space search. \nBrian Williams, Fall  10 \nFormalizing Graph Search \nBrian Williams, Fall  10 \nC\nS\nB\nG\nA\nD\nInput: A search problem SP =  <g, S, G> where \n-  graph g = <V, E>,  \n-  start vertex S in V, and \n-  goal vertex G in V.  \nOutput: A simple path P = <S, v2, ... G> in g from S to G. \n         (i.e., <vi,v\n> ∈ E, and v\nif i = j ). \ni+1\ni = vj \n\n9/20/10 \nBrian Williams, Fall  10 \nS\nB\nG\nA\n<S> \n<B, S> \n<A, S> \n<G, B, S> \n< A, B, S> \nGraph Search is a Kind  \nof State Space Search \nS \nB \nA \nG \nB \nGraph Search is a Kind  \nOf Tree Search \nBrian Williams, Fall  10 \nSoluVon: Depth First Search (DFS) \nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nSoluVon: Breadth First Search (BFS) \n\n9/20/10 \nBrian Williams, Fall  10 \nSoluVon: Depth First Search (DFS) \nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nSoluVon: Breadth First Search (BFS) \nDepth-first:\nAdd path extensions to front of Q\nPick first element of Q\nBreadth-first:\nAdd path extensions to back of Q\n   Pick first element of Q\nBrian Williams, Fall  10 \nThe Worst of The Worst \nSearch\nMethod\nWorst\nTime\nWorst\nSpace\nShortest\nPath?\nGuaranteed to\nfind path?\nDepth-first\n~bm\nb*m\nNo\nYes for finite graph\nBreadth-first\n~bm\nbm\nYes unit lngth\nYes\nWorst case time is proportional to number of nodes visited\nWorst case space is proportional to maximal length of Q\nS\nD\nB\nA\nC\nG\nC\nG\nD\nC\nG\nWhich is beler, depth‐first or breadth‐first? \nC\nS\nB\nG\nA\nD\n-  Assume d = m in the worst case, and call both m. \n-  Best‐first can't expand to level m+1, just m. \n\n9/20/10 \nElements of Algorithm Design \nDescripVon: (last Monday) \n- Problem statement. \n- Stylized pseudo code, sufficient to analyze and implement the \nalgorithm. \n- ImplementaVon (last Wednesday). \nAnalysis: (last Wednesday) \n- Performance: \n- Time complexity:  \n- how long does it take to find a soluVon? \n- Space complexity:  \n- how much memory does it need to perform search? \n- Correctness: (today) \n- Soundness:  \n- when a soluVon is returned, is it guaranteed to be correct? \n- Completeness:  \n- is the algorithm guaranteed to find a soluVon when there is one? \nBrian Williams, Fall  10 \nOutline \n- Review \n- Proof techniques and the axiomaVc method \n- Proofs of soundness and completeness of \nsearch algorithms \n- Limits of axiomaVc method \nBrian Williams, Fall  10 \n\n9/20/10 \nEnvelope game \nProbabili(es do not work!\n- I put an amount $N and $2N into two different envelopes  \n(you do not know N). \n- I open one of them, it has $X.  \n- Would you pick the open one or the other? \n- Reasoning 1: (I pick one at random)\n- seeing inside an envelope does not maler...  \n- Reasoning 2: (I pick the second one)\n- If I get this envelope, I get $X. \n- If I get the other envelope, I get, on average: \n(1/2) X/2 + (1/2) 2X = (5/4) X  \nUnexpected hanging paradox \nInduc(on does not work!\n- A judge tells a criminal that  \n\"the criminal will be hanged on a weekday at noon next\nweek, he will not know when he will be hanged, it will be a\ntotal surprise\".\n- Criminal's reasoning: \n- He can not be hanged on a Friday (by Thursday awernoon, he \nwill know - it won't be a surprise). \n- Then, he can not be hanged on Thursday either. \n- Then, he can not be hanged at all... So he feels safe. \n(He was hanged on Wed. at noon - it was a total surprise...) \n- What went wrong with criminal's deducVon? \n\n9/20/10 \nThe axiomaVc method \n- Invented by Euclid around 300BC (in \nAlexandria, Egypt).  \n- 5 axioms of geometry menVoned in his \nwork Elements.  \n- StarVng from these axioms,  \nEuclid established many \"proposi2ons\"  \nby providing \"proofs\".\nEuclid of Alexandria \nOldest surviving copy \nof the Elements  on a \npapyrus found in \nOxyrhynchus, Egypt.\nEuclid statute in Oxford \nThe axiomaVc method \n- A definiVon of a \"proof\": \n- Any sequence of logical deduc(ons from \naxioms and previously proven proposi(ons/\nstatements that concludes with the \nproposiVon in quesVon. \n- There are many types of \"proposi2ons\": \n- Theorem: Important results, main results \n- Lemma: a preliminary proposiVon for proving \nlater results \n- Corollary: An easy  (but important) conclusion, \nan awerthought of a theorem. \nEuclid of Alexandria \nEuclid statute in Oxford \nImages are in the public domain.\n\n9/20/10 \nThe axiomaVc method \n- Euclid's axiom‐proof approach is now \nfundamental to mathemaVcs! \n- Amazingly, essenVally all mathemaVcs can \nbe derived from just a handful of axioms... \n- How to even start a proof? \n- There are many \"templates\"  \n(outlines, or techniques) \n- The details differ... \nEuclid of Alexandria \nEuclid statute in Oxford \nProving an implica2on\n- Several mathemaVcal claims are of the form: \n- \"If P, then Q\", or equivalently \"P implies Q\". \n- QuadraJcs:  \n- If                                    and            , \nb\n√\nax + bx + c = 0\na = 0 then   x = -±\n- InequaliJes: \n- If                      , then  \n- Goldbach's Conjecture:  \n-  If n > 2, then n is a sum of two primes. \nb2 -4ac\n2a\n0 ≤x ≤2\n-x3 + 4x + 1 > 0\n\n9/20/10 \nProving implicaVons: \nSimplest proof technique \n- To prove \"P implies Q\", \n- \"Assume P\" and show that Q logically follows. \n- Theorem: \n- If                      , then    \n0 ≤x ≤2\n-x3 + 4x + 1 > 0\n- Proof: \n- Assume                        (P)  \n0 ≤x ≤2\n- Then,    ,           , and              ar\nx 2 -x\nx + 2\ne all non‐negaVve \n- Then,                                 is non‐neg\nx(2 -x)(2 + x)\naVve \n- Then,                                        is non‐neg\nx(2 -x)(2 + x) + 1\naVve \n- Then, mulVplying out the lew side gives \n-                                                                          (Q\n-x3 + 4x + 1 > 0\n) \nProof by ContradicVon \n- To prove that a statement P is True.  \n- Assume that it is not. \n- Show that some absurd (clearly false) statement follows. \n- Formalized: In order to prove a statement P is True\n- Assume that P is False, \n- Deduce a logical contradicVon (negaVon of a previous \nstatement or an axiom). \n\n9/20/10 \nProof by ContradicVon \n- Theorem:         is an irr\n√\naVonal number. \n- Proof:  \n- Assume that        is not irraVonal. \n- Then,       is a raVonal number and can be wrilen as        = a/b \nwhere a  and b  are integers and frac(on is in lowest terms\n- Then, squaring both sides and rearranging gives 2 = a2/b2 \n- Then, a  must be even \n- Then, a2 must be a mulVple of 4 \n- Then, 2b2 must also be a mulVple of 4 \n- Then, b is also even \n- Then, the fracVon is not in the lowest terms  \n(since a  and b are both even)  \n√\n√\n√\nProof by InducVon \nPick parameter N to define problem size. \n- Number of edges in the soluVon. \n- Number of nodes in graph. \nBase Step: N = 0 (or small N) \n- Prove property for N = 0 \nInducJon Step: \n- Assume property holds for N \n- Prove property for N+1 \n- Conclusion: property holds for all problem sizes N. \n\n9/20/10 \nProof by InducVon formalized\n- Let P(i) be a statement with parameter i.\n- Proof by inducVon states the following implicaVon: \n- \"P(0) is True\" (1)     and     \"P(i) implies P(i+1)\" (2) \n- (1) and (2) implies \"P(i) is True for all i\". \n- InducVon is one of the core principles of mathemaVcs. \n- It is generally taken as an axiom, or the axioms are \ndesigned so that inducVon principle can be proven. \nAn inducVon example \n- Theorem:                                             f\nn(n + 1)\n1 + 2 + · · · + n =\nor all n.  \n- Proof: \n- Base case: P(0) is True. \n- Because, 0 = 0. \n- InducVon step: P(n) implies P(n+1) \n- Assume that the hypothesis holds for n.\n- For n + 1: \nn(n + 1)\n1 + 2 + · · · + n + (n + 1)\n=\n+ n + 1\n(n + 1)(n + 2)\n=\n\n9/20/10 \nA faulty inducVon \n- Theorem[!]: All horses are the same color. \n- Proof[!]: \n- Base case: P(1) is True.  \n- because, there is only one horse. \n- Induc(on step: P(i) implies P(i+1). \n- Assume that P(i) is True. \n- By the induc(on hypothesis first i horses are the same color, and the \nlast i horses are also the same color. \nh1, h2, . . . , hi,hi+1\nh1, h2, . . . , hi, hi+1\n- So all the i+1 horses must be the same color.  \n- Hence, P(i+1) is also True. \n- What went wrong  here? \nProof by Invariance \nA common technique in algorithm analysis\n- Show that a certain property holds throughout  \nin an algorithm. \n- Assume that the property holds iniVally. \n- Show that in any step that the algorithm takes, \nthe property sVll holds.  \n- Then, property holds forever. \n- It is a simple applicaVon of inducVon. Why?  \n\n9/20/10 \nProving statements about algorithms \nHandle with care!\n- Correctness of simplest algorithms may be  \nvery hard to prove... \n- Collatz conjecture: \n- Algorithm (Half Or Triple Plus One ‐ HOTPO):  \n- Given an integer n.\n1. If n is even, then n = n/2 \n2. If n is odd, then n = 3n + 1 \n3. If n = 1, then terminate, else go to step 1. \n- Conjecture:  For any n, the algorithm always \nterminates (with n = 1). \nProving statements about algorithms \nHandle with care!\nCollatz conjecture: \n- First proposed in 1937. \n- It is not known whether the \nconjecture is true or false. \nFirst 1000  \nnumbers \n   Paul Erdos (1913‐1996)\n‐ famous number theorist - \n\"Mathema(cs is not yet ready\nfor such problems\", 1985.\nFirst 100  \nnumbers \nImages are in the public domain. Images by Keenan Pepper and Jon McLoone\n.\n\n9/20/10 \nSoundness and Completeness of \nSearch Algorithms \n- Today:  \n- prove statements about the search algorithms we \nhave studied in the class. \n- study whether the algorithm returns a correct \nsoluVon.  \n- study whether the algorithm returns a soluVon at \nall when one exists. \nSoundness and Completeness \nGiven a problem PR, an algorithm that aYempts to solve this \nproblem may have the following properJes: \nSoundness:\n  \n- The soluVon returned by the algorithm is correct. \nCompleteness: \n- The algorithm always returns a soluVon, if one exists. \n- If there is no soluVon, the algorithm reports failure. \nAlso, OpJmality: \n- The algorithm returns the opVmal soluVon, if it returns one. \n\n9/20/10 \nSome Other NoVons of  \nSoundness and Completeness \nProbabilisJc Completeness: \n- The algorithm returns a soluVon, if one exists, with probability \napproaching to one as the number of iteraVons increases. \n- If there is no soluVon, it may run for forever. \nProbabilisJc Soundness: \n- The probability that the \"soluVon\" reported solves the \nproblem approaches one, as the number of iteraVons \nincreases. \nAsymptoJc OpJmality: \n- The algorithm does not necessarily return an op(mal soluVon, \nbut the cost of the soluVon reported approaches the opVmal \nas the number of iteraVons increases. \nBrian Williams, Fall  10 \nProblem: State Space Search \nC\nS\nB\nG\nA\nD\nInput: A search problem S =  <g, S, G> where \n-  graph g = <V, E>,  \n-  start vertex S in V, and \n-  goal vertex G in V.  \nOutput: A simple path P = <S, v2, ... G> in g from S to G. \n\n9/20/10 \nPseudo Code For Simple Search \nLet g be a Graph\n\nG be the Goal vertex of g.\nS be the start vertex of g\n\nQ be a list of simple partial paths in GR,\n1. Initialize Q with partial path (S) as only entry; set Visited = ( );\n2. If Q is empty, fail. Else, pick some partial path N from Q;\n3. If head(N) = G, return N;\n\n(goal reached!)\n4. Else\na) Remove N from Q;\nb) Find all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc) Add to Q all the extended paths;\nd) Add children of head(N) to Visited;\ne) Go to step 2.\nSoundness and Completeness \nTheorems \nWe would like to prove the following two theorems: \nTheorem 1 (Soundness):  \nSimple search algorithm is sound. \nTheorem 2 (Completeness):  \nSimple search algorithm is complete.  \nWe will use a blend of proof techniques for proving them. \n\n9/20/10 \nSoundness and Completeness \nTheorems \nTheorem 1 (Soundness):  \nSimple search algorithm is sound. \nLet us prove 3 lemmas before proving this theorem. \nA lemma towards the proof \n- Lemma 1: If <v1, v2, ..., vk> is a path in the \nqueue at any given Vme, then vk = S. \n- Proof: (by invariance) \n- Base case: IniVally, there is only <S> in the queue. \nHence, the invariant holds. \n- Induc(on step: Let's check that the invariant\nconVnues to hold in every step of the algorithm. \n\n9/20/10 \nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Jme, then vk = S. \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Jme, then vk = S. \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\nBefore this line: assume that invariant holds. \nAIer this line: show that invariant is sJll true. \n \n In this case no new path is added to the queue. \n\n9/20/10 \nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Jme, then vk = S. \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\nBefore this line: assume that invariant holds. \nAIer this line: show that invariant is sJll true. \n \n In this case no new path is added to the queue. \nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Jme, then vk = S. \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\nBefore this line: assume that invariant holds. \nAIer this line: show that invariant is sJll true. \n \n In this case no new path is added to the queue (a path is removed)  38 \n\n9/20/10 \nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Jme, then vk = S. \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\nBefore this line: assume that invariant holds. \nAIer this line: show that invariant is sJll true. \n \n Several paths added, each saJsfy the invariant since N saJsfies it. \nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Jme, then vk = S. \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\nBefore this line: assume that invariant holds. \nAIer this line: show that invariant is sJll true. \n \n In this case no new path is added to the queue. \n\n9/20/10 \nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Jme, then vk = S. \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\nBefore this line: assume that invariant holds. \nAIer this line: show that invariant is sJll true. \n \n In this case no new path is added to the queue. \nAnother lemma towards the proof \n- DefiniJon: A path <v0, v1, ..., vk> is valid if  \n                                  f\n(vi-1, vi) ∈E\nor all    i ∈{1, 2, . . . , k}\n- Lemma 2: If <v1, v2, ..., vk> is a path in the queue \nat any given Vme, then it is valid. \n- Proof: (by invariance) \n- Base case: IniVally there is only one path <S>, which is \nvalid. Hence, the invariant holds. \n- Induc(on step: Let's check that the invariant conVnues\nto hold in every step of the algorithm. \n\n9/20/10 \nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Vme, then it is valid \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Vme, then it is valid \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\nBefore this line: assume that invariant holds. \nAIer this line: show that invariant is sJll true. \n \n In this case no new path is added to the queue. \n\n9/20/10 \nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Vme, then it is valid \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\nBefore this line: assume that invariant holds. \nAIer this line: show that invariant is sJll true. \n \n In this case no new path is added to the queue. \nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Vme, then it is valid \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\nBefore this line: assume that invariant holds. \nAIer this line: show that invariant is sJll true. \n \n In this case no new path is added to the queue. \n\n9/20/10 \nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Vme, then it is valid \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\nBefore this line: assume that invariant holds. \nAIer this line: show that invariant is sJll true. \n \n In this case no new path is added to the queue. \nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Vme, then it is valid \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\nBefore this line: assume that invariant holds. \nAIer this line: show that invariant is sJll true. \n \n Note that validity holds for all newly added path (from Line 4.b) \n\n9/20/10 \nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Vme, then it is valid \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\nBefore this line: assume that invariant holds. \nAIer this line: show that invariant is sJll true. \n \n In this case no new path is added to the queue. \nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Vme, then it is valid \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\nBefore this line: assume that invariant holds. \nAIer this line: show that invariant is sJll true. \n \n In this case no new path is added to the queue. \n\n9/20/10 \nYet another lemma towards the proof \n- Lemma 3: If <v1, v2, ..., vk> is a path in the \nqueue at any given Vme, then it is a simple \npath (contains no cycles). \n- Proof: (by invariance) \n- Base case: IniVally, there is only <S> in the queue. \nHence, the invariant holds. \n- Induc(on step: Let's check that the invariant\nconVnues to hold in every step of the algorithm. \nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Vme, then it is a simple path. \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\n\n9/20/10 \nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Vme, then it is a simple path. \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\nBefore this line: assume that invariant holds. \nAIer this line: show that invariant is sJll true. \n \n In this case no new path is added to the queue. \nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Vme, then it is a simple path. \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\nBefore this line: assume that invariant holds. \nAIer this line: show that invariant is sJll true. \n \n In this case no new path is added to the queue. \n\n9/20/10 \nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Vme, then it is a simple path. \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\nBefore this line: assume that invariant holds. \nAIer this line: show that invariant is sJll true. \n \n In this case no new path is added to the queue. \nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Vme, then it is a simple path. \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\nBefore this line: assume that invariant holds. \nAIer this line: show that invariant is sJll true. \n \n In this case no new path is added to the queue. \n\n9/20/10 \nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Vme, then it is a simple path. \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\nWe would like to show that each newly added path is simple assuming N is simple. \nProof: (by contradic2on) Assume one path is not simple. Then, a children of\nhead(N) appears in N. But, this is contradicts Line 4.b  \nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Vme, then it is a simple path. \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\nBefore this line: assume that invariant holds. \nAIer this line: show that invariant is sJll true. \n \n In this case no new path is added to the queue. \n\n9/20/10 \nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Vme, then it is a simple path. \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\nBefore this line: assume that invariant holds. \nAIer this line: show that invariant is sJll true. \n \n In this case no new path is added to the queue. \nSoundness and Completeness \nTheorems \nTheorem 1 (Soundness):  \nSimple search algorithm is sound. \nProof: by contradicVon... \n\n9/20/10 \nProof of Soundness \nAssume that the search algorithm is not sound: \nLet the returned path be  \n< v0, v1, . . . , vk >\nThen, one of the following must be True: \n- 1. Returned path does not start with S: \nvk = S\n- 2. Returned path does not contain G at head: \nv0 = G\n- 3. Some transiVon in the returned path is not valid: \n                                    \n(vi-1, vi) ∈/ E\nfor some  i ∈{1, 2, . . . , vk}\n- 4. Returned path is not simple: \n                         f\nvi = vj\nor some                                       with \ni, j ∈{0, 1, . . . , k}\ni = j\nProof of Soundness \n- 1. Returned path does not start with S:  vk = S\n- But, this contradicts Lemma 1! \n- Lemma 1: If <v1, v2, ..., vk> is a path in the \nqueue at any given Vme, then vk = S. \n\n9/20/10 \nProof of Soundness \n- 2. Returned path does not contain G at head: \nv0 = G\n- But clearly, the returned path has the property that  \nHead(N)= G  \n- Recall the pseudo code: \nPseudo Code For Simple Search \nInvariant: If <v1, v2, ..., vk> is a path in the queue at any given Vme, then it is a simple path. \n1.\nInitialize Q with partial path (S) as only entry; set Visited = ( );\n2.\nIf Q is empty, fail. Else, pick some partial path N from Q;\n3.\nIf head(N) = G, return N;\n\n(goal reached!)\n4.\nElse\na)\nRemove N from Q;\nb)\nFind all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc)\nAdd to Q all the extended paths;\nd)\nAdd children of head(N) to Visited;\ne)\nGo to step 2.\n\n9/20/10 \nProof of Soundness \n- 3. Some transiVon in the returned path is not valid: \n                                    f\n(vi-1, vi) ∈/ E\nor some  i ∈{1, 2, . . . , vk}\n- Contradicts Lemma 2! \n- Lemma 2: If <v1, v2, ..., vk> is a path in the \nqueue at any given Vme, then it is valid. \nProof of Soundness \n- 4. Returned path is not simple: \n                         f\nvi = vj\nor some                                  with \ni, j ∈{0, 1, . . . , k}\ni = j\n- Contradicts Lemma 3! \n- Lemma 3: If <v1, v2, ..., vk> is a path in the \nqueue at any given Vme, then it is a simple \npath (contains no cycles). \n\n9/20/10 \nProof of Soundness \nAssume that the search algorithm is not sound: \nLet the returned path be  \n< v0, v1, . . . , vk >\nThen, one of the following must be True: \n- 1. Returned path does not start with S: \nvk = S\n- 2. Returned path does not contain G at head: \nv0 = G\n- 3. Some transiVon in the returned path is not valid: \n                                    \n(vi-1, vi) ∈/ E\nfor some  i ∈{1, 2, . . . , vk}\n- 4. Returned path is not simple: \n                         f\nvi = vj\nor some                                       with \ni, j ∈{0, 1, . . . , k}\ni = j\nProof of Soundness \nAssume that the search algorithm is not sound: \nWe reach a contradicVon in all cases. \nHence, the simple search algorithm is sound. \n\n9/20/10 \nProof of Completeness \nTheorem 2 (Completeness):  \nSimple search algorithm is complete.  \nNeed to prove: \n- If there is a path to reach from S to G, then the \nalgorithm returns one path that does so. \nPseudo Code For Simple Search \nLet g be a Graph\n\nG be the Goal vertex of g.\nS be the start vertex of g\n\nQ be a list of simple partial paths in GR,\n1. Initialize Q with partial path (S) as only entry; set Visited = ( );\n2. If Q is empty, fail. Else, pick some partial path N from Q;\n3. If head(N) = G, return N;\n\n(goal reached!)\n4. Else\na) Remove N from Q;\nb) Find all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc) Add to Q all the extended paths;\nd) Add children of head(N) to Visited;\ne) Go to step 2.\n\n9/20/10 \nA common technique in  \nanalysis of algorithms  \n- Let's slightly modify the algorithm \n- We will analyze the modified algorithm. \n- Then, \"project\" our results to the original \nalgorithm. \nPseudo Code For Simple Search \nLet g be a Graph\n\nG be the Goal vertex of g.\nS be the start vertex of g\n\nQ be a list of simple partial paths in GR,\n1. Initialize Q with partial path (S) as only entry; set Visited = ( );\n2. If Q is empty, fail. Else, pick some partial path N from Q;\n3. // If head(N) = G, return N;\n\n(goal reached!)\n4. Else\na) Remove N from Q;\nb) Find all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc) Add to Q all the extended paths;\nd) Add children of head(N) to Visited;\ne) Go to step 2.\n\n9/20/10 \nProof of Completeness \n- The modified algorithm terminates when the \nqueue is empty. \n- Let us prove a few lemmas regarding the \nbehavior of the modified algorithm \nProof of Completeness \n- Lemma 1: A path that is taken out of the queue is not \nplaced into the queue again at a later step. \n- Proof: (using logical deduc(on)\n- Another way to state this: \"If p =<v0, v1, ..., vk> is a path \nthat is taken out of the queue, then p = <v0, v1, ..., vk> is \nnot placed in to the queue at a later step.\" \n- Assume that p = <v0, v1, ..., vk> is taken out of the \nqueue. \n- Then, p must be placed in to the queue at an earlier \nstep. \n- Then, v0 must be in the visited list at this step. \n- Then, p = <v0, v1, ..., vk> can not placed in to the queue \nat a later step, since v0 is in the visited list. \n\n9/20/10 \nProof of Completeness \n- DefiniJon: A vertex v is reachable from S, if there exists a \npath <v0, v1, ..., vk> that starts from S and ends at v, i.e., vk = \nS and v0 = v. \n- Lemma 2: If a vertex v is reachable from S, then v is placed \nin to the visited list awer a finite number of steps. \nProof of Completeness \n-\nLemma 2: If a vertex v is reachable from S, then v is placed in to the visited list \nawer a finite number of steps. \n-\nProof: (by contradic(on)\n-\nAssume v is reachable from S, but it is never placed on the visited list. \n-\nSince v is reachable from S, there exists a path that is of the form <v0, v1, ..., \nvk>, where v0 = v and vk = S. \n-\nLet vi be the first node (starVng from vk) in the chain that is never added to \nthe visited list. \n-\n(1) Note that vi was not in the visited list before this step. \n-\n(2) Note also that (vi+1, vi) is in E. \n-\nSince vi+1 was in the visited list, the queue included a path <vi+1, ..., vk> (not \nnecessarily the same as above), where vk = S. \n-\nThis path must have been popped from the queue, since there are only \nfinitely many different parVal paths and no path is added twice (by Lemma \n1)and vi was not in the visited list (see statement 1 above). \n-\nSince it is popped from the queue, then <vi+1, vi, ..., vk> must be placed in to \nqueue (see statement 2 above) and vi placed in to the visited list \n-\nRed statements contradict! \n\n9/20/10 \nProof of Completeness \n- Lemma 2: If a vertex v is reachable from S, \nthen v is placed in to the visited list awer a \nfinite number of steps. \n- Corollary: In the modified algorithm, G is \nplaced into the visited queue. \n- \"Project\" back to the original algorithm:\n- This is exactly when the original algorithm \nterminates \nProof of Completeness \nTheorem 2 (Completeness):  \nSimple search algorithm is complete.  \n- Proof: Follows from Lemma 2 evaluated in the \noriginal algorithm. \n\n9/20/10 \nPseudo Code For Simple Search \nLet g be a Graph\n\nG be the Goal vertex of g.\nS be the start vertex of g\n\nQ be a list of simple partial paths in GR,\n1. Initialize Q with partial path (S) as only entry; set Visited = ( );\n2. If Q is empty, fail. Else, pick some partial path N from Q;\n3. If head(N) = G, return N;\n\n(goal reached!)\n4. Else\na) Remove N from Q;\nb) Find all children of head(N) (its neighbors in g) not in Visited\nand create a one-step extension of N to each child;\nc) Add to Q all the extended paths;\nd) Add children of head(N) to Visited;\ne) Go to step 2.\nSummarize Completeness and \nSoundness \n- Hence, we have proven two theorems: \nTheorem 1 (Soundness):  \nSimple search algorithm is sound. \nTheorem 2 (Completeness):  \nSimple search algorithm is complete.  \n- Soundness and completeness is a requirement for most algorithms,  \nalthough we will their relaxaVons quite owen \n\n9/20/10 \nBack to the AxiomaVc Method \nDoes it really work?  \n- EssenVally all of what we know in mathemaVcs today can \nbe derived from a handful of axioms called the  \nZarmelo‐Frankel set theory with the axiom of Choice (ZFC). \n- These axioms were made up by Zarmelo  \n(they did not exist a priori, unlike physical phenomena). \n- We do not know whether these axioms are logically\nconsistent! \n- Sounds crazy! But, happened before...  \nAround 1900, B. Russell discovered that the axioms of that (me\nwere logically inconsistent, i.e., one could prove a contradic(on.\nBack to the AxiomaVc Method \nDoes it really work?  \n- ZFC axioms gives one what she/he wants:  \n- Theorem: 5 + 5 = 10. \n- However, absurd statements can also be driven: \n- Theorem (Banach‐Tarski): A ball can be cut into a finite \nnumber of pieces and then the pieces can be rearranged \nto build two balls of the same size of the original. \nClearly, this contradicts our geometric intui(on!\nImage by Benjamin D. Esham, in the public domain.\n\n9/20/10 \nBack to the AxiomaVc Method \nDoes it really work?  \n \nBack to the AxiomaVc Method \nDoes it really work?  \nOn the fundamental limits of mathema2cs\n-\nGodel showed in 1930 that there are some proposiVons that \nare true, but do not logically follow from the axioms. \n-\nThe axioms are not enough! \n-\nBut, Godel also showed that simply adding more axioms \ndoes not eliminate this problem. Any set of axioms that is \n \nnot contradictory will have the same problem! \n-\nGodel's results are directly related to computaVon. These \nresults were later used by Alan Turing in 1950s to invent a \nrevoluVonary idea: computer...\n \n \nImages of Godel, Turing, and Einstein removed due to copyright restrictions.\n\n9/20/10 \nWhat you should know \n- The definiVons of a proposiVon, proof, \ntheorem, lemma, and corollary. \n- Proof techniques such as proof by \ncontradicVon, inducVon, invariance proofs. \n- NoVons of soundness and completeness. \n- Proving soundness and completeness of\nsearch algorithms. \n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "MIT16_410F10_lec05.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/43a72dc4afb4a2813f28944d6d4d9056_MIT16_410F10_lec05.pdf",
      "content": "Constraint Programming:\nModeling, Arc Consistency\nand Propagation\nBrian C. Williams\n16.410-13\nSeptember 22nd, 2010\nSlides draw material from:\n6.034 notes, by Tomas Lozano Perez\nAIMA, by Stuart Russell & Peter Norvig\nConstraint Processing, by Rina Dechter\nBrian Williams, Fall 10\nBrian Williams, Fall 10\nAssignments\n- Assignment:\n- Problem Set #2 due today, Wed. Sept. 22nd, 2010.\n- Problem Set #3: Analysis, Path Planning and Constraint\nProgramming, out today, due Wed., Sept. 29th, 2010.\n- Reading:\n- Today: [AIMA] Ch. 6.1, 24.3-5; Constraint Modeling.\n- Monday: [AIMA] Ch. 6.2-5; Constraint Satisfaction.\n- To Learn More: Constraint Processing, by Rina Dechter\n- Ch. 2: Constraint Networks\n- Ch. 3: Consistency Enforcing and Propagation\n\nOutline\n- Interpreting line diagrams\n- Constraint satisfaction problems (CSP)\n[aka constraint programs (CP)].\n- Solving CSPs\n- Case study: Scheduling (Appendix)\nBrian Williams, Fall 10\nOutline\n- Interpreting line diagrams\n- Constraint modeling\n- Constraint propagation\n- Constraint satisfaction problems (CSP)\naka constraint programs (CP)\n- Solving CSPs\n- Case study: Scheduling (Appendix)\nBrian Williams, Fall 10\n\nLabeling Line Diagrams for\nVisual Interpretation\nInput:\nLine drawing (a graph)\nPhysical constraints\nOutput:\nConsistent assignment of line (edge) types\ndepth\ndiscontinuity\nsurface\norientation\ndiscontinuity\nreflectance\ndiscontinuity\nHuffman Clowes (1971): Interpret opaque, trihedral solids\nStep 1: Label line types.\n+\n+\n+ +\nConvex\nEdge\n+\nConcave\nEdge\nBrian Williams, Fall 10\nRequirement:\nLabeling must extend to complex objects\nBrian Williams, Fall 10\n\nLine Labeling as Constraint Programming\ndepth\ndiscontinuity\nsurface\norientation\ndiscontinuity\nHuffman Clowes (1971):\nInterpretation of opaque, trihedral solids with no surface marks.\n18 vertex labelings that are\nphysically realizable\n+\n+\n+\n+\nConvex\nEdge\n+\nConcave\nEdge\n+\n+\n+ +\nWaltz (1972): Compute labeling through local propagation.\nConstraints\nOutline\n- Interpreting line diagrams\n- Constraint modeling\n- Constraint propagation\n- Constraint satisfaction problems (CSP)\naka constraint programs (CP).\n- Solving CSPs\n- Case study: Scheduling (Appendix)\nBrian Williams, Fall 10\n\nModeling: Make Simplifying Assumptions\n1. Limited line interpretations:\nNo shadows or cracks.\n2. Three-faced vertices:\nIntersection of exactly three object faces\n(e.g., no pyramid tops).\n3. General position:\nSmall perturbations of selected viewing points can not\nlead to a change in junction type.\nBrian Williams, Fall 10\nModeling: Systematically derive\nall realizable junction types\nConsider:\n- a three face vertex, which divides space into octants,\n- (not guaranteed to be at right angles), and\n- all possible fillings of octants,\nviewed from all empty octants.\nBrian Williams, Fall 10\n\nModeling: Systematically derive\nall realizable junction types\n- Case 1: View seven filled octants from the only empty octant.\n_\n_\n_\nBrian Williams, Fall 10\nModeling: Systematically derive\nall realizable junction types\n- Case 2a: View one filled octant from all empty upper octants....\nL\nR\n+\n+\n+\nL\nR\nL\n+\nR\n+\nBrian Williams, Fall 10\n\nModeling: Systematically derive\nall realizable junction types\n- Case 2b: View one filled octant from all empty lower octants.\nL\nR\nL\nR\n+\nR\nL\nBrian Williams, Fall 10\nAll Junctions\nL Junctions\nFork Junctions\nArrow Junctions\nT Junctions\n+\n+\n+\n+\n+\n-\n-\n-\n-\n+\n+\n+\n-\n-\n-\n+\n-\n-\n+\nBrian Williams, Fall 10\n\nOutline\n- Interpreting line diagrams\n- Constraint modeling\n- Constraint propagation\n- Constraint satisfaction problems (CSP)\naka constraint programs (CP).\n- Solving CSPs\n- Case study: Scheduling (Appendix)\nBrian Williams, Fall 10\nC\nB\nA\nD\nC\nB\nA\nD\n+\n+\n+\n+\n+\n-\n-\n+\n+\n+\n+\n+\n-\n-\n-\n+\n+ +\n-\n-\n-\nSolution: Label Lines by\nPropagating Constraints\n+\n+\n+\n+\n-\nBrian Williams, Fall 10\n\nPropagate starting with the\nbackground borders\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n-\n+\n+\n-\n-\n-\n-\n-\n-\n-\n-\n-\n+\n+\n+\nBrian Williams, Fall 10\nWithout background borders,\ninterpretations become unstable.\nBrian Williams, Fall 10\n\nOutline\n- Interpreting line diagrams\n- Constraint satisfaction problems (CSP)\naka constraint programs (CP).\n- Solving CSPs\n- Case study: Scheduling (appendix)\nBrian Williams, Fall 10\nConstraint Satisfaction Problems\nVariables\nConstraints\nTwo positions on a line (vertical,\nhorizontal, diagonal) cannot both be Q\nDomains\nQueen 1-4 or blank\nChessboard positions\nQ\n4 Queens Problem:\nPlace 4 queens on a 4x4\nchessboard so that no\nqueen can attack another.\nHow do we formulate?\nQ\nQ\nQ\nBrian Williams, Fall 10\n\nC\nB\nA\nD\nC\nB\nA\nD\n+\n+\n+\n+\n+\n-\n-\n+\n+\n+\n+\n+\n-\n-\n-\n+\n+ +\n-\n-\n-\nVariables:\n?\nDomains:\n?\nConstraints:\n?\nBrian Williams, Fall 10\nConstraint Satisfaction Problems (CSP)\nInput: A Constraint Satisfaction Problem is a triple <V,D,C>, where:\n- V is a set of variables Vi\n- D is a set of variable domains,\n- The domain of variable Vi is denoted Di\n- C = is a set of constraints on assignments to V\n- Each constraint Ci = <Si,Ri> specifies allowed variable assignments.\n- Si the constraint's scope, is a subset of variables V.\n- Ri the constraint's relation, is a set of assignments to Si.\nOutput: A full assignment to V, from elements of V's domain,\nsuch that all constraints in C are satisfied.\nExample: \"Provide one A and two B's.\"\n- V = {A,B}, each with domain Di = {1,2}\n- C = {<{A,B}, {<1,2>, <1,1>}>\n\"one A\"\n<{A,B}, {<1,2>, <2,2>}>}\n\"two Bs\"\n- Output: <1,2>\nBrian Williams, Fall 10\n(for example)\n\nConventions\n- List scope in subscript.\n- Specify one constraint per scope.\nExample: \"Provide one A and two B's.\"\n- C = {CAB}\nCAB = {<1,2>}\n- C = {CA,CB}\nCA = {<1>}\nCB = {<2>}\nBrian Williams, Fall 10\nGood Encodings Are Essential: 4 Queens\nVariables\nConstraints\nTwo positions on a line (vertical,\nhorizontal, diagonal) cannot both be Q\nDomains\nQueen 1-4 or blank\nChessboard positions\nQ\n4 Queens Problem:\nPlace 4 queens on a 4x4\nchessboard so that no\nqueen can attack another.\nHow big is the encoding?\nQ\nQ\nQ\nBrian Williams, Fall 10\n\nGood Encodings Are Essential: 4 Queens\nPlace queens so that no\nqueen can attack another.\nWhat is a better encoding?\nQ\nQ\nQ\nQ\n-Assume one queen per column.\n- Determine what row each queen should be in.\nVariables\nQ1, Q2, Q3, Q4,\nDomains\n{1, 2, 3, 4}\nConstraints Qi<> Qj\n\"On different rows\"\n|Qi - Qj | <> |i-j|\n\"Stay off the diagonals\"\nExample\nC1,2 = {(1,3) (1,4) (2,4) (3,1) (4,1) (4,2)}\nBrian Williams, Fall 10\nGood Encodings Are Essential: 4 Queens\nPlace queens so that no\nqueen can attack another.\nVariables\nQ1, Q2, Q3, Q4,\nQ\nQ\nQ\nQ\nDomains\n{1, 2, 3, 4}\nConstraints Qi<> Qj\n\"On different rows\"\n|Qi- Qj | <> |i-j|\n\"Stay off the diagonals\"\nExample: C1,2 = {(1,3) (1,4) (2,4) (3,1) (4,1) (4,2)}\nWhat is C13?\nBrian Williams, Fall 10\n\nA general class of CSPs\nFinite Domain, Binary CSPs\nDepict as a Constraint Graph\n- each constraint relates at\n- Nodes (vertices) are\nmost two variables.\nvariables.\n- each variable domain is finite.\n-Arcs (edges) are binary\nconstraints.\nProperty: all n-ary CSPs are\nreducible to binary CSPs.\nBinary\nconstraint\narc\nUnary constraints\njust cut down domains\nUnary constraint arc\nVariable Vi with\nvalues in domain Di\nBrian Williams, Fall 10\nExample: Graph Coloring\nPick colors for map regions,\nwithout coloring adjacent regions\nwith the same color\nVariables\nregions\nDomains\nallowed colors\nConstraints adjacent regions must have different colors\nBrian Williams, Fall 10\n\nOutline\n- Interpreting line problems\n- Constraint satisfaction problems (CSP)\naka constraint programs (CP).\n- Solving CSPs\n- Arc-consistency and propagation\n- Analysis of constraint propagation (next lecture)\n- Search (next lecture)\n- Case study: Scheduling (appendix)\nBrian Williams, Fall 10\nGood News / Bad News\nGood News\n- very general & interesting family of\nproblems.\n- Problem formulation used extensively in\nautonomy and decision making applications.\nBad News\nincludes NP-Hard (intractable ?) problems\nBrian Williams, Fall 10\n\nAlgorithmic Design Paradigm\nSolving CSPs involves a combination of:\n1. Inference\n- Solve partially by eliminating values that\ncan't be part of any solution (constraint propagation).\n- Make implicit constraints explicit.\n2. Search\n- Try alternative assignments against constraints.\nInference: Waltz constraint propagation for visual interpretation\ngeneralizes to arc-consistency and the AC-3 algorithm.\nBrian Williams, Fall 10\nDirected Arc Consistency\nIdea: Eliminate values of a variable domain\nthat can never satisfy a specified constraint (an arc).\nX1\n{<1,3>,<1,4>,<2,1>}\nX2\n1 .\n2 .\n3 .\n4 .\n. 1\n. 2\n. 3\n. 4\nDefinition: arc <xi, xj> is arc consistent if <xi, xj> and <xj, xi> are\ndirected arc consistent.\nBrian Williams, Fall 10\n\nArc Consistency\nX\nX < Y\nY\n1 .\n2 .\n3 .\n. 1\n. 2\n. 3\nBrian Williams, Fall 10\nDirected Arc Consistency\nX1\n{<1,3>,<1,4>,<2,1>}\nX2\n1 .\n2 .\n3 .\n4 .\n. 1\n. 2\n. 3\n. 4\nDefinition: arc <xi, xj> is directed arc consistent if\n- for every ai in Di,\n- there exists some aj in Dj such that\n- assignment <ai,aj> satisfies constraint Cij,\n- ai Di, aj Dj such that <ai, aj> Cij\n- denotes \"for all,\" denotes \"there exists\" and denotes \"in.\"\nBrian Williams, Fall 10\n\nRevise: A directed arc consistency procedure\nDefinition: arc <xi, xj> is directed arc consistent if\nai Di, aj Dj such that <ai, aj> Cij\nRevise (xi, xj)\nInput: Variables xi and xj with domains Di and Dj and constraint relation Rij.\nOutput: pruned Di, such that xi is directed arc-consistent relative to xj.\n1. for each ai Di\n2.\nif there is no aj Dj such that <ai, aj> Rij\n3.\nthen delete ai from Di.\n4.\nendif\n5. endfor\nConstraint Processing,\nby R. Dechter\npgs 54-6\nBrian Williams, Fall 10\nFull Arc Consistency over All Constraints\nvia Constraint Propagation\nDefinition: arc <xi, xj> is directed arc consistent if\nai Di, aj Dj such that <ai, aj> Cij\nConstraint Propagation:\nTo achieve (directed) arc consistency over CSP:\n1. For every arc Cij in CSP, with tail domain Di, call Revise.\n2. Repeat until quiescence:\nIf an element was deleted from Di, then\nrepeat Step 1\n(AC-1)\nBrian Williams, Fall 10\n\nFull Arc-Consistency via AC-1\nAC-1(CSP)\nInput: A constraint satisfaction problem CSP = <X, D, C>.\nOutput: CSP', the largest arc-consistent subset of CSP.\n1. repeat\n2.\nfor every cij C,\nFor every arc,\n3.\nRevise(xi, xj)\nprune head\n4.\nRevise(xj, xi)\nand tail domains.\n5.\nendfor\nConstraint Processing,\n6. until no domain is changed.\nby R. Dechter\npgs 57\nBrian Williams, Fall 10\nFull Arc Consistency\nvia Constraint Propagation\nDefinition: arc <xi, xj> is directed arc consistent if\nai Di, aj Dj such that <ai, aj> Cij\nConstraint Propagation:\nTo achieve (directed) arc consistency over CSP:\n1. For every arc Cij in CSP, with tail domain Di, call Revise.\n2. Repeat until quiescence:\nIf an element was deleted from Di, then\nrepeat Step 1\n(AC-1)\nOR call Revise on each arc with head Di\n(AC-3)\n(use FIFO Q, remove duplicates)\nBrian Williams, Fall 10\n\nFull Arc-Consistency via AC-3 (Waltz CP)\nAC-3(CSP)\nInput: A constraint satisfaction problem CSP = <X, D, C>.\nOutput: CSP', the largest arc-consistent subset of CSP.\nConstraint Processing,\n1. for every cij C,\nby R. Dechter\n2.\nqueue queue {<xi, xj>, <xj, xi>}\npgs 58-9\n3. endfor\n4. while queue {}\n5.\nselect and delete arc <xi, xj> from queue\n6.\nRevise(xi, xj)\n7.\nif Revise(xi, xj) caused a change in Di\n8.\nthen queue queue {<xk, xi> | k i, k j}\n9.\nendif\nBrian Williams, Fall 10\n10. endwhile\nConstraint Propagation Example AC-3\nDifferent-color constraint\nGraph Coloring\nInitial Domains\nR,G,B\nG\nR, G\nV1\nV2\nV3\nEach undirected arc denotes two directed arcs.\nBrian Williams, Fall 10\n\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nR,G,B\nG\nR, G\nV2\nV3\nV1\nGraph Coloring\nInitial Domains\nArcs to examine\nV1 - V2, V1 - V3, V2 - V3\n- Introduce queue of arcs to be examined.\n- Start by adding all arcs to the queue.\nArc examined\nValue deleted\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nR,G,B\nG\nR, G\nV2\nV3\nV1\nGraph Coloring\nInitial Domains\nArcs to examine\nV1 - V2, V1 - V3, V2 - V3\n- Vi - Vj denotes two arcs, between Vi and Vj.\n- Vi > Vj denotes an arc from Vi to Vj.\nArc examined\nValue deleted\n\nConstraint Propagation Example AC-3\nDifferent-color constraint\nGraph Coloring\nInitial Domains\nR,G,B\nG\nR, G\nV1\nV2\nV3\nArc examined\nValue deleted\nV1 > V2\nV1\nArcs to examine\nR,G,B\nG\nR, G\nV2\nV3\nV2 > V1, V1 - V3, V2 - V3\n- Delete unmentioned tail values - Vi - Vj denotes two arcs, between Vi and Vj.\n- Vi > Vj denotes an arc from Vi to Vj.\nConstraint Propagation Example AC-3\nDifferent-color constraint\nGraph Coloring\nInitial Domains\nR,G,B\nG\nR, G\nV1\nV2\nV3\nArc examined\nValue deleted\nV1 > V2\nnone\nV1\nArcs to examine\nR,G,B\nG\nR, G\nV2\nV3\nV2 > V1, V1 - V3, V2 - V3\n- Delete unmentioned tail values - Vi - Vj denotes two arcs, between Vi and Vj.\n- Vi > Vj denotes an arc from Vi to Vj.\n\nConstraint Propagation Example AC-3\nDifferent-color constraint\nGraph Coloring\nInitial Domains\nR,G,B\nG\nR, G\nV1\nV2\nV3\nArc examined\nValue deleted\nV1 > V2\nnone\nV2 > V1\nV1\nArcs to examine\nR,G,B\nG\nR, G\nV2\nV3\nV1 - V3, V2 - V3\n- Delete unmentioned tail values - Vi - Vj denotes two arcs, between Vi and Vj.\n- Vi > Vj denotes an arc from Vi to Vj.\nConstraint Propagation Example AC-3\nDifferent-color constraint\nGraph Coloring\nInitial Domains\nR,G,B\nG\nR, G\nV1\nV2\nV3\nArc examined\nValue deleted\nV1 > V2\nnone\nV2 > V1\nnone\nV1\nArcs to examine\nR,G,B\nG\nR, G\nV2\nV3\nV1 - V3, V2 - V3\n- Delete unmentioned tail values - Vi - Vj denotes two arcs, between Vi and Vj.\n- Vi > Vj denotes an arc from Vi to Vj.\n\nConstraint Propagation Example AC-3\nDifferent-color constraint\nGraph Coloring\nInitial Domains\nR,G,B\nG\nR, G\nV1\nV2\nV3\nArc examined\nValue deleted\nV1 - V2\nnone\nV1\nArcs to examine\nR,G,B\nG\nR, G\nV2\nV3\nV1 - V3, V2 - V3\n- Delete unmentioned tail values - Vi - Vj denotes two arcs, between Vi and Vj.\n- Vi > Vj denotes an arc from Vi to Vj.\nConstraint Propagation Example AC-3\nDifferent-color constraint\nGraph Coloring\nInitial Domains\nR,G,B\nG\nR, G\nV1\nV2\nV3\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 > V3\nV1\nArcs to examine\nR,G,B\nG\nR, G\nV2\nV3\nV3 > V1, V2 - V3\n- Delete unmentioned tail values - Vi - Vj denotes two arcs, between Vi and Vj.\n- Vi > Vj denotes an arc from Vi to Vj.\n\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nGraph Coloring\nInitial Domains\nR,G,B\nG\nR, G\nV2\nV3\nV1\nArcs to examine\nV3 > V1, V2 - V3\nIF\nAn element of a variable's domain is removed,\nTHEN\nadd all arcs to that variable to the examination queue.\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 > V3\nV1(G)\nConstraint Propagation Example AC-3\nDifferent-color constraint\nGraph Coloring\nInitial Domains\nR,G,B\nG\nR, G\nV1\nV2\nV3\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 > V3\nV1(G)\nR,G,B\nG\nR, G\nV2\nV3\nV1\nArcs to examine\nV3 > V1, V2 - V3, V2 > V1, V3 > V1\nIF\nTHEN\nAn element of a variable's domain is removed,\nadd all arcs to that variable to the examination queue.\n\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nGraph Coloring\nInitial Domains\nR, B\nG\nR, G\nV2\nV3\nV1\nArcs to examine\nV2 - V3, V2 > V1\n- Delete unmentioned tail values\nIF\nAn element of a variable's domain is removed,\nTHEN\nadd all arcs to that variable to the examination queue.\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 > V3\nV1(G)\nV3 > V1\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nGraph Coloring\nInitial Domains\nR, B\nG\nR, G\nV2\nV3\nV1\nArcs to examine\nV2 - V3, V2 > V1\n- Delete unmentioned tail values\nIF\nAn element of a variable's domain is removed,\nTHEN\nadd all arcs to that variable to the examination queue.\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 > V3\nV1(G)\nV3 > V1\nnone\n\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nGraph Coloring\nInitial Domains\nR, B\nG\nR, G\nV2\nV3\nV1\nArcs to examine\nV2 - V3, V2 > V1\n- Delete unmentioned tail values\nIF\nAn element of a variable's domain is removed,\nTHEN\nadd all arcs to that variable to the examination queue.\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 - V3\nV1(G)\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nGraph Coloring\nInitial Domains\nR, B\nG\nR, G\nV2\nV3\nV1\nArcs to examine\nV3 > V2, V2 > V1\n- Delete unmentioned tail values\nIF\nAn element of a variable's domain is removed,\nTHEN\nadd all arcs to that variable to the examination queue.\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 - V3\nV1(G)\nV2 > V3\n\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nGraph Coloring\nInitial Domains\nR, B\nG\nR, G\nV2\nV3\nV1\nArcs to examine\nV3 > V3, V2 > V1\n- Delete unmentioned tail values\nIF\nAn element of a variable's domain is removed,\nTHEN\nadd all arcs to that variable to the examination queue.\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 - V3\nV1(G)\nV2 > V3\nV2(G)\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nGraph Coloring\nInitial Domains\nR, B\nG\nR, G\nV2\nV3\nV1\nArcs to examine\nV3 > V2, V2 > V1 , V1 > V2\n- Delete unmentioned tail values\nIF\nAn element of a variable's domain is removed,\nTHEN\nadd all arcs to that variable to the examination queue.\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 - V3\nV1(G)\nV2 > V3\nV2(G)\n\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nGraph Coloring\nInitial Domains\nR, B\nG\nR, G\nV2\nV3\nV1\nArcs to examine\nV3 > V2, V2 > V1 , V1 > V2\n- Delete unmentioned tail values\nIF\nAn element of a variable's domain is removed,\nTHEN\nadd all arcs to that variable to the examination queue.\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 - V3\nV1(G)\nV2 > V3\nV2(G)\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nGraph Coloring\nInitial Domains\nR, B\nG\nR\nV2\nV3\nV1\nArcs to examine\nV2 > V1 , V1 > V2\n- Delete unmentioned tail values\nIF\nAn element of a variable's domain is removed,\nTHEN\nadd all arcs to that variable to the examination queue.\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 - V3\nV1(G)\nV2 > V3\nV2(G)\nV3 > V2\n\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nGraph Coloring\nInitial Domains\nR, B\nG\nR\nV2\nV3\nV1\nArcs to examine\nV2 > V1 , V1 > V2\n- Delete unmentioned tail values\nIF\nAn element of a variable's domain is removed,\nTHEN\nadd all arcs to that variable to the examination queue.\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 - V3\nV1(G)\nV2 > V3\nV2(G)\nV3 > V2\nnone\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nGraph Coloring\nInitial Domains\nR, B\nG\nR\nV2\nV3\nV1\nArcs to examine\nV2 > V1 , V1 > V2\n- Delete unmentioned tail values\nIF\nAn element of a variable's domain is removed,\nTHEN\nadd all arcs to that variable to the examination queue.\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 - V3\nV1(G)\nV2 - V3\nV2(G)\n\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nGraph Coloring\nInitial Domains\nR, B\nG\nR\nV2\nV3\nV1\nArcs to examine\nV1 > V2\n- Delete unmentioned tail values\nIF\nAn element of a variable's domain is removed,\nTHEN\nadd all arcs to that variable to the examination queue.\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 - V3\nV1(G)\nV2 - V3\nV2(G)\nV2 > V1\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nGraph Coloring\nInitial Domains\nR, B\nG\nR\nV2\nV3\nV1\nArcs to examine\nV1 > V2\n- Delete unmentioned tail values\nIF\nAn element of a variable's domain is removed,\nTHEN\nadd all arcs to that variable to the examination queue.\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 - V3\nV1(G)\nV2 - V3\nV2(G)\nV2 > V1\nnone\n\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nGraph Coloring\nInitial Domains\nR, B\nG\nR\nV2\nV3\nV1\nArcs to examine\n- Delete unmentioned tail values\nIF\nAn element of a variable's domain is removed,\nTHEN\nadd all arcs to that variable to the examination queue.\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 - V3\nV1(G)\nV2 - V3\nV2(G)\nV2 > V1\nnone\nV1 > V2\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nGraph Coloring\nInitial Domains\nR, B\nG\nR\nV2\nV3\nV1\nArcs to examine\n- Delete unmentioned tail values\nIF\nAn element of a variable's domain is removed,\nTHEN\nadd all arcs to that variable to the examination queue.\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 - V3\nV1(G)\nV2 - V3\nV2(G)\nV2 > V1\nnone\nV1 > V2\nV1(R)\n\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nGraph Coloring\nInitial Domains\nR, B\nG\nR\nV2\nV3\nV1\nArcs to examine\nV2 > V1, V3 > V1\n- Delete unmentioned tail values\nIF\nAn element of a variable's domain is removed,\nTHEN\nadd all arcs to that variable to the examination queue.\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 - V3\nV1(G)\nV2 - V3\nV2(G)\nV2 > V1\nnone\nV1 > V2\nV1(R)\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nGraph Coloring\nInitial Domains\nR, B\nG\nR\nV2\nV3\nV1\nArcs to examine\nV2 > V1, V3 > V1\n- Delete unmentioned tail values\nIF\nAn element of a variable's domain is removed,\nTHEN\nadd all arcs to that variable to the examination queue.\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 - V3\nV1(G)\nV2 - V3\nV2(G)\nV2 - V1\nV1(R)\n\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nGraph Coloring\nInitial Domains\nB\nG\nR\nV2\nV3\nV1\nArcs to examine\n- Delete unmentioned tail values\nIF\nAn element of a variable's domain is removed,\nTHEN\nadd all arcs to that variable to the examination queue.\nV3 > V1\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 - V3\nV1(G)\nV2 - V3\nV2(G)\nV2 - V1\nV1(R)\nV2 > V1\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nGraph Coloring\nInitial Domains\nB\nG\nR\nV2\nV3\nV1\nArcs to examine\n- Delete unmentioned tail values\nIF\nAn element of a variable's domain is removed,\nTHEN\nadd all arcs to that variable to the examination queue.\nV3 > V1\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 - V3\nV1(G)\nV2 - V3\nV2(G)\nV2 - V1\nV1(R)\nV2 > V1\nnone\n\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nGraph Coloring\nInitial Domains\nB\nG\nR\nV2\nV3\nV1\nArcs to examine\n- Delete unmentioned tail values\nIF\nAn element of a variable's domain is removed,\nTHEN\nadd all arcs to that variable to the examination queue.\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 - V3\nV1(G)\nV2 - V3\nV2(G)\nV2 - V1\nV1(R)\nV2 > V1\nnone\nV3 > V1\nConstraint Propagation Example AC-3\nR,G,B\nG\nR, G\nDifferent-color constraint\nV1\nV2\nV3\nGraph Coloring\nInitial Domains\nB\nG\nR\nV2\nV3\nV1\nArcs to examine\nIF\nexamination queue is empty\nTHEN\narc (pairwise) consistent.\nArc examined\nValue deleted\nV1 - V2\nnone\nV1 - V3\nV1(G)\nV2 - V3\nV2(G)\nV2 - V1\nV1(R)\nV2 > V1\nnone\nV3 > V1\nnone\n\nNext: To Solve CSPs we combine\narc consistency and search\n1. Arc consistency (Constraint propagation),\n-\nEliminates values that are shown locally to not be a\npart of any solution.\n2.\nSearch\n-\nExplores consequences of committing to particular\nassignments.\nMethods Incorporating Search:\n-\nStandard Search\n-\nBackTrack Search (BT)\n-\nBT with Forward Checking (FC)\n-\nDynamic Variable Ordering (DVO)\n-\nIterative Repair\nBrian Williams, Fall 10\n-\nBackjumping (BJ)\nOutline\n- Interpreting line diagrams\n- Constraint satisfaction problem (CSPS)\naka constraint programs (CP).\n- Solving CSPs\n- Case study: Scheduling (appendix)\nBrian Williams, Fall 10\n\nReal World Example: Scheduling as a CSP\nChoose time of activities:\n- Observations by the Hubble telescope.\n- Jobs performed on machine tools.\n- Classes taken for degree.\nVariables\nare activities\ntime\nDomains\nAre possible start times (or \"chunks\" of time)\nConstraints\n1. Activities that use the same\nresource cannot overlap in time, and\n2. Prerequisites are satisfied.\nBrian Williams, Fall 10\nactivity\nCase Study: Course Scheduling\nGiven:\n- 32 required courses (8.01, 8.02, . . . . 16.410), and\n- 8 terms (Fall 1, Spring 1, . . . . , Spring 4).\nFind: a legal schedule.\nConstraints\n- Pre-requisites satisfied,\n- Courses offered only during certain terms,\n-A limited number of courses can be taken per\nterm (say 4), and\n-Avoid time conflicts between courses.\nNote, traditional CSPs are not for expressing (soft) preferences\ne.g. minimize difficulty, balance subject areas, etc.\nBut see recent research on valued CSPs!\n\nAlternative formulations for\nvariables and values\nVARIABLES\nDOMAINS\nA. 1 var per Term\nAll legal combinations of 4 courses,\n(Fall 1) (Spring 1)\nall offered during that term.\n(Fall 2) (Spring 2) . . .\nB. 1 var per Term-Slot\nsubdivide each term\nAll courses offered during that term.\ninto 4 course slots:\n(Fall 1,1) (Fall 1, 2)\n(Fall1, 3) (Fall 1, 4)\nC. 1 var per Course\nTerms or term-slots.\nTerm-slots make it easier to express\nthe constraint limiting the number of\ncourses per term.\nFor pairs of courses that\nmust be ordered.\nPrerequisite\nafter\nCourses offered only during certain terms\nFilter domain\nTerm-slots not equal\nLimit # courses\nUse term-slots only once\nEncoding Constraints\nAssume: Variables = Courses, Domains = term-slots\nConstraints:\n1.00\n16.410\nAt least 1\nterm\nbefore\nAt least\n1 term\nfor all pairs of vars.\nterm not equal\nAvoid time conflicts\nFor course pairs offered at\nsame or overlapping times\nBrian Williams, Fall 10\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "MIT16_410F10_lec06.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/7434ba1355d03e83bfac5effa7edd1d0_MIT16_410F10_lec06.pdf",
      "content": "Solving Constraint Programs using\nBacktrack Search and Forward Checking\n9/29/10\nSlides draw upon material from:\nBrian C. Williams\n6.034 notes, by Tomas Lozano Perez\nAIMA, by Stuart Russell & Peter Norvig\n16.410-13\nConstraint Processing, by Rina Dechter\nSeptember 27th, 2010\nAssignments\n- Remember:\n- Problem Set #3: Analysis and Constraint Programming,\ndue this Wed., Sept. 29th, 2010.\n- Reading:\n- Today: [AIMA] Ch. 6.2-5; Constraint Satisfaction.\n- Wednesday: Operator-based Planning [AIMA] Ch. 10\n\"Graph Plan,\" by Blum & Furst, posted on Stellar.\n- To Learn More: Constraint Processing, by Rina Dechter\n- Ch. 5: General Search Strategies: Look-Ahead\n- Ch. 6: General Search Strategies: Look-Back\n- Ch. 7: Stochastic Greedy Local Search\nBrian Williams, Fall 10\n\nConstraint Problems are Everywhere\n(c) Source unknown. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see http://ocw.mit.edu/fairuse.\nConstraint Satisfaction Problems (CSP)\nInput: A Constraint Satisfaction Problem is a triple <V,D,C>, where:\n- V is a set of variables Vi\n- D is a set of variable domains,\n- The domain of variable Vi is denoted Di\n- C = is a set of constraints on assignments to V\n- Each constraint Ci = <Si,Ri> specifies allowed variable assignments.\n- Si the constraint's scope, is a subset of variables V.\n- Ri the constraint's relation, is a set of assignments to Si.\nOutput: A full assignment to V, from elements of V's domain,\nsuch that all constraints in C are satisfied.\nBrian Williams, Fall 10\n\nConstraint Modeling (Programming) Languages\nFeatures Declarative specification of the problem that\nseparates the formulation and the search strategy.\nExample: Constraint Model of the Sudoku Puzzle in\nNumber Jack (http://4c110.ucc.ie/numberjack/home)\nmatrix = Matrix(N*N,N*N,1,N*N)\nsudoku = Model( [AllDiff(row) for row in matrix.row],\n[AllDiff(col) for col in matrix.col],\n[AllDiff(matrix[x:x+N, y:y+N].flat)\nfor x in range(0,N*N,N)\nfor y in range(0,N*N,N)] )\nConstraint Problems are Everywhere\n(c) Source unknown. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see http://ocw.mit.edu/fairuse.\n\nOutline\n- Analysis of constraint propagation\n- Solving CSPs using Search\nBrian Williams, Fall 10\nWhat is the Complexity of AC-1?\nAC-1(CSP)\nInput: A network of constraints CSP = <X, D, C>.\nOutput: CSP', the largest arc-consistent subset of CSP.\n1. repeat\n2.\nfor every cij C,\n3.\nRevise(xi, xj)\n4.\nRevise(xj, xi)\n5.\nendfor\n6. until no domain is changed.\nAssume:\n- There are n variables.\n- Domains are of size at most k.\n- There are e binary constraints.\nBrian Williams, Fall 10\n\nWhat is the Complexity of AC-1?\nAssume:\n- There are n variables.\n- Domains are of size at most k.\n- There are e binary constraints.\nWhich is the correct complexity?\n1. O(k2)\n2. O(enk2 )\n3. O(enk3)\n4. O(nek)\nBrian Williams, Fall 10\nRevise: A directed arc consistency procedure\nRevise (xi, xj)\nInput: Variables xi and xj with domains Di and Dj and constraint relation Rij.\nOutput: pruned Di, such that xi is directed arc-consistent relative to xj.\nO(k)\n1. for each ai Di\n2.\nif there is no aj Dj such that <ai, aj> Rij\n* O(k)\n3.\nthen delete ai from Di.\n4.\nendif\n5. endfor\nComplexity of Revise?\n= O(k2)\nwhere k = max |D |\ni\ni\nBrian Williams, Fall 10\n\n-\nFull Arc-Consistency via AC-1\nAC-1(CSP)\nInput: A network of constraints CSP = <X, D, C>.\nOutput: CSP', the largest arc-consistent subset of CSP.\n1. repeat\n2.\nfor every cij C,\nO(2e*revise)\n3.\nRevise(xi, xj)\n4.\nRevise(xj, xi)\n5.\nendfor\n* O(nk)\n6. until no domain is changed.\nComplexity of AC-1?\n= O(nk*e*revise)\n= O(enk3)\nwhere k = maxi |Di|\nBrian Williams, Fall 10\nn = |X|, e = |C|\nWhat is the Complexity of\nConstraint Propagation using AC-3?\nAssume:\n- There are n variables.\nDomains are of size at most k.\n- There are e binary constraints.\nWhich is the correct complexity?\n1. O(k2)\n2. O(ek2 )\n3. O(ek3)\n4. O(ek)\nBrian Williams, Fall 10\n\n-\nFull Arc-Consistency via AC-3\nAC-3(CSP)\nInput: A network of constraints CSP = <X, D, C>.\nOutput: CSP', the largest arc-consistent subset of CSP.\n1.\nfor every cij C,\nO(e) +\n2.\nqueue queue {<xi,xj>, <xi,xj>}\n3. endfor\n4. while queue {}\n5.\nselect and delete arc <xi, xj> from queue\n6.\nRevise(xi, xj)\nO(k2)\n7.\nif Revise(xI, xJ) caused a change in Di.\n* O(ek)\n8.\nthen queue queue {<xk,xI> | k i, k j}\n9.\nendif\n10. endwhile\nComplexity of AC-3?\n= O(e+ek*k2) = O(ek3)\nwhere k = max |D |, n = |X|, e = |C|\ni\ni\nBrian Williams, Fall 10\nIs arc consistency sound and complete?\nAn arc consistent solution selects a value for every variable\nfrom its arc consistent domain.\nSoundness: All solutions to the CSP are arc consistent\nsolutions?\nYes\n- No\nCompleteness: All arc-consistent solutions are solutions to the\nCSP?\n- Yes\n- No\nR, G\nR, G\nR, G\nBrian Williams, Fall 10\n\nIncomplete: Arc consistency doesn't\nrule out all infeasible solutions\nR, G\nR, G\nR, G\nR, G\nR, G\nB, G\nGraph\nColoring\narc consistent, but\nno solutions.\narc consistent, but\n2 solutions, not 8.\nB,R,G\nB,G,R\nBrian Williams, Fall 10\nTo Solve CSPs We Combine\n1. Arc consistency (via constraint propagation)\n-\nEliminates values that are shown locally to not be a\npart of any solution.\n2.\nSearch\n-\nExplores consequences of committing to particular\nassignments.\nMethods That Incorporate Search:\n-\nStandard Search\n-\nBack Track Search (BT)\n-\nBT with Forward Checking (FC)\n-\nDynamic Variable Ordering (DV)\n-\nIterative Repair (IR)\n-\nConflict-directed Back Jumping (CBJ)\n\nSolving CSPs using Generic Search\n- State\n- Partial assignment to variables,\nmade thus far.\n- Initial State\n- No assignment.\n- Operator\n- Creates new assignment (Xi = vij)\n- Select any unassigned variable Xi\n- Select any one of its domain values vij\n- Child extends parent assignments with new.\n- Goal Test\n- All variables are assigned.\n- All constraints are satisfied.\n- Branching factor?\nSum of domain size of all variables O(|v|*|d|).\n- Performance?\nExponential in the branching factor O([|v|*|d|]|v|).\nR, G\nR, G\nR, G, B V1\nV3\nV2\nSearch Performance on N Queens\n-\nStandard Search\n-\nBacktracking\n- A handful of queens\nQ\nQ\nQ\nQ\n\nSolving CSPs with Standard Search\nStandard Search:\n-\nChildren select any value for any variable [O(|v|*|d|)].\n-\nTest complete assignments for consistency against CSP.\nObservations:\n1. The order in which variables are assigned does not change the solution.\n-\nMany paths denote the same solution,\n-\n(|v|!),\nexpand only one path (i.e., use one variable ordering).\n2. We can identify a dead end before we assign all variables.\n-\nExtensions to inconsistent partial assignments are always\ninconsistent.\nCheck consistency after each assignment.\nR, G\nR, G\nR, G, B V1\nV3\nV2\nBack Track Search (BT)\n1.\nExpand assignments of one variable at each step.\n2.\nPursue depth first.\n3.\nCheck consistency after each expansion, and backup.\nV3 assignments\nPreselect order\nAssign\nof variables to\ndesignated\nassign\nvariable\nV1 assignments\nV2 assignments\nR\nG\nB\nR, G\nR, G\nR, G, B V1\nV3\nV2\n\nBack Track Search (BT)\n1.\nExpand assignments of one variable at each step.\n2.\nPursue depth first.\n3.\nCheck consistency after each expansion, and backup.\nR\nG\nR\nG\nR\nG\nR\nG\nR\nG\nB\nR\nG\nR\nG R\nG\nV1 assignments\nV2 assignments\nV3 assignments\nPreselect order\nAssign\nBackup at\nof variables to\ndesignated\ninconsistent\nassign\nvariable\nassignment\nR, G\nR, G\nR, G, B V1\nV3\nV2\nProcedure Backtracking(<X,D,C>)\nInput:\nA\n\nconstraint network R = <X, D, C>\nOutput: A solution, or notification that the network is inconsistent.\ni 1; ai = {}\nInitialize variable counter, assignments,\nD'i Di;\nCopy domain of first variable.\nwhile 1 i n\ninstantiate xi Select-Value();\nAdd to assignments ai.\nif xi is null\nNo value was returned,\ni i - 1;\nthen backtrack\nelse\ni i + 1;\nelse step forward and\nD'i Di;\ncopy domain of next variable\nend while\nif i = 0\nreturn \"inconsistent\"\nelse\nreturn ai , the instantiated values of {xi, ..., xn}\nend procedure\n\nProcedure Select-Value()\nOutput: A value in D'i consistent with ai-1, or null, if none.\nwhile D'i is not empty\nselect an arbitrary element a D'i and remove a from D'i;\nif consistent(ai-1, xi = a )\nreturn a;\nend while\nreturn null\nno consistent value\nend procedure\nConstraint Processing,\nby R. Dechter\npgs 123-127\nSearch Performance on N Queens\n-\nStandard Search\n-\nBacktracking\n-\nBT with Forward Checking\n- A handful of queens\n- About 15 queens\nQ\nQ\nQ\nQ\n\nCombining Backtracking and\nLimited Constraint Propagation\nInitially: Prune domains using constraint propagation (optional)\nLoop:\n- If complete consistent assignment, then return it, Else...\n- Choose unassigned variable.\n- Choose assignment from variable's pruned domain.\n- Prune (some) domains using Revise (i.e., arc-consistency).\n- If a domain has no remaining elements, then backtrack.\nQuestion: Full propagation is O(ek3),\nHow much propagation should we do?\nVery little (except for big problems)\nForward Checking (FC)\n- Check arc consistency ONLY for arcs that terminate\non the new assignment [O(e k) total].\nBacktracking with Forward Checking (BT-FC)\n2. After selecting each assignment, remove any values of\nneighboring domains that are inconsistent with the new assignment.\nR\nV1 assignments\nV2 assignments\nV3 assignments\nR, G\nR, G\nR, G, B V1\nV3\nV2\n1. Perform initial pruning.\n\nBacktracking with Forward Checking (BT-FC)\n2. After selecting each assignment, remove any values of\nneighboring domains that are inconsistent with the new assignment.\nR\nV1 assignments\nV2 assignments\nV3 assignments\nR, G\nR, G\nR\nV1\nV3\nV2\n1. Perform initial pruning.\nBacktracking with Forward Checking (BT-FC)\n2. After selecting each assignment, remove any values of\nneighboring domains that are inconsistent with the new assignment.\nR\nV1 assignments\nV2 assignments\nV3 assignments\nG\nG\nR\nV1\nV3\nV2\n1. Perform initial pruning.\n\nBacktracking with Forward Checking (BT-FC)\n2. After selecting each assignment, remove any values of\nneighboring domains that are inconsistent with the new assignment.\nR\nV1 assignments\nV2 assignments\nG\nV3 assignments\nNote: No need to\ncheck new\nassignment against\n1. Perform initial pruning.\nprevious assignments\nG\nG\nR\nV1\nV3\nV2\nBacktracking with Forward Checking (BT-FC)\n2. After selecting each assignment, remove any values of\nneighboring domains that are inconsistent with the new assignment.\nR\nV1 assignments\nV2 assignments\nG x\nV3 assignments\n3. We have a conflict whenever a domain becomes empty.\n- Backtrack\nG\nR\nV1\nV3\nV2\n1. Perform initial pruning.\n\nBacktracking with Forward Checking (BT-FC)\n2. After selecting each assignment, remove any values of\nneighboring domains that are inconsistent with the new assignment.\nR\nV1 assignments\nV2 assignments\nG x x\nV3 assignments\n3. We have a conflict whenever a domain becomes empty.\n- Backtrack\n1. Perform initial pruning.\nR\nV1\nV3\nV2\nBacktracking with Forward Checking (BT-FC)\n2. After selecting each assignment, remove any values of\nneighboring domains that are inconsistent with the new assignment.\nV1 assignments\nG\nV2 assignments\nV3 assignments\n3. We have a conflict whenever a domain becomes empty.\n- Backtrack\n- Restore domains\nR, G\nR, G\nG, B\nV1\nV3\nV2\n1. Perform initial pruning.\n\nBacktracking with Forward Checking (BT-FC)\n2. After selecting each assignment, remove any values of\nneighboring domains that are inconsistent with the new assignment.\nV1 assignments\nG\nV2 assignments\nV3 assignments\n3. We have a conflict whenever a domain becomes empty.\n- Backtrack\n- Restore domains\n1. Perform initial pruning.\nR, G\nR, G\nG\nV1\nV3\nV2\nBacktracking with Forward Checking (BT-FC)\n2. After selecting each assignment, remove any values of\nneighboring domains that are inconsistent with the new assignment.\nV1 assignments\nG\nV2 assignments\nV3 assignments\n3. We have a conflict whenever a domain becomes empty.\n- Backtrack\n- Restore domains\nR\nR\nG\nV1\nV3\nV2\n1. Perform initial pruning.\n\nBacktracking with Forward Checking (BT-FC)\n2. After selecting each assignment, remove any values of\nneighboring domains that are inconsistent with the new assignment.\nV1 assignments\nG\nV2 assignments\nR\nV3 assignments\n3. We have a conflict whenever a domain becomes empty.\n- Backtrack\n- Restore domains\n1. Perform initial pruning.\nR\nR\nG\nV1\nV3\nV2\nBacktracking with Forward Checking (BT-FC)\n2. After selecting each assignment, remove any values of\nneighboring domains that are inconsistent with the new assignment.\nV1 assignments\nG\nV2 assignments\nR x x\nV3 assignments\n3. We have a conflict whenever a domain becomes empty.\n- Backtrack\n- Restore domains\nR\nG\nV1\nV3\nV2\n1. Perform initial pruning.\n\nBacktracking with Forward Checking (BT-FC)\n2. After selecting each assignment, remove any values of\nneighboring domains that are inconsistent with the new assignment.\nB\nV1 assignments\nV2 assignments\nV3 assignments\n3. We have a conflict whenever a domain becomes empty.\n- Backtrack\n- Restore domains\n1. Perform initial pruning.\nR, G\nR, G\nB\nV1\nV3\nV2\nBacktracking with Forward Checking (BT-FC)\n2. After selecting each assignment, remove any values of\nneighboring domains that are inconsistent with the new assignment.\nB\nV1 assignments\nV2 assignments\nV3 assignments\n3. We have a conflict whenever a domain becomes empty.\n- Backtrack\n- Restore domains\nR, G\nR, G\nB\nV1\nV3\nV2\n1. Perform initial pruning.\n\nBacktracking with Forward Checking (BT-FC)\n2. After selecting each assignment, remove any values of\nneighboring domains that are inconsistent with the new assignment.\nB\nR\nV1 assignments\nV2 assignments\nV3 assignments\n3. We have a conflict whenever a domain becomes empty.\n- Backtrack\n- Restore domains\n1. Perform initial pruning.\nR\nR, G\nB\nV1\nV3\nV2\nBacktracking with Forward Checking (BT-FC)\n2. After selecting each assignment, remove any values of\nneighboring domains that are inconsistent with the new assignment.\nB\nV1 assignments\nV2 assignments\nR\nV3 assignments\n3. We have a conflict whenever a domain becomes empty.\n- Backtrack\n- Restore domains\nR\nG\nB\nV1\nV3\nV2\n1. Perform initial pruning.\n\nBacktracking with Forward Checking (BT-FC)\n2. After selecting each assignment, remove any values of\nneighboring domains that are inconsistent with the new assignment.\nB\nR\nV1 assignments\nV2 assignments\nV3 assignments\nG\n3. We have a conflict whenever a domain becomes empty.\n- Backtrack\nR\nG\nB\nV1\n- Restore domains\nV2\nV3\nSolution!\n1. Perform initial pruning.\nBacktracking with Forward Checking (BT-FC)\n2. After selecting each assignment, remove any values of\nneighboring domains that are inconsistent with the new assignment.\nB\nG\nV1 assignments\nV2 assignments\nV3 assignments\nR\n3. We have a conflict whenever a domain becomes empty.\n- Backtrack\nBT-FC is generally\nfaster than pure BT\n- Restore domains\nbecause it avoids\nG\nR\nB\nV1\nV3\nV2\nrediscovering\ninconsistencies.\n1. Perform initial pruning.\n\nProcedure Backtrack-Forward-Checking(<x,D,C>)\nInput: A constraint network R = <X, D, C>\nOutput: A solution, or notification the network is inconsistent.\nNote: Maintains n domain copies D' for resetting, one for each search level i.\nD'i Di for 1 i n;\n(copy all domains)\ni 1; ai = {}\n(init variable counter, assignments)\nwhile 1 i n\ninstantiate xi Select-Value-FC();\n(add to assignments, making ai)\nif xi is null\n(no value was returned)\nreset each D'k for k > i, to its value before xi was last instantiated;\ni i - 1;\n(backtrack)\nelse\ni i + 1;\n(step forward)\nend while\nif i = 0\nreturn \"inconsistent\"\nConstraint Processing,\nby R. Dechter\nelse\nreturn ai , the instantiated values of {xi, ..., xn}\npgs 131-4, 141\nend procedure\nProcedure Select-Value-FC()\nOutput: A value in D'i consistent with ai-1, or null, if none.\nO(ek2)\nwhile D'i is not empty\nselect an arbitrary element a D'i and remove a from D'i;\nfor all k, i < k n\nfor all values b in D'k\nif not consistent(ai-1, xi = a, xk = b)\nremove b from D'k;\nend for\nif D'k is empty\n(xi = a leads to a dead-end, don't select a)\nreset each D'k, i < k n to its value before a was selected;\nelse\nreturn a;\nend while\nConstraint Processing,\nreturn null\nby R. Dechter\nend procedure\npgs 131-4, 141\n\nSearch Performance on N Queens\n-\nStandard Search\n-\nBacktracking\n-\nBT with Forward Checking\n-\nDynamic Variable Ordering\n- A handful of queens\n- About 15 queens\n- About 30 queens\nQ\nQ\nQ\nQ\nBT-FC with dynamic ordering\nTraditional backtracking uses a fixed ordering over variables & values.\nTypically better to choose ordering dynamically as search proceeds.\n- Most Constrained Variable\nWhen doing forward-checking, pick variable with fewest legal\nvalues in domain to assign next.\nminimizes branching factor.\n- Least Constraining Value\nChoose value that rules out the smallest number of values in\nvariables connected to the chosen variable by constraints.\nLeaves most options to finding a satisfying assignment.\n\nColors: R, G, B, Y\nA\nB\nD\nE\nC\nR, Y\nG, B, Y\nF\nR, B, Y\nWhich country should we color next?\nWhat color should we pick for it?\nE most-constrained variable\n(smallest domain).\nRED least-constraining value\n(eliminates fewest values from\nneighboring domains).\nfor 1 i n;\nai = {}\nProcedure Dynamic-Var-Forward-Checking(<x,D,C>)\nInput: A constraint network R = <X, D, C>\nOutput: A solution, or notification the network is inconsistent.\nD'i Di\nCopy all domains\ni 1;\nInit variable counter and assignments\ns = mini < j n |D'j|\nFind unassigned variable w smallest domain\nxi+1xs\nRearrange variables so that xs follows xi\nwhile 1 i n\ninstantiate xi Select-Value-FC();\nSelect value (dynamic) and add to assignments, ai\nif xi is null\nNo value to assign was returned.\nreset each D'k for k > i, to its value before xi was last instantiated;\ni i - 1;\nBacktrack\nelse\nif I < n\ni i + 1;\nStep forward to xs\ns = mini < j n |D'j|\nFind unassignedvariable w smallest domain\nxi+1xs\nRearrange variables so that xs follows xi\nelse\ni i + 1;\nStep forward to xs\nend while\nif i = 0\nreturn \"inconsistent\"\nConstraint Processing,\nelse\nby R. Dechter\nreturn ai , the instantiated values of {xi, ..., xn}\nend procedure\npgs 137-140\n\nSearch Performance on N Queens\nQ\nQ\nQ\nQ\n-\nStandard Search\n- A handful of queens\n-\nBacktracking\n- About 15 queens\n-\nBT with Forward Checking\n- About 30 queens\n-\nDynamic Variable Ordering\n- About 1,000 queens\n-\nIterative Repair\n-\nConflict-directed Back\nJumping\nIncremental Repair (Min-Conflict Heuristic)\n1. Initialize a candidate solution using a \"greedy\" heuristic.\n- gets the candidate \"near\" a solution.\n2. Select a variable in a conflict and assign it a value that minimizes\nthe number of conflicts (break ties randomly).\nThe heuristic is used in a local hill-climber (without or with backup).\nR R R: 3\nBRR\nGRR\nRGR\nRRG\nR, G\nR, G\nR, G, B V1\nV3\nV2\n\nMin-Conflict Heuristic\nPure hill climber (w/o backtracking) gets stuck in local minima:\n-Add random moves to attempt to get out of minima.\n-Add weights on violated constraints and\nincrease weight every cycle the constraint remains violated.\nSec\n(Sparc 1)\n104 105\nPerformance on n-queens.\n(with good initial guesses)\n10-1\n10-2\nSize (n)\nGSAT: Randomized hill climber used to solve propositional logic\nSATisfiability problems.\nTo Solve CSP <X,D,C> We Combine:\n1. Reasoning - Arc consistency via constraint propagation\n-\nEliminates values that are shown locally to not be a part\nof any solution.\n2.\nSearch\n-\nExplores consequences of committing to particular\nassignments.\nMethods That Incorporate Search:\n-\nStandard Search\n-\nBack Track Search (BT)\n-\nBT with Forward Checking (FC)\n-\nDynamic Variable Ordering (DV)\n-\nIterative Repair (IR)\n-\nConflict-directed Back Jumping (CBJ)\n\nNext Lecture: Back Jumping\nBacktracking At dead end, backup to the most recent variable.\nBackjumping At dead end, backup to the most recent variable that\neliminated some value in the domain of the dead end variable.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "MIT16_410F10_lec07a.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/7a5cd091e89dff7ca4eed31df8a0aa08_MIT16_410F10_lec07a.pdf",
      "content": "Solving Constraint Programs using\nConflicts and Backjumping\n6/30/11\nBrian C. Williams\n16.410-13\nSeptember 29th, 2010\nSlides draw upon material from:\nProf. Patrick Prosser, Glasow University\nSearch Performance on N Queens\n-\nStandard Search\n-\nBacktracking\n-\nBT with Forward Checking\n-\nDynamic Variable Ordering\n-\nIterative Repair\n-\nConflict-directed Back\nJumping\n- A handful of queens\n- About 15 queens\n- About 30 queens\n- About 1,000 queens\n- About 10,000,000 queens\n(except truly hard problems)\nQ\nQ\nQ\nQ\n\nBack Jumping\nBacktracking At dead end, backup to the most recent variable.\nBackjumping At dead end, backup to the most recent variable that\neliminated some value in the domain of the dead end variable.\nExample of a CSP\nC\nE\nD\nB\nF\nA\nG\nH\nVa\nVb\nVc\nVd\nVe\nVf\nVg\nVh\n1 = red\n2 = blue\n3 = green\nVariables and Instantiation Order\nChecking back\nSlide progression due to Prosser [4C presentation, 2003]\n\nC\nE\nD\nB\nF\nA\nG\nH\nVa\nVb\nVc\nVd\nVe\nVf\nVg\nVh\n1 = red\n2 = blue\n3 = green\nVariables and Instantiation Order\nChecking back\nFind solution using\nBacktracking\nExample of a CSP\nC\nE\nD\nB\nF\nA\nG\nH\nVa\nVb\nVc\nVd\nVe\nVf\nVg\nVh\n1 = red\n2 = blue\n3 = green\nVariables and Instantiation Order\nChecking back\nExample of a CSP\n\nC\nE\nD\nB\nF\nA\nG\nH\nVa\nVb\nVc\nVd\nVe\nVf\nVg\nVh\n1 = red\n2 = blue\n3 = green\nVariables and Instantiation Order\nChecking back\nExample of a CSP\nC\nE\nD\nB\nF\nA\nG\nH\nVa\nVb\nVc\nVd\nVe\nVf\nVg\nVh\n1 = red\n2 = blue\n3 = green\nVariables and Instantiation Order\nChecking back\nExample of a CSP\n\nC\nE\nD\nB\nF\nA\nG\nH\nVa\nVb\nVc\nVd\nVe\nVf\nVg\nVh\n1 = red\n2 = blue\n3 = green\nVariables and Instantiation Order\nChecking back\nExample of a CSP\nC\nE\nD\nB\nF\nA\nG\nH\nVa\nVb\nVc\nVd\nVe\nVf\nVg\nVh\n1 = red\n2 = blue\n3 = green\nVariables and Instantiation Order\nChecking back\nFast forward ..\nExample of a CSP\n\nC\nE\nD\nB\nF\nA\nG\nH\nVa\nVb\nVc\nVd\nVe\nVf\nVg\nVh\n1 = red\n2 = blue\n3 = green\nVariables and Instantiation Order\nChecking back\nExample of a CSP\nC\nE\nD\nB\nF\nA\nG\nH\nVa\nVb\nVc\nVd\nVe\nVf\nVg\nVh\n1 = red\n2 = blue\n3 = green\nVariables and Instantiation Order\nChecking back\nExample of a CSP\n\nC\nE\nD\nB\nF\nA\nG\nH\nVa\nVb\nVc\nVd\nVe\nVf\nVg\nVh\n1 = red\n2 = blue\n3 = green\nVariables and Instantiation Order\nChecking back\nExample of a CSP\nC\nE\nD\nB\nF\nA\nG\nH\nVa\nVb\nVc\nVd\nVe\nVf\nVg\nVh\n1 = red\n2 = blue\n3 = green\nVariables and Instantiation Order\nChecking back\nExample of a CSP\n\nC\nE\nD\nB\nF\nA\nG\nH\nVa\nVb\nVc\nVd\nVe\nVf\nVg\nVh\n1 = red\n2 = blue\n3 = green\nVariables and Instantiation Order\nChecking back\nExample of a CSP\nC\nE\nD\nB\nF\nA\nG\nH\nVa\nVb\nVc\nVd\nVe\nVf\nVg\nVh\n1 = red\n2 = blue\n3 = green\nVariables and Instantiation Order\nChecking back\nWhy did it backtrack to E?\nThat was dumb!\nExample of a CSP\n\nC\nE\nD\nB\nF\nA\nG\nH\n1 = red\n2 = blue\n3 = green\nE1\nE2\nE3\nE4\nWhat would have happened if we had\nthe E* intermediate variables?\ni.e. it falls back on E4, then E3, towards E?\nExample of a CSP\nC\nE\nD\nB\nF\nA\nG\nH\nVa\nVb\nVc\nVd\nVe\nVf\nVg\nVh\n1 = red\n2 = blue\n3 = green\nVariables and Instantiation Order\nChecking back\nWhy did it backtrack to E?\nThat was dumb!\nWhats better and why?\nExample of a CSP\n\nC\nE\nD\nB\nF\nA\nG\nH\nVa\nVb\nVc\nVd\nVe\nVf\nVg\nVh\nWhy backtrack to D?\nD not F\nVariables and Instantiation Order\nChecking back\nExample of a CSP\nC\nE\nD\nB\nF\nA\nG\nH\nVa\nVb\nVc\nVd\nVe\nVf\nVg\nVh\nVariables and Instantiation Order\nChecking back\nWhy backtrack to D?\nD not F\nB not F\nExample of a CSP\n\nC\nE\nD\nB\nF\nA\nG\nH\nVa\nVb\nVc\nVd\nVe\nVf\nVg\nVh\nVariables and Instantiation Order\nChecking back\nWhy backtrack to D?\nD not F\nB not F\nC not F\nF or F or F\nnot D F\nnot B F\nnot C F\nnot D or not B or not C\nIts safe to remove the\ndeepest assignment.\nExample of a CSP\np\na\ns\nt\nf\nu\nt\nu\nr\ne\ncurrent variable\nv[i]\nconflict with v[h]\npast variable\nv[h]\nMove down like Backtrack Search:\n- Instantiate v[i] := x, for next x in D[i]\n- Check constraint (v[i],v[h]), if fails\n- say \"v[i] is in conflict with v[h]\"\n- add h to the set confSet[i]\nconfSet[i] denotes past\nvariables that conflict with\nvalues in the domain of v[i]\n{v[1] ... v[h] }\nMoving Forward:\n\nC\nE\nD\nB\nF\nA\nG\nH\nVa\nVb\nVc\nVd\nVe\nVf\nVg\nVh\nD not F\nVariables and Instantiation Order\nChecking back\nMoving Forward\nConfSet[F] = { }\nD,\nC\nE\nD\nB\nF\nA\nG\nH\nVa\nVb\nVc\nVd\nVe\nVf\nVg\nVh\nVariables and Instantiation Order\nChecking back\nD not F\nB not F\nMoving Forward\nConfSet[F] = { }\nD, B,\n\nC\nE\nD\nB\nF\nA\nG\nH\nVa\nVb\nVc\nVd\nVe\nVf\nVg\nVh\nVariables and Instantiation Order\nChecking back\nD not F\nB not F\nC not F\nMoving Forward\nConfSet[F] = { }\nD, B, C\n{4,1,0}\n{2,0}\nconflict sets\nBacking Up: Conflict-directed Back Jumping\nBacktrack when v[i] domain exhausted:\n- Jump to deepest var h in ConfSet[i].\n{0}\nPerson holding up a stop sign.\nImage by MIT OpenCourseWare.\n\n{2,1, ?}\n{4,1,0}\nBacking Up: Conflict-directed Back Jumping\nBacktrack when v[i] domain exhausted:\n- Jump to deepest var h in ConfSet[i].\n- Update ConfSet[h].\n{0}\n{2,1, ?}\n{4,1,0}\nAdd {1, 0} to confset[4]\nBacking Up: Conflict-directed Back Jumping\nBacktrack when v[i] domain exhausted:\n- Jump to deepest var h in ConfSet[i].\n- Update ConfSet[h] with ConfSet[i] / h.\n{0}\nPerson holding up a stop sign.\nImage by MIT OpenCourseWare.\nPerson holding up a stop sign.\nImage by MIT OpenCourseWare.\n\n{2,1, 0}\n{4,1,0}\nBacking Up: Conflict-directed Back Jumping\nBacktrack when v[i] domain exhausted:\n- Jump to deepest var h in ConfSet[i].\n- Update ConfSet[h] with ConfSet[i] / h.\n- Reset Domains, ConfSets below h.\n- Move forward: try next h assignments.\n{0}\nWhen jumping back from v[i] to v[h],\n1.\nUpdate conflict sets:\nconfSet[h] := confSet[h] confSet[i] \\ {h}\nconfSet[i] := {0}\n- This means:\nif we later jump back from v[h],\njump back to a variable that is\nin conflict with v[h] or with v[i].\n2.\nThrow away everything CBJ knows about v[i].\n3.\nReset all variables from v[h+1] to v[i] (i.e. domain and confSet)\nBacking Up: Conflict-directed Back Jumping\nPerson holding up a stop sign.\nImage by MIT OpenCourseWare.\n\nC\nE\nD\nB\nF\nA\nG\nH\nVa\nVb\nVc\nVd\nVe\nVf\nVg\nVh\nVariables and Instantiation Order\nChecking back\nD not F\nB not F\nC not F\nBacking Up\nConfSet[F] = { }\nD, B, C\n{ B, C}\n{2,1, 0}\nBacking Up: Conflict-directed Back Jumping\n{0}\nWhat do we do if variable 4s\ndomain is exhausted as well?\nPerson holding up a stop sign.\nImage by MIT OpenCourseWare.\n\n{2,1, 0}\nBacking Up: Conflict-directed Back Jumping\nBacktrack when v[h] domain exhausted:\n- Jump to deepest var g in ConfSet[h].\n- Update ConfSet[g] with ConfSet[h] / g.\n- Reset Domains, ConfSets below g.\n- Move forward: try next g assignments.\n{0}\nBacking Up: Conflict-directed Back Jumping\nBacktrack when v[h] domain exhausted:\n- Jump to deepest var g in ConfSet[h].\n- Update ConfSet[g] with ConfSet[h] / g.\n- Reset Domains, ConfSets below g.\n- Move forward: try next g assignments.\n{1, 0}\nPer\nson holding up a stop sign.\nImage by MIT OpenCourseWare.\nPerson holding up a stop sign.\nImage by MIT OpenCourseWare.\n\nIf there are no values remaining for v[i]\nJump back to v[h], the deepest variable in conflict with v[i].\nThe hope: re-instantiating v[h] will allow us to find a good value for v[i]\nIf there are no values remaining for v[h]\nJump back to v[g], the deepest variable in conflict with v[i] or v[h].\nThe hope: re-instantiating v[g] will allow us to find a good value for v[i] or a\ngood value for v[h] that will be good for v[i]\nIf there are no values remaining for v[g]\nJump back to v[f], the deepest variable in conflict with v[i] or v[h] or v[g]\nThe hope: re-instantiating v[f] will allow us to find a good value for v[i] or a\ngood value for v[h] that will be good for v[i] or a\ngood value for v[g] that will be good for v[h] and v[i]\nCBJ Supports Successive Jumps\nconsistent := false\nconfSet[i] := {0}\nfor x in domain[i] while not(consistent) // find a consistent value\nbegin\nconsistent := true\nv[i] := x\nfor h in (1 .. i-1) while consistent // check backwards\nbegin\nconsistent := (check(v[i],v[h])\nif not(consistent) then confSet[i] := confSet[i] {h}\nend\nif not(consistent)\nthen delete(x,domain[i])\nend\nCBJ: Prossers Original Formulation\n\nCBJ: Dechter Formulation\nConflict-directed Back Jumping:\nSupporting definitions\nPseudocode for conflict-directed backjumping\nremoved due to copyright restrictions.\nSupporting definitions (earlier constraint, earlier minimal\nconflict set, jumpback set) removed due to copyright restrictions.\n\nTo Solve CSP <X,D,C> We Combine:\n1.\nReasoning - Arc consistency via constraint propagation\n-\nEliminates values that are shown locally to not be a part\nof any solution.\n2.\nSearch\n-\nExplores consequences of committing to particular\nassignments.\nMethods That Incorporate Search:\n-\nStandard Search\n-\nBack Track Search (BT)\n-\nBT with Forward Checking (FC)\n-\nDynamic Variable Ordering (DV)\n-\nIterative Repair (IR)\n-\nConflict-directed Back Jumping (CBJ)\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "MIT16_410F10_lec07b.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/b886d40f6462310252d3787ea8880415_MIT16_410F10_lec07b.pdf",
      "content": "Activity Planning and Execution:\nIntroduction to Operator-based Planning\nBrian C. Williams\n16.410-13\nSeptember 29th, 2010\nSlides draw upon\nmaterial from:\nDr. David Smith,\nNASA Ames Research\nCenter\nAssignments\n- Remember:\n- Problem Set #3: Analysis and Constraint Programming,\ndue today Wednesday, Sept. 29th, 2010.\n- Problem Set #4: Constraint Satisfaction and Activity\nPlanning, out today, due Wednesday, October 6th, 2010.\n- Reading:\n- Today: Operator-based Planning [AIMA] Ch. 10.\nGraph Plan, by Blum & Furst.\n- Monday: Advanced Planning [AIMA] Ch. 11.\nBrian Williams, Fall 10\n\nMonitors\nAutonomous\nAgents\nCommand dispatch\nFault protection\nAttitude control\nMission Goal Scenario\nSelf-commanding\nSelf-diagnosing\nSelf-repairing\nRECOVERY\nPLANNING\nEXECUTION\nCommanded in terms of\n- Mission goals\n- Engineering goals\nOperator-based Planning\n- Input\n- Set of world states\n- Action operators\n- Fn: world-stateworld-state\n- Initial state of world\n- Goal\n- A partial state\n(set of world states)\na\na\na\nnorth11\nnorth12\nW0\nW2\nW1\nOutput\nSequence of actions that is\nComplete: Achieve goals\nConsistent: No negative\nside-effects\n\nOperators in STRIPS\nRepresentation\nTurn (?target):\nPre: Pointing(?direction),\n?direction ?target\nEff: ¬Pointing(?direction),\nPointing(?target)\nOutline\n- Example: DS1 and MER Mission-Planning\n- Overview of Operator-based Planning\n- Graph Plan\n\nOutline\n- Example: MER Mission Planning\n- Overview of Operator-based Planning\n- Graph Plan\nMars Rover slides removed due to copyright restrictions.\n\nPlanning\nFind:\nprogram of actions that achieves the objective\nPlanning\nFind:\nprogram of actions that achieves the objective\npartially-ordered set of actions\ngoals\ntypically unconditional\nno loops\n\nParadigms\nClassical planning\n(STRIPS, operator-based, first-principles)\ngenerative\nHierarchical Task Network planning\npractical planning\nMDP & POMDP planning\nplanning under uncertainty\nClassical Problem Statement\nOperators:\nGoals:\nGoal1\nGoal2\nGoal3\nOp\npre1\npre2\npre3\neff1\neff2\nInitial Conditions:\nP1\nP2\nP3\nP4\nPropositions:\nPi\n\nSimple Spacecraft Problem\nObservation-1\ntarget\ninstruments\nObservation-2\nObservation-3\nObservation-4\n...\ncalibrated\npointing\nPropositions:\nTarget Pointed To, Camera Calibrated?, Has Image?\nOperators:\nCalibrate, Turn to Y, and Take Image.\nExample\nIx\nIm\nc\npx\npC\nInit\nActions\nC\nc\nTy\n¬px\npy\npx\nIA\nGoal\npC\nPropositions:\nTarget Pointed To, Camera Calibrated?, Has Image?\nOperators:\nCalibrate, Turn to y, and Take Image.\nImage credit: NASA.\n\nBased on slides by Dave Smith, NASA Ames\nOperators in STRIPS\nRepresentation\nTakeImage (?target, ?instr):\nPre: Status(?instr, Calibrated),\nPointing(?target)\nEff: Image(?target)\n\nCalibrate (?instrument):\nPre: Status(?instr, On),\nCalibration-Target(?target),\nPointing(?target)\nEff: ¬Status(?inst, On),\nStatus(?instr, Calibrated)\n\nTurn (?target):\nPre: Pointing(?direction),\n?direction ?target\nEff: ¬Pointing(?direction),\nPointing(?target)\nBy convention,\nparameters start with\n?, as in ?var.\nBased on slides by Dave Smith, NASA Ames\nPlanning Domain Description\nLanguage (PDDL)\n(:action TakeImage :parameters (?target, ?instr)\n:precondition (and (Status ?instr Calibrated)\n\n(Pointing ?target))\n:effect\n(Image ?target))\n\n(:action Calibrate :parameters (?instrument)\n:precondition (and (Status ?instr On)\n\n(Calibration-Target ?target),\n\n(Pointing ?target)\n:effect\n(and (not (Status ?inst On))\n\n(Status ?instr Calibrated)))\n\n(:action Turn :parameters (?target)\n:precondition (and (Pointing ?direction)\n\n?direction ?target\n:effect\n(and (not (Pointing ?direction)\n\n(Pointing ?target)))\nBy convention,\nparameters start with\n?, as in ?var.\n\nPartial Order Plan\nIA\nF\npC\nS\nTA\n¬pC\nC\nIm\nc\npA\npC\nPlanning in the Past:\nPartial Order Causal Link Planning\n(SNLP, UCPOP)\n1. Select an open condition\n2. Choose an op that can achieve it\nLink to an existing instance or\nAdd a new instance\n3. Resolve threats\nIA\nF\nIm\nc\npA\nIA\nF\npC\nC\nIm\nIA\nF\nc\npA\nC\npC\nIm\nIA\nF\nc\npA\nS\nTA\n¬pC\nC\npC\nIm\nIA\nF\nc\npA\nS\npC\nIA\nF\npC\nS\nTA\n¬pC\nC\nIm\nc\npA\npC\nCurrent Planning: Graph-based Planners (Blum & Furst)\n\nWhat assumptions are implied by the\nSTRIPS representation?\nSTRIPS Assumptions:\n- Atomic time.\n- Agent is omniscient\n(no sensing necessary).\n- Agent is sole cause of\nchange.\n- Actions have deterministic\neffects.\n- No indirect effects.\nTakeImage (?target, ?instr):\nPre: Status(?instr, Calibrated),\nPointing(?target)\nEff:\nImage(?target)\n\nCalibrate (?instrument):\nPre: Status(?instr, On),\nCalibration-Target(?target),\nPointing(?target)\nEff: ¬Status(?inst, On),\nStatus(?instr, Calibrated)\n\nTurn (?target):\nPre: Pointing(?direction),\n?direction ?target\nEff: ¬Pointing(?direction),\nPointing(?target)\n\nBased on slides by Dave Smith, NASA Ames\nThe Simple Spacecraft Revisited:\nComplications\nObservation-1\npriority\ntime window\ntarget\ninstruments\nduration\nObservation-2\nObservation-3\nObservation-4\n...\nObjective:\nmaximize science return\nImage credit: NASA.\n\nBased on slides by Dave Smith, NASA Ames\nObservation-1\npriority\ntime window\ntarget\ninstruments\nduration\nObservation-2\nObservation-3\nObservation-4\n...\ncalibration\ntarget1\ntarget2\n...\nconsumables:\nfuel\npower\ndata storage\ncryogen\nangle between targets\nturn duration\nObjective:\nmaximize science return\nlinked\nThe Simple Spacecraft Revisited:\nComplications\nBased on slides by Dave Smith, NASA Ames\nMore Expressive Planners Include\nTime\nResources\nUtility\nUncertainty\nHidden State\nIndirect Control\nReasoning methods:\nSTNs or CSPs\nLPs or CSPs\nMDPs or MILPs\nHMMs or BNs\nHMMs or OCSPs\nLPs or RPs\nImage credit: NASA.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "MIT16_410F10_lec08a.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/6fe1bdbac2e836dd2cce4d11982a1e6b_MIT16_410F10_lec08a.pdf",
      "content": "Activity Planning and Execution I:\nOperator-based Planning and Plan Graphs\nBrian C. Williams\n16.410-13\nOctober 4th, 2010\nSlides draw upon\nmaterial from:\nProf. Maria Fox,\nUniv Strathclyde\nBrian Williams, Fall 10\nAssignments\n- Remember:\nProblem Set #5: Constraint Satisfaction and Activity Planning,\nout Wed. Sep. 29th , due Wed, Oct. 6th, 2010.\n- Reading:\n- Today: Advanced Planning [AIMA] Ch. 11;\nGraphPlan, by Blum & Furst.\n- Wednesday: Dechter, R., I. Meiri, J. Pearl, \"Temporal\nConstraint Networks,\" Artificial Intelligence, 49, pp.\n61-95,1991 posted on Stellar.\n- Exam:\n- Mid-Term - October 20th.\n\nSimple Spacecraft Problem\nObservation-1\ntarget\ninstruments\nObservation-2\nObservation-3\nObservation-4\n...\ncalibrated\npointing\nPropositions:\nTarget Pointed To, Camera Calibrated?, Has Image?\nOperators:\nCalibrate, Turn to Y, and Take Image.\nOutline\n- Graph Plan\n- Problem Statement\n- Planning Graph Construction\n- Plan Extraction\nImage credit: NASA.\n\nGraph Plan\n- Developed in 1995 by Avrim Blum and Merrick Furst, at CMU.\n- The Plan Graph compactly encodes all possible plans.\n- has been a key to scaling up to realistic problems.\n- Plan Graph representation used for:\n- An encoding method for formulating planning as a CSP.\n- Relaxed planning as an admissible heuristic (state space search + A*).\n- Approach has been extended to reason with temporally extended\nactions, metric and non-atomic preconditions and effects.\nApproach: Graph Plan\n1. Construct compact constraint encoding of state\nspace from operators and the initial state.\n- Planning Graph\n2. Generate plan by searching for a consistent\nsubgraph that achieves the goals.\nProposition\nInit State\nAction\nTime 1\nProposition\nTime 1\nAction\nTime 2\n\nRepresenting States\n- State\n- A consistent conjunction of propositions (positive literals).\n- E.g., (and (cleanhands) (quiet) (dinner) (present) (noGarbage))\n- All unspecified propositions are false.\n- Initial State\n- Problem state at time i = 0.\n- E.g., (and (cleanHands) (quiet)).\n- Goal State\n- A partial state.\n- E.g., (and (noGarbage) (dinner) (present)).\n- A Plan moves a system from its initial state to a final state\nthat extends the goal state.\nRepresenting Operators\n(:operator cook :precondition (cleanHands)\n:effect (dinner))\nPreconditions: Propositions that must be true to apply\nthe operator.\n- A conjunction of propositions (no negated propositions).\nEffects: Propositions that the operator changes,\ngiven that the preconditions are satisfied.\n- A conjunction of propositions (called adds) and\ntheir negation (called deletes).\n}\n\n(Parameterized) Operator Schemata\n- Instead of defining many operator instances:\npickup-A and pickup-B and ...\n- Define a schema:\n(:operator pick-up\n:parameters ((?ob1 - block))\n:precondition (and (clear ?ob1)\n(on-table ?ob1)\n(arm-empty))\n:effect (and (not (clear ?ob1))\n(not (on-table ?ob1))\n(not (arm-empty))\n(holding ?ob1)))\nExample Problem: Dinner Date\nInitial Conditions: (:init (cleanHands) (quiet))\nGoal:\n(:goal (noGarbage) (dinner) (present))\nActions:\n(:operator carry :precondition\n:effect (and (noGarbage) (not (cleanHands)))\n(:operator dolly\n:precondition\n:effect (and (noGarbage) (not (quiet)))\n(:operator cook\n:precondition (cleanHands)\n:effect (dinner))\n(:operator wrap\n:precondition (quiet)\n:effect (present))\n+ noops\nPlan: (Cook, Wrap, Carry)\n\nVisualizing Actions\n(:operator cook :precondition (cleanHands)\n:effect (dinner))\n(:operator carry :precondition\n:effect (and (noGarbage) (not (cleanHands)))\ncarry\nnoGarb\n\ncleanH\ncook\ndinner\ncleanHands\nVisualizing Actions\n- Persistence actions (No-ops)\n- Every literal has a no-op action,\nwhich maintains it from time i to i+1.\n(:operator noop-P :precondition (P) :effect (P))\nNoop-P\nP\nP\nIn Blum & Furst: (& lecture)\nOnly persist positive literals.\nAIMA:\nPersists negative literals as well.\neither approach okay for PSet.\n\nOperator Execution Semantics\nIf all propositions of :precondition appear in state i,\nThen create state i+1 from i, by\n- adding to i, all add propositions in :effects,\n- removing from i, all delete propositions\nin :effects.\n(:operator cook\n:precondition (cleanHands)\n:effect (dinner))\n(cleanHands)\n(quiet)\n(cleanHands)\n(quiet)\n(dinner)\ncook\nOperator Execution Semantics\nIf all propositions of :precondition appear in state i,\nThen create state i+1 from i, by\n- adding to i, all add propositions in :effects,\n- removing from i, all delete propositions\nin :effects.\n(:operator dolly\n:precondition\n:effect (and (noGarbage) (not (quiet)))\n(cleanHands)\n(quiet)\n(cleanHands)\n(noGarbage)\ndolly\n\ndinner\n\npresent\n\ncook\n\nwrap\n\ncarry\n\ncleanH\n\nquiet\nnoGarb\n\ncleanH\n\ndinner\n\npresent\n\nProp at 0 Action at 0 Prop at 1 Action at 1 Prop at 2\nnoop-dinner\nnoop-present\n- Sets of concurrent actions that are performed at each time [i]\n- Concurrent actions can be interleaved in any order.\nIf actions a and b occur at time i, then it must be valid to\nperform either a followed by b, OR b followed by a.\nRepresenting Plans: <Actions[i] >\nA Complete Consistent Plan\nGiven an initial state that holds at time 0, and goal propositions,\na plan is a solution iff it is:\nComplete:\n- The goal propositions all hold in the final state.\n-The preconditions of every operator at time i,\nare satisfied by propositions at time i.\nConsistent:\n\ndinner\n\npresent\n\ncook\n\nwrap\n\ncarry\n\ncleanH\n\nquiet\n\nnoGarb\n\ncleanH\n\ndinner\n\npresent\n\nProp at 0 Action at 0 Prop at 1 Action at 1 Prop at 2\n(noop dinner)\n(noop present)\nExample of a Complete Plan\nInitial Conditions: (and (cleanHands) (quiet))\nGoal:\n(and (noGarbage) (dinner) (present))\nA Complete Consistent Plan\nGiven an initial state that holds at time 0, and goal propositions,\na plan is a solution iff it is:\nComplete:\n- The goal propositions all hold in the final state.\n-The preconditions of every operator at time i,\nare satisfied by propositions at time i.\nConsistent:\n- The operators at any time i can be executed in any order,\nwithout one of these operators undoing:\n-the preconditions of another operator at time i.\n- the effects of another operator at time i.\n\ndinner\n\npresent\n\ncook\n\nwrap\n\ncarry\n\ncleanH\n\nquiet\n\nnoGarb\n\ncleanH\n\ndinner\n\npresent\n\nProp at 0 Action at 0 Prop at 1 Action at 1 Prop at 2\n(noop dinner)\n(noop present)\nExample of a\nComplete Consistent Plan\nInitial Conditions: (and (cleanHands) (quiet))\nGoal:\n(and (noGarbage) (dinner) (present))\n\ncook\n\nwrap\n\ncarry\n\ncleanH\n\nquiet\n\nnoGarb\n\ncleanH\n\ndinner\n\npresent\n\nProp at 0 Action at 0 Prop at 1 Action at 1 Prop at 2\n(noop dinner)\n(noop present)\nExample of a\nComplete Inconsistent Plan\nInitial Conditions: (and (cleanHands) (quiet))\nGoal:\n(and (noGarbage) (dinner) (present))\nnoGarb\n\ncleanH\n\ndinner\n\npresent\n\n(noop garb)\n(noop cleanH)\n\nOutline\n- Graph Plan\n- Problem Statement\n- Planning Graph Construction\n- Plan Extraction\nGraph Plan Algorithm\n- Phase 1 - Plan Graph Expansion\n- Graph includes all plans that are complete and consistent.\n- Graph prunes many infeasible plans.\n- Phase 2 - Solution Extraction\n- Graph frames a kind of constraint satisfaction problem (CSP).\n- Extraction selects actions to perform at each time point,\nby assigning variables and by testing consistency.\n\nExample: Planning Graph and Solution\nnoGarb\n\ncleanH\n\nquiet\n\ndinner\n\npresent\n\ncarry\n\ndolly\n\ncook\n\nwrap\n\ncarry\n\ndolly\n\ncook\n\nwrap\n\ncleanH\n\nquiet\n\nnoGarb\n\ncleanH\n\nquiet\n\ndinner\n\npresent\n\n0 Prop 0 Action 1 Prop 1 Action 2 Prop\nExample: Planning Graph and Solution\nnoGarb\n\ncleanH\n\nquiet\n\ndinner\n\npresent\n\ncarry\n\ndolly\n\ncook\n\nwrap\n\ncarry\n\ndolly\n\ncook\n\nwrap\n\ncleanH\n\nquiet\n\nnoGarb\n\ncleanH\n\nquiet\n\ndinner\n\npresent\n\n0 Prop 0 Action 1 Prop 1 Action 2 Prop\n\nGraph Plan Algorithm\n- Phase 1 - Plan Graph Expansion\n- Graph includes all plans that are complete and consistent.\n- Graph prunes many infeasible plans.\n- Phase 2 - Solution Extraction\n- Graph frames a kind of constraint satisfaction problem (CSP).\n- Extraction selects actions to perform at each time point,\nby assigning variables and by testing consistency.\n- Repeat Phases 1 and 2 for planning graphs with an\nincreasing numbers of action layers.\nPlanning Graphs Prune\nInitial state reachability:\nPrunes partial states and actions at each time\ni that are not reachable from the initial state,\nConsistency:\nPrunes pairs of propositions and actions\nthat are mutually inconsistent at time I, and\nGoal state reachability:\nplans that cannot reach the goals.\n\nGraph Properties\n- Plan graphs are constructed in polynomial\ntime and are of polynomial in size.\n- Plan graphs do not eliminate all infeasible\nplans.\nPlan generation requires focused search.\nConstructing the Planning Graph...\n(Reachability)\n- Initial proposition layer\n- Contains propositions that hold in the initial state.\n\nExample: Initial State, Layer 1\n\ncleanH\n\nquiet\n\n0 Prop 0 Action 1 Prop 1 Action 2 Prop\nConstructing the Planning Graph...\n(Reachability)\n- Initial proposition layer\n- Contains propositions that hold in the initial state.\n- Action layer i\n- If all of an actions preconditions appear in\nproposition layer i,\n- Then add action to layer i.\n- Proposition layer i+1\n- For each action at layer i,\n- Add all its effects at layer i+1.\n\nExample: Add Actions and Effects\nnoGarb\n\ncleanH\n\nquiet\n\ndinner\n\npresent\n\ncarry\n\ndolly\n\ncook\n\nwrap\n\ncleanH\n\nquiet\n\n0 Prop 0 Action 1 Prop 1 Action 2 Prop\nConstructing the Planning Graph...\n(Reachability)\n- Initial proposition layer\n- Contains propositions that hold in the initial state.\n- Action layer i\n- If all of an actions preconditions appear in\nproposition layer i,\n- Then add action to layer i.\n- Proposition layer i+1\n- For each action at layer i,\n- Add all its effects at layer i+1.\n- Repeat adding layers until all goal propositions appear.\n\nRound 1: Stop at Proposition Layer 1?\nnoGarb\n\ncleanH\n\nquiet\n\ndinner\n\npresent\n\ncarry\n\ndolly\n\ncook\n\nwrap\n\ncleanH\n\nquiet\n\n0 Prop 0 Action 1 Prop 1 Action 2 Prop\nDo all goal\npropositions\nappear?\nGoal: (and (noGarbage)\n(dinner)\n(present))\nConstructing the Planning Graph...\n(Consistency)\n- Initial proposition layer\n- Contains propositions that hold in the initial state.\n- Action layer i\n- If actions preconditions appear consistent in i [non-mutex],\n- Then add action to layer i.\n- Proposition layer i+1\n- For each action at layer i,\n- Add all its effects at layer i+1.\n- Identify mutual exclusions\n- Between actions in layer i, and\n- Between propositions in layer i + 1.\n- Repeat until all goal propositions appear non-mutex.\n\nMutual Exclusion: Actions\n- Actions A,B are mutually exclusive at level i\nif no valid plan could consistently contain both at i:\n- They have inconsistent effects.\n- A deletes Bs effects.\n- Effects interfere with preconditions.\n- A deletes Bs preconditions, or\n- vice-versa.\n- Their preconditions compete for needs.\n- A and B have inconsistent preconditions..\nMutual Exclusion: Actions\nnoGarb\n\ncleanH\n\nquiet\n\ndinner\n\npresent\n\ncarry\n\ndolly\n\ncook\n\nwrap\n\ncleanH\n\nquiet\n\n0 Prop 0 Action 1 Prop 1 Action 2 Prop\n1.\nInconsistent effects.\n2.\nEffect interferes\nwith precondition.\n3.\nCompeting needs.\n\nnoGarb\n\ncleanH\n\nquiet\n\ndinner\n\npresent\n\ncarry\n\ndolly\n\ncook\n\nwrap\n\ncleanH\n\nquiet\n\nMutual Exclusion: Actions\n0 Prop 0 Action 1 Prop 1 Action 2 Prop\n1.\nInconsistent effects.\n2.\nEffect interferes\nwith precondition.\n3.\nCompeting needs.\nnoGarb\n\ncleanH\n\nquiet\n\ndinner\n\npresent\n\ncarry\n\ndolly\n\ncook\n\nwrap\n\ncleanH\n\nquiet\n\nMutual Exclusion: Actions\n0 Prop 0 Action 1 Prop 1 Action 2 Prop\n1.\nInconsistent effects.\n2.\nEffect interferes\nwith precondition.\n3.\nCompeting needs.\n\nnoGarb\n\ncleanH\n\nquiet\n\ndinner\n\npresent\n\ncarry\n\ndolly\n\ncook\n\nwrap\n\ncleanH\n\nquiet\n\nMutual Exclusion: Actions\n0 Prop 0 Action 1 Prop 1 Action 2 Prop\n1.\nInconsistent effects.\n2.\nEffect interferes\nwith precondition.\n3.\nCompeting needs.\nLayer 1: Complete Action Mutexs\nnoGarb\n\ncleanH\n\nquiet\n\ndinner\n\npresent\n\ncarry\n\ndolly\n\ncook\n\nwrap\n\ncleanH\n\nquiet\n\n0 Prop 0 Action 1 Prop 1 Action 2 Prop\n1.\nInconsistent effects.\n2.\nEffect interferes\nwith precondition.\n3.\nCompeting needs.\n\nMutual Exclusion: Proposition Layer\nPropositions P,Q are inconsistent at i\n- if no valid plan could possibly contain both at i,\nif at i, all ways to achieve P exclude\neach way to achieve Q.\nP\n\nQ\nA1\n\nA2\nM\n\nN\nLayer 1: Add Proposition Mutexs\nnoGarb\n\ncleanH\n\nquiet\n\ndinner\n\npresent\n\ncarry\n\ndolly\n\ncook\n\nwrap\n\ncleanH\n\nquiet\n\n0 Prop 0 Action 1 Prop 1 Action 2 Prop\nDo all goal\npropositions\nappear non-mutex?\nNo proposition mutexs.\n\nRound 2: Extending The Planning Graph\nnoGarb\n\ncleanH\n\nquiet\n\ndinner\n\npresent\n\ncarry\n\ndolly\n\ncook\n\nwrap\n\ncarry\n\ndolly\n\ncook\n\nwrap\n\ncleanH\n\nquiet\n\nnoGarb\n\ncleanH\n\nquiet\n\ndinner\n\npresent\n\n0 Prop 0 Action 1 Prop 1 Action 2 Prop\nOutline\n- Graph Plan\n- Problem Statement\n- Planning Graph Construction\n- Plan Extraction\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "MIT6_046F05_lec02.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/d6c1bde6ba67532720e883dde4a79dcb_MIT6_046F05_lec02.pdf",
      "content": "September 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.1\nIntroduction to Algorithms\n6.046J/18.401J\nLECTURE 2\nAsymptotic Notation\n- O-, Ω-, and Θ-notation\nRecurrences\n- Substitution method\n- Iterating the recurrence\n- Recursion tree\n- Master method\nProf. Erik Demaine\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.2\nAsymptotic notation\nO-notation (upper bounds):\nWe write f(n) = O(g(n)) if there\nexist constants c > 0, n0 > 0 such\nthat 0 ≤f(n) ≤cg(n) for all n ≥n0.\nWe write f(n) = O(g(n)) if there\nexist constants c > 0, n0 > 0 such\nthat 0 ≤f(n) ≤cg(n) for all n ≥n0.\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.3\nAsymptotic notation\nO-notation (upper bounds):\nWe write f(n) = O(g(n)) if there\nexist constants c > 0, n0 > 0 such\nthat 0 ≤f(n) ≤cg(n) for all n ≥n0.\nWe write f(n) = O(g(n)) if there\nexist constants c > 0, n0 > 0 such\nthat 0 ≤f(n) ≤cg(n) for all n ≥n0.\nEXAMPLE: 2n2 = O(n3)\n(c = 1, n0 = 2)\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.4\nAsymptotic notation\nO-notation (upper bounds):\nWe write f(n) = O(g(n)) if there\nexist constants c > 0, n0 > 0 such\nthat 0 ≤f(n) ≤cg(n) for all n ≥n0.\nWe write f(n) = O(g(n)) if there\nexist constants c > 0, n0 > 0 such\nthat 0 ≤f(n) ≤cg(n) for all n ≥n0.\nEXAMPLE: 2n2 = O(n3)\n(c = 1, n0 = 2)\nfunctions,\nnot values\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.5\nAsymptotic notation\nO-notation (upper bounds):\nWe write f(n) = O(g(n)) if there\nexist constants c > 0, n0 > 0 such\nthat 0 ≤f(n) ≤cg(n) for all n ≥n0.\nWe write f(n) = O(g(n)) if there\nexist constants c > 0, n0 > 0 such\nthat 0 ≤f(n) ≤cg(n) for all n ≥n0.\nEXAMPLE: 2n2 = O(n3)\n(c = 1, n0 = 2)\nfunctions,\nnot values\nfunny, \"one-way\"\nequality\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.6\nSet definition of O-notation\nO(g(n)) = { f(n) : there exist constants\nc > 0, n0 > 0 such\nthat 0 ≤f(n) ≤cg(n)\nfor all n ≥n0 }\nO(g(n)) = { f(n) : there exist constants\nc > 0, n0 > 0 such\nthat 0 ≤f(n) ≤cg(n)\nfor all n ≥n0 }\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.7\nSet definition of O-notation\nO(g(n)) = { f(n) : there exist constants\nc > 0, n0 > 0 such\nthat 0 ≤f(n) ≤cg(n)\nfor all n ≥n0 }\nO(g(n)) = { f(n) : there exist constants\nc > 0, n0 > 0 such\nthat 0 ≤f(n) ≤cg(n)\nfor all n ≥n0 }\nEXAMPLE: 2n2 ∈O(n3)\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.8\nSet definition of O-notation\nO(g(n)) = { f(n) : there exist constants\nc > 0, n0 > 0 such\nthat 0 ≤f(n) ≤cg(n)\nfor all n ≥n0 }\nO(g(n)) = { f(n) : there exist constants\nc > 0, n0 > 0 such\nthat 0 ≤f(n) ≤cg(n)\nfor all n ≥n0 }\nEXAMPLE: 2n2 ∈O(n3)\n(Logicians: λn.2n2 ∈O(λn.n3), but it's\nconvenient to be sloppy, as long as we\nunderstand what's really going on.)\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.9\nMacro substitution\nConvention: A set in a formula represents\nan anonymous function in the set.\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.10\nMacro substitution\nConvention: A set in a formula represents\nan anonymous function in the set.\nf(n) = n3 + O(n2)\nmeans\nf(n) = n3 + h(n)\nfor some h(n) ∈O(n2) .\nEXAMPLE:\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.11\nMacro substitution\nConvention: A set in a formula represents\nan anonymous function in the set.\nn2 + O(n) = O(n2)\nmeans\nfor any f(n) ∈O(n):\nn2 + f(n) = h(n)\nfor some h(n) ∈O(n2) .\nEXAMPLE:\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.12\nΩ-notation (lower bounds)\nO-notation is an upper-bound notation. It\nmakes no sense to say f(n) is at least O(n2).\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.13\nΩ-notation (lower bounds)\nO-notation is an upper-bound notation. It\nmakes no sense to say f(n) is at least O(n2).\nΩ(g(n)) = { f(n) : there exist constants\nc > 0, n0 > 0 such\nthat 0 ≤cg(n) ≤f(n)\nfor all n ≥n0 }\nΩ(g(n)) = { f(n) : there exist constants\nc > 0, n0 > 0 such\nthat 0 ≤cg(n) ≤f(n)\nfor all n ≥n0 }\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.14\nΩ-notation (lower bounds)\nO-notation is an upper-bound notation. It\nmakes no sense to say f(n) is at least O(n2).\nΩ(g(n)) = { f(n) : there exist constants\nc > 0, n0 > 0 such\nthat 0 ≤cg(n) ≤f(n)\nfor all n ≥n0 }\nΩ(g(n)) = { f(n) : there exist constants\nc > 0, n0 > 0 such\nthat 0 ≤cg(n) ≤f(n)\nfor all n ≥n0 }\nEXAMPLE:\n(c = 1, n0 = 16)\n)\n(lgn\nn\nΩ\n=\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.15\nΘ-notation (tight bounds)\nΘ(g(n)) = O(g(n)) ∩Ω(g(n))\nΘ(g(n)) = O(g(n)) ∩Ω(g(n))\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.16\nΘ-notation (tight bounds)\nΘ(g(n)) = O(g(n)) ∩Ω(g(n))\nΘ(g(n)) = O(g(n)) ∩Ω(g(n))\n)\n(\nn\nn\nn\nΘ\n=\n-\nEXAMPLE:\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.17\nο-notation and ω-notation\nO-notation and Ω-notation are like ≤and ≥.\no-notation and ω-notation are like < and >.\nο(g(n)) = { f(n) : for any constant c > 0,\nthere is a constant n0 > 0\nsuch that 0 ≤f(n) < cg(n)\nfor all n ≥n0 }\nο(g(n)) = { f(n) : for any constant c > 0,\nthere is a constant n0 > 0\nsuch that 0 ≤f(n) < cg(n)\nfor all n ≥n0 }\nEXAMPLE:\n(n0 = 2/c)\n2n2 = o(n3)\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.18\nο-notation and ω-notation\nO-notation and Ω-notation are like ≤and ≥.\no-notation and ω-notation are like < and >.\nω(g(n)) = { f(n) : for any constant c > 0,\nthere is a constant n0 > 0\nsuch that 0 ≤cg(n) < f(n)\nfor all n ≥n0 }\nω(g(n)) = { f(n) : for any constant c > 0,\nthere is a constant n0 > 0\nsuch that 0 ≤cg(n) < f(n)\nfor all n ≥n0 }\nEXAMPLE:\n(n0 = 1+1/c)\n)\n(lgn\nn\nω\n=\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.19\nSolving recurrences\n- The analysis of merge sort from Lecture 1\nrequired us to solve a recurrence.\n- Recurrences are like solving integrals,\ndifferential equations, etc.\no Learn a few tricks.\n- Lecture 3: Applications of recurrences to\ndivide-and-conquer algorithms.\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.20\nSubstitution method\n1. Guess the form of the solution.\n2. Verify by induction.\n3. Solve for constants.\nThe most general method:\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.21\nSubstitution method\n1. Guess the form of the solution.\n2. Verify by induction.\n3. Solve for constants.\nThe most general method:\nEXAMPLE: T(n) = 4T(n/2) + n\n- [Assume that T(1) = Θ(1).]\n- Guess O(n3) . (Prove O and Ωseparately.)\n- Assume that T(k) ≤ck3 for k < n .\n- Prove T(n) ≤cn3 by induction.\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.22\nExample of substitution\n)\n)\n/\n((\n)\n/\n(\n)\n/\n(\n)\n/\n(\n)\n(\ncn\nn\nn\nc\ncn\nn\nn\nc\nn\nn\nc\nn\nn\nT\nn\nT\n≤\n-\n-\n=\n+\n=\n+\n≤\n+\n=\ndesired - residual\nwhenever (c/2)n3 - n ≥0, for example,\nif c ≥2 and n ≥1.\ndesired\nresidual\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.23\nExample (continued)\n- We must also handle the initial conditions,\nthat is, ground the induction with base\ncases.\n- Base: T(n) = Θ(1) for all n < n0, where n0\nis a suitable constant.\n- For 1 ≤n < n0, we have \"Θ(1)\" ≤cn3, if we\npick c big enough.\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.24\nExample (continued)\n- We must also handle the initial conditions,\nthat is, ground the induction with base\ncases.\n- Base: T(n) = Θ(1) for all n < n0, where n0\nis a suitable constant.\n- For 1 ≤n < n0, we have \"Θ(1)\" ≤cn3, if we\npick c big enough.\nThis bound is not tight!\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.25\nA tighter upper bound?\nWe shall prove that T(n) = O(n2).\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.26\nA tighter upper bound?\nWe shall prove that T(n) = O(n2).\nAssume that T(k) ≤ck2 for k < n:\n)\n(\n)\n/\n(\n)\n/\n(\n)\n(\nn\nO\nn\ncn\nn\nn\nc\nn\nn\nT\nn\nT\n=\n+\n=\n+\n≤\n+\n=\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.27\nA tighter upper bound?\nWe shall prove that T(n) = O(n2).\nAssume that T(k) ≤ck2 for k < n:\n)\n(\n)\n/\n(\n)\n/\n(\n)\n(\nn\nO\nn\ncn\nn\nn\nc\nn\nn\nT\nn\nT\n=\n+\n=\n+\n≤\n+\n=\nWrong! We must prove the I.H.\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.28\nA tighter upper bound?\nWe shall prove that T(n) = O(n2).\nAssume that T(k) ≤ck2 for k < n:\n)\n(\n)\n/\n(\n)\n/\n(\n)\n(\nn\nO\nn\ncn\nn\nn\nc\nn\nn\nT\nn\nT\n=\n+\n=\n+\n≤\n+\n=\nWrong! We must prove the I.H.\n)\n(\ncn\nn\ncn\n≤\n-\n-\n=\nfor no choice of c > 0. Lose!\n[ desired - residual ]\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.29\nA tighter upper bound!\nIDEA: Strengthen the inductive hypothesis.\n- Subtract a low-order term.\nInductive hypothesis: T(k) ≤c1k2 - c2k for k < n.\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.30\nA tighter upper bound!\nIDEA: Strengthen the inductive hypothesis.\n- Subtract a low-order term.\nInductive hypothesis: T(k) ≤c1k2 - c2k for k < n.\nT(n) = 4T(n/2) + n\n= 4(c1(n/2)2 - c2(n/2)) + n\n= c1n2 - 2c2n + n\n= c1n2 - c2n - (c2n - n)\n≤c1n2 - c2n if c2 ≥1.\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.31\nA tighter upper bound!\nIDEA: Strengthen the inductive hypothesis.\n- Subtract a low-order term.\nInductive hypothesis: T(k) ≤c1k2 - c2k for k < n.\nT(n) = 4T(n/2) + n\n= 4(c1(n/2)2 - c2(n/2)) + n\n= c1n2 - 2c2n + n\n= c1n2 - c2n - (c2n - n)\n≤c1n2 - c2n if c2 ≥1.\nPick c1 big enough to handle the initial conditions.\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.32\nRecursion-tree method\n- A recursion tree models the costs (time) of a\nrecursive execution of an algorithm.\n- The recursion-tree method can be unreliable,\njust like any method that uses ellipses (...).\n- The recursion-tree method promotes intuition,\nhowever.\n- The recursion tree method is good for\ngenerating guesses for the substitution method.\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.33\nExample of recursion tree\nSolve T(n) = T(n/4) + T(n/2) + n2:\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.34\nExample of recursion tree\nSolve T(n) = T(n/4) + T(n/2) + n2:\nT(n)\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.35\nExample of recursion tree\nSolve T(n) = T(n/4) + T(n/2) + n2:\nT(n/4)\nT(n/2)\nn2\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.36\nExample of recursion tree\nSolve T(n) = T(n/4) + T(n/2) + n2:\nn2\n(n/4)2\n(n/2)2\nT(n/16)\nT(n/8)\nT(n/8)\nT(n/4)\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.37\nExample of recursion tree\nSolve T(n) = T(n/4) + T(n/2) + n2:\nn2\n(n/16)2\n(n/8)2\n(n/8)2\n(n/4)2\n(n/4)2\n(n/2)2\nΘ(1)\n...\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.38\nExample of recursion tree\nSolve T(n) = T(n/4) + T(n/2) + n2:\nn2\nn\n(n/16)2\n(n/8)2\n(n/8)2\n(n/4)2\n(n/4)2\n(n/2)2\nΘ(1)\n...\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.39\nExample of recursion tree\nSolve T(n) = T(n/4) + T(n/2) + n2:\n(n/16)2\n(n/8)2\n(n/8)2\n(n/4)2\n(n/4)2\n(n/2)2\nΘ(1)\n...\n5 n\nn\nn2\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.40\nExample of recursion tree\nSolve T(n) = T(n/4) + T(n/2) + n2:\n(n/16)2\n(n/8)2\n(n/8)2\n(n/4)2\n(n/4)2\nΘ(1)\n...\n5 n\nn\n25 n\nn2\n(n/2)2\n...\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.41\nExample of recursion tree\nSolve T(n) = T(n/4) + T(n/2) + n2:\n(n/16)2\n(n/8)2\n(n/8)2\n(n/4)2\n(n/4)2\nΘ(1)\n...\n5 n\nn\n25 n\n( )\n( )\n(\n)\nL\n+\n+\n+\n+\nn\n= Θ(n2)\n...\nTotal =\nn2\n(n/2)2\ngeometric series\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.42\nThe master method\nThe master method applies to recurrences of\nthe form\nT(n) = aT(n/b) + f(n) ,\nwhere a ≥1, b > 1, and f is asymptotically\npositive.\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.43\nThree common cases\nCompare f(n) with nlogba:\n1. f(n) = O(nlogba - ε) for some constant ε > 0.\n- f(n) grows polynomially slower than nlogba\n(by an nε factor).\nSolution: T(n) = Θ(nlogba) .\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.44\nThree common cases\nCompare f(n) with nlogba:\n1. f(n) = O(nlogba - ε) for some constant ε > 0.\n- f(n) grows polynomially slower than nlogba\n(by an nε factor).\nSolution: T(n) = Θ(nlogba) .\n2. f(n) = Θ(nlogba lgkn) for some constant k ≥0.\n- f(n) and nlogba grow at similar rates.\nSolution: T(n) = Θ(nlogba lgk+1n) .\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.45\nThree common cases (cont.)\nCompare f(n) with nlogba:\n3. f(n) = Ω(nlogba + ε) for some constant ε > 0.\n- f(n) grows polynomially faster than nlogba (by\nan nε factor),\nand f(n) satisfies the regularity condition that\naf(n/b) ≤c f(n) for some constant c < 1.\nSolution: T(n) = Θ( f(n)) .\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.46\nExamples\nEX. T(n) = 4T(n/2) + n\na = 4, b = 2 ⇒nlogba = n2; f(n) = n.\nCASE 1: f(n) = O(n2 - ε) for ε = 1.\n∴T(n) = Θ(n2).\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.47\nExamples\nEX. T(n) = 4T(n/2) + n\na = 4, b = 2 ⇒nlogba = n2; f(n) = n.\nCASE 1: f(n) = O(n2 - ε) for ε = 1.\n∴T(n) = Θ(n2).\nEX. T(n) = 4T(n/2) + n2\na = 4, b = 2 ⇒nlogba = n2; f(n) = n2.\nCASE 2: f(n) = Θ(n2lg0n), that is, k = 0.\n∴T(n) = Θ(n2lgn).\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.48\nExamples\nEX. T(n) = 4T(n/2) + n3\na = 4, b = 2 ⇒nlogba = n2; f(n) = n3.\nCASE 3: f(n) = Ω(n2 + ε) for ε = 1\nand 4(n/2)3 ≤cn3 (reg. cond.) for c = 1/2.\n∴T(n) = Θ(n3).\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.49\nExamples\nEX. T(n) = 4T(n/2) + n3\na = 4, b = 2 ⇒nlogba = n2; f(n) = n3.\nCASE 3: f(n) = Ω(n2 + ε) for ε = 1\nand 4(n/2)3 ≤cn3 (reg. cond.) for c = 1/2.\n∴T(n) = Θ(n3).\nEX. T(n) = 4T(n/2) + n2/lgn\na = 4, b = 2 ⇒nlogba = n2; f(n) = n2/lgn.\nMaster method does not apply. In particular,\nfor every constant ε > 0, we have nε = ω(lgn).\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.50\nf(n/b)\nIdea of master theorem\nRecursion tree:\nf(n/b)\nf(n/b)\nΤ(1)\n...\n...\nf(n)\na\nf(n/b2)\nf(n/b2)\nf(n/b2)\n...\na\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.51\nf(n/b)\nIdea of master theorem\nRecursion tree:\nf(n/b)\nf(n/b)\nΤ(1)\n...\n...\nf(n)\na\nf(n/b2)\nf(n/b2)\nf(n/b2)\n...\na\nf(n)\naf(n/b)\na2f(n/b2)\n...\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.52\nf(n/b)\nIdea of master theorem\nf(n/b)\nf(n/b)\nΤ(1)\n...\nRecursion tree:\n...\nf(n)\na\nf(n/b2)\nf(n/b2)\nf(n/b2)\n...\na\nh = logbn\nf(n)\naf(n/b)\na2f(n/b2)\n...\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.53\nnlogbaΤ(1)\nf(n/b)\nIdea of master theorem\nf(n/b)\nf(n/b)\nΤ(1)\n...\nRecursion tree:\n...\nf(n)\na\nf(n/b2)\nf(n/b2)\nf(n/b2)\n...\na\nh = logbn\nf(n)\naf(n/b)\na2f(n/b2)\n#leaves = ah\n= alogbn\n= nlogba\n...\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.54\nf(n/b)\nIdea of master theorem\nRecursion tree:\nf(n/b)\nf(n/b)\nΤ(1)\n...\n...\nf(n)\na\nf(n/b2)\nf(n/b2)\nf(n/b2)\n...\na\nh = logbn\nf(n)\naf(n/b)\na2f(n/b2)\nCASE 1: The weight increases\ngeometrically from the root to the\nleaves. The leaves hold a constant\nfraction of the total weight.\nCASE 1: The weight increases\ngeometrically from the root to the\nleaves. The leaves hold a constant\nfraction of the total weight.\nΘ(nlogba)\nnlogbaΤ(1)\n...\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.55\nf(n/b)\nIdea of master theorem\nRecursion tree:\nf(n/b)\nf(n/b)\nΤ(1)\n...\n...\nf(n)\na\nf(n/b2)\nf(n/b2)\nf(n/b2)\n...\na\nh = logbn\nf(n)\naf(n/b)\na2f(n/b2)\nCASE 2: (k = 0) The weight\nis approximately the same on\neach of the logbn levels.\nCASE 2: (k = 0) The weight\nis approximately the same on\neach of the logbn levels.\nΘ(nlogbalgn)\nnlogbaΤ(1)\n...\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.56\nf(n/b)\nIdea of master theorem\nRecursion tree:\nf(n/b)\nf(n/b)\nΤ(1)\n...\n...\nf(n)\na\nf(n/b2)\nf(n/b2)\nf(n/b2)\n...\na\nh = logbn\nf(n)\naf(n/b)\na2f(n/b2)\n...\nCASE 3: The weight decreases\ngeometrically from the root to the\nleaves. The root holds a constant\nfraction of the total weight.\nCASE 3: The weight decreases\ngeometrically from the root to the\nleaves. The root holds a constant\nfraction of the total weight.\nnlogbaΤ(1)\nΘ(f(n))\n\nSeptember 12, 2005\nCopyright (c) 2001-5 Erik D. Demaine and Charles E. Leiserson\nL2.57\nAppendix: geometric series\n\nx\nx\nx\nx\nx\nn\nn\n-\n-\n=\n+\n+\n+\n+\n+\nL\nfor x =1\n\nx\nx\nx\n-\n=\n+\n+\n+\nL\nfor |x| < 1\nReturn to last\nslide viewed."
    },
    {
      "category": "Resource",
      "title": "MIT16_410F10_rec01.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/bb02e3225a65fe667d433de36de60fbb_MIT16_410F10_rec01.pdf",
      "content": "Principles of Autonomy &\nDecision Making\n16.410/16.413\nJava Tutorial\n\nUseful Reference\n- If you need to learn Java syntax:\n- Sun Java Tutorial\n- http://java.sun.com/docs/books/tutorial/\n- If you want to know about available packages:\n- http://java.sun.com/javase/6/docs/api/\n- You can find a link to these pages from the\ncourse website under \"Materials\"\n\nGraph\n- Directed Graph\n⎯ A directed graph or digraph G is an ordered pair G:= (V,\nE) with\n- V is a set, whose elements are called vertices or nodes,\n- E is a set of ordered pairs of vertices, called directed\nedges, arcs, or arrows.\n- Undirected Graph\n⎯ An undirected graph G is an ordered pair G:= (V, E) that\nis subject to the following conditions:\n- V is a set, whose elements are called vertices or nodes,\n- E is a set of pairs (unordered) of distinct vertices,\ncalled edges or lines. Simple graphs that look like a triangle. One is directed, and one is undirected.Simple graphs that look like a triangle. One is directed, and one is undirected.\nImage by MIT OpenCourseWare.\nImage by MIT OpenCourseWare.\n\nGraph as Adjacency Matrix\n\nfalse\ntrue\nfalse\nfalse\nfalse\ntrue\ntrue\nfalse\nfalse\n\nfalse\ntrue\ntrue\ntrue\nfalse\ntrue\ntrue\ntrue\nfalse\nS\ni\nm\nple graphs that look like a triangle. One is directed, and one is undirected. Vertices are labeled 0, 1, 2.\nS\ni\nm\nple graphs that look like a triangle. One is directed, and one is undirected. Vertices are labeled 0, 1, 2.\nImage by MIT OpenCourseWare.\nImage by MIT OpenCourseWare.\n\nLet's Begin Coding\n- Graph Class (i.e. Directed Graph)\n⎯Member Variables: Data stored in the object\n- protected boolean m_edges [][];\n⎯Constructors: How the object should be initialized\n- public Graph()\n- public Graph(int vertexCount);\n⎯Methods: Available operations on the object\n- public void addEdge(int from, int to)\n- public void deleteEdge(int from, int to)\n- public boolean isConnected(int from, int to)\n- public Set<Integer>getAdjacentVertices(int from)\n--\n\nDifference between\nDirected and Undirected\n- UndirectedGraph Class\n⎯ Member Variables: Data stored in the object\n- protected boolean m_edges[][];\n⎯ Constructors: How the object should be initialized\n- public Graph()\n- public Graph(int vertexCount)\n⎯ Methods: Available operations on the object\n- public void addEdge(int from, int to)\n- public void deleteEdge(int from, int to)\n- public boolean isConnected(int from, int to)\n- public Set<Integer> getAdjacentVertices(int from)\n--\n\nDifference between\nDirected and Undirected\n- UndirectedGraph Class\n⎯ Member Variables: Data stored in the object\n- protected boolean m_edges[][];\n⎯ Constructors: How the object should be initialized\n- public Graph()\n- public Graph(int vertexCount)\n⎯ Methods: Available operations on the object\n- public void addEdge(int from, int to)\n- public void deleteEdge(int from, int to)\n- public boolean isConnected(int from, int to)\n- public Set<Integer> getAdjacentVertices(int from)\n\nInheritance\n- Let UndirectedGraph inherit Graph\n⎯ Only implement the methods that are different.\n⎯ The undefined methods will be inherited from the Graph\nclass.\npublic class UndirectedGraph extends Graph {\npublic Graph(int vertexCount) {\n}\npublic void addEdge(int from, int to) {\n}\npublic void deleteEdge(int from, int to) {\n}\n}\n\nTest Cases\nWhat is adjacent to 2?\nWhat is adjacent to 2?\n⎯(5, 6)\n⎯(0, 5, 6)\nL\na\nr\ng\ne\nr\n\ngraphs arranged in a tree structure. One is directed, and one is undirected. Vertices are labeled 0-6.\nL\na\nr\nger graphs arran\ng\ne\nd\nin a tree structure. One is directed, and one is undirected. Vertices are labeled 0-6.\nImage by MIT OpenCourseWare.\nImage by MIT OpenCourseWare.\n\nWhat You Should Know\n- Basics of Programming\n- Basic Object Oriented Programming:\n⎯ Inheritance\n⎯ Abstract Class\n- Some methods may be specified, but not\nimplemented.\n⎯ Interface\n- Methods are specified, but not implemented.\n\nWhat You Should Know\n- Collections (i.e. Containers)\n⎯ Set <T>\n- Unordered collection of elements, without duplicates.\n⎯ List <T>\n- Ordered collection of elements.\n⎯ Queue <T>\n- Allow adding elements to the back and removing from\nthe front.\n⎯ Stack <T>\n- Allow pushing elements to the top and popping from\nthe top.\n- Templates\n⎯ Allows the user to specify the object type of the\nelements, e.g. Set<Integer> is a set of integers.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "MIT16_410F10_rec02_sol.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/7bdf8b0683264ac6a0d9041a647ed1a1_MIT16_410F10_rec02_sol.pdf",
      "content": "16.410-13 Recitation 2 Notes\nProblem 1: Complexity of Iterative Deepening Search\nRecall from the lecture notes that the (worst-case) running time of BFS was\nTbfs = 1 + b + b2 +\n+ bd + (bd+1 - b) = O(bd+1),\n· · ·\nwhere b is the branching factor and d is the depth of the goal in the search tree.\nIn iterative deepening search, we perform a depth-first search for each level. Thus the lower levels of the\ntree, i.e., those that are closer to the root, are visited more often. More precisely, the kth level of the tree is\nd + 1 - k times. (We denote the root note as the 0th level, the children to the root as the 1st level, and so\non.) Noting that the kth level has bk nodes, the worst-case running time of the iterative deepening search\ncan be written as\nTids\n=\n(d + 1) b0 + (d) b1 + (d - 1) b2 +\n+ (d + 1 - k) bk +\n+ (d + 1 - (d - 1)) bd-1 + (d + 1 - d) bd\n· · ·\n· · ·\n=\n(d + 1) + d b + (d - 1)b2 +\n+ 2 bd-1 + bd .\n(1)\n· · ·\nAlso, multiplying this equation by b, we obtain\nb Tids = (d + 1) b + d b2 + (d - 1) b3 +\n+ 2bd + bd+1\n(2)\n· · ·\nThen, subtracting (1) and (2) yields\n(b - 1) Tids = (d + 1) + b + b2 + b3 +\n+ bd + bd+1\n· · ·\nThe right hand side can be computed exactly using (finite) power series, i.e.,\nbd+2 + 1\n(b - 1) Tids = d +\nb - 1\nDividing both sides by b - 1,\nTids = bd+2d (b - 1) + 1 = O(bd).\n(b - 1)2\nHence, for large b, we see that the iterative-deepening search scales better than the breadth-first search.\n\nProblem 2: Analysis of Depth-first and Breadth-first Search\nFigure 1: Graph for Problem 1. Goal ver\ntex is marked with a double circle.\nConsider the graph given in Figure 1 and derive a precise ana\nlytical expression for the following both for depth-first and for\nbreadth-first search. In both cases, carry your analysis both\nwhen the algorithm is maintaining a visited list and when it\nis not. You should only provide upper and lower bounds for\nbreath-first search without a visited vertices list.\ni. the number of paths that are examined,\nii. the largest number of paths that will be under considera\ntion at any given time,\niii. the length of the path returned.\nSolution to Problem 1\nSolution for depth-first search with no visited nodes list\nNote that the depth-first search algorithm will place all the de\nscendents of the node to the queue and expand the left-most\nnode. In Figure 2(a), all the nodes that are expanded by the\nalgorithm are shown. The nodes that are in the queue are shown\nin blue.\nThe number of vertices visited is 3N + 3.\n-\n- The largest number paths that will be in the queue is\n2N + 3.\n- The path returned looks as follows:\n(0, 1, 3, 4, 6, 7, · · · , 3(N - 1), 3(N - 1) + 1, 3N, 3N + 2).\nThe length of this path is 2N + 1.\nSolution for depth-first search with visited nodes list\nThe paths that are in the queue are labeled in Figure 2(b). For\nthe depth-first search the following results are obtained:\nThe number of vertices visited is 3N + 3.\n-\n- The largest number of paths in the queue is N + 3.\n- The path returned looks as follows:\n(0, 3, 6, 9, . . . , 3N, 3N + 2)\nHence the length of the path is N + 2 (i.e., the shortest\npath).\n\nSolution for the breadth-first search with visited nodes list\nThe number of vertices visited is 3N + 3.\n-\n- The largest number of paths in the queue is 3.\n- The path returned looks as follows:\n(0, 3, 6, 9, . . . , 3N, 3N + 2)\nHence the length of the path is N + 2 (i.e., the shortest path).\nSolution for the breadth-first search without visited nodes list\n- The number of vertices visited is Θ(2N ).\n- The largest number of paths in the queue is Θ(2N ).\n- The path returned looks as follows:\n(0, 3, 6, 9, . . . , 3N, 3N + 2)\nHence the length of the path is N + 2 (i.e., the shortest path).\n(a)\n(b)\nFigure 2:\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "MIT16_410F10_rec02.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/8fa89372917a3aea8db9b9f3c2fb8997_MIT16_410F10_rec02.pdf",
      "content": "16.410-13 Recitation 2 Problems\nProblem 1: Complexity of Iterative Deepening Search\nAnalyze the complexity of iterative deepening search. Compare your result to the complexity of breadth-first\nsearch. Which one is better? Explain your conclusions.\nProblem 2: Analysis of Depth-first and Breadth-first Search\nConsider the graph given in Figure 1 and derive a precise ana\nlytical expression for the following both for depth-first and for\nbreadth-first search. In both cases, carry out your analysis both\nwhen the algorithm is maintaining a visited list and when it\nis not. You should only provide upper and lower bounds for\nbreath-first search without a visited vertices list.\ni. the number of paths that are examined (time complexity),\nii. the largest number of paths that will be under considera\ntion at any given time, (i.e., queue size) (space complexity),\niii. the length of the path returned (quality of the solution).\nFigure 1: Graph for Problem 1. Goal ver\ntex is marked with a double circle.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "MIT16_410F10_rec03_sol.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/6727843badb0448089e0515a6ff60655_MIT16_410F10_rec03_sol.pdf",
      "content": "16.410-13 Recitation 3 Problems\nProblem 1: Soundness of Arc Consistency Algorithms\nProve that AC-1 algorithm is sound, i.e., the solution returned by the algorithm is indeed an arc consistent\nnetwork.\nSolution The AC-1 algorithm is formalized below.\nAlgorithm 1: REVISE(hxi, xj i)\nDELETED\nFALSE;\n←\nfor each ai ∈ Di do\nif there is no aj ∈ Dj such that hai, aj i ∈ Rij then\nDelete ai from Di;\nDELETED\nTRUE;\n←\nreturn DELETED\nAlgorithm 2: AC - 1\nQ ← {hxi, xj i | hxi, xj i ∈ Arcs};\nrepeat\nCHANGE\nFALSE;\n←\nfor each hxi, xj i ∈ Q do\nif REVISE(hxi, xj i) = TRUE then\nCHANGE\nTRUE;\n←\nuntil CHANGE = FALSE;\nWe prove by contradiction. Observe that when the algorithm terminates, the variable CHANGE is set\nto false, which means that the REVISE operation returned false for each hxi, xj i ∈ Q. To arrive at a\ncontradiction, assume that there exists some arc that is not consistent, i.e., there exists some ai ∈ Di for\nwhich there is no aj such that hai, aj i ∈ Ri,j . But in this case, the REVISE operation must have deleted this\narc and returned true, when called with hxi, xj i, which contradicts our earlier observation.\n\nProblem 2: Modeling using Constraints\nCrossword puzzles can be modeled as constraint satisfaction problems. The task is to assign words from\nthe dictionary into vertical and horizontal slots according to certain constraints. The dictionary is given as\nfollows.\n{HOSES, LASER, SHEET, SNAIL, ST EER, ALSO, EARN, HIKE,\nIRON, SAME, EAT, LET, RUN, SUN, TEN, Y ES, BE, IT, NO, US}\nThe crossword puzzle is provided in the figure below. First, consider a formulation in which each blank\nsquare is a variable. Write down the domains and the constraints. Second, consider a formulation where\neach starting point for a word (either vertical or horizontal) is a variable. Write the domains and the\nconstraints.\nSolution When each blank square is a variable, we have 13 variables, which we denote by {x1, x2, . . . , x13}.\nEach variable may take values from the alphabet A = {A, B, C, . . . , X, Y, Z}. Thus, the domain of each\nvariable is Di = A for all i ∈{1, 2, . . . , 13}. Formulating the constraints, in this case, can be carried out by\nconsidering the left-to-right and top-to-bottom words in the crossword puzzle. For instance, the variables\nx1, x2, x3, x4, and x5 are constrained so that\nhx1, x2, x3, x4, x5i ∈{HOSES, LASER, SHEET, SNAIL, STEER}\nSimilarly, for instance, the variables x3, x6, x9, x12 are constrained as follows\nhx3, x6, x9, x12i ∈{ALSO, EARN, HIKE, IRON, SAME}.\nIn this way, the constraints for variables hx5, x7, x11i, hx8, x9, x10, x11i, hx5, x7, x11i, and hx10, x11i can be\nconstructed.\nIn the second formulation, we have six starting points, namely starting from 1 to left, from 3 to bottom,\nfrom 5 to bottom, from 8 to left, from 10 to bottom, and from 12 to left. Let us denote these variables by\nx1, x3, x5, x8, x10, and x12. Their domains, denoted by D1, D3, D5, D8, D10, D12, respectively, depend on\nthe number of letters that they are formed by. That is, for five-letter words,\nD1 ∈{HOSES, LASER, SHEET, SNAIL, STEER},\nfor four-letter words\nD3 = D8 = {ALSO, EARN, HIKE, IRON, SAME},\nfor three-letter words,\nD5 = {EAT, LET, RUN, SUN, TEN, YES},\nand finally for two-letter words,\nD10 = D12 = {BE, IT, NO, US}.\n\nThe constraints, in this case, depend on the relationship between each pair of variables as they share certain\nletters. For instance, take variables x1 and x3. Clearly, the third letter of x1 must be the same as the first\nletter of x3, which induces the following constraint\nhx1, x3i ∈ {hHOSES, SAMEi, hLASER, SAMEi, hSHEET, EARNi, hSNAIL, ALSOi, hSTEER, EARNi}.\nSimilarly, the constraints between other variables that share certain letters can be extracted in this way.\nNotice that in the first formulation we had to use constraints that involve more than two variables,\nwhereas the second formulation involves only binary constraints (constraints with two variables).\n\nProblem 3: Arc consistency\nConsider the network given in the figure below. Each node labeled via A, B, C, D, E, F, G, and H take\nvalues in {1, 2, 3, 4}. Find an equivalent arc consistent network (using the AC-1 and AC-3 algorithms).\nSolution We provide a partial solution using the AC-1 algorithm and leave the solution using AC-3 algo\nrithm as an exercise. The AC-1 algorithm is described in Algorithms 1 and 2 (see the solution to Problem\n1). Roughly speaking, the algorithm tests each arc for inconsistency and removes any inconsistent values\nfrom the domains of the variables; if a value is removed then the algorithm repeats this procedure until no\nassignments are removed.\nIn this case, we have 12 arcs, namely\nhA, Bi, hA, Gi, hA, Hi, hB, Ci, hB, Di, hC, Ei, hC, F i, hC, Gi, hD, Ei, hE, F i, hF, Gi, hG, Hi .\nThe AC-1 algorithm, in its first iteration, goes through every arc to identify inconsistent assignments. That\nis, first it considers the arc hA, Bi and runs REVISE(hA, Bi). This procedure immediately identifies that the\nvalue 4 ∈ DA = {1, 2, 3, 4} is indeed inconsistent, i.e., there is no other value d ∈ DB = {1, 2, 3, 4} such that\n4 < d is satisfied. Hence, the REVISE procedure removes the value 4 from the domain of variable A, and\nreturns TRUE. The new domain of variable A is set to DA ←{1, 2, 3}. The algorithm, then, considers the\narc (A, H). Notice tat in this case all variables in the domain of A are indeed consistent. So, no variable is\nremoved. The algorithm examines the remaining arcs in this manner. Since the examination of the first arc\nby the REVISE procedure returned true. The AC-1 algorithm reexamines all the arcs in the next iteration.\nThis is continued until no value is removed from a domain.\nYou are strongly encouraged to complete this exercise for both the AC-1 algorithm and the AC-3 to\nbetter understand how the two algorithms work, and how they differ. Notice that the AC-3 algorithm does\nthe same work using significantly less computation time.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "MIT16_410F10_rec03.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/acf7ec080873ac77e4eef559d0d12c71_MIT16_410F10_rec03.pdf",
      "content": "16.410-13 Recitation 3 Problems\nProblem 1: Soundness of Arc Consistency Algorithms\nProve that AC-1 algorithm is sound, i.e., the solution returned by the algorithm is indeed an arc consistent\nnetwork.\nProblem 2: Modeling using Constraints\nCrossword puzzles can be modeled as constraint satisfaction problems. The task is to assign words from\nthe dictionary into vertical and horizontal slots according to certain constraints. The dictionary is given as\nfollows.\n{HOSES, LASER, SHEET, SNAIL, STEER, ALSO, EARN, HIKE,\nIRON, SAME, EAT, LET, RUN, SUN, TEN, Y ES, BE, IT, NO, US}\nThe crossword puzzle is provided in the figure below. First, consider a formulation in which each blank\nsquare is a variable. Write down the domains and the constraints. Second, consider a formulation where\neach starting point for a word (either vertical or horizontal) is a variable. Write the domains and the\nconstraints.\nProblem 3: Arc consistency\nConsider the network given in the figure below. Each node labeled via A, B, C, D, E, F, G, and H take values\nin {1, 2, 3, 4}. Find an equivalent arc consistent network (practice using the AC-1 and AC-3 algorithms).\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "MIT16_410F10_rec04_sol.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/021aa39e2d090fbe67fdc894d1f2d8b7_MIT16_410F10_rec04_sol.pdf",
      "content": "16.410-13 Recitation 4 Problems\nProblem 1: Backtracking and Forward-checking\nConsider the following coloring problem.\nDraw the search tree of the backtracking algorithm and number the nodes according to their order of\nexpansion until the algorithm finds a feasible assignment that solves the constraint satisfaction problem. The\nalgorithm picks the colors according to the following order: blue, green, red, teal.Assume that the algorithm\ntraces the variables according to the following order: x1, x2, x3, x4, x5, x6, x7.\nSolution: The tree that backtracking would explore is given in the following figure. The tracing order\nuntil a solution is found is indicated with numbers on the nodes. The square nodes indicate the case when\nthe algorithm gets stuck, circle nodes indicate the cases when the algorithm can continue search or has found\na solution (the leaves).\n\nAssume that the algorithm uses the following order for picking variables: x1, x7, x4, x5, x6, x3, x2. How\nwould your answer change?\nSolution: The solution for this case is provided in the following figure.\nConsider the case when the algorithm also does forward checking and assume that the algorithm is tracing\nthe variables according to the first order, i.e., x1, x2, x3, x4, x5, x6, x7. At some point during search, the\nalgorithm assigns x1 = red, x2 = blue, and x3 = blue. How would the forward checking algorithm change the\nrest of the search? Indicate which values are eliminated from the domains of other variables in each step.\nIndicate the part of the rest of the tree that the algorithm does not have search due to forward checking.\nSolution: The assignment is depicted in the following figure. The inconsistencies detected using forward-\nchecking are indicated with white boxes. The part of the tree that is not explored due to forward-checking\nis also shown in the figure.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "MIT16_410F10_rec04.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/2faafccf5132f01be30e4e296b5b1600_MIT16_410F10_rec04.pdf",
      "content": "16.410-13 Recitation 4 Problems\nProblem 1: Backtracking and Forward-checking\nConsider the following coloring problem.\nDraw the search tree of the backtracking algorithm and number the nodes according to their order of\nexpansion until the algorithm finds a feasible assignment that solves the constraint satisfaction problem. The\nalgorithm picks the colors according to the following order: blue, green, red, teal.Assume that the algorithm\ntraces the variables according to the following order: x1, x2, x3, x4, x5, x6, x7.\nAssume that the algorithm uses the following order for picking variables: x1, x7, x4, x5, x6, x3, x2. How\nwould your answer change?\nConsider the case when the algorithm also does forward checking and assume that the algorithm is tracing\nthe variables according to the first order, i.e., x1, x2, x3, x4, x5, x6, x7. At some point during search, the\nalgorithm assigns x1 = red, x2 = blue, and x3 = blue. How would the forward checking algorithm change\nthe rest of the search? Indicate which values are eliminated from the domains of other variables in each step.\nIndicate the part of the rest of the tree that the algorithm does not have search due to forward checking.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "MIT16_410F10_rec05_sol.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/fdc52ebe1b6b370b1143add0fcd641c1_MIT16_410F10_rec05_sol.pdf",
      "content": "16.410-13 Recitation 5 Problems\nProblem 1: PDDL example\nWe car that has a flat tire. We are in the following situation.\nThe car has its flat tire on the axle.\n-\nThere is a spare tire in the trunk.\n-\nThe driver can remove any tire from any place (i.e., either axle or trunk) and put it on the ground.\n-\nThe driver can put any tire that is on the ground to any place that is empty.\n-\nFormulate this problem in PDDL and draw the corresponding plan graph.\nSolution: First let us define two predicates, namely AT and Empty. The predicate AT takes two parameters\ndenoted by x and y, where x is a tire type (e.g., flat or spare) and y is a place (e.g., trunk or axle); if AT\nx y is true, then x is at y. For instance, if x = flat and y = trunk, then AT x y is true whenever the flat\ntire is inside the trunk. The predicate Empty takes one parameter denoted by x, which in this case is a place\nsuch as the axle or the trunk. If Empty x is true, then x is empty. For instance, if x = axle, then Empty x\nindicates that the axle is empty, i.e., there is no tire on the axle. In PDDL, these predicates can be written\nas follows:\n(:predicates (AT ?x ?y)\n(EMPTY ?x))\nNext, let us consider the actions available to us in fixing our car. Let us define two actions, namely\nRemove and Put. Remove action takes three parameters: tire, place, and ground. The action is tailored\nto remove the tire from its place and put the tire on the ground. Hence, a precondition is that the tire\nmust be at the place. The effect, on the other hand, is threefold: (i) the tire is not at the place anymore,\n(ii) the tire is on the ground, and (iii) the place becomes empty (does not have a tire on it). This action\ncan be represented in PDDL as follows:\n(:action Remove :parameters (?tire ?place ?ground)\n:precondition (AT ?tire ?place))\n:effect\n(and (not (AT ?tire ?place))\n(AT ?tire ?ground)\n(EMPTY ?place))\nThe Put action also takes the same three parameters, namely tire, place, and ground. This time,\nhowever, the action will take the tire off of the ground, and put it on the place. Note that the preconditions\nthat need to be satisfied are: (i) the tire has to be on the ground and (ii) place has to be empty. The\neffects are again threefold: (i) the tire is not on the ground anymore, (ii) the tire is at the place, and\n(iii) the place is not empty. Following is a PDDL description of this action.\n\n(:action Put :parameters (?tire ?place ?ground)\n:precondition (and (AT ?tire ?ground))\n(EMPTY ?place)\n:effect\n(and (not (AT ?tire ?ground))\n(AT ?tire ?place)\n(not (EMPTY ?place)))\nIn this problem, we have five objects in total. Two of the objects are the tires, namely flat and spare.\nTwo others are the places, namely axle and trunk. The final object is ground. The PDDL description of\nthis will be:\n(:objects flat space axle trunk ground)\nThe initial condition is that the flat tire is on the axle, whereas the spare tire is in the trunk. The\nPDDL form of this is:\n(:init (AT flat axle)\n(AT spare trunk))\nThe goal is to have the spare tire on the axle.\n(:goal (AT spare axle)\nProblem 2: More PDDL\nSuppose you have a robot that moves in a house with several rooms and can pickup balls and put them down.\nMore precisely, the robot has three actions: Navigate from one room to another, Pickup a certain ball from\na certain room, and Putdown a certain ball to a certain room. Your robot can carry several balls all at once.\nModel this problem using PDDL. Write down the predicates and the actions.\nAssume that the house has a bedroom and a kitchen. Assume also that there is only one ball called the\nblueball. Initially, the blueball is in the bedroom. The robot starts in the kitchen. The goal is to take\nthe blueball to the kitchen. Write down your objects, initial condition, and goal condition in PDDL.\nSolution: The corresponding PDDL specification is given below. Note that there are three predicates.\nThe predicate IN takes two parameters ?ball and ?room. The predicate IN(?ball, ?room) is true if the\nball indicated by ?ball is in room indicated by ?room. The predicate AT takes on parameter, ?room. If\nAT(?room) is true, then the robot is at room indicated by ?room. Finally, the predicate HAS takes one\nparameter, ?ball. If HAS(?ball) is true, then the robot has the ball indicated by ?ball.\nThree actions are defined. The Navigate action takes two parameters: ?roomfrom and ?roomto. By\nexecuting Navigate(?roomfrom, ?roomto) the robot moves from the room indicated by ?roomfrom to the\nroom indicated by ?roomto. Notice that the precondition ensures that the robot is currently at ?roomfrom\nand not ?roomto. The Pickup action takes two parameters, namely ?ball and ?room. By executing the\naction Pickup(?ball, ?room), the robot picks up the ?ball in ?room. Of course, the robot has to be at\nthe ?room to pickup the ?ball. Moreover, ?ball has to be in the ?room. The action Putdown reverses the\naction Pickup. It takes the same parameters, but by executing Putdown (?ball, ?room), the robot puts\nthe ?ball into the ?room. Again, the robot has to be at the ?room to execute this action and have the ball.\n\n(:predicates (IN ?ball ?room)\n(AT ?room)\n(HAS ?ball)\n(:action Navigate :parameters (?roomfrom ?roomto)\n:precondition (and (AT ?roomfrom)\n(not (AT ?roomto)))\n:effect\n(and (not (AT ?roomfrom))\n(AT ?roomto)))\n(:action Pickup :parameters (?ball ?room)\n:precondition (and (AT ?room)\n(not (HAS ?ball))\n(IN ?ball ?room))\n:effect\n(and (HAS ?ball)\n(not (IN ?ball ?room))))\n(:action Putdown :parameters (?ball ?room)\n:precondition (and (AT ?room)\n(HAS ?ball))\n:effect\n(and (not (HAS ?ball))\n(IN ?ball ?room)))\nExtra exercise: You must have noticed that some of the conditions on the pre\nconditions and effects include some redundancies. Can you point those out? That\nis, give a PDDL description of the actions with fewer clauses.\nThe list of objects along with the initial conditions and goal specification are given below.\n(:objects blueball kitchen bedroom)\n(:init (IN blueball bedroom)\n(AT kitchen))\n(:goal (IN ?blueball ?kitchen)\nExtra exercise: Try to add more balls and rooms into the house. What if the\nhouse had a certain topology. That is only certain rooms are connected to one\nanother directly. To navigate from one room to another you need to go through\na different room. For example, imagine having an entrance which is connected to\na hallway. Then the hallway is connected to three bedrooms. Inside one of these\nbedrooms there is a bathroom. So, if you would like to go from entrance to the\nbathroom. You need to be in four different rooms sequentially, i.e., (i) start with\nthe entrance, (ii) go through the hallway, (iii) go through the bedroom with the\nbathroom, and (iv) go inside the bathroom. But there is no direct passage from the\nentrance to the bathroom. And assume that your robot can pick up or put down\nballs along the way. For instance, you can pick a ball up from the hallway as you\nare going through the hallway. How would you model such a problem in PDDL?\nWhat would be difference?\n\nProblem 3: Planning graphs - baking the cake\nConsider the following PDLL specification. Draw the corresponding plangraph until it levels off, i.e., reaches\na fixed point. Indicate the mutexes.\n(:predicates (AT ?ball ?room)\n(IN ?room)\n(:action Eat :parameters (?cake)\n:precondition (HAVE ?cake)\n:effect\n(and (not (HAVE ?cake))\n(EATEN ?cake)))\n(:action Bake :parameters (?cake)\n:precondition (not (HAVE ?cake))\n:effect\n(HAVE ?cake))\n(:objects cake)\n(:init (HAVE cake))\n(:goal (and (HAVE ?cake)\n(EATEN ?cake)))\nSolution: The resulting plan graph is shown in the figure below.\n\nProblem 4: More planning graphs - Robot navigation\nRecall the PDDL specification you had worked with in Problem 2. Draw the first two levels of the correspond\ning plan graph. Explain the execution of the GRAPHPLAN algorithm on the first two layers.\nSolution: First two layers of the corresponding planning graph is shown below.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "MIT16_410F10_rec05.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/50dfb1a3fb7974367c0d03c8c77a050c_MIT16_410F10_rec05.pdf",
      "content": "16.410-13 Recitation 5 Problems\nProblem 1: PDDL example\nWe car that has a flat tire. We are in the following situation.\nThe car has its flat tire on the axle.\n-\n- There is a spare tire in the trunk.\n- The driver can remove any tire from any place (i.e., either axle or trunk) and put it on the ground.\n- The driver can put any tire that is on the ground to any place that is empty.\nFormulate this problem in PDDL and draw the corresponding plan graph.\nProblem 2: More PDDL\nSuppose you have a robot that moves in a house with several rooms and can pickup balls and put them\ndown. More precisely, the robot has three actions: Navigate from one room to another, Pickup a certain\nball from a certain room, and Putdown a certain ball to a certain room. Your robot can carry several balls\nall at once. Model this problem using PDDL. Write down the predicates and the actions.\nAssume that the house has a bedroom and a kitchen. Assume also that there is only one ball called the\nblueball. Initially, the blueball is in the bedroom. The robot starts in the kitchen. The goal is to take\nthe blueball to the kitchen. Write down your objects, initial condition, and goal condition in PDDL.\n\nProblem 3: Planning graphs - baking the cake\nConsider the following PDLL specification. Draw the corresponding plangraph until it levels off, i.e., reaches\na fixed point. Indicate the mutexes.\n(:predicates (AT ?ball ?room)\n(IN ?room)\n(:action Eat :parameters (?cake)\n:precondition (HAVE ?cake)\n:effect\n(and (not (HAVE ?cake))\n(EATEN ?cake)))\n(:action Bake :parameters (?cake)\n:precondition (not (HAVE ?cake))\n:effect\n(HAVE ?cake))\n(:objects cake)\n(:init (HAVE cake))\n(:goal (and (HAVE ?cake)\n(EATEN ?cake)))\nProblem 4: More planning graphs - Robot navigation\nRecall the PDDL specification you had worked with in Problem 2. Draw the first two levels of the corre\nsponding plan graph. Explain the execution of the GRAPHPLAN algorithm on the first two layers.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n16.410 / 16.413 Principles of Autonomy and Decision Making\nFall 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    }
  ]
}